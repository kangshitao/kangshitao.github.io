{"meta":{"title":"Live And Learn","subtitle":"","description":"记录学习过程","author":"Kangshitao","url":"http://kangshitao.github.io","root":"/"},"pages":[{"title":"关于","date":"2020-10-25T07:53:55.000Z","updated":"2022-05-22T13:30:54.807Z","comments":true,"path":"about/index.html","permalink":"http://kangshitao.github.io/about/index.html","excerpt":"","text":"Me磨刀不误砍柴工，读完硕士再打工。"},{"title":"categories","date":"2020-10-25T07:50:36.000Z","updated":"2022-05-22T13:30:54.807Z","comments":true,"path":"categories/index.html","permalink":"http://kangshitao.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-10-25T07:49:42.000Z","updated":"2022-05-22T13:30:54.808Z","comments":true,"path":"tags/index.html","permalink":"http://kangshitao.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Ubuntu20安装MySQL8","slug":"Ubuntu20-install-mysql8","date":"2022-05-22T13:40:18.000Z","updated":"2022-05-22T13:55:28.189Z","comments":true,"path":"2022/05/22/Ubuntu20-install-mysql8/","link":"","permalink":"http://kangshitao.github.io/2022/05/22/Ubuntu20-install-mysql8/","excerpt":"Win11的WSL安装MySQL8","text":"一、版本信息系统：Ubuntu 20.04.4 123456root@LAPTOP-4LK64UFH:/etc# lsb_release -aNo LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 20.04.4 LTSRelease: 20.04Codename: focal MySQL：8.0.29 12root@LAPTOP-4LK64UFH:/# mysql --versionmysql Ver 8.0.29-0ubuntu0.20.04.3 for Linux on x86_64 ((Ubuntu)) 二、安装步骤1、卸载旧版本安装之前确保旧版本已经卸载干净： 123456789101112# 卸载mysql-commonsudo apt-get remove mysql-common# 卸载mysql-serversudo apt-get autoremove --purge mysql-server-5.0# 查看MySQL剩余的包，然后卸载dpkg --list|grep mysql# 清除残留数据dpkg -l |grep ^rc|awk '{print $2}' |sudo xargs dpkg -P # 删除MySQL数据文件sudo rm /var/lib/mysql/ -R# 删除MySQL配置文件sudo rm /etc/mysql/ -R 2、安装更新软件库： 1sudo apt update 安装MySQL服务： 12sudo apt install mysql-server# 这里会自动安装mysql-client 安装依赖： 1sudo apt install libmysqlclient-dev 安装完后，检查状态： 1sudo netstat -tap | grep mysql 常用命令： 123456# 启动MySQL服务sudo service mysql start# 停止MySQL服务sudo service mysql stop# 重启MySQL服务sudo service mysql restart 三、使用MySQLMySQL8版本中，用户密码字段为authentication_string，并且新增了caching_sha2_password加密插件。 1、设置用户密码用户表保存在mysql库的user表中: 12345ALTER mysql.user 'userName'@'hostName' IDENTIFIED WITH caching_sha2_password BY 'userName';# 这里用caching_sha2_password，则plugin字段也应该是caching_sha2_password# 修改完后刷新flush privileges; 使用这个指令前，要确保authentication_string字段为空，否则会执行失败。 2、远程连接MySQL服务服务器上安装好MySQL后，客户端连接服务器的数据库，需要检查下面几项内容： 服务器防火墙关闭。 服务器ssh服务开启。 服务端端口打开：使用netstat -an | grep 3306指令查看3306端口情况，如果端口前面的地址是127.0.0.1，需要将etc/mysql/mysql.conf.d/mysqld.cnf中的bind-address = 127.0.0.1注释掉，确保其他地址客户端可以连接。 四、问题排查问题一：修改完密码登录，提示拒绝登录 错误信息：ERROR 1045 (28000): Access denied for user ‘root’@’localhost’ (using password: YES) 原因：可能是缓存密码的加密方式和当前用的加密插件不一致，确保设置密码时的加密插件和用户的plugin字段是相同的加密插件。 如果第三方客户端不支持caching_sha2_password，可以改成旧的mysql_native_password 加密方式。 问题二：无法连接MySQL服务器 错误信息：ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/var/run/mysqld/mysqld.sock’ (13) 原因：1、检查目录是否有指定文件。2、可能是当前用户没有此文件的权限，添加权限即可。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://kangshitao.github.io/tags/MySQL/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://kangshitao.github.io/tags/Ubuntu/"}]},{"title":"RabbitMQ学习笔记","slug":"rabbitmq","date":"2021-10-26T14:16:25.000Z","updated":"2022-05-22T13:30:54.801Z","comments":true,"path":"2021/10/26/rabbitmq/","link":"","permalink":"http://kangshitao.github.io/2021/10/26/rabbitmq/","excerpt":"RabbitMQ工作模式，Exchange、Queue基本概念，发布确认机制，死信队列、延迟队列，RabbitMQ集群简介","text":"一、消息队列1.1 MQ相关概念1.1.1 什么是MQ消息队列（MQ，Message Queue）本质是一个队列，队列中存放的内容是message，是一种跨进程的通信机制，用于上下游传递消息。 使用MQ以后，消息发送上游只需要依赖MQ，不用依赖其他服务。 1.1.2 MQ的作用 流量削峰 应用解耦 异步处理 1.1.3 MQ分类常见的MQ有以下几种： ActiveMQ：高吞吐量场景较少使用。 Kafka：为大数据而生，百万级TPS，吞吐量高，在日志领域比较成熟。适合有日志采集需求的大型企业。 RocketMQ：出自阿里巴巴，单机吞吐量十万级，消息0丢失，支持10亿级别的消息堆积。适合金融互联网。 RabbitMQ：由Erlang语言开发，在AMQP（高级消息队列协议）基础上完成，当前最流行的MQ。吞吐量万级，支持多种语言。适合数据量不是特别大的中小型公司。 1.2 RabbitMQ1.2.1 核心概念RabbitMQ RabbitMQ是一个消息中间件，它接受、存储、转发消息数据。 生产者（Producer） 产生数据、发送消息的程序是生产者。 交换机（Exchange） 交换机是RabbitMQ的一个重要组件。它一方面接收来自生产者的消息，另一方面将消息推送到队列中。交换机决定了将消息推送到特定队列还是推送到多个队列。 队列（Queue） 队列是RabbitMQ内部使用的一种数据结构。消息只能存储在队列中，队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者也可以尝试从一个队列接收数据。 消费者（Consumer） 消费者指的是等待接受消息的程序。同一个应用程序既可以是生产者也可以是消费者。 1.2.2 安装RabbitMQ官方文档：Docs RabbitMQ基于Erlang环境，因此需要先安装Erlang。 安装之前需要确保RabbitMQ和Erlang的版本要对应：RabbitMQ Erlang Version Requirements 本机环境： CentOS-7.9 Erlang-23.2.3 RabbitMQ-3.8.15 使用rpm方式，在packagecloud网站下载安装包。 1、安装Erlang 下载对应版本的安装包，packagecloud： 1wget --content-disposition https://packagecloud.io/rabbitmq/erlang/packages/el/7/erlang-23.2.3-1.el7.x86_64.rpm/download.rpm 安装： 1rpm -ivh erlang-23.2.3-1.el7.x86_64.rpm 安装完后，输入erl进入Erlang的命令行界面，安装成功。 2、安装socat 除了Erlang环境，还需要安装socat： 1yum install socat logrotate -y 3、安装RabbitMQ 下载对应版本的安装包，packagecloud： 1wget --content-disposition https://packagecloud.io/rabbitmq/rabbitmq-server/packages/el/8/rabbitmq-server-3.8.15-1.el8.noarch.rpm/download.rpm 安装： 1rpm -ivh rabbitmq-server-3.8.15-1.el8.noarch.rpm 安装完成后，启动rabbit服务： 1systemctl start rabbitmq-server.service 4、安装插件 可以通过以下命令开启web管理插件，需要先停止rabbitmq服务： 1rabbitmq-plugins enable rabbitmq_management 插件开启成功后就可以在浏览器中访问，默认端口号为15672（记得关闭防火墙或者开放端口）。 管理界面需要账号密码登陆，默认的账号和密码都是guest。 查看当前所有用户： 1rabbitmqctl list_users 添加新用户admin，密码也为admin： 1rabbitmqctl add_user admin admin 设置用户角色（标签），将admin设置为administrator 1rabbitmqctl set_user_tags admin administrator 设置用户权限： 1rabbitmqctl set_permissions -p \"/\" admin \".*\" \".*\" \".*\" 1.2.3 原理和工作模式工作原理 RabbitMQ的工作原理如图所示： RabbitMQ工作原理 生产者将消息通过Channel发送到Exchange，Exchange决定将消息分发到哪个队列，然后由消费者从队列中接收消息。 其中的核心概念： Broker：接收和分发消息的应用，RabbitMQ Server就是Message Broker Virtual host：虚拟的分组，当多个不同的用户使用同一个RabbitMQ server提供的服务时，可以划分出多个vhost，每个用户在自己的vhost创建exchange/queue等。 Connection：publisher/consumer和broker之间的TCP连接。 Channel：Channel是在connection内部建立的逻辑连接，多线程情况下通常每个线程创建单独的channel进行通讯。AMQP method包含了channel id帮助客户端和broker识别channel，channel是完全隔离的。Channel作为轻量级的Connection极大减少了操作系统建立TCP connection的开销。 Exchange：交换机。消息到达broker中会首先到达Exchange，Exchange根据分发规则，匹配查询表中的routing key，分发消息到queue中去。常用的类型有：direct（point-to-point）、topic（publish-subscribe）、fanout（multicast）。 Queue：消息被送到Queue中，然后被消费者取走。 Binding：exchange和queue之间的虚拟连接。binding中可以包含Routing key，binding信息被保存到exchange中的查询表中，用于message的分发依据。声明binding关系的时候，可以声明RoutingKey参数 工作模式 RabbitMQ一共有7种工作模式，参考Get Started： RabbitMQ工作模式 二、Hello World2.1 介绍Hello World模式是RabbitMQ最简单的一个模式。下图中的P表示生产者，C是消费者，中间框是一个队列，是RabbitMQ代表消费者保存的消息缓冲区。 Hello World模式 2.2 实现1、在IDEA中创建Maven项目，然后引入依赖： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2、编写生产者的代码 12345678910111213141516171819202122232425262728public class Producer { // 队列名称 public static final String QUEUE_NAME = \"hello\"; //发消息 public static void main(String[] args) throws IOException, TimeoutException { //创建一个连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置工厂的ip，连接队列 factory.setHost(\"192.168.198.198\"); //RabbitMQ服务主机的ip //设置用户名和密码 factory.setUsername(\"admin\"); factory.setPassword(\"admin\"); //创建连接，每个连接有多个channel，channel是用来发消息的。 Connection connection = factory.newConnection(); //获取channel Channel channel = connection.createChannel(); //生成一个队列用于通信，简单起见，使用默认的交换机 channel.queueDeclare(QUEUE_NAME, false, false, false, null); //发消息 String message = \"hello, world\"; channel.basicPublish(\"\", QUEUE_NAME, null, message.getBytes()); System.out.println(\"消息发送完毕！\"); }} 其中关键方法的说明： queueDeclare()，用于声明一个队列，其中的各个参数依次解释如下： 队列名。 队列的消息是否持久化，默认情况下消息存储在内存中(不持久化）。 该队列是否进行消费共享，true表示允许多个消费者消费。 是否自动删除 最后一个消费者端开连接以后，该队列是否自动删除。 其他参数。 basicPublish()，用于发布消息： 交换机名称，用于指定发送到哪个交换机。 routingKey，路由的key值。这里使用的是channel名字作为routingKey 其他参数信息。 发送消息的消息体。 3、编写消费者的代码 1234567891011121314151617181920212223242526272829public class Consumer { // 队列名称 public static final String QUEUE_NAME = \"hello\"; //接收消息 public static void main(String[] args) throws IOException, TimeoutException { //创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置ip factory.setHost(\"192.168.198.198\"); //设置用户名和密码 factory.setUsername(\"admin\"); factory.setPassword(\"admin\"); //创建连接 Connection connection = factory.newConnection(); //创建信道 Channel channel = connection.createChannel(); //消费者接收消息（消费消息） //接收消息的回调函数 DeliverCallback deliverCallback = (consumerTag,message)-&gt;{ System.out.println(new String(message.getBody())); }; CancelCallback cancelCallback = (consumerTag)-&gt;{ System.out.println(\"消息消费被中断\"); }; channel.basicConsume(QUEUE_NAME,true, deliverCallback,cancelCallback); }} basicConsume()的参数说明： 指定消费的队列名，即从哪个队列中取消息。 消费成功之后是否自动应答。 消费者接收的回调函数。 消费者取消消费的回调函数。 如果需要修改现有的exchange和queue，需要删除现有的队列，重新创建。 4、运行 启动生产者程序，会创建Channel并发送消息，然后启动消费者程序，会收到来自生产者的消息。 三、Work QueuesWork Queues模式的主要思想是避免因立即执行资源密集型任务而不得不等待它完成。在这个模式中，我们将任务封装为消息，并将其发送到队列。当有多个工作线程时，这些工作线程将一起处理这些任务。 Work Queues 3.1 轮询分发消息Work Queues模式下使用的轮询分发的机制，对于多个消费者线程，会轮流分发任务。 下面我们以一个生产者，两个消费者线程来模拟。 抽取工具类 创建channel之前的代码是相同的，因此可以单独抽取出来，作为工具类： RabbitMqUtils.java 1234567891011121314151617181920212223public class RabbitMqUtils { public static Channel getChannel(){ ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"192.168.198.198\"); factory.setUsername(\"admin\"); factory.setPassword(\"admin\"); Connection connection = null; try { connection = factory.newConnection(); } catch (IOException e) { e.printStackTrace(); } catch (TimeoutException e) { e.printStackTrace(); } Channel channel = null; try { channel = connection.createChannel(); } catch (IOException e) { e.printStackTrace(); } return channel; }} 生产者 启动发送线程： 12345678910111213141516public class Task01 { public static final String QUEUE_NAME = \"hello\"; public static void main(String[] args) throws IOException { Channel channel = RabbitMqUtils.getChannel(); channel.queueDeclare(QUEUE_NAME,false,false,false,null); //从控制台接收信息发送到消费者 Scanner scanner = new Scanner(System.in); while(scanner.hasNext()){ String message = scanner.next(); channel.basicPublish(\"\",QUEUE_NAME,null,message.getBytes()); System.out.println(message+\"发送完成！\"); } }} 启动两个工作线程 12345678910111213141516public class Worker01 { public static final String QUEUE_NAME = \"hello\"; public static void main(String[] args) throws IOException { Channel channel = RabbitMqUtils.getChannel(); //消息的接收 DeliverCallback deliverCallback = (consumerTag,message)-&gt;{ System.out.println(\"接收到的消息：\"+new String(message.getBody())); }; CancelCallback cancelCallback = (consumerTag)-&gt;{ System.out.println(consumerTag+\"消息被取消接受\"); }; System.out.println(\"Consumer 1------\"); channel.basicConsume(QUEUE_NAME,true,deliverCallback,cancelCallback); }} 使用IDEA设置并行运行，Edit Configurations-&gt;Allow multiple instances，这样可以同时启动两个消费者线程。 运行 生产者发送消息，消费者1和消费者2会轮流处理消息。 比如生产者发送1、2、3、4、5、6，消费者1接收到1、3、5，消费者2接收到2、4、6。 3.2 消息应答概念 消费者完成一个任务需要耗费一定的时间，RabbitMQ一旦向消费者发送消息后，会将此消息标记为删除，这种情况下，如果消费者处理任务的过程中出现故障，会导致任务丢失。为了保证消息不会丢失，RabbitMQ引入了消息应答机制。 消息应答（Message acknowledgment）：消费者在接收到消息并且处理完该消息之后，告诉RabbitMQ此消息已经被处理，RabbitMQ可以将该消息删除。这样就保证当某一个消费者线程故障后，消息会被重新发送给其他消费者，确保消息不会丢失（前提是RabbitMQ无故障）。 消息应答包括自动应答和手动应答两种方式： 自动应答：消息发送后立即被认为已经传送成功。这种方式没有对传递的消息数量做限制，会导致消费者端消息积压，线程被系统杀死。这种模式仅适用于消费者可以高效并以某种速率能够处理这些消息的情况下使用。 手动应答：默认是手动应答模式。如果一个消费者线程宕机，其消息可以被其他消费者线程消费，而不会出现消息丢失的情况。 手动应答示例： 1234567891011121314151617181920212223242526/** * 消息在手动应答时不丢失、放回队列中重新消费 */public class Worker03 { public static final String TASK_QUEUE_NAME = \"ack_queue\"; public static void main(String[] args) throws IOException { Channel channel = RabbitMqUtils.getChannel(); //获取channel System.out.println(\"消费者1等待接收消息，处理时间较短------\"); //手动应答 boolean autoAck = false; DeliverCallback deliverCallback = (consumerTag, message)-&gt;{ //沉睡1s，模拟处理信息场景。 SleepUtils.sleep(1); //工具类SleepUtils用来睡眠线程。 System.out.println(\"接收到的消息：\"+new String(message.getBody(),\"UTF-8\")); //手动应答。参数1为消息的标记tag，参数2表示是否批量应答 channel.basicAck(message.getEnvelope().getDeliveryTag(),false); }; CancelCallback cancelCallback = (consumerTag)-&gt;{ System.out.println(consumerTag+\"消息被取消接受\"); }; //设置为手动应答 channel.basicConsume(TASK_QUEUE_NAME,autoAck,deliverCallback,cancelCallback); }} 手动应答主要是在接收消息的回调方法中调用basicAck()方法，已经在basicConsume()方法中设置自动应答方式为false。 其中basicAck()方法的第二个参数表示是否批量化应答。如果是批量化应答(Multiple)，则每次会应答一个批次的消息。 手动应答的好处就是可以批量应答并且减少网络拥堵。 消息重新入队：如果某个消费者由于某些原因失去连接（或发生故障），导致消息未发送ACK确认，RabbitMQ将了解到消息未完全处理，并将其重新排队发送给其他消费者。这样，即使某个消费者偶尔死亡，也可以确保不丢失消息。 3.3 RabbitMQ持久化消息应答能够确保消费者线程故障后，消息不会丢失，如何保障当RabbitMQ服务停掉以后消息也不丢失？ 这就需要将队列和消息都标记为持久化。 队列持久化 在声明队列时将是否持久化的参数置为true即可： 1channel.queueDeclare(TASK_QUEUE_NAME,true,false,false,null); 第二个参数就表示是否持久化队列。 如果已经存在的队列需要持久化，需要将队列删除，重新创建。 消息持久化 仅将队列持久化不能保证消息不丢失，因为如果消费者线程宕机断开连接，仍然有可能出现消息丢失的情况。 设置消息持久化，需要在channel发布消息时设置： 1channel.basicPublish(\"\",TASK_QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN,message.getBytes(\"UTF-8\")); 这种方式只是尽量保证持久化，如果绝对保证持久化，需要使用发布确认机制。 预取值 basicQos()方法可以设置消费者线程的预取值。 预取值表示一个消费者线程对应的信道最大可以堆积的消息个数，即通道上允许的未确认消息的最大数量。 类似于缓冲池，预取值最大值就是缓存池的最大值。最多只能存放预取值个数的未确认消息。 如果不设置预取值，可能会有大量已传递但尚未处理的消息的数量堆积，导致消费者RAM消耗。 不公平分发 轮询方式是不管每个消费者的处理速度，给每个消费者线程轮流分发任务。 不公平分发是指根据每个消费者线程的处理能力，为每个消费者线程分配不同个数的消息。——能者多劳。 在消费者的信道上，设置Qos的值为1，就可以表示按处理能力分发： 12//将Qos设置为1，就是不公平分发；默认为0，表示轮询分发channel.basicQos(1); Qos的值为1时，表示根据消费者线程的处理能力分发，最多堆积一个任务。 四、发布确认如果想要确保消息一定不会丢失，除了上面提到的队列持久化和消息持久化，还需要使用发布确认（Publisher confirm）。这三种设置保证了消息不会丢失。 官方文档：Publisher Confirms 4.1 发布确认原理生产者将channel设置为confirm模式，一旦channel进入confirm模式，所有在该channel上面发布的消息都会被指派一个唯一的ID（从1开始）。一旦消息被投递到所有匹配的队列之后，broker会发送一个确认给生产者。 生产者得知消息已经正确到达目的队列后，如果消息和队列是可持久化的，确认消息会在消息写入磁盘后发出。 broker回传给生产者的确认消息中delivery-tag域中包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。 发布确认（Publisher confirm）是broker给生产者发送的确认消息。 消息应答（Message acknowledgment）是消费者处理完消息发送给broker的ack确认。 confirm模式的好处在于它是异步的，发布一条消息后，生产者可以边等确认消息边发送下一条消息。消息得到确认或者丢失，生产者都会通过相应的回调方法进行处理。 4.2 发布确认策略4.2.1 开启发布确认生产者创建信道后，调用confirmSelect()方法即可开启发布确认模式。 1channel.confirmSelect(); 发布确认可以有单个确认、批量确认、异步确认三种方式。 4.2.2 单个确认发布单个确认发布，即对每一条消息进行同步确认，生产者发布一条消息后只有它被确认发布后，后续的消息才能继续发布。 123456789101112131415161718192021public static void publishMessageIndividually() throws Exception{ Channel channel = RabbitMqUtils.getChannel(); //信道名字使用随机的UUID String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName,true,false,false,null); //开启发布确认 channel.confirmSelect(); long start = System.currentTimeMillis(); //批量发消息 for(int i=0;i&lt;1000;i++){ String message = i+\"\"; channel.basicPublish(\"\",queueName,null,message.getBytes()); //单个消息马上确认 boolean flag = channel.waitForConfirms(); if(flag){ System.out.println(\"第\"+i+\"条消息发送成功\"); } } long end = System.currentTimeMillis(); System.out.println(\"发布1000个单独确认消息，耗时\"+(end-start)+\"ms\");} 单个确认发布的速度是最慢的，因为要每条消息都确认一次。 4.2.3 批量确认发布批量确认发布是指根据批次大小确认发布，这种方式的缺点是当发生故障导致发布出现问题时，不知道哪个消息出问题。 123456789101112131415161718192021222324//批量发布确认public static void publishMessageBatch() throws Exception{ Channel channel = RabbitMqUtils.getChannel(); //信道名字使用随机的UUID String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName,true,false,false,null); //开启发布确认 channel.confirmSelect(); long start = System.currentTimeMillis(); //批量发消息，并批量确认消息 int batchSize = 100; //每100条确认一次 for(int i=0;i&lt;1000;i++){ String message = i+\"\"; channel.basicPublish(\"\",queueName,null,message.getBytes()); if((i+1)%batchSize==0){ //每100条消息确认一次 boolean flag = channel.waitForConfirms(); if(flag){ System.out.println(\"确认前\"+i+\"条数据\"); } } } long end = System.currentTimeMillis(); System.out.println(\"发布1000个批量确认消息，耗时\"+(end-start)+\"ms\");} 4.2.4 异步确认发布异步确认发布是效率和可靠性最高的。对于已确认消息和未确认消息，异步确认方式都能够处理。 异步确认发布主要是通过addConfirmListener方法监听确认和未确认的消息，使用哈希表记录所有发布的消息，对于成功确认的消息从哈希表中删除，剩下的是未确认的消息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//异步批量确认public static void publishMessageAsync() throws Exception{ Channel channel = RabbitMqUtils.getChannel(); //信道名字使用随机的UUID String queueName = UUID.randomUUID().toString(); channel.queueDeclare(queueName,true,false,false,null); //开启发布确认 channel.confirmSelect(); //使用哈希表记录所有消息，便于多个线程进行消息的添加和删除 /*线程安全的哈希表，适用于高并发的情况。 1.哈希表能够轻松的将序号和消息进行关联。 2.可以轻松地批量删除条目，只需要知道序号 3.支持高并发（多线程） */ ConcurrentSkipListMap&lt;Long,String&gt; map = new ConcurrentSkipListMap&lt;&gt;(); long start = System.currentTimeMillis(); //创建消息的监听器，监听哪些消息成功了，哪些消息失败了。 //消息确认成功 回调函数 /*参数：1. 消息的标记（序号）2.是否为批量确认*/ ConfirmCallback ackCallback = (deliveryTag, multiple) -&gt;{ //2.删除掉已经确认的消息，剩下的就是未确认的消息 if(multiple){ //默认multiple是true，即批量确认的 //如果是批量确认的，则找到所有小于当前序号的值，并清除。这样剩下的就是未确认的消息 //headMap方法就是返回所有小于指定序号的值的map，第二个参数表示是否找出等于序号的。 ConcurrentNavigableMap&lt;Long, String&gt; navigableMap = map.headMap(deliveryTag, true); navigableMap.clear(); }else{//如果不是批量确认，则只删除当前已经确认的消息即可。 map.remove(deliveryTag); } System.out.println(\"确认的消息：\"+deliveryTag); }; //监听确认失败的消息 ConfirmCallback nackCallback = (deliveryTag, multiple) -&gt;{ //3.打印未确认的消息 System.out.println(\"未确认的消息：\"+deliveryTag); }; /*参数：1.监听确认成功的消息 2. 监听确认失败的消息*/ channel.addConfirmListener(ackCallback,nackCallback); //批量发消息，异步确认消息 int batchSize = 100; //每100条确认一次 for (int i = 0; i &lt; 1000; i++) { String message = \"消息\" + i; //1.记录下所有要发送的消息 map.put(channel.getNextPublishSeqNo(),message); //发布消息 channel.basicPublish(\"\",queueName,null,message.getBytes()); } long end = System.currentTimeMillis(); System.out.println(\"发布\"+MESSAGE_COUNT+\"个异步确认消息，耗时\"+(end-start)+\"ms\");} 五、交换机5.1 相关概念生产者生产的消息不会直接发送到队列，只能将消息发送到交换机（exchange），然后由交换机发送到队列。 交换机的功能：①接收来自生产者的消息。②将消息推入队列。 交换机主要的三个类型： fanout：这种类型的交换机不分析Routing Key，将消息转发到所有和该交换机绑定的队列中。用于Publish/Subscribe模式。 direct：这类交换机需要精准匹配Routing Key，只将消息转发到指定Routing Key的队列中。用于Routing模式。 topic：这类交换机按照一定规则匹配Routing Key，将消息转发到匹配到的队列中，通常是一组相同主题的队列。用于Topics模式 临时队列 创建一个随机名称的临时队列： 1String queueName = channel.queueDeclare().getQueue(); 绑定（bindings） binding是指exchange和queue之间的关系，将exchange和queue进行绑定。 其中一个交换机和一个队列之间可以有多个binding key 5.2 Publish/Subscribe发布订阅模式是使用的扇出（fanout）类型的交换机。 交换机会将消息推送至所有和他绑定的队列，不会匹配Routing Key。无论绑定的Routing Key是什么值，都会发送到所有和其绑定的队列中。 Publish/Subscribe 实例 如上图所示，一个交换机，两个队列。 生产者： 123456789101112131415161718public class EmitLog { //交换机名字为logs public static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] args) throws IOException { Channel channel = RabbitMqUtils.getChannel(); //声明为fanout类型，可以用枚举类型或者字符串。 //channel.exchangeDeclare(EXCHANGE_NAME,\"fanout\"); channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT); Scanner scanner = new Scanner(System.in); while(scanner.hasNext()){ String message = scanner.next(); //绑定信息为空 channel.basicPublish(EXCHANGE_NAME,\"\",null,message.getBytes(\"UTF-8\")); System.out.println(\"生产者发出消息：\"+message); } }} 消费者1 123456789101112131415161718192021public class ReceiveLogs01 { public static void main(String[] args) throws IOException { Channel channel = RabbitMqUtils.getChannel(); /*声明临时队列 临时队列的队列名称是随机的 当消费者断开与队列的连接后，队列会被自动删除。 */ String queueName = channel.queueDeclare().getQueue(); /* 将队列和交换机绑定 binding，routingKey为空 */ channel.queueBind(queueName,EXCHANGE_NAME,\"\"); DeliverCallback deliverCallback = (consumerTag, message)-&gt;{ System.out.println(\"消费者1控制台打印接收到的消息：\"+new String(message.getBody(),\"UTF-8\")); }; CancelCallback cancelCallback = consumerTag-&gt;{}; channel.basicConsume(queueName,deliverCallback,cancelCallback); }} 消费者2的代码和消费者1相同，会生成另一个随机名称的临时队列。 这样，当生产者每次发送一条消息，消费者1和消费者2都能接收到。 5.3 RoutingRouting模式使用的是direct类型交换机，这种模式下，交换机需要精准匹配Routing Key，只将消息转发到指定Routing Key的队列中。 Routing 如图，交换机X绑定了Q1和Q2两个队列，其中和Q1之间的Binding Key为orange，和Q2的Binding Key包括black和green两个。 Routing Key为orange的消息会被推送到Q1队列。Routing Key为black和green的消息会被推送到Q2队列。 多重绑定：允许不同队列和交换机之间的Binding Key是相同的，这种情况下效果和Publish/Subscribe模式相同。 实现 生产者： 123456789101112131415161718public class DirectProducer { public static final String EXCHANGE_NAME = \"X\"; public static void main(String[] args) throws IOException { Channel channel = RabbitMqUtils.getChannel(); //声明交换机,类型为direct channel.exchangeDeclare(EXCHANGE_NAME,\"direct\"); Scanner scanner = new Scanner(System.in); while(scanner.hasNext()){ String message = scanner.next(); //当Bingding Key取不同值时，会根据情况发送的相应的队列。 channel.basicPublish(EXCHANGE_NAME,\"orange\",null,message.getBytes(\"UTF-8\"));// channel.basicPublish(EXCHANGE_NAME,\"black\",null,message.getBytes(\"UTF-8\"));// channel.basicPublish(EXCHANGE_NAME,\"green\",null,message.getBytes(\"UTF-8\")); System.out.println(\"Direct类型，生产者发出消息：\"+message); } }} 消费者1： 123456789101112131415161718192021public class DirectConsumer01 { public static final String EXCHANGE_NAME = \"X\"; public static final String QUEUE_NAME = \"Q1\"; public static final String BINGDING_NAME = \"orange\"; public static void main(String[] args) throws IOException { Channel channel = RabbitMqUtils.getChannel(); //声明交换机,类型为direct channel.exchangeDeclare(EXCHANGE_NAME,\"direct\"); //声明名为Q1的队列 channel.queueDeclare(QUEUE_NAME,false,false,false,null); //将队列和交换机绑定 channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,BINGDING_NAME); DeliverCallback deliverCallback = (consumerTag, message)-&gt;{ System.out.println(\"C1接收到消息：\"+new String(message.getBody(),\"UTF-8\")); }; CancelCallback cancelCallback = consumerTag-&gt;{}; channel.basicConsume(QUEUE_NAME,deliverCallback,cancelCallback); }} 消费者2和消费者1类似，不同的是有两个Bingding： 123//多重绑定，一个channel和交换机有两个绑定,两个不同的routing keychannel.queueBind(\"Q2\",\"X\",\"black\");channel.queueBind(\"Q2\",\"X\",\"green\"); 这样，当发送消息的Routing Key为orange时，消息会被推送到Q1，Routing Key为black或green时，消息被推送到Q2。 5.4 TopicsTopics模式使用的是Topic类型的交换机，队列可以匹配一定规则的多个Routing Key。 Topic模式的Routing Key必须符合一定的要求：必须是一个单词列表，以.号分开，单词可以是任意的，比如stock.usd.nyse, nyse.vmw, quick.orange.rabbit等。单词列表最多为255个字节。 *号可以代替一个单词。 #号可以代替0个或多个单词。 Topics 如上图所示，交换机X和Q1的Binding Key为*.orange.*，X和Q2的Binding Key为*.*.rabbit和lazy.#。 一些案例： ①quick.orange.rabbit：Q1、Q2接收到消息。 ②quick.orange.rabbit ： Q1、Q2接收到消息。 ③lazy.orange.elephant：Q1、Q2 接收到消息。 ④quick.orange.fox：Q1 接收到消息。 ⑤lazy.brown.fox：Q2 接收到消息。 ⑥lazy.pink.rabbit ：Q2 接收一次消息，虽然两种绑定都匹配，但只接收一次。 ⑦quick.brown.fox ：不匹配任何绑定，被丢弃。 ⑧quick.orange.male.rabbit ：是四个单词，不匹配任何绑定，被丢弃。 ⑨lazy.orange.male.rabbit ：是四个单词，Q2接收到消息。 实现 声明交换机： 1channel.exchangeDeclare(\"X\",\"topic\"); 队列Q1绑定： 1channel.queueBind(\"Q1\",\"X\",\"*.orange.*\"); 队列Q2绑定： 12channel.queueBind(\"Q1\",\"X\",\"*.*.rabbit\");channel.queueBind(\"Q1\",\"X\",\"lazy.#\"); 六、死信队列关于死信队列的官方文档：死信队列 队列中的消息如果发生以下情况就会变成死信（Dead Letter）： 消息被拒绝（basic.reject或basic.nack），并且requeue参数为false 消息TTL超时，即消息过期。 队列长度超过最大限制。 队列过期不会导致消息变为死信。 死信交换机（Dead Letter eXchanges，DLXs）是正常的交换机，它可以将Dead Letter转发给死信队列，进一步处理。 如图，正常情况下，消息通过normal_exchange推送到normal_queue，然后被C1消费；如果消息变为死信，normal_queue会将死信转发给死信交换机DLX，DLX将死信推送给死信队列dead_letter_queue，然后被C2消费。 死信队列 实现 生产者： 12345678910111213141516171819202122public class Producer { public static final String NORMAL_EXCHANGE=\"normal_exchange\"; public static final String NORMAL_ROUTING_KEY=\"normal_routing_key\"; public static void main(String[] args) throws IOException { Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(NORMAL_EXCHANGE,\"direct\"); //设置过期时间为10s //AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().expiration(\"10000\").build(); //模拟发10条消息 for (int i = 0; i &lt; 10; i++) { String message = String.valueOf(i); //超过ttl变为死信 //channel.basicPublish(NORMAL_EXCHANGE,NORMAL_BINDING,properties,message.getBytes(\"UTF-8\")); //超过最大长度变为死信 //channel.basicPublish(NORMAL_EXCHANGE,NORMAL_BINDING,null,message.getBytes(\"UTF-8\")); channel.basicPublish(NORMAL_EXCHANGE,NORMAL_ROUTING_KEY,null,message.getBytes(\"UTF-8\")); //消息被拒绝变为死信 System.out.println(\"生产者发出消息：\"+message); } }} 消费者C1： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Consumer01 { public static final String NORMAL_EXCHANGE=\"normal_exchange\"; public static final String DEAD_EXCHANGE=\"dead_exchange\"; public static final String NORMAL_QUEUE=\"normal_queue\"; public static final String DEAD_QUEUE=\"dead_queue\"; public static final String NORMAL_ROUTING_KEY=\"normal_routing_key\"; public static final String DEAD_ROUTING_KEY=\"dead_routing_key\"; public static void main(String[] args) throws IOException { Channel channel = RabbitMqUtils.getChannel(); //声明普通交换机和死信交换机，类型均为direct channel.exchangeDeclare(NORMAL_EXCHANGE,\"direct\"); channel.exchangeDeclare(DEAD_EXCHANGE,\"direct\"); //声明正常队列。正常队列需要将死信消息转发到死信交换机，需要用到map参数 Map&lt;String, Object&gt; arguments = new HashMap&lt;&gt;(); //过期时间,比如为10s；也可以在生产者发送消息的时候设置过期时间 //arguments.put(\"x-message-ttl\",10000); //指定队列的最大长度，一旦消息个数超出这个长度，就会成为死信 //arguments.put(\"x-max-length\",6); //设置死信交换机，即死信消息将要转发到的交换机 arguments.put(\"x-dead-letter-exchange\",DEAD_EXCHANGE); //设置死信routingkey,死信消息通过此路由键发送到死信队列。 arguments.put(\"x-dead-letter-routing-key\",DEAD_ROUTING_KEY); channel.queueDeclare(NORMAL_QUEUE,false,false,false,arguments); channel.queueBind(NORMAL_QUEUE,NORMAL_EXCHANGE,NORMAL_ROUTING_KEY); //绑定 //声明死信队列 channel.queueDeclare(DEAD_QUEUE,false,false,false,null); channel.queueBind(DEAD_QUEUE,DEAD_EXCHANGE,DEAD_ROUTING_KEY); //绑定 DeliverCallback deliverCallback = (consumerTag, message)-&gt;{ //模拟拒绝消息 String msg = new String(message.getBody(),\"UTF-8\"); if(Integer.parseInt(msg)%2==0){ System.out.println(msg+\"被拒绝\"); //拒绝消息 channel.basicReject(message.getEnvelope().getDeliveryTag(),false); }else{ System.out.println(\"C1打印接收到的消息：\"+msg); //手动应答消息 channel.basicAck(message.getEnvelope().getDeliveryTag(),false); } }; CancelCallback cancelCallback = consumerTag-&gt;{}; //模拟拒绝消息时，要关闭自动应答。 channel.basicConsume(NORMAL_QUEUE,false,deliverCallback,cancelCallback); }} 疑问：为什么要在正常队列中设置x-dead-letter-routing-key? 不设置会导致死信队列收不到消息，但是下文中也设置了死信队列和DLX和Routing Key，二者如果不一致也会导致死信队列收不到死信消息。 消费者C2： 12345678910111213141516//C2只需要从死信队列中接收消息即可public class Consumer02 { public static final String DEAD_QUEUE=\"dead_queue\"; public static void main(String[] args) throws IOException { Channel channel = RabbitMqUtils.getChannel(); DeliverCallback deliverCallback = (consumerTag, message)-&gt;{ System.out.println(\"C2打印接收到的消息：\"+new String(message.getBody(),\"UTF-8\")); }; CancelCallback cancelCallback = consumerTag-&gt;{}; channel.basicConsume(DEAD_QUEUE,true,deliverCallback,cancelCallback); }} 七、延迟队列7.1 概念理解延迟队列是用来存放需要在指定时间被处理的元素的队列。如果我们希望一条消息在指定时间到了以后或之前处理，可以使用延迟队列。 延迟队列常见的使用场景：订单一段时间内未支付则自动取消、预定会议开始前十分钟通知与会人员参加会议。 TTL是RabbitMQ中一个消息或者队列的属性，表明一条消息或者一个队列中所有消息的最大存活时间。单位是ms 如果一条消息设置了TTL属性，或者一条消息进入了设置TTL属性的队列，则这条消息如果在TTL设置的时间内没有被消费，就会成为“死信”。 如果同时配置了消息的TTL和队列的TTL，较小的值会被使用。 7.2 设置TTL消息设置TTL 12345//在发送消息时，针对当前这条消息单独设置ttl时间为ttlTimerabbitTemplate.convertAndSend(\"exchange\",\"routingKey\",message,msg-&gt;{ msg.getMessageProperties().setExpiration(ttlTime); return msg; }); 队列设置TTL 12arguments.put(\"x-message-ttl\",10000);Queue q = QueueBuilder.durable(QUEUE_A).withArguments(arguments).build(); 其中argumengts是Map，用于给队列设置参数。x-message-ttl表示队列的延迟时间。 durable()意为设置队列为持久化队列。 注意 如果设置了队列的TTL，那么消息一旦超过了这个时间就会被丢弃（如果有死信队列会被丢弃到死信队列） 如果设置的是消息的TTL，消息过期了不一定马上被抛弃。因为消息是否过期是在即将投递到消费者之前判定的，当队列出现消息积压的情况时，已过期的消息仍然能在队列中存活。 不设置TTL，表示消息永远不会过期。 TTL设置为0，表示除非此时可以直接投递该消息到消费者，否则改消息将会被丢弃。 7.3 DLX+TTL实现延迟队列我们可以使用消息和队列的TTL的属性和死信队列，实现延迟队列。思路是将过期队列转发到死信队列，消费者只要消费死信队列中的消息即可，就实现了延迟队列的功能。 1、创建SpringBoot项目 创建SpringBoot项目，然后引入以下依赖： 12345678910111213141516171819202122232425262728293031323334&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- RabbitMQ依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--fastjson--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.62&lt;/version&gt; &lt;/dependency&gt; &lt;!-- RabbitMQ --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2、修改配置文件 在application.properties配置文件中，添加RabbitMQ的相关配置： 12345# 配置RabbitMQ的相关配置spring.rabbitmq.host=192.168.198.198spring.rabbitmq.port=5672spring.rabbitmq.username=adminspring.rabbitmq.password=admin 3、创建配置类 根据下面的架构图，X为正常的交换机，Y是死信交换机，QA和QB是具有TTL属性的延迟队列，QC是没有TTL属性的正常队列，QD是死信队列。各个队列和交换机之间的binding关系如图所示。 架构图 首先创建一个配置类，将各个组件构建出来。其中包括两个交换机，四个队列，四个绑定关系： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class TtlQueueConfig { //普通交换机的名称 public static final String X_EXCHANGE = \"X\"; //死信交换机的名称 public static final String Y_DEAD_LETTER_EXCHANGE = \"Y\"; //普通队列的名称 public static final String QUEUE_A = \"QA\"; public static final String QUEUE_B = \"QB\"; //死信队列的名称 public static final String DEAD_LETTER_QUEUE = \"QD\"; //普通队列，没有过期时间。可以适用于任意过期时间的消息。不需要每个过期时间都创建一个新队列 public static final String QUEUE_C = \"QC\"; //声明QC //普通队列C，不设置过期时间 @Bean(\"queueC\") public Queue queueC(){ Map&lt;String, Object&gt; arguments = new HashMap&lt;&gt;(); arguments.put(\"x-dead-letter-exchange\",Y_DEAD_LETTER_EXCHANGE); arguments.put(\"x-dead-letter-routing-key\",\"YD\"); return QueueBuilder.durable(QUEUE_C).withArguments(arguments).build(); } //绑定.队列QC和交换机X绑定，Routing Key为XC @Bean public Binding queueCBindingX(@Qualifier(\"queueC\") Queue queueC, @Qualifier(\"xExchange\") DirectExchange xExchange){ return BindingBuilder.bind(queueC).to(xExchange).with(\"XC\"); } //声明普通交换机，别名为xExchange @Bean(\"xExchange\") public DirectExchange xExchange(){ return new DirectExchange(X_EXCHANGE); } //声明死信交换机，别名为yExchange @Bean(\"yExchange\") public DirectExchange yExchange(){ return new DirectExchange(Y_DEAD_LETTER_EXCHANGE); } //声明队列 //普通队列A，过期时间为10s @Bean(\"queueA\") public Queue queueA(){ Map&lt;String, Object&gt; arguments = new HashMap&lt;&gt;(); arguments.put(\"x-dead-letter-exchange\",Y_DEAD_LETTER_EXCHANGE); arguments.put(\"x-dead-letter-routing-key\",\"YD\"); //设置过期时间,单位是ms arguments.put(\"x-message-ttl\",10000); return QueueBuilder.durable(QUEUE_A).withArguments(arguments).build(); } //普通队列B，过期时间为40s @Bean(\"queueB\") public Queue queueB(){ Map&lt;String, Object&gt; arguments = new HashMap&lt;&gt;(); arguments.put(\"x-dead-letter-exchange\",Y_DEAD_LETTER_EXCHANGE); arguments.put(\"x-dead-letter-routing-key\",\"YD\"); //设置过期时间,单位是ms arguments.put(\"x-message-ttl\",40000); return QueueBuilder.durable(QUEUE_B).withArguments(arguments).build(); } //死信队列QD @Bean(\"queueD\") public Queue queueD(){ return QueueBuilder.durable(DEAD_LETTER_QUEUE).build(); } //绑定.队列QA和交换机X绑定，Routing Key为XA @Bean public Binding queueABindingX(@Qualifier(\"queueA\") Queue queueA, @Qualifier(\"xExchange\") DirectExchange xExchange){ return BindingBuilder.bind(queueA).to(xExchange).with(\"XA\"); } //绑定.队列QB和交换机X绑定，Routing Key为XB @Bean public Binding queueBBindingX(@Qualifier(\"queueB\") Queue queueB, @Qualifier(\"xExchange\") DirectExchange xExchange){ return BindingBuilder.bind(queueB).to(xExchange).with(\"XB\"); } //绑定.队列QD和交换机Y绑定，Routing Key为YD @Bean public Binding queueDBindingY(@Qualifier(\"queueD\") Queue queueD, @Qualifier(\"yExchange\") DirectExchange yExchange){ return BindingBuilder.bind(queueD).to(yExchange).with(\"YD\"); }} 创建队列可以使用new Queue()方式，也可以使用QueueBuilder构建器的方式。 同样地，声明交换机和Binding都有new和构建器两种方法。 4、创建生产者和消费者 生产者： 12345678910111213141516171819202122232425@RestController@RequestMapping(\"/ttl\")public class SendMsgController { @Autowired private RabbitTemplate rabbitTemplate; @GetMapping(\"/sendMsg/{message}\") public void sendMsg(@PathVariable String message){ System.out.println(\"发送消息：\"+message); rabbitTemplate.convertAndSend(\"X\",\"XA\",\"消息来自ttl为10s的队列：\"+message); rabbitTemplate.convertAndSend(\"X\",\"XB\",\"消息来自ttl为40s的队列：\"+message); } //发送带有ttl的消息，消息的过期时间由消息本身确定，不需要单独创建队列 @GetMapping(\"/sendExpirationMsg/{message}/{ttlTime}\") public void sendMsg(@PathVariable String message,@PathVariable String ttlTime){ System.out.println(new Date()+\"发送一条时长为\"+ttlTime+\"毫秒的消息:\"+message); rabbitTemplate.convertAndSend(\"X\",\"XC\",message,msg-&gt;{ //设置消息的ttl大小 msg.getMessageProperties().setExpiration(ttlTime); return msg; }); }} 消费者： 123456789@Componentpublic class DeadLetterQueueConsumer { //从QD死信队列接收消息 @RabbitListener(queues = \"QD\") public void receiveD(Message message) throws Exception{ String msg = new String(message.getBody()); System.out.println(new Date()+\"收到死信队列的消息：\"+msg); }} 5、运行结果 测试QA和QB这两个设置TTL属性的队列。 在浏览器中访问http://localhost:8080/ttl/sendMsg/hello world，消费者在10s和40s后会收到内容为hello world的两条消息。这两条消息的延迟时间是由队列本身决定的。 测试指定消息TTL。 在浏览器中访问http://localhost:8080/ttl/sendExpirationMsg/hello world/10000，消费者会在10s后收到消息。这种方式可以任意指定TTL的大小，可以适用于任意的延迟时间。 比较队列TTL和消息TTL两种方式 队列设置TTL属性实现延迟队列，这种方式中，当队列到了过期时间，一定会被放到死信队列。但是这种方式不够灵活，如果想要改变延迟时间，就需要新建队列，面对大量不同时间需求，无法实现。 消息设置TTL属性实现延迟队列，这种方式足够灵活，可以满足任意的延迟时间的需求。但是这种方式的严重缺陷是如果队列中消息积压，会导致过期的消息无法被丢弃（放到死信队列），导致死信队列的消费者无法按时收到消息。 比如，如果第一个消息的过期时间较长，第二个消息的过期时间较短，则两个消息如果先后发送，会同时被消费者收到。因为RabbitMQ只检查当前第一个消息，直到等到第一个消息到了TTL时间，才会被死信队列收到，然后第二个消息被处理。 正确的结果应该是根据消息的TTL，第二个消息先到达。 为了解决TTL消息的这种缺陷，我们可以使用插件实现延迟队列，满足不同延迟时间的需求。 7.4 RabbitMQ插件实现延迟队列7.4.1 安装插件rabbitmq_delayed_message_exchange插件正是为了解决TTL消息无法及时死亡的问题。 在https://www.rabbitmq.com/community-plugins.html 地址下载插件并安装。 下载完以后，将.ez后缀的文件复制到usr/lib/rabbitmq/lib/rabbitmq_server-3.x.x/plugins目录，这个目录用于存放RabbitMQ的插件。 进入到这个目录，然后执行语句： 1rabbitmq-plugins enable rabbitmq_delayed_message_exchange 即可安装插件。 安装成功以后，在web管理界面，添加交换机可以看到新增的x-delayed-message类型。 7.4.2 代码实现如图，使用插件实现延迟队列的原理是创建一个类型为x-delayed-message的交换机（延迟交换机），这个类型的交换机支持延迟投递机制，即消息传递到以后先暂存到mnesia表中，到达指定的延迟时间以后才将消息投递出去。 这种方式在发送消息的时候设置每条消息的延迟时间，延迟交换机根据7延迟时间发送消息。 结构图 实现代码框架和思路和7.3相同： 1、编写配置类，创建各个组件： 1234567891011121314151617181920212223242526272829303132@Configurationpublic class DelayedQueueConfig { //延迟交换机 public static final String DELAYED_EXCHANGE_NAME = \"delayed.exchange\"; //队列 public static final String DELAYED_QUEUE_NAME = \"delayed.queue\"; //Routingkey public static final String DELAYED_ROUTING_KEY = \"delayed.routingkey\"; //声明交换机,使用自定义类型的交换机 //交换机类型为\"x-delayed-message\"，传播模式为direct @Bean public CustomExchange delayedExchange(){ Map&lt;String,Object&gt; arguments = new HashMap&lt;&gt;(); arguments.put(\"x-delayed-type\",\"direct\"); //声明匹配模式 return new CustomExchange(DELAYED_EXCHANGE_NAME,\"x-delayed-message\",true,false,arguments); } //声明队列 @Bean public Queue delayedQueue(){ return new Queue(DELAYED_QUEUE_NAME); } //binding @Bean public Binding delayQueueBindingDelayedExchange( @Qualifier(\"delayedQueue\") Queue delayedQueue, @Qualifier(\"delayedExchange\") CustomExchange delayedExchange){ //自定义类型交换机需要调用noargs()或args()方法指定是否有参数 return BindingBuilder.bind(delayedQueue).to(delayedExchange).with(DELAYED_ROUTING_KEY).noargs(); }} 创建延迟交换机，需要创建自定义交换机，即CustomExchange，类型为x-delayed-message，然后设置分配模式。 CustomExchange交换机的绑定，需要调用noargs()或args()指定有无参数。 2、生产者代码： 123456789101112//发送消息。基于插件，使用延迟交换机。@GetMapping(\"/sendDelayedMsg/{message}/{delayTime}\")public void sendDelayedMsg(@PathVariable String message,@PathVariable Integer delayTime){ System.out.println(new Date()+\"给延迟交换机发送一条延迟时间为\"+delayTime+\"毫秒的消息:\"+message); rabbitTemplate.convertAndSend(DelayedQueueConfig.DELAYED_EXCHANGE_NAME, DelayedQueueConfig.DELAYED_ROUTING_KEY,message, msg-&gt;{ //设置延迟时间 msg.getMessageProperties().setDelay(delayTime); return msg; });} 在发送消息时，调用setDelay()方法设置延迟时间。 3、消费者代码： 12345678@Componentpublic class DelayQueueConsumer { @RabbitListener(queues = DelayedQueueConfig.DELAYED_QUEUE_NAME) public void receiveDelayQueue(Message message) { String msg = new String(message.getBody()); System.out.println(new Date() + \"收到延迟队列的消息：\" + msg); }} 这样，在浏览器中访问http://localhost:8080/ttl/sendDelayedMsg/hello world/10000，消费者会在10s后收到消息。并且，对于先后发送的多条延迟时间不同的消息，消费者也能在正确的延迟时间后收到消息。 八、发布确认SpringBoot版发布确认用于确保消息的可靠投递，如果消息投递成功，返回确认信息，如果投递失败，返回失败信息并确保消息不会丢失。 第四章提到过发布确认，这里要讲的是在SpringBoot项目中使用发布确认机制。 8.1 发布确认发布确认的回调方法可以判断出交换机是否收到消息，当交换机宕机或其他原因导致交换机没有收到生产者发出的消息时，回调方法能够做出反馈。 实现代码 1、配置文件 需要在配置文件中配置开启发布确认： 12# 配置交换机发布确认，correlated表示发布消息成功到交换机后会触发回调方法spring.rabbitmq.publisher-confirm-type=correlated 确认类型有三种： none表示禁用发布确认模式。 correlated表示发布消息成功到交换器后会触发回调方法。 simple不仅有和correlated相同的功能，此外，simple模式在发布消息成功后使用rabbitTemplate调用watiForConfirms或waitForConfirmsOrDie方法等待broker节点返回发送结果，根据返回结果来判定下一步的逻辑。 2、添加配置类，构建各个组件 ConfirmConfig.java: 12345678910111213141516171819202122232425@Configurationpublic class ConfirmConfig { public static final String CONFIRM_EXCHANGE_NAME = \"confirm_exchange\"; //交换机 public static final String CONFIRM_QUEUE_NAME = \"confirm_queue\"; //队列 public static final String CONFIRM_ROUTING_KEY = \"key1\"; //绑定 //声明确认交换机 @Bean public DirectExchange confirmExchange(){ return new DirectExchange(CONFIRM_EXCHANGE_NAME); } //声明确认队列 @Bean public Queue confirmQueue(){ return new Queue(CONFIRM_QUEUE_NAME,true); } //确认交换机和确认队列的绑定 @Bean public Binding queueBingdingExchange(@Qualifier(\"confirmExchange\") DirectExchange directExchange, @Qualifier(\"confirmQueue\") Queue queue){ return BindingBuilder.bind(queue).to(directExchange).with(CONFIRM_ROUTING_KEY); }} 3、生产者代码 生产者代码可以指定消息id，即回调接口中消息的id。 此外，可以通过修改交换机和队列的名字，模拟交换机/队列宕机的故障情况。 ProducerController.java： 123456789101112131415161718192021@RestController@RequestMapping(\"/confirm\")public class ProducerController { @Autowired private RabbitTemplate rabbitTemplate; @GetMapping(\"/send/{message}\") public void sendMessage(@PathVariable String message){ //发送消息 CorrelationData correlationData = new CorrelationData(\"1\"); //设置回调接口中的消息,id为1 rabbitTemplate.convertAndSend(ConfirmConfig.CONFIRM_EXCHANGE_NAME, ConfirmConfig.CONFIRM_ROUTING_KEY,message,correlationData); //模拟队列宕机的情况 CorrelationData correlationData2 = new CorrelationData(\"2\"); //设置回退接口中的消息,id为2 rabbitTemplate.convertAndSend(ConfirmConfig.CONFIRM_EXCHANGE_NAME, ConfirmConfig.CONFIRM_ROUTING_KEY+\"aaaa\", message,correlationData2); System.out.println(\"已发送消息\"); }} 4、回调接口 我们需要实现RabbitTemplate类的一个内部接口，并重写其中的confirm方法，用来判断交换机是否收到消息。 MyCallBack.java 123456789101112131415161718192021222324@Componentpublic class MyCallBack implements RabbitTemplate.ConfirmCallback{ //由于实现的是内部类，RabbitTemplate对象不包括当前对象。 //需要将MyCallBack对象注入到RabbitTemplate中。 //第二种方式是不使用这种实现接口的方式，在配置类中实现接口 @Autowired private RabbitTemplate rabbitTemplate; //将当前实现类注入到RabbitTemplate中,postConstruct会在autowired之后执行 @PostConstruct public void init(){ rabbitTemplate.setConfirmCallback(this); } @Override public void confirm(CorrelationData correlationData, boolean ack, String reason) { String id = correlationData != null ? correlationData.getId() : \"\"; if(ack){ System.out.println(\"交换机收到了id为\"+id+\"的消息\"); }else{ System.out.println(\"交换机未收到消息，原因为\"+reason); } } } 关于@PostConstruct注解，参考https://www.cnblogs.com/lay2017/p/11735802.html confirm()方法的参数解析： correlationData保存回调消息的ID及相关信息 ack表示交换机是否收到了消息。true表示交换机接收到了消息，否则表示接收消息失败。 reason表示消息接收失败的原因，如果接收成功则为null 5、消费者代码 消费者代码就是正常的接收消息。 ConfirmConsumer.java： 1234567@Componentpublic class ConfirmConsumer { @RabbitListener(queues = ConfirmConfig.CONFIRM_QUEUE_NAME) public void receiveConfirmMessage(Message message){ System.out.println(\"消费者接收到消息：\"+new String(message.getBody())); }} 结果分析 状态正常时，消费者接收到消息，回调方法ack为true。 交换机宕机，消费者收不到消息，回调方法ack为false。 队列宕机，或者消息无法路由，消费者收不到消息，但是回调方法ack为true，表示交换机收到了消息（虽然没有被路由到队列）。 8.2 回退消息由上一节的发布确认机制可知，生产者通过回调方法只能得知消息有没有被发送到交换机，如果消息不可路由，那么消息会被直接丢弃，生产者并不知道消息被丢弃。为了解决这一问题，需要回退消息机制。 回退消息用在消息无法被路由（队列宕机）的情况。 回退消息的实现和发布确认类似，不同之处为： 1、设置参数： 12# 开启消息回退机制，如果消息无法被路由，则消息会被回退spring.rabbitmq.publisher-returns=true 2、配置类： 配置类中需要实现RabbitTemplate.ReturnsCallback内部接口，并实现其中的方法。 MyCallBack.java： 123456789101112131415161718@Componentpublic class MyCallBack implements RabbitTemplate.ReturnsCallback { @Autowired private RabbitTemplate rabbitTemplate; @PostConstruct public void init(){ //true表示交换机发现消息无法被路由时，会将消息返回给生产者；false表示直接丢弃。 rabbitTemplate.setMandatory(true); rabbitTemplate.setReturnsCallback(this); } //回退消息，当消息无法被路由，会被回退。 @Override public void returnedMessage(ReturnedMessage returnedMessage) { String replyText = returnedMessage.getReplyText(); System.out.println(\"消息被回退，回退原因为：\"+replyText); }} 生产者和消费者的实现并无特殊。当发送的消息无法被路由（比如队列宕机、RoutingKey错误等）时，会调用回退方法。 通过发布确认机制，生产者可以得知消息是否被交换机接收；通过回退消息机制，生产者可以得知消息消息是否被分发到队列中。 8.3 备份交换机通过回退消息，我们可以感知到无法被路由的消息，但是只能把消息回退，无法继续处理。想要处理无法被路由的消息，需要使用备份交换机。 备份交换机可以理解为RabbitMQ中交换机的备胎，当交换机收到一条不可路由消息时，将会把这条消息转发到备份交换机中。通常备份交换机的类型为Fanout，这样就能将不可路由消息广播到所有和它绑定的队列中。 备份交换机除了添加备份队列以外，还可以添加一个报警队列，这样如果有无法被路由的消息，报警队列的消费者可以发出警报信息进行提示。 和死信队列不同的是，死信队列是消息已经转发到了队列，而备份交换机处理的是不能被路由转发到队列的消息。 备份交换机 如图，正常交换机无法路由的消息会交给备份交换机处理，备份交换机接收到消息后，将消息广播，其中一个队列是报警队列，用于提示消息无法路由。 实现备份交换机，需要在声明普通交换机的时候添加备份交换机： 12345//声明一个交换机，其备份交换机为\"backup_exchange\"Exchange exchange = ExchangeBuilder.directExchange(\"confirm_exchange\"). durable(true). withArgument(\"alternate-exchange\",\"backup_exchange\"). build(); 备份交换机需要声明为fanout类型： 1FanoutExchange exchange = new FanoutExchange(\"backup_exchange\"); 然后声明报警队列和消费者队列，并且声明各自和交换机之间的绑定。 其中，报警队列的消费者可以用来发出警告信息，表示生产者发出的消息无法被路由： 12345678@Componentpublic class WarningConsumer { //报警队列 @RabbitListener(queues = \"warning_queue\") public void receiveWarningMessage(Message message){ System.out.println(\"报警！发现不可路由消息：\"+new String(message.getBody())); }} 如果消息回退机制和备份交换机同时配置，则备份交换机机制优先。因为备份队列收到了消息，理解为消息成功路由。 九、RabbitMQ其他知识点9.1 幂等性幂等性(idempotence)指的是用户对同一操作发起的一次请求或多次请求的结果是一致的，不会因为多次点击而产生了副作用。消息重复消费时需要考虑消息的幂等性。 消息重复消费：如果MQ已经把消息发送给了消费者，消费者在返回ack时网络中断，MQ未收到确认消息，会将消息重新发送给其他的消费者，或者再次发送给该消费者，就会造成消息重复消费。 解决方式： 对于消费端，可以使用全局ID或者唯一标识比如时间戳等唯一的id，每次消费时用该id判断该消息是否已消费过。 对于发送端，有两种方式：①唯一ID+指纹码机制（基于业务规则拼接的唯一字符串），查询数据库判断是否重复；②利用redis的原子性，setnx指令天然具有幂等性。 9.2 优先队列优先队列可以根据消息的优先级进行消息的分发，优先队列会将队列中的消息按照优先级进行排序，按照优先级从高到低的顺序进行消息的发送，而不考虑消息进入队列的顺序。因此，使用优先级队列需要确保所有消息都发送到队列中以后，消费者才开始消费，确保这些消息能够在队列中排序。 使用优先队列需要满足两个条件：①队列是优先队列；②消息需要设置优先级。 声明优先队列： 123Map&lt;String, Object&gt; params = new HashMap();params.put(\"x-max-priority\",10); //设置队列为优先级队列，且消息的最大优先级为10channel.queueDeclare(\"Q1\",true,false,false,params); 设置消息的优先级： 123// 在生产者代码中，设置消息的优先级为5AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(5).build();channel.basicPublish(\"exchange\",\"routingKey\",properties,message.getBytes(\"UTF-8\")); 当不同优先级的消息都进入优先队列以后，优先队列将消息进行排序，然后消费者进行消费，接收到的消息是按照优先级从高到低排列。 9.3 惰性队列RabbitMQ 3.6.0版本引入了惰性队列的概念。惰性队列会尽可能的将消息存入磁盘中，消费者消费到对应的消息时，才会被加载到内存中。 惰性队列的目的是为了能够支持更长的队列，当消费者下线或者宕机等情况导致长时间不能消费消息造成堆积时，惰性队列就发挥作用了。 开启惰性队列： 123Map&lt;String, Object&gt; params = new HashMap();params.put(\"x-queue-mode\",lazy); //设置队列为惰性队列channel.queueDeclare(\"Q1\",false,false,false,params); x-queue-mode表示队列的模式，默认为default模式，如果想要声明惰性队列，则将其设置为lazy模式即可。 在面对大量消息积压的情况下，惰性队列能够占用更少的内存，从而存储更多的消息。 十、RabbitMQ集群10.1 集群搭建RabbitMQ集群是指搭建多台RabbitMQ服务器，这样当其中的某台服务器出现故障时，其他服务器可以保障服务可用。并且集群能够提升服务的性能。 搭建步骤 需要准备三台机器。 建立三个节点，node1-node2-node3 1、修改3台机器的主机名称 将3台机器的主机名分别修改为node1、node2、node3，方便识别。 12# 在/etc/hostname文件中修改vim /etc/hostname 2、配置各个节点的hosts文件 配置hosts文件，确保各个节点能够互相认识对方。 1vim /etc/hosts 在每台主机的/etc/hosts文件中添加三个节点的ip地址和主机名，比如： 123123.123.123.1 node1123.123.123.2 ndoe2123.123.123.3 node3 3、确保各个节点的cookie文件相同 在其中一个节点上，比如node1节点上，执行远程复制命令，将本机的cookie文件远程复制到另外两个节点中： 12scp /var/lib/rabbitmq/.erlang.coolie root@node2:/var/lib/rabbitmq/.erlang.cookiescp /var/lib/rabbitmq/.erlang.coolie root@node3:/var/lib/rabbitmq/.erlang.cookie 4、启动RabbitMQ服务 在每台机器上启动RabbitMQ服务： 12# detached代表以后台守护进程方式启动rabbitmq-server start -detached 5、将节点加入集群 在node2中执行下列指令，将node2加入到node1的集群： 12345# stop_app表示之关闭RabbitMQ服务，stop则会将Erlang虚拟机也关闭rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl join_cluster rabbit@node1rabbitmqctl start_app 同理，将node3加入到node2的集群。 6、查看集群状态 1rabbitmqctl cluster_status 7、需要重新设置用户 123456# 添加用户，用户名admin，密码123rabbitmqctl add_user admin 123# 设置用户角色rabbitmqctl set_user_tags admin administrator# 设置用户权限rabbitmqctl set_permissions -p \"/\" admin \".*\" \".*\" \".*\" 至此，包括三个节点的集群搭建完成。 如果想要解除集群节点，需要在节点中执行解除指令，比如 在节点1中解除节点2，需要在节点1中执行下面的指令： 12# node1解除node2节点rabbitmqctl forget_cluster_node rabbit@node2 10.2 镜像队列镜像队列是指将队列镜像到集群中的其他Broker节点之上，这样当集群中某一节点失效后，队列能够自动切换到镜像中的另一个节点上保证服务的可用性。 和集群保证的可用性不同的是，集群中某一节点宕机后，其中的队列都不可用了，队列中的消息也无法被消费。而镜像队列能够保证集群中的节点宕机后，队列中的消息也不会丢失。 搭建步骤 以3个集群节点为例，通过web管理页面创建镜像队列。 1、启动三个集群节点 2、添加policy 选一个节点，比如node1，然后Add/update a policy，进行如下设置： 镜像队列配置 如果在代码中设置镜像队列，参数名称前需要加x- 这样，在node1上创建一个队列，则其他两个节点都有这个队列的镜像队列。当node1宕机以后，可以继续使用node2节点中的队列，保证了高可用性。 10.3 高可用负载均衡1、使用Haproxy实现负载均衡。 Nginx、lvs、Haproxy之间的区别：http://www.ha97.com/5646.html 假设当前有一个Haproxy服务器，要负责一个3个节点的RabbitMQ集群的负载均衡，需要在Haproxy服务器配置如下： 安装Haproxy： 1yum -y install haproxy 修改haproxy.cfg： 1vim /etc/haproxy/haproxy.cfg 修改以下内容，将IP改为集群中节点的IP地址： 1234# 检测心跳频率server rabbitmq_node1 123.123.123.1:5672 check inter 5000 rise 2 fall 3 weight1server rabbitmq_node1 123.123.123.2:5672 check inter 5000 rise 2 fall 3 weight1server rabbitmq_node1 123.123.123.3:5672 check inter 5000 rise 2 fall 3 weight1 启动Haproxy： 123haproxy -f /etc/haproxy/haproxy.cfg# 查看服务是否启动ps -ef | grep haproxy 访问地址： http://haproxy主机地址:8888/stats 2、Keeplived实现双机热备份 上面只使用了一个Haproxy主机进行负载均衡，如果Haproxy主机宕机，虽然RabbitMQ集群没有故障，但是对于外界客户端来说所有的连接都会断开。为了确保负载均衡服务的可靠性，使用Keepalied做高可用，实现故障转移。 Keepalived能够通过自身健康检查，资源接管功能做双机热备份。 Keepalived实现双机热备的步骤可参考：https://blog.51cto.com/hellocjq/2089450 10.4 Federation PluginFederation插件的目的是在不同集群的Broker之间同步消息。 Federation plugin可以实现Federation Exchange和Federation Queue两种功能。 Federation Exchange 比如，位于两个地区（不同集群）的两个交换机，如果需要两个地区的用户访问两个节点速度一致，不会出现A地区用户访问B地区服务器延迟比较高的情况，需要使用Federation exchange。 将其中一个设置为上游交换机，另一个设置为下游交换机，这样发送到上游交换机的信息会通过federation机制同步到下游交换机。这样下游交换机的消费者访问两个交换机的速度是一致的。 Federation Plugin 搭建步骤参考：https://www.cnblogs.com/yeyongjian/p/13964161.html Federation Queue 联邦队列可以在多个Broker节点或集群之间，为单个队列提供负载均衡的功能。一个联邦队列可以连接一个或多个上游队列，并从这些上游队列中获取消息以满足本地消费者消费消息的需求。 Federation Queue 10.5 Shovel PluginShovel plugin能够可靠、持续地从一个Broker中的队列（源，source）拉去数据并转发到另一个Broker中的交换器中（目的端，destination）。 源端的队列和目的端的交换机可以同时位于同一个Broker，也可以位于不同的Broker上。 部署方法可以参考官方文档：https://www.rabbitmq.com/shovel.html","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://kangshitao.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://kangshitao.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://kangshitao.github.io/tags/RabbitMQ/"}]},{"title":"Nginx安装与配置","slug":"nginx","date":"2021-10-09T05:15:06.000Z","updated":"2022-05-22T13:30:54.800Z","comments":true,"path":"2021/10/09/nginx/","link":"","permalink":"http://kangshitao.github.io/2021/10/09/nginx/","excerpt":"Nginx安装，反向代理、负载均衡、动静分离案例","text":"一、安装Nginx环境： CentOS 7.9 Nginx 8.45 安装步骤： 1、首先需要确保系统已经安装了编译工具和库文件，可以使用yum命令安装： 12# 安装 make、zlib、zlib-devel、gcc-c++、libtool、openssl、openssl-develyum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 2、需要PCRE的支持 Nginx的安装需要PCRE的支持，PCRE的作用是让Nginx支持Rewrite功能。安装PCRE的步骤如下： 可以手动去官网下载安装包，或者使用wget命令下载： 首先进入/usr/src/目录，将pcre下载到这个目录 12[root@localhost /]# cd /usr/src/ [root@localhost src]# wget https://sourceforge.net/projects/pcre/files/pcre/8.45/pcre-8.45.tar.gz/download 解压文件 1[root@localhost src]# tar -zxvf download 解压后进入安装包目录 1[root@localhost src]# cd pcre-8.45/ 执行configure文件，编译并安装 12[root@localhost pcre-8.45]# ./configure[root@localhost pcre-8.45]# make &amp;&amp; make install 查看版本号，安装成功 12[root@localhost pcre-8.45]# pcre-config --version8.45 3、安装Nginx 手动下载，或者使用wget下载安装包。 同样在/usr/src/目录下下载安装包： 12[root@localhost src]# lsdebug kernels nginx-1.20.1.tar.gz pcre-8.45 然后解压： 1[root@localhost src]# tar -zxvf nginx-1.20.1.tar.gz 解压完后，进入nginx-1.20.1文件夹中，执行configure文件： 1[root@localhost nginx-1.20.1]# ./configure 编译并安装： 1[root@localhost nginx-1.20.1]# make &amp;&amp; make install 安装完成后，在/usr/local/目录会生成nginx的安装包： 12[root@localhost local]# lsbin etc games include lib lib64 libexec mysql nginx redis sbin share src 4、启动并测试Nginx 在/usr/local/nginx/sbin目录下就包括了Nginx的启动脚本。直接执行脚本即可启动Nginx服务： 1[root@localhost sbin]# ./nginx 在/usr/local/nginx/conf/目录下包括了各种配置文件，其中nginx.conf为nginx的配置文件，里面配置了Nginx的默认监听端口为80，我们可以使用curl命令访问测试： 1234567891011121314151617181920212223242526[root@localhost conf]# curl localhost:80&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; }&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=\"http://nginx.org/\"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=\"http://nginx.com/\"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 可以看到，返回了html页面的内容，说明安装成功，并能够连接到Nginx。 5、修改端口号 默认情况下，由于防火墙限制，外界是无法直接访问Linux中Nginx的，有两个解决方法： 关闭Linux的防火墙。 开放访问的端口号，不需要关闭防火墙。 查看开放的端口号： 1firewall-cmd --list-all 设置要开放的端口号： 12# 将80端口开放，并使其永久生效firewall-cmd --add-port=80/tcp --permanent 重启防火墙即可生效。 1firewall-cmd --reload 或者使用： 1systemctl restart firewalld.service 这样，即使不关闭防火墙，外界也能通过地址访问到Nginx。 二、常用命令如果不配置环境变量，则使用Nginx命令需要在按照目录下面的sbin/目录中使用，即/usr/local/nginx/sbin/目录里面。 1、查看Nginx的版本号： 12[root@localhost sbin]# ./nginx -vnginx version: nginx/1.20.1 2、查看帮助： 123456789101112131415161718[root@localhost sbin]# ./nginx -hnginx version: nginx/1.20.1Usage: nginx [-?hvVtTq] [-s signal] [-p prefix] [-e filename] [-c filename] [-g directives]Options: -?,-h : this help -v : show version and exit -V : show version and configure options then exit -t : test configuration and exit -T : test configuration, dump it and exit -q : suppress non-error messages during configuration testing -s signal : send signal to a master process: stop, quit, reopen, reload -p prefix : set prefix path (default: /usr/local/nginx/) -e filename : set error log file (default: logs/error.log) -c filename : set configuration file (default: conf/nginx.conf) -g directives : set global directives out of configuration file 3、启动Nginx： 1[root@localhost sbin]# ./nginx 4、关闭Nginx： 1[root@localhost sbin]# ./nginx -s stop 5、重新加载Nginx，即不需要重启，只重新加载配置文件： 1[root@localhost sbin]# ./nginx -s reload 三、Nginx配置文件Nginx的配置文件默认为/usr/local/nginx/conf/nginx.conf。 nginx.conf配置文件主要有三部分组成： 第一部分：全局块 全局块指的是配置文件开始到events块之间的内容。主要配置服务器整体运行的配置指令，比如配置运行Nginx服务器的用户（组）、允许生成的worker process数，进程PID存放路径、日志存放路径和类型以及配置文件的引入等。 第二部分：events块 events块主要影响Nginx服务器和用户的网络连接。常用的设置包括是否开启对多work process下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个word process可以同时支持的最大连接数等。 这部分配置对Nginx的性能影响较大。 第三部分：http块 http块是Nginx服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。 http块又分为http全局块和server块。 http全局块：包括文件引入、MIME-TYPE定义、日志自定义、连接超时时间、单链接请求数上限等。 server块：每个http块可以包括多个server块，每个server块相当于一个虚拟主机。每个server块也分为全局server块和location块： 全局server块：常见的配置包括本虚拟主机的监听配置、名称或IP配置 location块：一个server块可以配置多个location块。主要作用是基于Nginx服务器接收到的请求字符串，对虚拟主机名称之外的字符串进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，以及一些第三方模块的配置也在这里进行。 四、反向代理1、概念正向代理：代理的对象是客户端。客户端通过代理访问服务器，但服务端不知道具体的客户端是谁。 反向代理：代理的对象是服务器。客户端直接访问代理，代理去访问服务器，客户端只知道代理是谁，不知道服务器是谁。 2、实例一实现效果：在浏览器中访问www.hellonginx.com，跳转到Linux系统tomcat主页面中。 流程：www.hellonginx.com—-&gt;Nginx代理服务器—-&gt;tomcat服务器 准备工作： 确保Linux系统安装了tomcat，这里使用默认端口8080。 确保外界能够访问到Linux系统中的tomcat。可以通过设置开放端口、直接关闭防火墙两种方式。 具体配置： 1、将域名和Nginx主机地址做映射。 在Windows系统的host文件中进行域名和ip对应关系的配置，即域名对应Nginx的主机地址，例www.hellonginx.com—-192.168.198.198:80。 在C:\\Windows\\System32\\drivers\\etc\\hosts文件中，添加内容： 1192.168.198.198 www.hellonginx.com 配置好以后，在Windows系统浏览器中输入www.hellonginx.com就会访问Linux系统的Nginx，因为http默认端口就是80端口。 2、在Nginx中进行请求转发的配置（反向代理配置）。 在Nginx的配置文件nginx.conf中，在http块的server块中，将主机名改为主机ip地址，然后在location块中，添加请求转发的地址： 1proxy_pass http://127.0.0.1:8080 配置好以后的内容如下图： 反向代理配置 保存以后，重启Nginx服务即可生效。 反向代理成功 3、实例二实现效果：使用Nginx反向代理，根据访问的路径跳转到不同端口的服务中。 比如Nginx的监听端口为9001： 访问http://192.168.198.198:9001/edu/，直接跳转到192.168.198.198:8080 访问http://192.168.198.198:9001/vod/，直接跳转到192.168.198.198:8081 准备工作： 1、需要准备两个tomcat服务器，一个是8080端口，一个是8081端口。 可以使用docker容器，创建两个容器，分别用两个端口映射。也可以使用基础的方法，安装两个tomcat，将其中一个tomcat的默认端口号改为8081，在安装目录的server.xml文件中修改端口号。 启动两个tomcat。 成功启动两个tomcat 2、在两个tomcat服务器中分别准备两个测试页面。 在8080端口的tomcat服务器的webapps文件夹中创建目录edu，然后创建文件edu/0.html，测试通过192.168.198.198:8080/edu/0.html能够访问成功。 在8081端口的tomcat服务器的webapps文件夹中创建目录vod，然后创建文件edu/1.html，测试通过192.168.198.198:8081/edu/1.html能够访问成功。 具体配置： 在Nginx的配置中，在http块中添加一个server块，内容如下 1234567891011server { listen 9001; # 监听端口9001 server_name 192.168.198.198; #代理服务器ip location ~/edu/ { # 添加规则：如果请求中包括edu，则跳转到http://127.0.0.1:8080 proxy_pass http://127.0.0.1:8080; } location ~/vod/ { proxy_pass http://127.0.0.1:8081; }} location后面的~表示后面的字符串是正则表达式形式。 注意：如果是在外面系统访问Linux中的Nginx，记得开放端口，9001、8080、8081都需要开放。 代理结果 配置好以后，重新加载Nginx或者重启服务即可。就可以实现根据条件代理到不同服务器的效果： 反向代理不同服务器 浏览器访问192.168.198.198:9001/edu/0.html，通过Nginx反向代理，会访问192.168.198.198:8080/edu/0.html 关于location反向代理的匹配规则，可以参考：https://segmentfault.com/a/1190000009651161 五、负载均衡1、实例实现目标 在浏览器输入http://192.168.198.198/edu/a.html，通过负载均衡，将请求平均分发到8080和8081两个tomcat服务器上。 准备工作 准备两台tomcat服务器，一台端口为是8080，另一台为8081。确保在Linux系统外都能够访问到这两个服务器。 在两个tomcat服务器的webapps目录下，创建edu/a.html文件，用于测试 具体配置 在Nginx的配置文件nginx.conf中配置。 在http块中添加upstream，命名为myserver，然后列出服务器的列表。 在server块中的location中添加规则，设置proxy_pass的值为http://myserver。 负载均衡配置 重新加载Nginx即可生效。这样，每次访问192.168.198.198:80时，Nginx服务器会将请求根据配置要求分发到myserver列出的服务器中。 2、分配策略Nginx的实现负载均衡有以下几种分配服务器策略： 1、轮询（默认） 轮询方式是Nginx默认的分配方式。 轮询是指每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 2、权重weight weight表示权重，默认为1，权重越高被分配的客户端越多。 配置方式： 1234upstream server_pool{ server 192.168.198.198:8080 weight=5; server 192.168.198.198:8081 weight=10;} 3、ip_hash 每个请求按访问ip的hash结果分配，这样同一个ip地址每次访问固定的一个后端服务器，可以解决session共享的问题。 配置方式： 12345upstream server_pool{ ip_hash; server 192.168.198.198:8080; server 192.168.198.198:8081;} 4、fair 按照后端服务器的响应时间分配请求，响应时间短的优先分配。 配置方式： 12345upstream server_pool{ server 192.168.198.198:8080; server 192.168.198.198:8081; fair;} 六、动静分离1、概念动静分离：将动态请求和静态请求分开，可以理解为使用Nginx处理静态页面，Tomcat处理动态页面。 静态请求比如html页面、css样式、image图片等。 动态请求比如请求数据库的数据等。 动静分离有两种实现方式： 第一种是将静态文件独立成单独的域名，放在独立的服务器上。是目前常用的方法。 第二种是动态和静态文件混合在一起发布，通过Nginx分开。 通过配置文件的location可以指定不同的后缀名实现不同的请求转发。 expires参数可以设置浏览器缓存的过期时间。每次请求时，会对比服务器文件的更新时间，如果没有变化，则直接从浏览器缓存中取数据，否则才会从服务器下载。适合不经常变动的资源。 2、实例实现目标 对于静态资源，使用Nginx访问，不通过tomcat服务器。 资源准备 准备好a.html和一个图片，例如/data/www/a.html和/data/image/abc.jpg。 具体配置 主要配置是在server块的location中： 动静分离配置 root表示根目录，以/www/为例，当访问192.168.198.198/www/a.html时，Nginx会去访问/data/www/a.html。 index用于查找主页。 autoindex on表示开启自动显示目录。 效果如下，这样的静态请求不会经过tomcat，由Nginx代理直接访问指定的目录。因此即使tomcat关闭，不会影响以下请求： 动静分离实现效果","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://kangshitao.github.io/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://kangshitao.github.io/tags/Nginx/"}]},{"title":"Redis基础","slug":"redis","date":"2021-07-30T09:16:56.000Z","updated":"2022-05-22T13:30:54.802Z","comments":true,"path":"2021/07/30/redis/","link":"","permalink":"http://kangshitao.github.io/2021/07/30/redis/","excerpt":"Redis数据库的数据类型、事务、配置、主从配置等","text":"一、Redis入门Redis（Remote Dictionary Server）远程字典服务。基于键值对的NoSQL数据库 Redis教程参考：Redis中文教程 Redis命令参考：Redis命令 1.1 Redis安装获取安装包： 1wget http://download.redis.io/releases/redis-5.0.8.tar.gz 一般我们将安装的第三方文件放到usr/local目录下。 因此将其解压到usr/local/redis目录下，作为redis的根目录。 解压到指定目录： 1tar xzvf redis-5.0.8.tar.gz /usr/local/redis 进入redis目录进行安装： 1234cd redis# 因为Redis是c语言编写的，需要gcc编译器的支持，因此需要保证系统中已安装了gcc# 编译make 编译后，在redis目录下会生成一个src目录，里面包含了redis-server服务端和redis-cli客户端，已经可以启动redis服务了。 编译后的目录 通常，我们还会执行make install进行安装，这样可以方便管理： 1234# 进入src目录cd src# 安装，并指定安装的位置，在这个位置下会生成一个bin目录make install PREFIX=/usr/local/redis 安装完后，指定的/usr/local/redis目录下会生成一个bin目录，这个目录里面包含了常用的几个可执行文件，我们将redis/redis.conf配置文件复制一份到redis/bin这个目录，作为我们自己的配置文件。 1cp redis.conf ./bin/myredis.conf bin目录 这样，我们以后只需要在redis/bin这个目录下进行操作就可以了。 redis服务默认是前台执行的，将配置文件中的daemonize值修改为yes，就可以将redis启动为后台进程。 在bin目录下启动redis服务端： 12# 在bin目录下，根据指定的配置文件启动,如果不指定，会根据默认的配置文件启动./redis-server myredis.conf 启动成功。 1.2 Redis启动Redis的默认端口号是6379。 启动服务端，在安装目录下： 1234# 使用默认的配置文件启动./redis-server # 也可以使用指定的配置文件启动./redis-server redis-config.conf 启动客户端连接服务端： 1./redis-cli -p 6379 如果是服务端就是本机，则端口号和服务器主机地址可以不用写 在客户端中，可以使用exit命令退出连接，使用shutdown命令关闭服务端。 Redis命令不区分大小写。 redis默认有16个数据库，select命令选择指定的数据库 12# 选择第0号数据库select 0 清空当前数据库： 1flushdb 清空所有数据库： 1flushall 删除当前数据库的某个key 1del mykey Redis是单线程的，基于内存的，没有使用多线程，redis6.0之后引入了多线程，主要是为了提高网络IO读写性能。 Redis基于内存，因此其瓶颈主要受限于内存和网络。 1.3 Redis速度快的原因1、基于内存 Redis的绝大部分请求是纯粹的内存操作，非常快速。 2、数据结构简单 Redis的数据结构简单，并且数据操作也简单，Redis中的数据结构是专门采用C语言进行设计的 3、采用单线程 Redis使用单线程模型，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不需要考虑锁的问题以及加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。 因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈是内存的大小和网络带宽，因此可以采用单线程的方式。 Redis在4.0版本加入了多线程支持，主要的目的是针对大键值对删除操作的命令，使用这些命令就会使用主处理之外的其他线程来“异步处理”。 Redis 6.0正式引入了多线程，目的是为了提高网络IO读写性能。Redis6.0虽然引入了多线程，但是只在网络数据的读写这类耗时操作上使用，执行命令仍然是单线程顺序执行。 4、使用多路I/O复用模型 Redis虽然是单线程，但采用非阻塞的IO多路复用程序来监听来自客户端的大量连接。 非阻塞IO可以在等待期间做其他事情；阻塞IO等待期间什么也不能做。 5、使用底层模型不同 Redis自己构建了VM 机制 ，因为一般的系统调用系统函数，会浪费一定的时间去移动和请求； 二、数据类型Redis中有五种基本数据类型：String、List、Set、Hash、sorted set（Zset） 另外有三种特殊的数据类型：geospatial、hyperloglog、bitmaps 2.1 五大数据类型2.1.1 基础操作查看所有的key： 1keys * 设置一个key: 1set name Rick # 设置key为name，value为Rick 获取key的值： 1get name # 获取名为name的这个key的值 判断key是否存在： 1exists name # 判断name这个key是否存在 查看key的类型： 1type name # 查看name这个key的类型 移动指定key到其他数据库： 1move name 1 # 将当前数据库中的name这个键值对移动到1号数据库中 设置key的过期时间： 1expire name 10 # 将name这个key设置为10秒后过期，10s后就会被销毁 查看某个key的剩余存活时间 1ttl name # 查看name的剩余存活时间,-1表示永久有效 2.1.2 Stringappend追加字符串 12set key1 v1 # 设置一个keyappend key1 hello # 向key1的值后面追加一个字符串hello，结果为v1hello 如果当前key不存在，会新建一个，相当于set命令 strlen 查看字符串长度 1strlen key1 # key1为v1时，结果为2 incr将key的值+1，前提是key的值必须是整数： 12set key1 10 # 设置一个keyincr key1 # 将key1的值+1，结果是11 incrby：将key的值加上指定的值： 12set key1 10 # 设置key1的值为10incrby key1 5 # 将key1的值+5，结果是15 decr将key的值减一。 decrby将key的值减指定的值。 getrange获取指定范围的字符： 123set key1 hello getrange key1 0 3 # 获取key1的值的0-3范围的字符，结果是hellgetrange key1 0 -1 # hello，-1表示全部字符串 setrange替换指定位置开始的字符串： 123set key1 hellosetrange key1 3 world # helworld，将索引从3开始的字符开始往后替换setrange key1 1 hh # hhhworld，字符从指定位置向后覆盖 setex，set with expire，即设置一个带过期时间的key： 1setex key1 10 hello # 设置key1的值为hello，且10秒后过期 setnx，set if not exist，如果当前key不存在，就创建，否则创建失败（而普通的set指令会替换值）： 123set key1 hello # 当前有一个key1setnx key1 world # 返回值为0，表示设置失败，因为key1已经存在了setnx key2 world # 返回值为1，key2不存在的时候，会新建成功 mset和mget同时设置和获取多个值 12mset k1 v1 k2 v2 k3 v3mget k1 k2 k3 # 结果为v1 v2 v3 msetnx如果指定的key都不存在才创建，只要有一个已经存在，就创建失败，这是一个原子性的指令。 使用set/mset命令创建对象，可以有两种方式，一种是保存JSON格式的字符串，另一种则是以键值对的方式： 12345# 方式一：JSONset user:1 {name:Rick,age:20}# 方式二：完全使用键值对mset user:1:name Rick user:1:age:20 方式一保存了一条数据，key为user:1，value为{name:Rick,age:20}的数据； 方式二保存了两条数据，key为user:1:name，value为Rick；第二条数据的key为user:1:age，value为20。 两种方式都能够用来表示一个user对象，使用key来区分不同的对象。第二种方式的key是一个巧妙的设计。 getset先获取值，再设置值，如果key不存在，则会新建一个key，并把值赋进去： 12getset key1 value1 # 如果key1不存在，则会返回nilgetset key1 value2 # 再次执行，此时可以获取到上一条指令设置的value1 String类型的使用场景，value值除了是字符串以外，还可以是数字型的字符串，可以用来计算。 应用场景： 计数器 记录阅读量、浏览量等 2.1.3 Listlist，列表，可以当作栈、队列、阻塞队列来使用，本质是一个双向链表。具体用法参考：List list的指令一般是以l和r开头的。l可以理解为list或left，r理解为right。 list中的值，索引是从最新的值为0开始算的，类似于栈顶元素的索引值为0。 lpush向一个list中添加一个值或多个值，从左边添加，即从头部添加： 123456# 向list1这个list中添加3个数据1、2、3、4、5lpush list1 1lpush list1 2lpush list1 3lpush list1 4 5# 此时的list1值为5，4,3,2,1 lindex通过索引获取列表中的元素： 1lindex list1 0 # 值为5 此时数据1、2、3、4、5在list1中的索引为4、3、2、1、0 lrange取出list数据中指定范围的值： 1lrange list1 0 -1 # 获取list1的所有值 rpush在列表中添加一个或多个值，从尾部添加： 1rpush list1 0 # 此时的list1值为5,4,3,2,1,0 lpop从头部移除一个数据 rpop从尾部移除一个数据 blpop移除并获取列表的第一个元素 brpop移除并获取列表的最后一个元素 llen获取列表长度 lrem移除指定的元素： 12# 从key中，移除count个值为value的元素lrem key count value count&gt;0：从头到尾移除count个值为value的元素 count&lt;0：从尾到头移除count个置为value的元素 count=0：移除所有值为value的元素。 ltrim将一个list截取为指定的元素，list的值会改变。 rpoplpush移除列表最后一个元素，并将其添加到指定的列表 lset通过索引设置列表指定索引元素的值。前提是list和这个索引位置必须存在。 linsert在列表的指定的值前或后插入元素 应用场景 发布或订阅 消息队列、慢查询 2.1.4 Setset，集合，其中的值无序、不能重复。 set的指令以s开头。 指令 操作 sadd 向集合添加一个或多个成员 scard 获取集合的成员数 sdiff 返回给定所有集合的差集，返回值是第一个集合中独有的元素 sdiffstore 返回给定所有集合的差集并存储在指定集合中 sinter 返回给定所有集合的交集 sinterstore 返回给定所有集合的交集并存储在指定集合中 sismember 判断 member 元素是否是集合 key 的成员 smembers 返回集合中的所有成员 smove 将 member 元素从 source 集合移动到指定的集合 spop 移除并返回集合中的一个随机元素 srandmember 返回集合中一个或多个随机数 srem 移除集合中一个或多个成员 sunion 返回所有给定集合的并集 sunionstore 所有给定集合的并集存储在指定集合中 sscan 迭代集合中的元素 应用场景 需要存放的数据不能重复，以及需要获取多个数据源交集和并集的情况，比如共同关注，共同粉丝等。 2.1.5 Hashhash类似于HashMap，即key的值是一个键-值对（域-值对），即field和value的映射。特别适合存放对象。 12hset user:1 name Rick age 20 # 设置user:1这个hash的name为Rick，age为20hget user:1 name # 结果为Rick hash的指令以h开头，表示其操作是对hash类型的数据操作的。 命令 描述 hdel 删除一个或多个哈希表字段 hexists 查看哈希表key中，指定的字段是否存在 hget 获取存储在哈希表中指定字段的值 hgetall 获取在哈希表中指定key的所有字段和值 hset 设置哈希表中field的值 hsetnx 只有在字段filed不存在时，设置哈希表字段的值 hmget 获取所有给定字段的值 hmset 同时将多个filed-value对设置到哈希表中 hkeys 获取所有哈希表中的字段 hvals 获取哈希表中所有值 hincrby 为哈希表key中指定字段的整数值加上增量 hincrbyfloat 为哈希表key中指定字段的浮点数值加上增量 hlen 获取哈希表中字段的数量 hscan 迭代哈希表中的键值对 hstrlen 返回哈希表中与给定域field相关联的值的字符串长度 应用场景 常用于存储对象数据 2.1.6 ZsetZset，即sorted set，有序集合。与set相比，Zset增加了一个权重参数score，使得集合中的元素能够按照score进行有序排列，还可以通过score的范围来获取元素的列表。 命令 描述 zadd 向有序集合添加一个或多个成员，或者更新已存在成员的分数 zcard 获取有序集合的成员数 zcount 计算在有序集合中指定区间分数的成员数 zincrby 有序集合中对指定成员的分数加上增量 zinterstore 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中 zlexcount 在有序集合中计算指定字典区间内成员数量 zrange 通过索引区间返回有序集合成指定区间内的成员 zrangebylex 通过字典区间返回有序集合的成员 zrangebyscore 通过分数返回有序集合指定区间内的成员，默认是闭区间，-inf为负无穷，+inf正无穷 zrank 返回有序集合中指定成员的索引 zrem 移除有序集合中的一个或多个成员 zremrangebylex 移除有序集合中给定的字典区间的所有成员 zremrangebyrank 移除有序集合中给定的排名区间的所有成员 zremrangebyscore 移除有序集合中给定的分数区间的所有成员 zrevrange 返回有序集中指定区间内的成员，通过索引，分数从高到低 zrevrangebyscore 返回有序集中指定分数区间内的成员，分数从高到低排序 zrevrank 返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序 zscore 返回有序集中，成员的分数值 zunionstore 计算一个或多个有序集的并集，并存储在新的 key 中 zscan 迭代有序集合中的元素（包括元素成员和元素分值） 应用场景 常用于需要对数据根据权重进行排序的场景，比如成绩排名、直播间礼物排行榜、热度排行榜等 2.2 三种特殊数据类型2.2.1 geospatialRedis GEO 主要用于存储地理位置信息，并对存储的信息进行操作，是 Redis 3.2新增的类型。 Redis GEO 操作方法有： geoadd：添加地理位置的坐标。 geopos：获取地理位置的坐标。 geodist：计算两个位置之间的距离。 georadius：根据给定的经纬度坐标为中心，获取指定半径范围内的地理位置集合。 georadiusbymember：根据储存在位置集合里面的某个地点，获取指定半径范围内的地理位置集合。 geohash：返回一个或多个位置对象的 geohash 值。 使用举例： geoadd key 经度 纬度 member(即地点名) 12345geoadd city 116.40 39.90 beijing # key为city，成员为beijing，经纬度数据为116.4 39.90geoadd city 121.47 31.23 shanghaigeoadd city 120.16 30.24 hangzhougeoadd city 114.05 22.52 shenzhengeoadd city 106.50 29.53 chongqing geopos获取地理位置的坐标。 1234geopos city beijing# 输出结果为：1) 1) \"116.39999896287918091\" 2) \"39.90000009167092543\" geodist key member1 member2 [unit] 可以指定单位，比如m、km 123# 计算beijing和shanghai之间的直线距离，默认是m为单位geodist city beijing shanghai km \"1067.3788\" geospatial底层使用Zset实现，因此可以使用Zset的部分指令，比如查看所有成员，或者移除成员： 1234127.0.0.1:6379&gt; type city # 查看geospatial的数据类型zset # geospatial的类型是zsetzrange city 0 -1 # 查看city里面的所有成员zrem city hangzhou # 移除city里面的hangzhou这个成员 应用场景 比如查找附近的人、查找指定地点周围的地点等。 2.2.2 hyperloglogHyperLogLog是用来做基数统计的算法，它的优势是在输入元素的数量或者体积非常大时，计算基数所需的空间总是固定的、并且是很小的。 HyperLogLog只会根据输入元素来计算基数，不会存储输入元素本身，所以它不能像集合那样返回输入的各个元素。 基数，即集合中不重复的元素，比如{1,2,3,4,4,5,2,3}，其基数为{1,2,3,4,5} 使用HyperLogLog是由计算基数值是有误差的，但误差率小于1%。 常用命令： 命令 描述 pfadd 添加指定元素到HyperLogLog中 pfcount 返回给定HyperLogLog的基数估算值，误差小于1% pfmerge 将多个HyperLogLog合并为一个HyperLogLog 应用场景 比如计算网站的UV（独立访客，访问用户数），前提是允许有误差，否则只能用set。 2.2.3 bitmapsBitmaps使用二进制位来记录数据，只有0和1，比较适合表示某个元素的两种状态。 常用命令： 命令 描述 setbit 设置数据，返回值为之前位的值，默认为0。 getbit 获取某个位上的值 bitcount 计算并返回1的个数 bitop 对一个或多个key进行位运算（and、or、not、xor），将结果保存到另一个key中 bitpos 查找指定范围内，0或1出现的第一个位置。 使用案例： setbit key offset value，将key上指定offset上的值设置为value（0或1），offset可以用来表示用户id或日期。 123456789101112131415161718# 设置day的7个值，表示七天的签到状态，1表示签到，0表示未签到# 即1101011setbit day 0 1setbit day 1 1setbit day 2 0setbit day 3 1setbit day 4 0setbit day 5 1setbit day 6 1getbit day 5 #获取offset为5的值，结果为1bitcount day # 统计day中1的个数，结果为5，表示有5个1bitpos day 1 # 查找day中1第一次出现的位置，默认是所有位，可以指定范围# day1 1101011# day2 1001100bitop and day3 day1 day2 # 将day1和day2的与运算结果保存到day3中，结果为1001000bitop or day4 day1 day2 # 将day1和day2的或运算结果保存到day4中，结果为1101111 常用场景 用户是否活跃、用户签到状态等。 三、Redis事务3.1 Redis执行事务Redis的单条命令是原子性的，但是Redis中的事务不保证原子性。因此没有隔离级别的概念 Redis事务不支持回滚，因而不满足原子性，并且不满足持久性。Redis事务就是将多个命令请求打包，按顺序执行，并且中途不会被打断。 只有当发生语法错误(语法错误在命令队列时无法检测到)，对keys赋予了一个类型错误的数据时，Redis命令才会执行失败, 这些都是程序性错误，这类错误在开发的过程中就能够发现并解决掉，几乎不会出现在生产环境。因此不需要回滚机制 由于不需要回滚，这使得Redis内部更加简单，而且运行速度更快。 Redis的事务本质：一组命令的集合。一个事务中的所有命令都会被序列化，在事务的执行过程中，会按照顺序执行。 Redis 事务可以一次执行多个命令， 并且带有以下三个重要的保证： 批量操作在发送EXEC命令前被放入队列缓存。 收到EXEC命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。 在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。 Redis事务从开始到执行的过程： 开始事务：multi 命令入队，即批量操作的命令，以队列FIFO的顺序执行 执行事务：exec 可以使用discard命令取消一个事务。 使用案例： 123456789101112131415161718192021222324&gt; multi # 开启事务OK&gt; set k1 v1 # 命令入队QUEUED&gt; set k2 v2QUEUED&gt; set k3 v3QUEUED&gt; get k2QUEUED&gt; exec # 执行事务，会按照入队顺序依次执行命令1) OK2) OK3) OK4) \"v2\"===================&gt; multi #开启事务OK&gt; set k4 v4 # 命令入队QUEUED&gt; discard # 取消事务OK &gt; get k4 # 事务被取消，命令没有被执行，因此k4为空(nil) 如果事务中的命令本身有语法错误，比如命令拼写错误，则事务不会执行，即事务中所有命令都不会执行； 如果某条命令执行失败，比如对字符串进行incr操作，则其他命令仍然会被执行，执行错误的命令会抛出异常。 3.2 watchwatch用于监听一个或多个key，如果被监听的key在事务执行之前被其他命令（比如其他线程）改动，则事务不会执行，直接返回失败。（即乐观锁的机制） unwatch取消watch命令对所有key的监视。 事务执行完成后，成功或失败，都会自动解锁。 四、JedisJedis是Redis官方推荐的Java连接开发工具，即使用Java操作Redis的一个中间件。 1、导入jedis依赖 导入jedis依赖 12345678&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/redis.clients/jedis --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2、编写代码测试 123456789101112public class TestPing { public static void main(String[] args) { //1.new Jedis对象;通过主机名和端口号连接 Jedis jedis = new Jedis(\"127.0.0.1\", 6379); //jedis.auth(\"123456\"); //如果是远程连接，需要验证密码 //jedis中的所有命令就是redis的基础指令 //测试连接，如果输出PONG，说明连接成功 System.out.println(jedis.ping()); jedis.close(); //关闭连接 }} 如果是远程的Redis，需要进行以下配置： 将redis配置文件的bind 127.0.0.1注释掉，确保外部主机可以访问。 protected-mode如果为true，则需要设置访问redis的密码requirepass或bind指定ip，外部网络才可以访问；如果关闭保护模式，则外部网络可以直接访问。 安全起见，建议开启protected-mode，设置访问密码，并修改默认的端口号。 确保服务器的防火墙关闭，systemctl status firewalld.service查看防火墙状态。 重启redis服务。 如果设置了密码，需要在Java代码中使用auth()方法验证密码，才能使用Redis数据库。 3、连接成功后，可以使用jedis对象进行操作 方法名和操作Redis的指令名是相同的，比如： 123jedis.keys(\"*\");等价于&gt; keys * 在Java代码中使用Redis事务 12345678910111213141516171819public class TestTransaction { public static void main(String[] args) { //1.new Jedis对象 Jedis jedis = new Jedis(\"127.0.0.1\", 6379); jedis.auth(\"123456\"); //验证密码 Transaction multi = jedis.multi();//开启事务 try{ multi.set(\"user1\",\"v1\"); multi.set(\"user2\",\"v2\"); //int i = 1/0; //模拟一个java中的异常 multi.exec(); //执行事务 }catch (Exception e){ multi.discard(); //在exec()方法执行之前出现了Java代码异常，会放弃事务 e.printStackTrace(); }finally { jedis.close(); //关闭连接 } }} 这里catch中的异常，只能是捕获Java代码的异常，如果是Redis中的异常不会被捕获。比如，如果对字符串进行incr操作，Java代码并不会抛出异常，只是底层这个Redis语句会返回执行异常，事务中的其他命令仍然会执行。 五、SpringBoot整合Redis5.1 环境配置在SpringBoot中使用Redis，主要是通过Spring Data Redis 在SpringBoot项目中，可以使用模版自动引入启动器，或者手动引入Spring Data Redis启动器： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 在SpringBoot 2.x版本，底层使用的是lettuce，而不再是Jedis： Jedis：直连，多个线程操作时是不安全的；如果要避免不安全的情况，需要使用jedis pool连接池。更像BIO模式 lettuce：使用netty，实例可以在多个线程中共享，不存在线程不安全的情况。可以减少线程数据，更新NIO模式。 根据自动配置类，找到Redis自动配置的源码，并且根据配置类RedisProperties，可以找到配置Redis的前缀为spring.redis 12345678910111213141516171819202122232425262728@Configuration(proxyBeanMethods = false)@ConditionalOnClass(RedisOperations.class)@EnableConfigurationProperties(RedisProperties.class)@Import({ LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class })public class RedisAutoConfiguration { //可以自定义redisTemplate来替换这个默认的 @Bean @ConditionalOnMissingBean(name = \"redisTemplate\") public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { //默认的template没有过多的设置；redis对象都是需要序列化的 //两个类型都是Object类型，需要根据需求强制类型转换，比如&lt;String,Object&gt; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); return template; } //由于String类型是最常使用的类型，所以单独定义了一个bean @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; }} 在导入依赖后，可以进行配置，然后测试 application.properties 12345# 配置redisspring.redis.host=127.0.0.1spring.redis.port=6379# 如果有密码，要配置密码spring.redis.password=123456 测试： 12345678910111213141516171819202122232425@SpringBootTestclass Redis02SprintbootApplicationTests { //注入redisTemplate @Autowired private RedisTemplate redisTemplate; @Test void contextLoads() { /*redisTemplate调用不同的方法操作不同的数据类型 opsForValue 操作字符串，类似String opsForList 操作List 类似List 常用的方法，可以直接调用方法，比如multi()方法 */// redisTemplate.opsForValue().set(\"k1\",\"v1\");// redisTemplate.opsForList().leftPush(\"k2\",\"v2\");// redisTemplate.multi(); /* 获取连接对象 */// RedisConnection connection = redisTemplate.getConnectionFactory().getConnection();// connection.flushDb(); redisTemplate.opsForValue().set(\"mykey\",\"test\"); System.out.println(redisTemplate.opsForValue().get(\"mykey\")); }} 5.2 自定义RedisTemplate根据Redis自动配置类，我们也可以自定义RedisTemplate，实际开发过程中都是使用自定义的RedisTemplate： 1234567891011121314151617/*定义一个配置类，编写自定义的redisTemplate*/@Configurationpublic class RedisConfig { @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); //底层默认的是JDK序列化，我们可以配置自定义的序列化方式 //具体序列化方式根据实际情况确定 //template.setKeySerializer(); template.setConnectionFactory(redisConnectionFactory); return template; }} 此外，通常会创建工具类，使用工具类调用RedisTemplate的方法，这样更简洁。 12345678910111213141516//自定义Redis工具类，将原生的方法封装到这个工具类。@Componentpublic class RedisUtil { //使用自定义的配置类 @Autowired private RedisTemplate redisTemplate; //调用原生的方法，创建工具类方法。这样可以更简洁地调用方法 /** * 获取指定key的值 */ public Object get(String key){ //工具类中功能调用底层方法 return key==null ? null:redisTemplate.opsForValue().get(key); }} 然后，我们就可以使用我们定义的工具类实现功能： 1234567891011121314@SpringBootTestclass Redis02SprintbootApplicationTests { //创建好工具类以后，进行装配 @Autowired private RedisUtil redisUtil; @Test void test(){ //调用工具类提供的get方法，更简洁 System.out.println(redisUtil.get(\"t1\")); //功能上相当于直接调用底层方法 System.out.println(redisTemplate.opsForValue().get(\"t1\")); }} 六、 Redis配置文件Redis安装完以后，配置文件为redis.conf，对其中的内容进行解析。 Redis启动，是通过配置文件来启动的。 配置文件主要有以下部分： 1、UNITS 配置文件对单位的大小写不敏感，比如1GB和1gb相同。 2、INCLUDES 可以包含其他配置文件。如： 12include /path/to/local.confinclude /path/to/other.conf 3、NETWORK 可以使用bind来绑定ip，比如： 12# 绑定指定的ip地址bind 127.0.0.1 保护模式： 12# yes表示保护模式开启protected-mode yes 端口设置： 1port 6379 4、GENERAL 是否以守护进程方式启动 123# 默认是no# yes表示以守护进程方式运行，即后台运行daemonize yes 配置文件的pid文件保存位置，如果redis以后台方式运行，就需要指定pid文件： 1pidfile /var/run/redis_6379.pid 日志： 1234567# 有四种日志级别，默认是notice，适用于生产环境# This can be one of:# debug (a lot of information, useful for development/testing)# verbose (many rarely useful info, but not a mess like the debug level)# notice (moderately verbose, what you want in production probably)# warning (only very important / critical messages are logged)loglevel notice 生成的日志文件名： 12# 如果为空，则为标准的输出logfile \"\" 默认的数据库个数： 12# 默认16个数据库，从0-15databases 16 是否显示启动时的logo： 12# 默认为开启状态always-show-logo yes 5、SNAPSHOTTING 用于设置持久化rdb的配置。 持久化：在规定的时间内，执行了多少次操作，就会持久化到文件.rdb Redis是内存数据库，如果没有持久化操作，就会断电即失。 设置持久化时间： 123456789# 如果下面时间n内，至少m个key被修改，就会进行持久化操作# In the example below the behaviour will be to save:# after 900 sec (15 min) if at least 1 key changed# after 300 sec (5 min) if at least 10 keys changed# after 60 sec if at least 10000 keys changedsave 900 1save 300 10save 60 10000# 可以根据需求设置 rdb文件名称： 12# The filename where to dump the DBdbfilename dump.rdb 如果bgsave操作失败，是否停止写入硬盘（持久化）： 12# 默认是yes，即bgsave出错时，停止写入stop-writes-on-bgsave-error yes 是否压缩rdb文件： 12# 这个操作需要消耗一定的CPU资源rdbcompression yes 是否校验rdb文件： 12# 保存rdb文件的时候，进行错误校验检查rdbchecksum yes 持久化（rdb文件）保存的目录： 12# 默认是当前目录，即rdb文件保存的目录dir ./ 6、REPLICATION replication是主从复制相关的配置 7、SECURITY 安全相关的配置 设置密码： 12# 设置数据库密码为123456requirepass 123456 也可以在命令行设置： 1127.0.0.1:6379&gt; config set requirepass \"123456\" 设置完密码后，需要使用auth进行密码验证才能使用数据库： 1127.0.0.1:6379&gt; auth 123456 8、CLIENTS 客户端配置。 限制最大客户端连接数： 12# 设置最大连接数为10000maxclients 10000 9、MEMORY MANAGEMENT Redis的内存配置。 设置最大内存： 12# 设置redis的最大内存容量maxmemory &lt;bytes&gt; 内存满时的处理策略： 1234567891011# 默认是noevictionmaxmemory-policy noeviction# 一共有以下几种策略：# volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set.# allkeys-lru -&gt; Evict any key using approximated LRU.# volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set.# allkeys-lfu -&gt; Evict any key using approximated LFU.# volatile-random -&gt; Remove a random key among the ones with an expire set.# allkeys-random -&gt; Remove a random key, any key.# volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)# noeviction -&gt; Don't evict anything, just return an error on write operations. 10、APPEND ONLY MODE 持久化aof配置。 默认不开启aof，而是使用rdb方式持久化： 12# 默认使用rdb方式持久化，大部分情况下，rdb方式就够用了appendonly no aof持久化文件的名字： 12# rdb文件的后缀名就是rdbappendfilename \"appendonly.aof\" 同步策略： 123# appendfsync always # 每次修改都会同步，消耗性能appendfsync everysec # 每秒同步一次，可能会丢失最后一秒的数据# appendfsync no # 不执行同步，此时操作系统自己同步数据，速度最快 七、数据持久化Redis是一个内存数据库，内存的特征是断电即失，因此Redis的持久化操作是将数据写入硬盘进行持久化。 Redis中的持久化操作有两种方式：RDB（Redis DataBase）、AOF（Append Only File） 7.1 RDB持久化RDB(Redis DataBase)方式也叫快照(snapshotting)方式，因为这种方式是通过生成快照进行持久化的。Redis默认的持久化方式就是rdb方式。 RDB方式是通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。 Redis会单独创建 ( fork )一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程结束后，再用这个临时文件替换上次持久化好的文件（原子性系统调用rename重命名）。整个过程中，主进程是不进行任何IO操作的。这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。 如果最后一次修改，还未来得及进行rdb持久化就宕机，则最后一次持久化的数据就会丢失。 redis配置文件中的SNAPSHOTTING部分，就是关于rdb持久化的配置。其中的save设置： 123save 900 1 # 表示如果900秒后，至少有一个key发生了改变，就进行持久化。save 300 10save 60 10000 RDB持久化一般通过bgsave操作创建快照，创建的文件名默认为dump.rdb RDB持久化有三种保存数据的机制：save、bgsave、自动化。 save方式会阻塞Redis服务器，执行save命令期间，不能执行其他命令，直到RDB过程完成位置。 bgsave（background save），常用的方式，会使用fork子进程的方式 自动化：通过配置文件完成。 生成.rdb文件的情况： 满足save指定的规则 执行flushall命令 退出Redis，也会生成.rdb文件 开发中要对dump.rdb文件进行备份，防止误删.rdb文件导致数据无法恢复。 恢复rdb文件 只需要将rdb文件放入Redis的启动目录就可以，Redis启动的时候会自动检查dump.rdb，恢复其中的数据。 查看需要存放的位置： 123127.0.0.1:6379&gt; config get dir1) \"dir\"2) \"/usr/local/redis/bin\" RDB方式的优缺点 优点 适合大规模的数据恢复。 缺点： 需要一定的时间间隔来生成快照，如果没有到时间间隔系统宕机，则最后一段时间内的数据未被持久化导致数据丢失。 fork进程的时候，会占用一定的内存空间。fork操作会对主进程进行阻塞（只是fork时会阻塞，fork完成后的子进程操作不会影响主进程），影响主进程读写。 RDB是对完整的数据进行持久化，如果数据量较大，fork操作会消耗比较大的资源。 7.2 AOF持久化AOF（Append Only File），只追加文件。 RDB方式是的持久化数据库所有数据，而AOF方式是追加日志。AOF是将所有命令都记录下来，恢复的时候把这个文件记录的命令再执行一遍。 与RDB方式相比，AOF的实时性更好，开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。Redis也会fork一个子进程用于追加日志文件，重启后，会读取AOF文件根据指令重新构建数据。 只记录写操作，不记录读操作。 只追加文件，不改写文件 AOF的配置在Redis配置文件的APPEND ONLY MODE部分。AOF 文件的保存位置和 RDB 文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。AOF默认是关闭的，需要手动开启。 Redis提供了三种AOF同步策略： 123# appendfsync always # 每次修改都会同步，消耗性能appendfsync everysec # 每秒同步一次，但可能会丢失最后一秒的数据# appendfsync no # 不执行同步，此时操作系统自己同步数据，速度最快 兼顾性能和数据，可以选用everysec方式，每秒同步一次，这样最多只会丢失一秒的数据。 appendonly.aof文件的内容是记录的写入指令，可以被人为破坏。如果.aof文件有错误，会导致Redis启动失败。可以使用redis-check-aof对其进行修复： 12# 执行redis-check-aof修复aof文件./redis-check-aof --fix appendonly.aof 重写规则 由于AOF是增量持久化方式，因此AOF文件会不断增大，这时候需要使用重写对其进行瘦身。 1234567891011121314151617181920no-appendfsync-on-rewrite no# Automatic rewrite of the append only file.# Redis is able to automatically rewrite the log file implicitly calling# BGREWRITEAOF when the AOF log size grows by the specified percentage.## This is how it works: Redis remembers the size of the AOF file after the# latest rewrite (if no rewrite has happened since the restart, the size of# the AOF at startup is used).## This base size is compared to the current size. If the current size is# bigger than the specified percentage, the rewrite is triggered. Also# you need to specify a minimal size for the AOF file to be rewritten, this# is useful to avoid rewriting the AOF file even if the percentage increase# is reached but it is still pretty small.## Specify a percentage of zero in order to disable the automatic AOF# rewrite feature.auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# 当文件大小大于当前文件的100%且文件大小至少是64MB时，才会触发重写机制。 AOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。AOF是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。 AOF Rewrite 虽然是“压缩”AOF文件的过程，但并非采用“基于原AOF文件”来重写或压缩，而是采取了类似RDB快照的方式：基于Copy On Write，全量遍历内存中数据，然后逐个序列到AOF文件中。因此AOF rewrite能够正确反应当前内存数据的状态。 AOF持久化流程 在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作. AOF的优缺点 优点： 可以每次修改都同步、每秒同步一次、从不同步三种同步策略。数据完整性从高变低，而效率从低变高。 缺点： 相对于RDB方式来说，AOF恢复数据慢，因为其要重新执行一遍指令重构数据。 AOF是文本文件，体积较大，需要不断进行AOF重写，进行瘦身。 Redis 4.0 对于持久化机制的优化 Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。 如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。缺点是 AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。 八、数据删除与淘汰8.1 数据过期时间Redis是内存数据库，而内存是有限的，如果缓存中的所有数据都一直保存的话，很容易导致内存溢出。因此需要对数据设置过期时间。此外，一些场景中的数据本身就只需要存活一段时间，比如验证码，通过设置过期时间，可以省略多余的判断操作。 设置过期时间 string类型有自带的创建带有过期时间的指令： 1setex key 60 value # 设置key为60s后过期 通用的设置过期时间的指令是expire，使用persist指令可以移除一个键的过期时间： 1expire name 10 # 将name这个key设置为10秒后过期，10s后就会被销毁 查看某个key的剩余存活时间 1ttl name # 查看name的剩余存活时间,-1表示永久有效 Redis是如何判断数据是否过期的？ Redis如何判断数据是否过期 Redis 通过过期字典（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向Redis中的某个 key，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。 过期字典是存储在redisDb这个结构里的： 123456typedef struct redisDb { ... dict *dict; // 数据库键字典,保存着数据库中所有键值对 dict *expires // 过期字典,保存着键的过期时间 ...} redisDb; 8.2 过期数据删除对于过期的数据，Redis有三种删除策略：立即删除、惰性删除、定期删除。 1、立即删除 在设置键的过期时间时，创建一个回调事件，当过期时间达到时，由时间处理器自动执行键的删除操作。 优点： 立即删除能保证内存中数据的最大新鲜度，因为它保证过期键值会在过期后马上被删除，其所占用的内存也会随之释放。 缺点： 立即删除对cpu是最不友好的。因为删除操作会占用cpu的时间，如果刚好碰上了cpu很忙的时候，比如正在做交集或排序等计算的时候，就会给cpu造成额外的压力。 redis事件处理器对时间事件的处理方式是无序链表，查找一个key的时间复杂度为O(n)，所以并不适合用来处理大量的时间事件。 2、惰性删除 只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。 优点： key被使用的时候才会检查是否过期。对 CPU 最友好。 缺点： 浪费内存。比如某些数据在过期后可能很长一段时间内不会被访问（比如日志数据），但是这段时间dict字典和expires字典都要保存这个键值的信息，会浪费很多空间，对于依赖内存大小的Redis来说这个确定是致命的。 3、定期删除 ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。 优点： 对CPU比较友好，优势介于立即删除和惰性删除之间。 另一方面，减少了因惰性删除带来的内存浪费。 Redis 采用的是 定期删除+惰性/懒汉式删除 。 但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，同样会导致OOM。解决方法就是通过Redis的内存淘汰机制。 8.3 内存淘汰机制当内存满的时候，Redis可以通过内存淘汰策略，将选中的数据淘汰。Redis一共有8种淘汰策略： volatile-lru：从设置过期时间的数据集中挑选出最近最少使用（LRU）的数据淘汰。 allkeys-lru ：从数据集中挑选出最近最少使用（LRU）的数据淘汰。 volatile-lfu ：从设置过期时间的数据集中挑选出最近最不常使用（LFU）的数据淘汰。 allkeys-lfu ：从的数据集中挑选出最近最不常使用的数据淘汰。 volatile-random ：从设置过期时间的数据集中随机挑选数据淘汰。 allkeys-random：从数据集中随机挑选数据淘汰。 volatile-ttl：从设置过期时间的数据集中挑选最近要过期的数据淘汰。 noeviction ：禁止淘汰数据，当内存不足以容纳新写入数据时，新写入操作会报错。 其中LFU是Redis 4.0版本新增的淘汰策略。 九、Redis发布订阅9.1 介绍Redis的发布订阅（pub/sub）是一种消息通信模式：发送者（pub）发送消息，订阅者（sub）接收消息。传递消息的通道称为频道（channel）。 订阅者可以订阅任意数量的频道。 当发送者通过PUBLISH命令将新消息发送给频道时，这个消息就会被发送给订阅这个频道的n个订阅者。 发布订阅常用的命令： 命令 描述 psubscribe 订阅一个或多个符合给定模式的频道。 pubsub 查看订阅与发布系统状态。 publish 将信息发送到指定的频道。 punsubscribe 退订所有给定模式的频道。 subscribe 订阅给定的一个或多个频道的信息。 unsubscribe 指退订给定的频道。 使用案例 订阅者订阅频道： 12345127.0.0.1:6379&gt; subscribe pubTestReading messages... (press Ctrl-C to quit)1) \"subscribe\"2) \"pubTest\"3) (integer) 1 发布者往频道内发布消息： 12127.0.0.1:6379&gt; publish pubTest \"hello,world\"(integer) 1 # 表示有1个客户端收到 此时的订阅者能够收到消息： 12345678127.0.0.1:6379&gt; subscribe pubTestReading messages... (press Ctrl-C to quit)1) \"subscribe\"2) \"pubTest\"3) (integer) 11) \"message\" # 收到message2) \"pubTest\" # 来自频道pubTest3) \"hello,world\" # 消息内容为\"hello,world\" Redis中的订阅功能最明显的用途就是用作实时消息系统，比如普通的即时聊天，群聊等功能。 9.2 pub/sub原理subscribe命令 通过SUBSCRIBE命令订阅某频道后，redis-server里会维护一个字典，字典的键代表channel，字典的是一个链表，链表中保存了所有订阅这个channel的客户端。SUBSCRIBE命令的关键，就是将客户端添加到给定 channel 的订阅链表中。 publish命令 通过PUBLISH命令向订阅者发送消息，redis-server会使用给定的频道作为键，在它所维护的 channel 字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者。 十、Redis主从复制10.1 介绍主从复制：将一台Redis服务器的数据，复制到其他的Redis服务器，前者称为主节点（master/leader），后者称为从节点（slaver/follower)。 数据的复制是单向的，只能由主节点到从节点。master以写为主，slaver以读为主。默认情况下每个服务器都是主节点，一个主节点可以由多个从节点，而一个从节点只能有一个主节点。 主从复制的作用： 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用（集群）基石：主从复制是哨兵和集群能够实施的基础，是Redis高可用的基础。 10.2 环境配置查看当前库信息： 12345678910111213# 使用info命令查看信息127.0.0.1:6379&gt; info replication # Replicationrole:master # 角色：masterconnected_slaves:0 # 从机个数：0master_replid:0fae2ec2d0ed428e4a08a46f126d426e70f45601master_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 在一台服务器上通过创建多个配置文件，模拟多个Redis主机： 修改端口号 修改pid文件名 修改日志文件名 修改dump.rdb文件名 在单机上，通过不同端口，模拟一主二从的配置。 两个配置文件，用来启动不同端口的Redis服务 多个Redis服务 Redis主从复制遵循配从不配主的原则，只对从机进行配置。 在从机客户端使用slaveof命令指定其主机地址： 1234567891011121314151617181920212223# 设置其从机地址127.0.0.1:6380&gt; slaveof 127.0.0.1 6379# 查看此时的状态，已经变为了从机127.0.0.1:6380&gt; info replication# Replicationrole:slave # 当前角色：从机master_host:127.0.0.1 # 主机地址master_port:6379master_link_status:up # 主机连接状态master_last_io_seconds_ago:2master_sync_in_progress:0slave_repl_offset:42slave_priority:100slave_read_only:1connected_slaves:0master_replid:e93e4bf39bf9973a62074e0d6a8e40f4babc71edmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:42second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:29repl_backlog_histlen:14 Redis 5.0之前的版本使用slaveof，5.0之后的版本可以使用replicaof命令。 使用命令行配置从机的方式是一次性的，重启服务就失效了。如果要永久生效，需要在配置文件中配置replicaof选项，这样每次启动时会自动被设置为从机，这种方式是常用的方式： 12# 配置主机地址和端口号replicaof 127.0.0.1 6379 如果主机设置了密码，会导致master_link_status这一项结果为down，需要在从机的配置文件中设置masterauth添加主机密码： 12# 指定主机密码masterauth 123456 两个从机都设置好后，我们可以在主机客户端看到已连接的从机： 1234567891011121314127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2 # 有两个从机，然后是从机的详细信息slave0:ip=127.0.0.1,port=6381,state=online,offset=42,lag=0slave1:ip=127.0.0.1,port=6380,state=online,offset=42,lag=1master_replid:e93e4bf39bf9973a62074e0d6a8e40f4babc71edmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:42second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:42 简单的主从复制模型就配置好了。 10.3 主从复制测试主机中的所有信息和数据，都会自动被从机保存。 默认情况下，从机是只读复制模式，即从机只能读，不能写。 在只读复制模式下，从机写入数据，会失败： 12127.0.0.1:6380&gt; set t1 v1(error) READONLY You can't write against a read only replica. 测试1、主机写入数据，从机会自动保存数据，可以读取 测试2、如果主机宕机再重连以后，从机同样能够保存新写入的数据 测试3、如果从机宕机，如果重启后仍然是之前主机的从机，那么仍然可以获取到主机的数据 如果从机使用配置文件配置的主机地址，那么从机重启后仍然是从机，仍然可以获取到主机的数据。 10.4 复制原理从机和主机的数据会保持一致，无论是哪一方宕机，重启后仍然能够同步数据，其复制原理如下： Slave启动成功连接到Master后会发送一个sync同步命令。 Master接到命令，启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave，并完成一次完全同步。 复制方式有两种： 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。 增量复制：Master继续将新的所有收集到的修改命令依次传给slave，完成同步 每次重新连接master，都会自动执行一次完全同步（全量复制）。因此即使从机宕机，重连以后也能同步到主机的数据。 10.5 链路模式上述模式是一主机多从机的模式，主机和从机是一对多的关系。 还有一种主从复制是链路模式，主机和从机是一对一的关系，每个从机又有其自己的从机，层层相连。中间的从机既是主机，又是从机。 最顶端的主机写数据，后面的所有从机都能同步到数据。 十一、哨兵模式哨兵模式实现了自动主从切换。 11.1 哨兵的作用如果主机宕机，需要选用其中一个从机当作主机。使用slaveof no one命令，使当前从机变回主机。然后其他从机就可以连接到这个从机。在没有哨兵模式之前，上述操作是手动完成的。 Redis从2.8版本提供了Sentinel架构（哨兵模式）自动解决上述问题，哨兵模式能够自动剩余的从机中选出一个当作主机。 哨兵模式是一种特殊的模式，Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。 实际情况中， 我们通常会设置多个哨兵，多个哨兵之间互相监督，防止单一哨兵出现问题时无法及时主从切换。 多哨兵模式，基本原理如下： 正常情况下，哨兵会向master发送心跳ping来确认Master是否存活。 假设主服务器宕机，master会不回应PONG或者回复错误值，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，即主观下线（Subjectively Down，SDOWN）。 当其他哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover（故障转移）操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，即客观下线（Objectively Down，ODOWN）。 客观下线才是真正的进行主从切换。 11.2 创建哨兵以一个哨兵为例，每一个哨兵都需要一个自己的配置文件： sentinel.conf 12#格式：sentinel monitor &lt;option_name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;sentinel monitor T1 127.0.0.1 6379 1 上述是最基础的哨兵配置。监控的master的名字叫做T1（自定义），地址为127.0.0.1:6379，行尾最后的数字1表示在sentinel集群中，至少有多少个哨兵认为masters挂掉了，才能真正认为该master不可用了，开始选举从机作为主机。 如果主机设置了密码，客户端和从机在连接时都需要提供密码。master通过requirepass设置自身的密码，slave通过masterauth来设置访问master时的密码。客户端需要auth提供密码。 但是当使用了sentinel时，由于一个master可能会变成一个slave，一个slave也可能会变成master，所以需要同时设置上述两个配置项，即同时配置requirepass和masterauth，并且哨兵需要连接master和slave，也必须设置参数：sentinel auth-pass &lt;master_name&gt; xxxxx。 配置好哨兵的配置文件以后，就可以执行redis-sentinel，并指定配置文件，启动指定的哨兵进程: 启动哨兵 手动将主机shutdown掉，哨兵检测到主机宕机，会投票选出新的主机节点： 执行了主从转换 一个一主二从一哨兵的架构就搭建好了，通常情况下，我们不会使用单个哨兵，而是使用多个哨兵组成哨兵集群。如果是哨兵集群，则需要配置多个哨兵配置文件，并且每个哨兵都需要配置自己的端口。详细的哨兵配置，参考Redis哨兵机制 如果主机重新连接回来，只能归并到新的主机下，当作新的主机的从机。 关于哨兵的底层原理，可以参考哨兵选举底层原理 11.3 哨兵模式总结优缺点 优点： 基于主从复制原理，用于主从复制的优点。 主从可以切换，故障可以转移，系统的可用性更好。 哨兵模式就是主从模式的升级，从手动主从切换到自动主从切换。 缺点： redis较难支持在线扩容，如果集群容量到达上限，在线扩容很复杂。 实现哨兵集群的配置选择项很多，不容易配置。 十二、缓存穿透、缓存击穿、缓存雪崩12.1 缓存穿透缓存穿透的概念 用户查询一个redis缓存中没有的数据，并且数据库中也没有，因此每次都会到持久层中查询数据库，因为数据库中没有，最终查询失败。当用户很多，这种不存在的数据查询量很大的时候，都去请求持久层，给持久层数据库造成了很大的压力，导致失去了缓存保护后端数据库的意义，相当于穿透了缓存。 解决方法 1、缓存空对象 如果不存在此key，则在缓存中为这个key设置一个空值，这样每次查询就会直接从缓冲中返回空值。 但是这种方法存在两个问题： 值为null不代表不占用内存空间，空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间，因此会造成一定程度上的空间浪费。比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。 缓存和数据库的数据会有一段时间数据不一致，这可能会对业务有一定影响。例如过期时间设置为5分钟，如果此时数据库中添加了这个数据，那此段时间就会出现缓存和数据库中数据不一致的情况，此时可以利用消息系统或者其他方式清除掉缓存层中的空对象。 2、布隆过滤器 在访问缓存和持久层之前，将存在的key用布隆过滤器提前保存起来，做第一层拦截，当收到一个对key请求时先用布隆过滤器验证是key否存在，如果存在才会进入缓存、持久层。否则就直接返回。 布隆过滤器是一个bit向量或者说bit数组，其基本原理是事先将所有可能查询的key映射到这个数组，是使用多个不同的哈希函数对插入的对象进行hash操作并生成多个哈希值，将每个生成的哈希值指向的bit位置置为1。当用户查询的时候，会查找多个哈希值对于位置的值是否为1，如果这多个位置上的值都是1，说明这个值可能存在，否则一定不存在。 布隆过滤器只能判断可能存在，并不能确定一定会存在，但是能够判断一定不存在的情况。 参考：详解布隆过滤器原理 布隆过滤器 12.2 缓存击穿缓存击穿的概念 与缓存穿透不同的是，缓存击穿指的是某一时刻某一个热点数据失效，对应的大量请求涌入数据库，造成数据库压力过大。 比如微博某一热点数据设置了过期时间，导致过期后到重新创建的这一小段时间内热点数据短暂失效，在这段时间内大量对于这一数据的查询请求会直接访问数据库，导致数据库压力过大，好比缓存被击穿。 解决方案 1、设置热点数据永不过期 从缓存层面来看，没有设置过期时间，所以不会出现热点 key过期后产生的问题。但是会存在数据不一致的情况。 2、分布式互斥锁 使用分布式锁，保证对于每个key同时只有一个线程去查询后端服务，其他线程没有获得分布式锁的权限，因此只需要等待即可。这种方式将高并发的压力转移到了分布式锁，因此对分布式锁的考验很大。 12.3 缓存雪崩缓存雪崩概念 缓存雪崩指的是缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。就像雪崩一样。 造成缓存雪崩有两种情况：一种是因为缓存模块本身的故障，比如宕机，导致原本应该访问缓存的请求都去访问了数据库；另一种造成缓存雪崩的情况是大量热点数据在某一时刻大面积失效，导致对应的请求落到了数据库上。 解决方案 针对Redis服务不可用的情况（情况一）： 使用redis集群。采用Redis集群，避免单机出现问题整个缓存服务都不可用。（比如异地多活) 限流降级。限流，避免同时处理大量的请求，设置最高的QPS阈值，当请求数超过这个阈值后，就不再调用后续资源。降级，指的是服务器压力剧增的情况下，根据业务情况，对一些服务和页面进行有策略的降级，以此释放服务器资源保证核心任务的正常运行。 针对Redis服务可用的情况（情况二）： 设置不同的失效时间，比如随机设置缓存的失效时间。或者设置缓存永不失效。 数据预热。在正式部署之前，先将可能的数据预先访问一遍，使那些可能大量访问的数据预先加载到缓存中。 ReferenceRedis教程","categories":[{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"SQL","slug":"SQL","permalink":"http://kangshitao.github.io/tags/SQL/"},{"name":"Redis","slug":"Redis","permalink":"http://kangshitao.github.io/tags/Redis/"}]},{"title":"Java并发编程-JUC基础","slug":"juc-basis","date":"2021-07-25T14:30:24.000Z","updated":"2022-05-22T13:30:54.797Z","comments":true,"path":"2021/07/25/juc-basis/","link":"","permalink":"http://kangshitao.github.io/2021/07/25/juc-basis/","excerpt":"JUC、锁、多线程、并发编程、阻塞队列、线程池等","text":"一、JUC基础1.1 JUC简介java.util.concurrent简称JUC，是一个处理线程的工具包，JDK 1.5出现。 1.2 进程与线程参考进程与线程 Thread类中定义的进程几种状态： NEW：线程还未开始时的状态 RUNNABLE：线程可运行的状态（就绪状态） BLOCKED：线程为了进入同步方法或同步代码块，而等待监视器锁(monitor lock)的状态。 WAITING：由于调用wait`join\\LockSupport.park`方法进入的等待状态，直到被唤醒为止。 TIMED_WAITING：由于调用wait`join\\LockSupport.parkNanos\\LockSupport.Until`方法进入的超时等待状态，等待具体的时间后就会自动停止等待。 TERMINATED：终止状态，线程执行完成。 1.3 多线程锁1、平锁和非公平锁 非公平锁：可能造成一个线程独占资源，其他线程被饿死的情况；但效率高 公平锁：只有当前线程在等待队列的第一个位置时，才会执行；各个线程都能获取到锁；效率较低. 2、可重入锁 “可重入锁”（递归锁） 指的是自己可以再次获取自己的内部锁。进入最外层的锁，内层也可以直接获取当前的锁，不需要等外层释放锁。 synchronized和Lock都是可重入锁. synchronized是隐式的；Lock是显式的。Lock的上锁和解锁必须成对出现，如果没有解锁，可能会影响别的线程。 3、死锁 两个或两个以上的进程在执行过程中，因为争夺资源而造成互相等待的现象；如果没有外力干涉，他们无法继续进行下去。 产生死锁的原因：系统资源不足；进程运行推进顺序不合适；资源分配不当。死锁的产生条件和解决方法：操作系统-死锁 验证是否是死锁： jps命令找到要验证的进程。 jstack对指定id的进行进行分析，这是jvm自带的堆栈跟踪工具。 1.4 wait/sleepwait和sleep的区别： sleep是Thread类的静态方法，而wait是Object类的方法，任何对象实例都能调用。 sleep不会释放锁，调用它不要求必须占用锁，因此可以在任何地方使用。wait会释放锁，但调用它的前提是当前线程已经占有锁(即代码要在synchronized中，Lock锁需要使用Condition的await方法)。 他们都可以被interrupted方法中断。 他们都是在哪里执行，就在哪里醒来。即原地唤醒。 为什么sleep方法定义在Thread类中，而wait方法定义在Object类中？ 调用对象的wait方法，会导致当前线程进入等待状态，并且释放这个锁，前提是要求当前线程必须持有这个对象锁。二者的施加者是不同的；二者本质区别是一个是线程的运行状态控制，一个是线程之间的通讯问题。 1.5 并发和并行并发（concurrent）指的是多个程序或进程同时运行，对于单核心CPU来说，同一时刻只能允许一个线程，其并发就表示多个线程采用时间片方式执行多个线程。同一时刻多个线程访问同一个资源，多个线程对一个点，比如抢票、电商秒杀。 并行是指多项工作一起执行，之后再汇总。 1.6 多线程编程Java创建线程的几种方式：线程的创建和使用，主要有以下四种： 继承Thread类 实现Runnable接口 实现Callable接口 使用线程池 Java多线程编程的一般步骤： 1、创建资源类，定义属性和操作方法 2、在资源类中操作方法：判断、操作、通知 3、创建多个线程，调用资源类的操作方法 4、防止虚假唤醒问题，将wait使用在while中，这样每次唤醒后都做判断。 如果在if中使用wait，这样只会判断一次，之后唤醒就不会再判断了 二、synchronized与Lock接口2.1 synchronizedsynchronized是Java中的关键字，是一种同步锁。使用方法参考：线程的同步 补充：synchronized并不属于方法定义的一部分，因此synchronized关键字不能被继承。如果在父类中的某个方法使用了synchronized关键字，而在子类中覆盖了这个方法，在子类中的这个方法默认情况下并不是同步的，而必须显式地在子类的这个方法中加上synchronized关键字才可以。 当然，还可以在子类方法中调用父类中相应的方法，这样虽然子类中的方法不是同步的，但子类调用了父类的同步方法，因此，子类的方法也就相当于同步了。 关于synchronized锁 如果一个类中有多个synchronized方法，对于类的对象，某一时刻内，只能有一个线程调用其中的一个同步方法，其他线程都必须等待。因为锁的是当前对象this，当前对象被锁定后，其他对象无法获取这个锁，也就无法使用其中的方法。 如果是一个类的两个不同的对象作为锁，则二者互不影响。synchronized实现同步的基础是每个对象都可以作为锁。 对于普通同步方法，锁的是当前实例对象。 对于静态同步方法，锁的是当前类的Class对象 对于同步方法块，锁的是括号内指定的对象。 对于synchronized的锁问题，需要判断其锁对象是否相同来分析，如果多个线程要用同一把锁，必然有竞态条件，如果用的不是同一把锁，则不会有关系。比如一个类的普通同步方法和一个静态同步方法，如果两个线程一个要访问普通同步方法，另一个线程访问静态同步方法，二者不会竞争，因为用的不是同一把锁。 2.2 Lock接口2.2.1 LockLock接口是使用最多的方式，作用是用来手动获取和释放锁。 一般来说Lock的加锁语句放在try结构外面，这样如果加锁失败，就不会执行finally中的释放锁的操作。并且，需要在加锁和try之间不建议有别的操作，如果有异常会导致不能释放锁。参考Lock.lock()为什么在try之前执行 释放锁语句放在finally里面，保证锁一定会被释放，防止死锁的发生。 2.2.2 Condition如果使用Lock锁，想要实现类似于notify方法的功能，就要使用Condition接口类对象。 12Lock lock = new ReentrantLock(); //创建Lock对象Condition condition = lock.newCondition(); //获取Condition对象 Condition中的两个常用方法： await()：相当于wait()，会使当前线程等待，同时会释放锁，其他线程调用当前Condition对象的signal()方法时才会继续执行。 signal()相当于notify()。 调用这两个方法前，需要线程持有相关的Lock锁，调用await()后，线程会释放这个锁，而调用某个Condition对象的signal()方法时，会从当前Condition对象的等待队列中，唤醒一个线程，当某个线程获取锁成功就会继续执行。 2.3 ReentryantLockReentryantLock表示可重入锁，是Lock的一个实现类，我们可以用它声明一个Lock对象。 使用ReentryantLock可以指定公平锁和非公平锁。 2.4 synchronized和Lock的区别 synchronized是Java语言的关键字，是Java语言内置的。而Lock是一个接口，通过这个类可以实现同步访问； synchronized不需要手动释放锁，同步方法或同步代码块执行完之后，系统会自动让线程释放对锁的占用；Lock必须手动释放锁，如果没有主动释放锁，就有可能导致出现死锁现象。 Lock可以让等待锁的线程响应中断，synchronized不能，会导致线程一直等待下去。 Lock可以知道有没有成功获取锁，synchronized不能。 竞争资源激烈时，Lock的性能优于synchronized 二者都是独占锁。 2.5 案例：多个售票员售票模拟3个售票员售30张票，售完为止： synchronized方式 123456789101112131415161718192021222324252627282930313233343536373839404142434445//创建资源类class Ticket{ private int number = 30;//定义属性：票数 //操作方法 public synchronized void sale(){ //判断：是否还有票 if(number&gt;0){ System.out.print(\"当前\"+number+\"张--\"); number--; System.out.println(Thread.currentThread().getName()+\": 卖出1，剩余\"+number+\"张\"); } }}public class SaleTicket { public static void main(String[] args) { Ticket ticket = new Ticket(); //创建资源类对象 //创建3个线程，代表3个售票员 new Thread(new Runnable() { @Override public void run() { for(int i=0;i&lt;30;i++){ ticket.sale(); } } },\"售票员A\").start(); new Thread(new Runnable() { @Override public void run() { for(int i=0;i&lt;30;i++){ ticket.sale(); } } },\"售票员B\").start(); new Thread(new Runnable() { @Override public void run() { for(int i=0;i&lt;30;i++){ ticket.sale(); } } },\"售票员C\").start(); } Lock锁的方式： 12345678910111213141516171819202122232425262728293031class LTicket{ private int number=30; //创建可重入锁对象 private final ReentrantLock lock = new ReentrantLock(); //编写方法 public void sale(){ //上锁 lock.lock(); //一般将上锁操作写在try外面,且和try直接不能有其他操作 try{ //做操作 if(number&gt;0){ System.out.print(\"当前\"+number+\"张--\"); number--; System.out.println(Thread.currentThread().getName()+\": 卖出1，剩余\"+number+\"张\"); } }finally { //将解锁操作放到finally中，保证一定能够解锁 //解锁 lock.unlock(); } }}public class SaleTicket_L { public static void main(String[] args) { LTicket lTicket = new LTicket(); //调用start方法不一定是马上创建线程，需要底层操作系统情况。 new Thread(()-&gt;{for(int i=0;i&lt;30;i++) lTicket.sale();},\"售票员A\").start(); new Thread(()-&gt;{for(int i=0;i&lt;30;i++) lTicket.sale();},\"售票员B\").start(); new Thread(()-&gt;{for(int i=0;i&lt;30;i++) lTicket.sale();},\"售票员C\").start(); }} 三、线程通信线程通信主要是通过wait()、notify()、notifyall()方法，或者是Condition的await()、siginal()、signalAll()这些方法。前者适用于sychronized方式，而后者是Lock锁的方式。 3.1 案例：线程通信创建两个线程A和B，一个线程对当前数值+1，另一个线程对当前数字-1，利用线程间的通信，使这两个线程交替操作。 方式一：使用synchronized： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//一、创建资源类，定义属性和操作方法//操作方法中判断、操作、通知class Share{ //初始值 private int number = 0; //+1的方法 public synchronized void increat() throws InterruptedException { /* if只会判断一次，wait在哪里睡就在哪里醒，因此如果使用if，则会导致虚假唤醒问题。 解决虚假唤醒问题，需要使用while代替if，因为while每次都会判断 */ while(number !=0){ wait(); //如果值不是0，就释放锁,进入阻塞状态，等待被唤醒 } number++; System.out.println(Thread.currentThread().getName()+\"::\"+number); notifyAll(); } //-1的方法 public synchronized void decreat() throws InterruptedException { while(number !=1){ wait(); } number--; System.out.println(Thread.currentThread().getName()+\"::\"+number); notifyAll(); }}public class ThreadDemo1 { public static void main(String[] args) { Share share = new Share(); new Thread(() -&gt; { for(int i=1;i&lt;=10;i++){ try { share.increat(); } catch (InterruptedException e) { e.printStackTrace(); } } },\"Thread A\").start(); new Thread(() -&gt; { for(int i=1;i&lt;=10;i++){ try { share.decreat(); } catch (InterruptedException e) { e.printStackTrace(); } } },\"Thread B\").start(); }} 方式二：使用Lock锁： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061//第一步：创建资源类，定义属性和操作方法class Share{ private int number = 0; //创建Lock对象 private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); //定义方法 public void incr() throws InterruptedException { lock.lock();//上锁 try { while(number!= 0){condition.await();}//判断 number++;//操作 System.out.println(Thread.currentThread().getName()+\"::\"+number); condition.signalAll();//通知 } finally { lock.unlock();//解锁 } } public void decr() throws InterruptedException { lock.lock(); try{ while(number!=1){condition.await();} number--; System.out.println(Thread.currentThread().getName()+\"::\"+number); condition.signalAll(); }finally { lock.unlock(); } }}public class ThreadDemo1_L { public static void main(String[] args) { Share share = new Share(); //创建A、B两个线程 new Thread(new Runnable() { @Override public void run() { for(int i=0;i&lt;10;i++){ try { share.incr(); } catch (InterruptedException e) { e.printStackTrace(); } } } },\"Thread A\").start(); new Thread(new Runnable() { @Override public void run() { for(int i=0;i&lt;10;i++){ try { share.decr(); } catch (InterruptedException e) { e.printStackTrace(); } } } },\"Thread B\").start(); }} 3.2 案例：线程间定制化通信一般的线程通信我们不能控制他们的执行次数和顺序，如果想要实现多个线程按照指定的顺序执行，就需要使用定制化通信。比如下面的例子。 案例：A线程打印5次，B线程打印10次，C线程打印15次，重复以上步骤n次 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104/*线程通信案例2：实现线程间的定制化通信：A线程打印5次，B线程打印10次，C线程打印15次，重复以上步骤n次实现方法为设置标志位flag，1表示A执行，2表示B执行，3表示C执行 */class ShareResource{ private int flag = 1; // 1-A,2-B,3-C private Lock lock = new ReentrantLock(); //声明锁 //为了实现定制化通信，需要创建3个condition；保证唤醒的是指定的线程 private Condition c1 = lock.newCondition(); //相当于钥匙，用于通信 private Condition c2 = lock.newCondition(); private Condition c3 = lock.newCondition(); public void print5(int loop) throws InterruptedException { lock.lock(); try{ while(flag!=1){ c1.await(); } for(int i=0;i&lt;5;i++){ System.out.println(Thread.currentThread().getName()+\"::\"+i+\",当前轮数:\"+loop); } flag = 2; //修改标志位是2 c2.signal(); //通知B线程；signal表示唤醒当前Condition对象中的等待队列中的一个线程。 }finally { lock.unlock(); } } public void print10(int loop) throws InterruptedException { lock.lock(); try{ while(flag!=2){ c2.await(); } for(int i=0;i&lt;10;i++){ System.out.println(Thread.currentThread().getName()+\"::\"+i+\",当前轮数:\"+loop); } flag = 3; //修改标志位是2 c3.signal(); //通知C线程；signal表示唤醒当前Condition对象中的等待队列中的一个线程。 }finally { lock.unlock(); } } public void print15(int loop) throws InterruptedException { lock.lock(); try{ while(flag!=3){ c3.await(); } for(int i=0;i&lt;15;i++){ System.out.println(Thread.currentThread().getName()+\"::\"+i+\",当前轮数:\"+loop); } flag = 1; //修改标志位是2 c1.signal(); //通知A线程；signal表示唤醒当前Condition对象中的等待队列中的一个线程。 }finally { lock.unlock(); } }}public class ThreadDemo2_L { public static void main(String[] args) { ShareResource shareResource = new ShareResource(); new Thread(new Runnable() { @Override public void run() { for(int i=0;i&lt;10;i++){ try { shareResource.print5(i); } catch (InterruptedException e) { e.printStackTrace(); } } } },\"A\").start(); new Thread(new Runnable() { @Override public void run() { for(int i=0;i&lt;10;i++){ try { shareResource.print10(i); } catch (InterruptedException e) { e.printStackTrace(); } } } },\"B\").start(); new Thread(new Runnable() { @Override public void run() { for(int i=0;i&lt;10;i++){ try { shareResource.print15(i); } catch (InterruptedException e) { e.printStackTrace(); } } } },\"C\").start(); }} 四、集合的线程安全4.1 集合线程安全问题对于非线程安全的集合类，如果多个线程对其进行并发读写，就会出现并发异常： 12345678910111213141516171819public class ThreadDemo4_L { public static void main(String[] args) { ThreadDemo4_L demo4L = new ThreadDemo4_L(); demo4L.testHashMap(); } public void testHashMap(){ Map&lt;String,String&gt; map = new HashMap&lt;&gt;(); for(int i=1;i&lt;=100;i++){ new Thread(new Runnable() { @Override public void run() { //向hashmap中写入随机数 map.put(UUID.randomUUID().toString().substring(0,8),\"t\"); System.out.println(map); } },String.valueOf(i)).start(); } }} 以上程序，并发情况下，对HashMap进行读写，会出现ConcurrentModificationException异常，表示出现了读写冲突。 对于不同的集合类，一般有对应的线程安全类，或者是其他的解决方法。 4.2 ArrayListArrayList是线程不安全的，如果多个线程同时添加数据，读取的时候就会出现ConcurrentModificationException异常。 解决方法： 使用Vector代替ArrayList 使用Collections中的synchronizedList代替ArrayList 使用CopyOnWriteArrayList代替ArrayList CopyOnWriteArrayList是JUC包下的一个ArrayList线程安全类，其功能和ArrayList一样，但是其使用写时复制的思想，保证了其是线程安全的，有以下特点： 适合于读操作多于写操作、List较小的情况。 写时复制，在进行写操作的时候，会复制一份，在复制出来的容器中添加元素，添加完以后，将原容器的引用指向新的容器。 CopyOnWriteArrayList底层使用volatile修饰数组，保证当前线程读的时候总能看到线程对数组最后的写入。避免了脏数据读取。 CopyOnWriteArrayList使用互斥锁来保护数据，在“添加、修改、删除”数据时，会先获取互斥锁，修改完毕后，先将数据更新到volatile数组中，然后释放锁，以此保护数据。 4.3 HashSetJUC中对应的HashSet的线程安全类为： java.util.concurrent.CopyOnWriteArraySet 4.4 HashMapJUC中对应的HashMap的线程安全类为： java.util.concurrent.ConcurrentHashMap 五、Callable&amp;Future实现Callable接口来创建线程最大的特点可以返回结果。 Runnable接口和Callable接口对比： 对比项 Runnable.run() Callable.call() 是否有返回值 否 是 是否抛出异常 否 是 Callable不能直接替换Runnable，因为new Thread()这个构造器只接受Runnable类型的参数，如果是Callable的实现类怎么办呢？ 我们可以使用Futrure接口的实现类对象，Future接口中定义了5个方法： 1234567891011121314151617public interface Future&lt;V&gt; { //用于停止任务 boolean cancel(boolean mayInterruptIfRunning); //如果任务在完成前被取消，则返回true boolean isCancelled(); //如果任务完成，返回true，否则返回false boolean isDone(); //用户获取任务的结果 V get() throws InterruptedException, ExecutionException; //在指定的等待时间内，获取结果，如果超时还没有获取到结果，则抛出超时异常 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;} FutureTask类实现了Future和Runnable接口，同时具备了这两个类的功能，并且其构造函数的参数是Callable类型，因此我们可以借助这个类来使用Callable接口创建线程： 123456789101112131415161718//实现Callable接口class MyThread2 implements Callable { @Override public Integer call() throws Exception { System.out.println(Thread.currentThread().getName()+\"--come in callable\"); return 200; }}public class Demo1 { public static void main(String[] args) throws ExecutionException, InterruptedException { //创建FutureTask对象并传入Callable实现类对象 FutureTask&lt;Integer&gt; futureTask1 = new FutureTask&lt;&gt;(new MyThread2()); new Thread(futureTask1,\"futureTask1\").start(); }} FutureTask中的get()方法如果被调用时计算未完成，会进入阻塞状态，直到计算完成，才会返回结果或者抛出异常。因此，FutureTask多用于耗时的计算任务，主线程可以再完成其他任务之后，再使用get()获取结果。 get()方法只计算一次，再次调用时会直接返回计算好的结果，因此get()方法通常放到最后。 六、JUC三大辅助类JUC中提供了三种常用的辅助类，通过这些辅助类可以很好的解决线程数量过多时，手动操作Lock锁的频繁操作： CountDownLatch：减少计数 CyclicBarrier：循环栅栏 Semaphore：信号量 6.1 CountDownLatchCountDownLatch类可以设置一个计数器，然后通过countDown方法进行减1操作，使用await()方法等待计数器小于或等于0时，调用await()方法之后的语句。 countDown()方法会将计数器减1 await()方法会将当前线程阻塞，直到计数器的值小于等于0 案例：当所有学生都离开教室以后关灯。 123456789101112131415161718/*场景：当教室的n个人都离开后，才可以锁门*/public class countDownLatchDemo { public static void main(String[] args) throws InterruptedException { //1.创建CountDownLatch对象并设置初始计数值，假设有6个学生 CountDownLatch countDownLatch = new CountDownLatch(6); for(int i=1;i&lt;=6;i++){ new Thread(()-&gt;{ System.out.println(Thread.currentThread().getName()+\":离开\"); countDownLatch.countDown(); //每次一个线程离开后，计数器减一 },String.valueOf(i)).start(); } //只要计数器大于0，当前线程就一直等待；直到计数器等于0，当前线程才被唤醒 countDownLatch.await(); System.out.println(Thread.currentThread().getName()+\"可以关灯了\"); }} 6.2 CyclicBarrierCyclicBarrier的构造方法第一个参数是目标障碍数，每次执行其中的await()方法，都会使障碍数加1，当障碍数达到目标障碍数，就会执行await()方法之后的语句。 线程调用await()表示自己已经到达栅栏。当CyclicBarrier达到了指定的栅栏数，才会执行后面的语句。 案例：集齐七颗龙珠召唤神龙 123456789101112131415161718192021222324//场景：集齐七颗龙珠召唤神龙public class CyclicBarrierDemo { private static final int NUMBER = 7; public static void main(String[] args) { //新建循环栅栏对象，设置一个固定值，并指定达到这个固定值以后，需要做的事 CyclicBarrier cyclicBarrier = new CyclicBarrier(NUMBER, () -&gt; { System.out.println(\"召唤神龙!\"); }); //集齐七颗龙珠的过程 for(int i=1;i&lt;=7;i++){ new Thread(()-&gt;{ System.out.println(Thread.currentThread().getName()+\"星龙珠已收集到\"); try { //await表示已经到达栅栏，每执行一次，计数加一 cyclicBarrier.await(); //如果没有到达指定的7颗，cyclicBarrier会一直处于等待状态 } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } },String.valueOf(i)).start(); } }} 6.3 SemaphoreSemaphore的构造方法中传入的第一个参数是最大信号量，类似于线程池中最大的线程数量，每个信号量初始化为一个最多只能分发一个许可证，线程通过acquire()方法获得许可证，release()方法释放许可证。 案例：6辆车抢3个车位 12345678910111213141516171819202122232425//场景：6辆汽车，停到3个车位public class SemaphoreDemo { public static void main(String[] args) { //创建semaphore，模拟3个车位，即设置3个许可量，即同时只能有3个线程获取到许可量 Semaphore semaphore = new Semaphore(3); //模拟6辆汽车 for(int i=1;i&lt;=6;i++){ new Thread(()-&gt;{ try { //获取许可量，即占用车位 semaphore.acquire(); System.out.println(Thread.currentThread().getName()+\"抢占到了车位\"); //模拟停车时间 TimeUnit.SECONDS.sleep(new Random().nextInt(5)); System.out.println(Thread.currentThread().getName()+\"离开了车位\"); } catch (InterruptedException e) { e.printStackTrace(); } finally { //释放许可量 semaphore.release(); } },i+\"号车\").start(); } }} 七、读写锁7.1 读写锁概念悲观锁：每次操作都上锁，不支持并发 乐观锁：支持并发。通过版本号进行控制，每次提交事务都会比较当前版本号和自己的版本号，如果一致，则提交成功，如果版本号高于自己的版本号，说明别人已经优先一步做了修改，自己提交失败。 表锁：不会发生死锁 行锁：会发生死锁 读锁：共享锁。会发生死锁 写锁：独占锁。会发生死锁 进入读锁的前提条件 没有其他线程的写锁 没有写请求，或者写请求和当前持有锁的线程是同一个，即可重入锁。 进入写锁的前提条件 没有其他线程的读锁 没有其他线程的写锁 读写锁：一个资源可以被多个读线程访问，或者可以被一个写线程访问；但是不能同时存在读和写线程。即读写互斥，读读共享。 读写锁缺点： 容易造成锁饥饿现象。比如一直读，不能写 读的时候不能写，只能读完再写。而写的时候可以读。 JUC提供了ReentrantReadWriteLock，这个类可以提供读写锁。读写锁有以下特征： 公平选择性：支持公平和非公平锁（默认）两种方式，非公平锁的吞吐量优于公平锁。 重进入：读锁和写锁都支持线程重进入。 锁降级：遵循获取写锁、获取读锁再释放写锁的顺序，写锁能够降级为读锁。写操作的时候可以进行读操作；但是读锁不能升级为写锁，因此读操作的时候不能进行写。 7.2 ReadWriteLockReadWriteLock表示读写锁接口，ReentrantReadWriteLock是它的一个实现类，其中提供了readLock()和writeLock()两个方法用来获取读锁和写锁： 12345678910111213public interface ReadWriteLock { /** * Returns the lock used for reading. * @return the lock used for reading */ Lock readLock(); /** * Returns the lock used for writing. * @return the lock used for writing */ Lock writeLock();} 读写锁将文件的读写操作分开，分成2个锁来分配给线程，使多个线程可以同时进行读操作。 ReentrantReadWriteLock实现了ReadWriteLock接口，并提供了更多丰富的方法。 案例：使用ReentrantReadWriteLock对哈希表进行读写操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485//场景：模拟缓存机制public class ReadWriteLockDemo { public static void main(String[] args) { MyCache myCache = new MyCache(); //创建线程放数据 for(int i=1;i&lt;=5;i++){ final int num = i; new Thread(()-&gt;{ myCache.put(num+\"\",num+\"\"); },\"线程\"+i).start(); } //创建线程取数据 for(int i=1;i&lt;=5;i++){ final int num = i; new Thread(()-&gt;{ myCache.get(num+\"\"); },\"线程\"+i).start(); } }}//使用读写锁，每次读和写之前都上锁，保证了不会出现还没写完就读的情况class MyCache{ private volatile Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); //创建读写锁对象 private ReadWriteLock rwl = new ReentrantReadWriteLock(); //放数据 public void put(String key, Object value) { rwl.writeLock().lock(); //加上一个写锁 try { System.out.println(Thread.currentThread().getName()+\"正在写\"+key); TimeUnit.MILLISECONDS.sleep(300); map.put(key,value); System.out.println(Thread.currentThread().getName()+\"写完了\"+key); } catch (InterruptedException e) { e.printStackTrace(); } finally { //释放写锁 rwl.writeLock().unlock(); } } //取数据 public Object get(String key) { //添加读锁 rwl.readLock().lock(); Object o = null; try { System.out.println(Thread.currentThread().getName()+\"正在读\"+key); TimeUnit.MILLISECONDS.sleep(300); o = map.get(key); System.out.println(Thread.currentThread().getName()+\"读完了\"+key); } catch (InterruptedException e) { e.printStackTrace(); } finally { //释放读锁 rwl.readLock().unlock(); } return o; }}/*运行结果线程1正在写1线程1写完了1线程3正在写3线程3写完了3线程4正在写4线程4写完了4线程5正在写5线程5写完了5线程2正在写2线程2写完了2线程1正在读1线程4正在读4线程3正在读3线程2正在读2线程5正在读5线程2读完了2线程5读完了5线程4读完了4线程3读完了3线程1读完了1*/ 可以看到，读锁可以被多个线程共享，因此出现了多个线程同时进行读操作的情况。而写锁是互斥锁，同时只能一个线程持有，因此只能等当前线程写操作执行完释放锁以后，其他线程才可以获取到写锁。 八、阻塞队列8.1 BlockingQueueJUC提供了BlockingQueue接口表示阻塞队列。 阻塞队列，首先是一个队列，其通过一个共享的队列，使数据从队列的一端输入，从另外一端输出。 当队列是空的，从队列中获取元素的操作将会被阻塞，直到其他线程往空队列中添加了新元素。 当队列是满的，向队列中添加元素的操作将会被阻塞，直到其他其他线程从队列中移除一个或多个元素。 使用阻塞队列，我们不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为阻塞队列自动判断。以常见的生产者-消费者模型为例，当生产者将队列填满产品时，就会进入阻塞状态，直到队列中有元素被“消费”；而当队列没有数据时，消费者线程就会被自动阻塞，直到有产品入队。 BlockingQueue接口中的核心方法主要包括添加、移除、检查元素三种，每种方法有多个具体的方法，其差别如下： 方法类型 抛出异常 返回特殊值 阻塞 超时 插入数据 add(e) offer(e) put(e) offer(e,time,unit) 移除数据 remove() poll() take() poll(time,unit) 检查数据 element() peek() 不可用 不可用 抛出异常：方法执行失败就会抛出异常，比如队列满时添加数据，或者队列空时移除数据。 返回特殊值：对于offer()方法，添加成功返回true，失败则返回false；poll()方法，移除成功则返回移除的元素，否则返回null 阻塞：队列满时，添加数据就会进入阻塞状态；队列空时，移除数据会进入阻塞状态。 超时：带有阻塞时间的方法，在阻塞到指定的时长后，退出线程。 8.2 常见的阻塞队列8.2.1 ArrayBlockingQueueArrayBlockingQueue是由数组结构组成的有界阻塞队列. 底层使用数组实现，长度固定，声明时必须指定大小，先进先出。 创建时，可以指定公平锁或者非公平锁。 8.2.2 LinkedBlockingQueueLinkedBlockingQueue是由链表结构组成的有界阻塞队列。 底层使用链表结构(Node节点)，可以手动指定固定的大小，默认为Integer.MAX_VALUE。 以生产者消费者模型为例，ArrayBlockingQueue在生产者和消费者操作的时候，共用同一个锁对象，因此它们不是完全并行的；LinkedBlockingQueue对于生产者和消费者使用独立的锁来控制数据同步，在高并发情况下提高整个队列的并发性能。 8.2.3 DelayQueueDelayQueue是使用优先级队列实现的延迟无界阻塞队列 DelayQueue中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。 DelayQueue长度无限制，意味着添加数据的进程用于不会被阻塞，只有获取数据的线程才可能会被阻塞。 8.2.4 PriorityBlockingQueuePriorityBlockingQueue是支持优先级排序的无界阻塞队列 基于优先级队列实现，长度无限制，不会阻塞添加数据的进程。 内部控制同步的锁是公平锁。 使用PriorityBlockingQueue要注意的是，如果生产者的速度快于消费者，会导致可用堆内存空间耗尽。 8.2.5 SynchronousQueueSynchronousQueue是不存储元素的阻塞队列 SynchronousQueue不存储元素，或者说只有单个元素。是一个无缓冲区的阻塞队列，类似于消费者生产出一个产品以后，亲自交到消费者手中以后才生产下一个，而没有类似其他阻塞队列的“缓冲区”可以存放生产好的产品。 一个线程的插入操作，必须等待其他线程的移除操作执行完后才能执行，相当于队列只能同时有一个元素。 SynchronousQueue有公平锁和非公平锁模式。 8.2.6 LinkedTransferQueueLinkedTransferQueue是由链表组成的无界阻塞队列 由链表结构组成，相较于其他阻塞队列，多了tryTransfer和transfer方法。 LinkedTransferQueue采用一种预占模式，消费者取数据时，如果队列为空，会生成一个节点（节点元素为null），这个消费者线程会等待在这个节点上，当生产者线程入队时，发现这个节点后，就直接将数据填充到该节点，并唤醒在此等待的消费者线程，消费者线程取走元素。 8.2.7 LinkedBlockingDequeLinkedBlockingDeque是由链表组成的双向有界阻塞队列 和LinkedBlockingQueue相比，LinkedBlockingDeque是由链表组成的双向队列，同样是有界的，最大容量为最大整型数值。 数据可以从队列两端入队出队。 九、线程池9.1 使用线程池Java中的线程池主要是Executor这个接口及其子类。继承体系如下： 线程池接口体系 Executor接口中只有一个execute()方法，用于执行Runnable实现类的线程。 ExecutorService是真正意义上的线程池接口，定义了submit()、shutdown()等线程池相关的方法。 ThreadPoolExecutor是ExecutorService的一个实现类，其定义了对线程池操作的各种方法，比如设置核心池大小，最大线程数等方法。创建线程池就是创建这个类的对象。 Executors类是线程池的一个工具类，提供了多种方法可以创建多种线程池： newCachedThreadPool()：创建一个可缓存线程池，如果线程池长度超过了处理需要的长度，可灵活回收空闲线程，如果没有可回收的线程，则新建线程。 线程池数量不固定，不限制数量，但最大值为Integer.MAX_VALUE 线程池中的线程可进行缓存重复利用和回收。 线程池中没有可用线程时，才会创建新线程。 newFixedThreadPool()：创建一个可重用固定线程数的线程池，以无界队列方式运行这些线程。 线程池中的线程处于一定的量，可以很好的控制线程的并发量 线程可以重复被使用，在显式关闭之前，都将一直存在 超出一定量的线程被提交时需要在队列中等待。 newSingleThreadExecutor()：创建一个只有一个活动线程的线程池，以无界队列方式运行该线程，保证同时只有一个线程在工作。 线程池中同时最多只执行一个线程，之后提交的线程都会排到队列中。 newScheduleThreadPool()：创建一个带有延时执行命令的线程池。线程池支持定时以及周期性执行任务。 newWorkStealingPool()：创建一个拥有多个任务队列的线程池，创建当前可用cpu核数的线程来并行执行任务。JDK 8.0出现，适用于耗时、可并行执行的场景。 案例：银行窗口办理业务，假设有5个窗口，10个客户 123456789101112131415161718// 以银行窗口办理业务为例public class ThreadPoolDemo1 { public static void main(String[] args) { //一池5线程，表示5个窗口 ExecutorService threadPool1 = Executors.newFixedThreadPool(5); try{ //假设有10个顾客 for(int i=1;i&lt;=10;i++){ threadPool1.execute(()-&gt;{ System.out.println(Thread.currentThread().getName()+\"正在办理业务\"); }); } }finally { //关闭线程池 threadPool1.shutdown(); } }} 9.2 线程池原理及参数线程池参数 Executors工具类中创建线程池，都是调用的ThreadPoolExecutor类的构造参数来创建的，只是根据不同的需求，传入的参数不同。 ThreadPoolExecutor构造器： 123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;} 其中的7个参数： int corePoolSize：核心线程数量、常驻线程数量 int maximumPoolSize：最大支持线程数量 long keepAliveTime：线程没有任务时的存活时间（只针对除了核心线程以外的线程） TimeUnit unit：keepAliveTime的时间单位，比如秒、毫秒等 BlockingQueue&lt;Runnable&gt; workQueue：阻塞队列。如果常驻线程数量用完，其他请求就会放到阻塞队列中。当阻塞队列再满的时候，如果有其他请求进入，才创建新的线程，直到达到最大支持的数量。 ThreadFactory threadFactory：线程工厂，用于创建线程 RejectedExecutionHandler handler：拒绝策略，表示什么时候拒绝线程。 当提交的任务数，大于线程池最大支持的线程数量时，就会触发线程池的拒绝策略。 拒绝策略有以下四种： AbortPolicy。默认策略。直接抛出RejectedExecutionException异常阻止系统正常运行。 CallerRunsPolicy：既不会抛弃任务，也不会抛出异常，而是将这些任务回退到调用者，从而降低新任务的流量。 DiscardOldestPolity：抛弃队列中等待最久的任务，然后把当前任务加入队列中并尝试再次提交当前任务。 DiscardPolicy： 默默地丢弃无法处理的任务，不予任何处理也不抛出异常。 线程池工作原理 假设当前线程池的常驻线程数为2，最大线程数为5，阻塞队列固定大小为3，下面分析运行流程。 线程池运行原理 1、提交两个任务，此时常驻线程被占用。 2、当常驻线程都被占用时，再次提交任务3,4,5会进入阻塞队列。 3、当阻塞队列满的时候，再提交任务6,7,8的时候，才会创建新线程。 4、当创建了3个线程后，达到了最大支持线程数量，此时提交任务9，就会触发拒绝策略。 当非核心线程超过存活时间后，会被销毁。 9.3 自定义线程池虽然Executor工具类提供了各种创建线程池的方法，但是一般我们不会使用，根据《阿里巴巴Java开发手册》，开发中创建线程池必须手动创建，手动指定线程池的参数。 这是因为Executors返回的线程池对象有以下弊端： FixedThreadPool和SingleThreadPool：允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。 CachedThreadPool和ScheduledThreadPool：允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。 即使用工具类创建的线程池可能会因为堆积大量请求而导致OOM。 手动创建线程池，需要指定7个参数。 案例：使用自定义线程池实现银行窗口办理业务场景模拟。 12345678910111213141516171819202122//自定义线程池public class ThreadPoolDemo2 { public static void main(String[] args) { //自定义线程池, //常驻线程数量为2，最大为5，超时时间为0秒，阻塞队列为3，拒绝策略为AbortPolicy ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(2, 5, 0L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(3), Executors.defaultThreadFactory(), new ThreadPoolExecutor.AbortPolicy()); //使用线程池。模拟10个客户 try{ for(int i=1;i&lt;=10;i++){ threadPoolExecutor.execute(() -&gt; System.out.println( Thread.currentThread().getName()+\"正在办理业务\")); } }finally { threadPoolExecutor.shutdown(); } }} 上述代码中，当最大线程数为5，阻塞队列容量为3时，面对10个任务请求，会触发拒绝策略， 如果将最大线程数或者队列容量提高，保证二者之和大于等于最大任务请求，就不会触发拒绝策略。实际大小需要根据实际情况而定。","categories":[{"name":"并发编程","slug":"并发编程","permalink":"http://kangshitao.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"},{"name":"JUC","slug":"JUC","permalink":"http://kangshitao.github.io/tags/JUC/"}]},{"title":"SpringBoot2-配置与原理深入解析","slug":"springboot-advance","date":"2021-07-12T13:29:42.000Z","updated":"2022-05-22T13:30:54.804Z","comments":true,"path":"2021/07/12/springboot-advance/","link":"","permalink":"http://kangshitao.github.io/2021/07/12/springboot-advance/","excerpt":"SpringBoot2的自动配置原理、启动流程","text":"一、SpringBoot自动配置原理SpringBoot中的自动配置原理，需要从@SpringBootApplication这个注解出发。 这个注解相当于以下三个注解： @SpringBootConfiguration：等价于@Configuration，表明这是一个SpringBoot项目的配置类。 @EnableAutoConfiguration：开启自动配置功能。 @ComponentScan：自动扫描并加载给定的路径中符合条件的组件，注入到IOC容器中。 其中自动配置的原理，就和@EnableAutoConfiguration有关。 下面着重对其进行分析。 @EnableAutoConfiguration的源码： 123@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration {} 可以看到，@EnableAutoConfiguration是由@AutoConfigurationPackage和@Import两个注解组成的。 其中@AutoConfigurationPackage会自动导入主程序所在包及其子包的一系列组件。即自动导入包机制。 @Import主要是按需加载自动配置类，将生效的自动配置类加载到容器。 下面对这两个注解详细分析。 1.1 @AutoConfigurationPackage自动导包@AutoConfigurationPackage注解是用来自动导入包的，下面深入解析其是如何导入的。 进入其源码： 12@Import(AutoConfigurationPackages.Registrar.class)public @interface AutoConfigurationPackage {} 可以看到，AutoConfigurationPackage为我们自动引入了一个注册器。继续进入AutoConfigurationPackages.Registrar： 内部类Registrar的声明 Registrar是AutoConfigurationPackages的一个内部类，其中有两个方法，主要关注第一个方法。 对registerBeanDefinitions()这个方法进行分析 metadata参数：注解的元信息。这里指的是@AutoConfigurationPackage这个注解，而这个注解相当于直接配置在了启动类上，因此从元信息中获取包名，就是启动类所在的目录名。比如当前启动类在com/kang/root目录下，则new PackageImports(metadata).getPackageNames()的值为com.kang.root。 register()：将指定目录下的包的所有组件注册进来。 由此，我们可以得知，@AutoConfigurationPackage注解，利用Registrar给容器中导入一系列组件，将指定的一个包下的所有组件导入进来，这个包就是主程序所在的包。 因此我们可以解释，为什么SpringBoot扫描包的路径就是主程序所在包及其子包。 1.2 @Import 按需加载配置类@EnableAutoConfiguration第二个重要的注解是@Import，其引入了AutoConfigurationImportSelector，这个类的继承体系如下： AutoConfigurationImportSelector的继承体系 可以看到其实现了ImportSelector接口，并且实现了这个接口的selectImports方法，这个方法主要用于获取所有符合条件的全限定类名，这些类需要被加载到IOC容器中。 AutoConfigurationImportSelector类： 1234567891011@Overridepublic String[] selectImports(AnnotationMetadata annotationMetadata) { //判断自动装配开关是否打开 if (!isEnabled(annotationMetadata)) { return NO_IMPORTS; } //获取所有需要装配的bean AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry(annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());} 接下来进入getAutoConfigurationEntry()这个方法，查看是如何获取需要装配的bean的。 这个方法的源码如下： 1234567891011121314151617181920protected AutoConfigurationEntry getAutoConfigurationEntry( AnnotationMetadata annotationMetadata) { //1.判断自动装配开关是否打开 if (!isEnabled(annotationMetadata)) { return EMPTY_ENTRY; } //2. AnnotationAttributes attributes = getAttributes(annotationMetadata); //3.扫描spring.factories下需要自动装配的所有类 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); //4.下面是过滤出真正需要加载的类。 configurations = removeDuplicates(configurations); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = getConfigurationClassFilter().filter(configurations); fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions);} 代码解析如下： 1、判断自动装配开关是否打开，即spring.boot.enableautoconfiguration的值是否为true. 2、获取@EnableAutoConfiguration注解的所有属性，即exclude和excludeName。 3、getCandidateConfigurations()方法，从META-INF/spring.factories中获取所有需要自动装配的配置类。 内部调用SpringFactoriesLoader.loadFactoryNames()，然后调用loadSpringFactories()方法。然后进入这个方法。 可以看到，这个方法加载了META-INF/spring.factories这个配置文件，默认扫描当前系统里面所有的META-INF/spring.factories位置的文件。 当前版本一共131个需要自动装配的类，没有第三方starter时，他们都是来自spring-boot-autoconfigure-2.5.2包里的META-INF/spring.factories文件。这个自动配置包里面规定了SpringBoot自动配置的一些属性，其中的EnableAutoConfiguration属性就是所有要自动装配的类，如图。 META-INF/spring.factories里配置的需要自动装配的类 因此，如果我们想要实现一个starter，就必须在META-INF/spring.factories文件中配置这样的配置项，指定要加载的自动配置包。 这一步中将自动配置类的所有需要加载的包都读取过来了，那么这些包必须全部加载吗？答案是否定的。 顺着源码继续往下。 4、按需开启自动配置项。虽然读取了所有需要自动加载的类，但是这些类生效都是有条件的，比如需要导入相关的包，这个类才能被加载。因此最终只加载生效的部分类。 配置类中使用@Condition条件装配，判断当前类是否生效。 1.3 总结关于自动配置： SpringBoot先读取所有的自动配置类：xxxxxAutoConfiguration 每个自动配置类按照条件生效，默认都会绑定xxxxProperties类，这个类里面设置了默认的值。 xxxProperties类和配置文件进行了绑定，可以通过配置文件对默认值进行设置。 生效的配置类就会给容器中装配很多组件。只要容器中有这些组件，相当于这些功能就有了 如果我们需要的包没有被starter，则需要手动导入。 我们可以在配置文件中对配置项的值进行修改。 二、Profile功能为了方便多环境适配，SpringBoot简化了profile功能。 我们可以配置多套环境，比如测试环境和生产环境，可以方便的在不同的环境中切换。 比如同时配置多个配置文件，表示多个配置环境，根据需求使用不同的配置： 1234application.yaml 总配置文件application-test.yaml test环境application-prod.yaml prod环境... 2.1 application-profile功能 默认配置文件 application.yaml任何时候都会加载 指定环境配置文件，格式： application-{env}.yaml，比如application-prod.yaml文件，代表prod环境。 激活指定环境： 方式一：使用配置文件激活。比如在默认配置文件中使用spring.profiles.active=test激活test环境。 方式二：命令行激活。对于已经打包的程序，命令行也能够指定环境并修改配置文件的任意值。比如使用命令行激活prod环境，并指定参数值 12# 这时，命令行的参数值会生效java -jar xxx.jar --spring.profiles.active=prod --person.name=haha 默认配置与环境配置同时生效 对于同名配置项，指定的环境配置生效。 2.2 @Profile条件装配功能@Profile可以用在类上或者方法上，表示只有在指定的环境下才生效。 比如@Profile(\"test\")标注，表示这个类/方法只有在test环境下才生效。 比如： person.java 123@Component@ConfigurationProperties(\"person\")public interface Person {} Boss.java 123456789101112//这个类只在prod环境下注册@Profile(\"prod\") @Componentpublic class Boss implements Person{ private String name; private Integer age; public String getName() {return name;} public void setName(String name) {this.name = name;} public Integer getAge() {return age;} public void setAge(Integer age) {this.age = age;}} Worker.java 123456789101112//这个类只在test环境下注册@Profile(\"test\")@Componentpublic class Worker implements Person{ private String name; private Integer age; public String getName() {return name;} public void setName(String name) {this.name = name;} public Integer getAge() {return age;} public void setAge(Integer age) {this.age = age;}} 然后定义一个controller类，HelloController.java 12345678910@RestControllerpublic class HelloController { @Autowired Person person; @GetMapping(\"/\") public String hello(){ return person.getClass().getName(); }} 这样，如果在test环境下，访问主页就会返回com.kang.boot.bean.Worker，如果在prob环境下，返回值为com.kang.boot.bean.Boss。 2.3 profile分组可以使用spring.profiles.group对配置文件进行分组，然后同时激活同一个组的多个配置文件。比如： application.properties 1234567# 激活myprod组spring.profiles.active=myprod# 定义两个配置组，myprod和mytestspring.profiles.group.myprod[0]=prodspring.profiles.group.myprod[1]=prod2spring.profiles.group.mytest[0]=test 三、配置加载优先级参考官方文档Externalized Configuration 后加载的会覆盖前面加载的。 根据官方文档，SpringBoot的配置文件可以来自于以下方面，按照从上往下的顺序，其中后加载的会覆盖前面的： Default properties (specified by setting SpringApplication.setDefaultProperties). @PropertySource annotations on your @Configuration classes. Please note that such property sources are not added to the Environment until the application context is being refreshed. This is too late to configure certain properties such as logging.* and spring.main.* which are read before refresh begins. Config data (such asapplication.properties files) A RandomValuePropertySource that has properties only in random.*. OS environment variables. Java System properties (System.getProperties()). JNDI attributes from java:comp/env. ServletContext init parameters. ServletConfig init parameters. Properties from SPRING_APPLICATION_JSON (inline JSON embedded in an environment variable or system property). Command line arguments. properties attribute on your tests. Available on @SpringBootTest and the test annotations for testing a particular slice of your application. @TestPropertySource annotations on your tests. Devtools global settings properties in the $HOME/.config/spring-boot directory when devtools is active. 加粗是比较常用的两种。 3.1 外部配置源常用：Java属性文件、YAML文件、环境变量、命令行参数； 3.2 配置文件查找位置配置文件的查找顺序： (1) classpath 根路径（Java文件夹和resource文件夹都属于根路径，编译后都位于target根目录下） (2) classpath 根路径下config目录 (3) jar包当前目录 (4) jar包当前目录的config目录 (5) /config子目录的直接子目录 3.3 配置文件加载顺序： 当前jar包内部的application.properties和application.yml 当前jar包内部的application-{profile}.properties 和 application-{profile}.yml 引用的外部jar包的application.properties和application.yml 引用的外部jar包的application-{profile}.properties 和 application-{profile}.yml 3.4 总结指定环境优先，外部优先，后面的可以覆盖前面的同名配置项。 四、自定义starter4.1 starter启动原理starter的启动流程： 1、指定要加载的自动配置类 在引入starter后，会加载指定的自动配置类。 SpringBoot的autoconfigure包中，META-INF下的spring.factories文件，使用了 EnableAutoConfiguration 的值指定了项目启动时要加载的自动配置类。如图： SpringBoot的spring.factories 2、自动配置类中指定要加载的类xxxProperties 一般来说，自动配置类用于自动注册组件，并使用指定的配置类，进行属性值的注入。 以org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration为例，加载这个自动配置类，这个配置类的声明如下： 1234567891011@Configuration(proxyBeanMethods = false)@ConditionalOnClass(CacheManager.class)@ConditionalOnBean(CacheAspectSupport.class)@ConditionalOnMissingBean(value = CacheManager.class, name = \"cacheResolver\")@EnableConfigurationProperties(CacheProperties.class)@AutoConfigureAfter({ CouchbaseDataAutoConfiguration.class, HazelcastAutoConfiguration.class, HibernateJpaAutoConfiguration.class, RedisAutoConfiguration.class })@Import({ CacheConfigurationImportSelector.class, CacheManagerEntityManagerFactoryDependsOnPostProcessor.class })public class CacheAutoConfiguration {...} 这个自动配置类使用@EnableConfigurationProperties注解，指定了要加载的配置类CacheProperties。 其余的注解则规定了这个自动配置类的生效条件，比如@ConditionalOnBean、@ConditionalOnMissingBean等注解。例如：@ConditionalOnBean(CacheAspectSupport.class)表示当前容器中有CacheAspectSupport这个类的组件时，当前的自动配置类才生效。 3、xxxProperties中绑定配置文件中的配置属性 这个类中规定了默认值，自动配置组件的值就是从这里取。并且这个类和配置文件绑定，我们可以通过配置文件对默认值进行修改。 12@ConfigurationProperties(prefix = \"spring.cache\")public class CacheProperties {...} 比如CacheProperties这个配置类，使用@ConfigurationProperties(prefix = \"spring.cache\")注解，将配置文件中spring.cache开头的配置项的值，绑定到当前类中对应的属性。 这样，我们在总配置文件中使用spring.cache.xxx=xxx，就可以对cache相关的内容进行配置。 4.2 自定义starter仿照官方的starter启动流程，我们可以创建自定义的starter。 1、创建starter和starter-autoconfigure项目 自定义starter需要创建一个starter项目和一个对这个starter自动配置的项目。 如图： 自定义的启动器一般是xxx-spring-boot-starter的命名格式，对其自动配置的包一般是xxx-spring-boot-starter-autoconfigure格式。 在启动器中引入自动配置包的依赖，如图： 启动器中引入自动配置包的依赖 这样，我们使用的时候，只需要引入starter就可以使用，它就会自动为我们导入自动配置的依赖包。 我们可以把需要的配置，都在自动配置包中引入依赖。 2、在spring.factories中指定要加载的自动配置类 为了保证我们的自动配置类能自动加载，需要在自动配置包的META-INF/spring.factories文件中，指定项目启动时要加载的自动配置类： spring.factories中的内容如下： 123# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.kang.hello.auto.HelloServiceAutoConfiguration 指定项目启动时，会加载com.kang.hello.auto.HelloServiceAutoConfiguration这个配置类。 3、编写xxxAutoConfiguration和xxxProperties和功能类 配置类HelloProperties，对属性值和配置文件中的值进行绑定 1234567891011//绑定配置文件中的前缀@ConfigurationProperties(prefix = \"kang.hello\")public class HelloProperties { private String prefix; private String suffix; public String getPrefix() {return prefix;} public void setPrefix(String prefix) {this.prefix = prefix;} public String getSuffix() {return suffix;} public void setSuffix(String suffix) {this.suffix = suffix;}} 这样，项目中在配置文件中使用kang.hello就可以对prefix和suffix进行配置。 自动配置类HelloServiceAutoConfiguration，用于注册组件： 12345678910@Configuration@EnableConfigurationProperties(HelloProperties.class)public class HelloServiceAutoConfiguration { @Bean @ConditionalOnMissingBean(HelloService.class) public HelloService helloService(){ return new HelloService(); }} 当容器中没有HelloService组件时，自动配置类才会注册HelloService组件，并根据HelloProperties中的绑定的值，对HelloProperties中的属性值进行注入。 HelloService中定义了自定义启动器要封装的功能方法。 1234567891011121314/*默认不要放在容器中 */public class HelloService { @Autowired //自动装配配置类 HelloProperties helloProperties; //定义一个方法，在输入参数中添加前缀和后缀 public String sayHello(String userName){ String prefix = helloProperties.getPrefix(); String suffix = helloProperties.getSuffix(); return prefix+\",\"+userName+\",\"+suffix; }} 4、将 starter和starter-autoconfigure项目进行打包安装 将自动配置包使用Maven进行install，然后对starter进行install。 这样，我们的自定义启动器就算创建好了，别的项目直接引入自定义的starter依赖就可以使用其中提供的方法了。 5、测试自定义starter 新建一个项目，引入自定义的starter依赖： pom.xml 12345&lt;dependency&gt; &lt;groupId&gt;com.kang&lt;/groupId&gt; &lt;artifactId&gt;kang-hello-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 然后在配置类中，使用kang.hello对两个参数进行配置 application.properties 12kang.hello.prefix = hellokang.hello.suffix = bye 编写方法，调用starter中定义好的方法完成功能： HelloController 123456789101112@RestControllerpublic class HelloController { //引入了自定义的启动器，可以使用其提供的方法。 @Autowired HelloService helloService; @GetMapping(\"/hello\") public String sayHello(){ String str = helloService.sayHello(\"KANG\"); return str; }} 这样，在浏览器中发送hello请求，返回值为： 1hello,KANG,bye 测试成功，说明自定义的启动器没有问题。 上面使用的是自动装配的HelloService，如果我们不希望使用提供的原方法，就可以自定义HelloService，这样，自动配置类不会自动注册HelloService，项目会使用我们自己的HelloService。实现了SpringBoot中的自定义优先的情况。 因此，如果我们在使用starter的过程中，如果现有的方法不能满足我们的需求，我们就可以根据源码找到其方法进行重写，这样项目就会使用我们重写之后的方法。 比如我们定义一个配置类，并自己新建一个HelloService对象，通过调用方法实现需求，这时底层使用的就是我们创建的这个对象： 123456789@Configurationpublic class MyConfig { @Bean public HelloService helloService(){ HelloService helloService = new HelloService(); //对helloService进行自定义的操作，比如setXxx() return helloService; }} 五、SpringBoot启动原理5.1 SpringBoot启动过程进入run方法： run方法代码 可以看到主要有两步，创建SpringApplication和运行SpringApplication. 1、创建SpringApplication 进入new SpringApplication方法，创建SpringApplication，应用创建的过程，简单来说就是先将一些组件读取到应用中。 SpringApplication.java的构造器方法： 123456789101112131415161718public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) { //加载一些信息 this.resourceLoader = resourceLoader; //判断是否有主配置类信息 Assert.notNull(primarySources, \"PrimarySources must not be null\"); //保存主配置类信息 class com.kang.boot.Springboot09HelloTestApplication this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); //判断应用类型 Servlet this.webApplicationType = WebApplicationType.deduceFromClasspath(); //去spring.factories查找初始启动引导器 null this.bootstrapRegistryInitializers = getBootstrapRegistryInitializersFromSpringFactories(); //去spring.factories查找ApplicationContextInitializer 找到n个 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); //去spring.factories查找监听器 找到n个 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //查找主程序 class com.kang.boot.Springboot09HelloTestApplication this.mainApplicationClass = deduceMainApplicationClass();} 主要步骤总结如下： 用于保存一些信息。 判定当前应用的类型。内部使用了ClassUtils工具类。判断结果为Servlet类型 bootstrapRegistryInitializers：初始启动引导器注册初始化，其内部通过SpringFactoriesLoader去spring.factories文件中找org.springframework.boot.Bootstrapper，即查看是否有初始的启动引导器。 去spring.factories文件找 ApplicationContextInitializer，即ApplicationContext初始化器 结果保存到：List","categories":[{"name":"SpringBoot2","slug":"SpringBoot2","permalink":"http://kangshitao.github.io/categories/SpringBoot2/"}],"tags":[{"name":"SpringBoot2","slug":"SpringBoot2","permalink":"http://kangshitao.github.io/tags/SpringBoot2/"},{"name":"Spring","slug":"Spring","permalink":"http://kangshitao.github.io/tags/Spring/"}]},{"title":"SpringBoot数据访问-SQL","slug":"springboot-sql","date":"2021-07-12T09:07:01.000Z","updated":"2022-05-22T13:30:54.804Z","comments":true,"path":"2021/07/12/springboot-sql/","link":"","permalink":"http://kangshitao.github.io/2021/07/12/springboot-sql/","excerpt":"SpringBoot进行数据访问，整合MyBatis进行CRUD操作","text":"一、DataSource1.1 HikariDataSource数据源如果未指定数据源，SpringBoot中默认使用HikariDataSource数据源。 使用其进行数据库的CRUD操作步骤： 1、确保项目引入了JDBC场景 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; 官方的JDBC启动器没有引入数据库驱动，我们需要根据需求，引入指定的数据库驱动，以MySQL为例： 12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.49&lt;/version&gt;&lt;/dependency&gt; 我们要确保数据库版本和数据库驱动版本一致。SpringBoot2.5.2中的MySQL驱动版本是8，则需要数据库版本也是8以上。 如果想要修改驱动版本，有两种方式： 直接依赖引入具体版本（maven的就近依赖原则），比如上面的做法。 重新声明版本（maven的属性的就近优先原则），比如下面的做法： 12345&lt;!-- 通过属性修改版本 --&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;mysql.version&gt;5.1.49&lt;/mysql.version&gt;&lt;/properties&gt; 2、分析自动配置 分析SpringBoot为我们自动配置好的配置，通过分析源码可知，底层配置好了HikariDataSource连接池，以及事务管理器，分布式事务等。 底层还有一个JdbcTemplate组件。 连接池的配置可以使用spring.datasource配置。 3、修改配置项 在配置文件中，配置以下内容： 1234567891011spring: datasource: url: jdbc:mysql://localhost:3306/springboot?useSSL=false&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver# 可以根据需求设置其他参数 jdbc: template: query-timeout: 3 4、测试 1234567891011class Boot05WebAdminApplicationTests { @Autowired JdbcTemplate jdbcTemplate; @Test public void test() { Long aLong = jdbcTemplate.queryForObject( \"select count(*) from books\", Long.class); System.out.println(aLong); }} 1.2 Druid数据源Druid项目地址：https://github.com/alibaba/druid 整合第三方技术有两种方式： 自定义方式 使用其提供的starter 1.2.1 自定义方式1、引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.22&lt;/version&gt;&lt;/dependency&gt; 2、并创建数据源 创建数据源，可以根据需求定义一些配置。可以使用传统XML的方式注册bean 123456&lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" destroy-method=\"close\"&gt; &lt;property name=\"url\" value=\"${jdbc.url}\" /&gt; &lt;property name=\"username\" value=\"${jdbc.username}\" /&gt; &lt;property name=\"password\" value=\"${jdbc.password}\" /&gt;&lt;/bean&gt; 也可以定义一个配置类，在配置类中使用@Bean注册组件： 12345678910111213141516171819/*手动配置数据源。在配置类中配置 */@Configurationpublic class MyDataSourceConfig { @Bean //绑定配置文件。数据源的属性会跟配置文件的spring.datasource数据一一绑定 @ConfigurationProperties(\"spring.datasource\") public DataSource dataSource() throws SQLException { DruidDataSource druidDataSource = new DruidDataSource(); //可以在这里配置，也可以直接读取配置文件中的配置，建议后者。 //druidDataSource.setUrl(); //druidDataSource.setUsername(); //druidDataSource.setPassword(); //可以加入或开启其他功能 return druidDataSource; }} 将账号密码等信息配置在配置文件中： 123456spring: datasource: url: jdbc:mysql://localhost:3306/ssmbuild?useSSL=false&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver 3、测试 123456789101112@Controllerpublic class DataSourceController { @Autowired JdbcTemplate jdbcTemplate; @ResponseBody @GetMapping(\"/sql\") public String druidTest(){ Long aLong = jdbcTemplate.queryForObject(\"select count(*) from books\", Long.class); return aLong.toString(); }} 1.2.2 使用官方starter1、引入starter 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.17&lt;/version&gt;&lt;/dependency&gt; 启动器为我们自动引入了数据源 2、分析自动配置 根据源码，分析官方已经配置好的配置，已经配置参数的使用。 可以使用spring.datasource.druid在配置文件中对druid进行各项的配置。 3、配置示例 可以参考：https://github.com/alibaba/druid/tree/master/druid-spring-boot-starter 12345678910111213141516171819202122232425262728293031spring: datasource: url: jdbc:mysql://localhost:3306/db_account username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver druid: aop-patterns: com.atguigu.admin.* #监控SpringBean filters: stat,wall # 底层开启功能，stat（sql监控），wall（防火墙） stat-view-servlet: # 配置监控页功能 enabled: true login-username: admin login-password: admin resetEnable: false web-stat-filter: # 监控web enabled: true urlPattern: /* exclusions: '*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*' filter: stat: # 对上面filters里面的stat的详细配置 slow-sql-millis: 1000 logSlowSql: true enabled: true wall: enabled: true config: drop-table-allow: false 二、整合MyBatisSpringBoot整合MyBatis的主要步骤如下： 导入MyBatis的官方starter 编写mapper接口，并使用@Mapper接口注册。 编写Service类 编写映射文件，绑定mapper接口 在总配置文件application.yaml中指定映射文件的位置，以及MyBatis配置文件的位置（建议直接将MyBatis的配置写在总配置文件中）。 2.1 配置模式1、引入stater 首先引入官方starter，其为我们配置好了SqlSession pom.xml 123456&lt;!-- 引入MyBatis的starter --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.4&lt;/version&gt;&lt;/dependency&gt; 2、编写mapper和service 编写mapper接口和service层，所有的Mapper接口都需要使用@Mapper注解标注，表示注册当前接口为Mapper。 BookMapper.java 1234@Mapperpublic interface BookMapper { public Book getBookById(int id);} 也可以在SpringBoot启动类上，使用@MapperScan(\"com.kang.admin.mapper\") 注解，表示将指定包下的所有类统一注册为Mapper，这样其中的接口就可以不用单独使用@Mapper注解。 @Mapper的功能类似于@Repository，都是用在DAO层，表示注册当前类。 @Mapper不需要配置扫描地址，而@Repository需要配置扫描地址。 SpringBoot中一般使用@Mapper注解。 源码对@Mapper的解释：Marker interface for MyBatis mappers BookService.java 12345678@Servicepublic class BookService { @Autowired BookMapper bookMapper; public Book getBookById(int id){ return bookMapper.getBookById(id); }} 3、编写sql映射器文件并绑定mapper接口 BookMapper.xml 12345678910&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.kang.admin.mapper.BookMapper\"&gt; &lt;select id=\"getBookById\" resultType=\"com.kang.admin.bean.Book\"&gt; select * from ssmbuild.books where bookID=#{id} &lt;/select&gt;&lt;/mapper&gt; 在application.yml中指定MyBatis的映射器文件和MyBatis总配置文件的位置。 application.yml 1234567# 配置数据源...# 配置MyBatismybatis: config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xml mybatis-config.xml 1mybatis配置文件 这里的路径，应该是编译后的配置文件路径，resources下的文件都会被直接编译到target目录下。 我们也可以在application.yml中的mybatis.configuration，对MyBatis进行配置，比如驼峰命名映射等，取代mybatis-config.xml配置文件。推荐这一种方式，尽量不写多余的配置文件。 比如： 123456# 配置MyBatismybatis: # 将MyBatis配置写在这里，就不需要config-location这个配置了 mapper-locations: classpath:mybatis/mapper/*.xml configuration: map-underscore-to-camel-case: true # 驼峰命名映射开启 2.2 注解模式参考官方：https://github.com/mybatis/spring-boot-starter/wiki/Quick-Start 使用注解模式编写SQL语句，避免了为每个Mapper编写映射文件。 常用的注解：@Select、@Insert、@Update、@ Delete 具体使用方式可以参考：MyBatis注解模式 案例： 12345@Mapperpublic interface CityMapper { @Select(\"select * from city where id=#{id}\") public City getById(Long id);} 2.3 混合模式混合使用注解和配置文件两种方式。 123&lt;insert id=\"indert\" useGenerateKeys=\"true\" keyProperty=\"id\"&gt; insert into city(`name`,`state`,`country`) values(#{name},#{state},#{country})&lt;/insert&gt; insert语句中的useGenerateKeys属性，能够确保类似id这种自增主键插入数据库后，也能够返回到参数city中。 以上代码使用注解方式为： 123@Insert(\"insert into city(`name`,`state`,`country`) values(#{name},#{state},#{country})\")@Options(useGeneratedKeys = true,keyProperty = \"id\")public void insert(City city); 最佳实践： 引入mybatis-starter 配置application.yaml中，指定mapper-location位置（将MyBatis配置文件单独配置） 编写Mapper接口并标注@Mapper注解 简单方法直接注解方式；复杂方法编写mapper.xml进行绑定映射。 三、整合MyBatis-Plus3.1 什么是MyBatis-PlusMyBatis-Plus是MyBatis的一个增强工具，在MyBatis的基础上只做增强不做改变，简化开发。 3.2 整合MyBatis-Plus1、引入starter 123456&lt;!-- 引入MyBatis-Plus的starter --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt;&lt;/dependency&gt; MyBatis-Plus的starter自动帮我们引入了JDBC、MyBatis、MyBatis-Spring等依赖包，因此如果使用MyBatis-Plus则不必单独这些依赖。 2、分析starter，查看配置信息 分析其自动配置类可知，可以通过mybatis-plus对其进行配置。 为我们配置好了SqlSessionFactory，数据源是容器中默认的数据源。 自动配置了mapperLocations，默认值为classpath*:/mapper/**/*.xml，即任意包的类路径（编译之后的路径）下的所有mapper文件夹中任意路径的xml文件，都作为映射文件。因此建议以后的映射文件放在mapper目录下面。 @Mapper标注的接口，也会被自动扫描，不需要再配置。建议还是使用@MapperScan注解批量扫描。 3、使用MyBatis-Plus MyBatis-Plus为我们提供了BaseMapper接口，其定义了大部分的增删查改操作。我们只需要在接口上继承BaseMapper即可，不需要写任何方法，无需写映射文件，使用的时候直接调用BaseMapper中的方法。 UserMapper.java接口 1public interface UserMapper extends BaseMapper&lt;User&gt; {} 如果我们要编写service层，是否要实现BaseMapper中的所有方法？MyBatis-Plus也为我们提供了一个service层的接口IService，这是顶级service，其定义了常用的service层方法。 并且，MyBatis-Plus还为我们提供了IService的实现类ServiceImpl，我们的实现类只需要继承它即可，同样也不需要重写方法。 UserService.java 1public interface UserService extends IService&lt;User&gt; {} UserServiceImpl.java 123@Servicepublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService {} 一般@Service\\@Repository之类的注解使用在类上。@Autowired可以用在接口上 这样，我们就可以直接调用方法进行使用了。 使用MyBatis-Plus，为我们省去了配置映射文件，手动实现CRUD操作的步骤。 其他说明 @TableName注解和@TableField注解： @TableName ：可以用来指定要查找的表。因为MyBatis-Plus默认对和Mapper接口名相同的表进行操作。 TableField：MyBatis-Plus默认要求实体类的属性必须都在表中存在，如果某个属性不在表中，可以使用这个注解进行标注。 123456//指定要查找的表@TableName(\"user\")public class User { @TableField(exist = false) private String userName; //假设这个属性在表中不存在} 3.3 分页功能MyBatis-Plus为我们提供了分页插件，我们可以使用它完成分页功能。 首先需要将MybatisPlusInterceptor这个组件设置参数，并注入容器。 123456789101112131415161718@Configurationpublic class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); // 设置请求的页面大于最大页后操作， true调回到首页，false 继续请求 默认false // paginationInterceptor.setOverflow(false); // 设置最大单页限制数量，默认 500 条，-1 不受限制 // paginationInterceptor.setLimit(500); // 开启 count 的 join 优化,只针对部分 left join PaginationInnerInterceptor paginationInnerInterceptor = new PaginationInnerInterceptor(); paginationInnerInterceptor.setOverflow(true); paginationInnerInterceptor.setMaxLimit(100L); interceptor.addInnerInterceptor(paginationInnerInterceptor); return interceptor; }} 然后在controller中获取Page类对象，实现分页功能。 1234567891011121314151617181920212223242526272829303132333435363738394041@Controllerpublic class TableController { @Autowired UserService userService; //controller层调用service层 //使用MyBatis-Plus中的Page对象，实现分页查询。 @GetMapping(\"/dynamic_table\") public String dynamic_table(@RequestParam(value = \"pn\",defaultValue = \"1\") Integer pn, Model model) { Page&lt;User&gt; userPage = new Page&lt;&gt;(pn, 2); //指定当前页码和每页数量 Page&lt;User&gt; page = userService.page(userPage, null); //可以获取page对象的各种参数，比如总页数，当前页之类的 //long current = page.getCurrent(); //long pages = page.getPages(); //long total = page.getTotal(); //List&lt;User&gt; records = page.getRecords(); model.addAttribute(\"page\",page); return \"table/dynamic_table\"; } /** * 删除指定id的数据，然后重定向到当前页。 * @param id 使用RESTFul风格传递，因此使用@PathVariable注解 * @param pn 页码使用参数传递，因此使用@RequestParam绑定 * @param ra RedirectAttributes类型用于给重定向时添加参数 * @return */ @GetMapping(\"/user/delete/{id}\") public String deleteUser(@PathVariable(\"id\") Long id, @RequestParam(value=\"pn\",defaultValue=\"1\") Integer pn, RedirectAttributes ra){ //RedirectAttributes用于给重定向添加参数 userService.removeById(id); ra.addAttribute(\"pn\",pn); return \"redirect:/dynamic_table\"; }} 前端页面从Page对象中取数据，并分页显示：","categories":[{"name":"SpringBoot2","slug":"SpringBoot2","permalink":"http://kangshitao.github.io/categories/SpringBoot2/"}],"tags":[{"name":"SpringBoot2","slug":"SpringBoot2","permalink":"http://kangshitao.github.io/tags/SpringBoot2/"},{"name":"Spring","slug":"Spring","permalink":"http://kangshitao.github.io/tags/Spring/"},{"name":"MyBatis","slug":"MyBatis","permalink":"http://kangshitao.github.io/tags/MyBatis/"}]},{"title":"使用SpringBoot2进行Web开发","slug":"springboot-web","date":"2021-07-11T08:01:39.000Z","updated":"2022-05-22T13:30:54.805Z","comments":true,"path":"2021/07/11/springboot-web/","link":"","permalink":"http://kangshitao.github.io/2021/07/11/springboot-web/","excerpt":"使用SpringBoot框架开发Web项目，包括视图解析、参数传递、数据响应等","text":"一、对SpringMVC的自动配置1.1 自动配置SpringBoot中自动配置了SpringMVC，大多场景我们都不需要自定义配置。 在Spring的基础上，SpringBoot添加了以下的特征： ContentNegotiatingViewResolver （内容协商视图解析器）和BeanNameViewResolver（BeanName）视图解析器 支持静态资源，包括webjars 自动注册 Converter，GenericConverter，Formatter 支持HeepMessageConverters 自动注册MessageCodesResolver，用于国际化 静态index.html支持 自定义facicon 自动使用 ConfigurableWebBindingInitializer ，（DataBinder负责将请求数据绑定到JavaBean上） 1.2 自定义配置SpringBoot为我们提供了WebMvcConfigurer接口，可以实现对SpringMVC的各项自定义功能： 12345678910111213141516171819202122232425262728293031323334353637383940public interface WebMvcConfigurer { default void configurePathMatch(PathMatchConfigurer configurer) {} default void configureContentNegotiation(ContentNegotiationConfigurer configurer) {} default void configureAsyncSupport(AsyncSupportConfigurer configurer) {} default void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) {} default void addFormatters(FormatterRegistry registry) {} default void addInterceptors(InterceptorRegistry registry) {} default void addResourceHandlers(ResourceHandlerRegistry registry) {} default void addCorsMappings(CorsRegistry registry) {} default void addViewControllers(ViewControllerRegistry registry) {} default void configureViewResolvers(ViewResolverRegistry registry) {} default void addArgumentResolvers(List&lt;HandlerMethodArgumentResolver&gt; resolvers) {} default void addReturnValueHandlers(List&lt;HandlerMethodReturnValueHandler&gt; handlers) {} default void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {} default void extendMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {} default void configureHandlerExceptionResolvers(List&lt;HandlerExceptionResolver&gt; resolvers) {} default void extendHandlerExceptionResolvers(List&lt;HandlerExceptionResolver&gt; resolvers) {} @Nullable default Validator getValidator() {return null;} @Nullable default MessageCodesResolver getMessageCodesResolver() {return null;}} 我们有两种方式自定义这个接口，都需要先准备一个配置类： 直接实现接口，然后按需实现其中的方法。 使用@Bean注解返回组件。 两种方式的代码如下： 1234567//方式一：实现WebMvcConfigurer接口@Configuration(proxyBeanMethods = false)public class WebConfig implements WebMvcConfigurer { //重写需要自定义的方法即可 @Override public void configurePathMatch(PathMatchConfigurer configurer) {...}} 1234567891011121314//方式二：使用注解@Configuration(proxyBeanMethods = false)public class WebConfig { @Bean public WebMvcConfigurer webMvcConfigurer(){ //将匿名实现类返回 return new WebMvcConfigurer() { //重写需要自定义的方法 @Override public void configurePathMatch(PathMatchConfigurer configurer) {...} }; }} 关于SpringMVC的功能定制，都可以在这个配置类中进行自定义。 二、简单功能分析2.1 静态资源访问2.1.1 静态资源目录SpringBoot默认将静态资源放在以下目录，查找顺序从上往下： main/resources/META-INF/resources main/resources/resources main/resources/static main/resources/public 以上文件夹的静态资源访问时，使用当前项目根路径/静态资源名即可访问。 SpringBoot底层使用/**拦截了所有请求。当收到一个请求时，会先判断controller能不能处理，如果不能处理就交给静态资源处理，都不能处理则返回404。 2.1.2 静态资源访问前缀默认静态资源访问无前缀，可以通过配置，改变默认的静态资源访问前缀和访问路径： 12345spring: mvc: static-path-pattern: /res/** # 指定所有静态资源的访问前缀 resources: static-locations: [classpath:/mystatic/] # 重新指定静态资源的存放路径 如果添加了静态资源的访问前缀，这样访问所有静态资源都要使用指定的前缀。 如果修改了静态资源的目录，这样只能访问指定路径下的静态资源，默认的路径全失效。 2.1.3 webjar项目路径/webjars/** webjar 需要引入依赖，比如引入webjars的jquery： 12345&lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt;&lt;/dependency&gt; 此时访问地址为：http://localhost:8080/webjars/jquery/3.5.1/jquery.js，后面的地址需要按照依赖里面的包路径。 2.2 欢迎页支持SpringBoot支持欢迎页，默认静态资源路径下的index.html会被当作欢迎页。 可以配置静态资源路径。 但是如果配置了静态资源的访问前缀，欢迎页就会失效，因为源码中判断只能在默认静态资源路径中访问欢迎页： 1if (welcomePage != null &amp;&amp; \"/**\".equals(staticPathPattern)){} 2.3 自定义Favicon将图标命名为favicon.ico，并放在静态资源目录下即可。同样地，静态资源访问前缀会导致其失效。 2.4 静态资源配置原理2.4.1 资源处理的默认规则1、SpringBoot启动默认加载自动配置类。 2、添加了Web框架支持的项目会自动导入web常见启动器，然后SpringMVC的自动配置类 WebMvcAutoConfiguration就会生效： 12345678910111213141516171819@Configuration(proxyBeanMethods = false)@ConditionalOnWebApplication(type = Type.SERVLET)@ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class })@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter({ DispatcherServletAutoConfiguration.class, TaskExecutionAutoConfiguration.class, ValidationAutoConfiguration.class })public class WebMvcAutoConfiguration { //The default Spring MVC view prefix. public static final String DEFAULT_PREFIX = \"\"; //The default Spring MVC view suffix. public static final String DEFAULT_SUFFIX = \"\"; private static final String SERVLET_LOCATION = \"/\"; ...} 3、WebMvcAutoConfiguration中有一个静态内部类，WebMvcAutoConfigurationAdapter: 123456789@SuppressWarnings(\"deprecation\") @Configuration(proxyBeanMethods = false) @Import(EnableWebMvcConfiguration.class) @EnableConfigurationProperties({WebMvcProperties.class, ResourceProperties.class, WebProperties.class }) @Order(0) public static class WebMvcAutoConfigurationAdapter implements WebMvcConfigurer, ServletContextAware{} 可以看到，其绑定了三个xxxProperties类，这三个类中定义了SpringMVC应用的参数的默认值，并且绑定了配置文件中的spring.mvc、spring.resources、spring.web三个对应的配置前缀，我们只需要在配置文件中配置这些参数即可修改默认值。其中在WebProperties这个类中，就定义了静态资源的默认访问路径。 这个内部类，只有一个有参构造器，这个构造器中所有参数的值都会从容器中确定，构造器代码： 123456789101112131415161718public WebMvcAutoConfigurationAdapter(...一堆参数) { //获取和spring.resources绑定的所有的值的对象 this.resourceProperties = resourceProperties.hasBeenCustomized() ? resourceProperties: webProperties.getResources(); //获取和spring.mvc绑定的所有的值的对象 this.mvcProperties = mvcProperties; //Spring的beanFactory this.beanFactory = beanFactory; //找到所有的HttpMessageConverters this.messageConvertersProvider = messageConvertersProvider; //找到资源处理器的自定义器 this.resourceHandlerRegistrationCustomizer = resourceHandlerRegistrationCustomizerProvider.getIfAvailable(); this.dispatcherServletPath = dispatcherServletPath; //给应用注册Servlet、Filter.... this.servletRegistrations = servletRegistrations; this.mvcProperties.checkConfiguration();} 2.4.2 欢迎页的处理规则12345678910111213141516171819final class WelcomePageHandlerMapping extends AbstractUrlHandlerMapping { ... WelcomePageHandlerMapping(TemplateAvailabilityProviders templateAvailabilityProviders, ApplicationContext applicationContext, Resource welcomePage, String staticPathPattern) { //可以看到，要使用欢迎页，必须是/** if (welcomePage != null &amp;&amp; \"/**\".equals(staticPathPattern)) { logger.info(\"Adding welcome page: \" + welcomePage); setRootViewName(\"forward:index.html\"); } else if (welcomeTemplateExists(templateAvailabilityProviders, applicationContext)) { logger.info(\"Adding welcome page template: index\"); setRootViewName(\"index\"); } } ...} 三、请求映射和参数处理3.1 请求映射3.1.1 REST的使用与原理使用 使用xxxMapping注解表示对收到的请求进行处理。 RequestMapping：适用于各种请求 @GetMapping：只适用于get请求，RESTful风格中表示获取、查询信息 @PostMapping：只适用于post请求，RESTful风格中表示添加信息 @PutMapping：只适用于put请求中，RESTful风格中表示修改信息 @DeleteMapping：只适用于delete请求，RESTful风格中表示删除信息。 form表单只支持get和post两种提交方式，如何确保请求方式为put和delete呢？ 方法： 首先需要在配置文件中开启隐藏域方法支持，SpringBoot2.5.2已经默认开启了： 12345spring: mvc: hiddenmethod: filter: enabled: true form表单中有一个隐藏方法域，在其中定义请求方式，需要在method=post的前提下使用： test.html 123456789101112131415&lt;form action=\"/user\" method=\"get\"&gt; &lt;input value=\"REST-GET提交\" type=\"submit\"/&gt;&lt;/form&gt;&lt;form action=\"/user\" method=\"post\"&gt; &lt;input value=\"REST-POST提交\" type=\"submit\"/&gt;&lt;/form&gt;&lt;!-- 必须在post请求里面定义_method隐藏域才能生效 --&gt;&lt;form action=\"/user\" method=\"post\"&gt; &lt;input name=\"_method\" type=\"hidden\" value=\"delete\"/&gt; &lt;input value=\"REST-DELETE提交\" type=\"submit\"/&gt;&lt;/form&gt;&lt;form action=\" /user\" method=\"post\"&gt; &lt;input name=\"_method\" type=\"hidden\" value=\"PUT\"/&gt; &lt;input value=\"REST-PUT提交\" type=\"submit\"/&gt;&lt;/form&gt; 这样，在controller收到请求后，如果是post请求，带有_method隐藏域的话，会获取其value值，确认请求方式。 12345678910111213141516171819@GetMapping(\"/user\")public String getUser(){ return \"GET请求\";}@PostMapping(\"/user\")public String saveUser(){ return \"POST请求\";}@PutMapping(\"/user\")public String putUser(){ return \"PUT请求\";}@DeleteMapping(\"/user\")public String deleteUser(){ return \"DELETE请求\";} 我们也可以自定义过滤器，将_method修改为自定义的字符串。根据源码分析可以，我们需要对HiddenHttpMethodFilter这个过滤器组件进行配置。 因此我们定义一个配置类，在其中使用@Bean注解，注入我们自定义的组件，这样底层就会使用我们手动注入的组件： 123456789101112//定义一个配置类@Configuration(proxyBeanMethods = false)public class WebConfig{ //配置组件并注入 @Bean public HiddenHttpMethodFilter hiddenHttpMethodFilter(){ HiddenHttpMethodFilter hiddenHttpMethodFilter = new HiddenHttpMethodFilter(); //在这里将隐藏域方法名改为自定义名字,比如改为_m hiddenHttpMethodFilter.setMethodParam(\"_m\"); return hiddenHttpMethodFilter; }} REST原理 表单提交的时候，会带上隐藏域_method 请求会被HiddenHttpMethodFilter拦截，判断请求是否正常，并且是POST方式，才做以下操作： 获取到_method的值，将value的值统一转化为大写。 会兼容PUT、DELETE、PATCH三种请求 原生request的包装(装饰器)模式，requestWrapper重写了getMethod()方法，返回的是传入的值。 过滤器链放行的时候，使用的是wrapper，以后的方法调用的都是requestWrapper的getMethod()方法 3.1.2 请求映射原理SpringMVC的功能分析都从DispatcherServlet的doDispatch()方法入手，其继承体系如下： DispatcherServlet继承体系 doDispatch()方法会遍历查找，找到当前请求会使用哪个Handler（即Controller方法）进行处理。 具体来说，所有的请求映射，都会保存在HandlerMapping中。 共有以下几种HandleMapping RequestMappingHandlerMapping WelcomePageHandlerHandlerMapping BeanNameUrlHandlerMapping RouterFunctionHandlerMapping SimpleUrlHandlerMapping： 比如WelcomePageHandlerMapping，就能够访问index.html这个页面 SpringBoot自动配置了默认的RequestMappingHandlerMapping 请求进来后，会依次遍历所有的HandlerMapping，查看是否有请求信息。 如果有就找到这个请求对应的handler 如果没有就继续查找下一个 HandlerMapping 如果我们需要自定义的映射处理，我们可以定义自己的HandlerMapping。具体做法为在配置类中，使用@Bean注入定义的组件，在方法里面自定义我们自己的组件。 3.2 参数处理这里的参数处理主要指的是控制器（controller）方法中的参数。 3.2.1 基本注解在参数中，可以使用以下注解： @PathVariable：路径变量，比如RESTful风格的变量 @RequestHeader：获取请求头 @RequestAttribute：获取请求域属性 @RequestParam：获取请求参数，比如url中?后面的变量 @RequestBody：获取请求体 @MatrixVariable：矩阵变量。如果矩阵变量同名，可以使用这个注解的pathVar进行区分。使用详情参考：矩阵变量 @CookieValue：获取cookie值 3.2.2 Servlet API除了在参数位置使用简单的注解外，我们还可以传入Servlet API类型的参数。 比如在controller中进行结果跳转的时候，我们有一种使用Servlet API的方式进行跳转： 123456789@Controllerpublic class RequestAttributeController { @GetMapping(\"/goto\") public String goToPage(HttpServletRequest request){ request.setAttribute(\"msg\",\"Success!\"); request.setAttribute(\"code\",\"200\"); return \"forward:/success\"; //请求转发到/success请求 }} 通过debug源码可知，对HttpServletRequest类型的参数解析，使用的是名为ServletRequestMethodArgumentResolver的参数解析器进行解析的，这个参数解析器能够解析的所有类型如下： 12345678910111213141516@Overridepublic boolean supportsParameter(MethodParameter parameter) { Class&lt;?&gt; paramType = parameter.getParameterType(); return (WebRequest.class.isAssignableFrom(paramType) || ServletRequest.class.isAssignableFrom(paramType) || MultipartRequest.class.isAssignableFrom(paramType) || HttpSession.class.isAssignableFrom(paramType) || (pushBuilder != null &amp;&amp; pushBuilder.isAssignableFrom(paramType)) || Principal.class.isAssignableFrom(paramType) || InputStream.class.isAssignableFrom(paramType) || Reader.class.isAssignableFrom(paramType) || HttpMethod.class == paramType || Locale.class == paramType || TimeZone.class == paramType || ZoneId.class == paramType);} 3.2.3 复杂参数controller方法中的参数也可以是Map、Model、ModelMap、ModelAndView类型的对象。 这些类型的对象里面的数据，会被放到请求域中。 3.2.4 自定义对象参数controller方法中的参数也可以是自定义类型，会自动将参数名和变量名匹配。如果不匹配的则值为null。 比如： 1234567891011121314151617181920212223242526272829303132/** 前端页面请求 * 姓名： &lt;input name=\"userName\"/&gt; &lt;br/&gt; * 年龄： &lt;input name=\"age\"/&gt; &lt;br/&gt; * 生日： &lt;input name=\"birth\"/&gt; &lt;br/&gt; * 宠物姓名：&lt;input name=\"pet.name\"/&gt;&lt;br/&gt; * 宠物年龄：&lt;input name=\"pet.age\"/&gt; *///Person类public class Person { private String userName; private Integer age; private Date birth; private Pet pet; ... }//Pet类public class Pet { private String name; private String age; ...}//controller@RestControllerpublic class MyController { @GetMapping(\"/person\") public String goToPage(Person person){ //person中的值会自动匹配参数的值 return person; }} 3.3 参数处理原理HandlerMapping中找到能够处理请求的Handler，然后为当前Handler找一个适配器，即HandlerAdapter，比如说RequestMappingHandlerAdapter。 适配器执行目标方法并确定方法参数的每一个值。大致流程如下： 1、执行目标方法。 1mav = invokeHandlerMethod(request, response, handlerMethod); //执行目标方法 执行目标方法的细节进一步分析如下。 2、确定要执行的目标方法的每一个参数的值是什么。SpringMVC目标方法能写多少种参数类型，取决于参数解析器。 在InvocableHandlerMethod类的getMethodArgumentValues方法中确定目标方法每个参数的值。 底层会遍历参数解析器，如果当前参数解析器能解析当前参数，就调用这个解析器的相关方法进行解析。 3、返回值处理器。返回值处理由返回值处理器进行处理，比如ModelMethodProcessor、ResponseBodyEmitterReturnValueHandler等。 4、当目标方法完成后，所有的数据都会保存在ModelAndViewContainer中，其中包含了视图View，以及Model数据。 5、最后处理派发结果，调用processDispatchResult()方法。 在执行的过程中，底层会将model中的所有数据都放到请求域中： 123456789101112protected void exposeModelAsRequestAttributes(Map&lt;String, Object&gt; model, HttpServletRequest request) throws Exception { //model中的所有数据遍历挨个放在请求域中 model.forEach((name, value) -&gt; { if (value != null) { request.setAttribute(name, value); } else { request.removeAttribute(name); } });} 3.4 自定义类型参数封装POJO底层对参数封装为POJO对象的时候，定义了大量的类型转换器(converter)，比如StringToNumber是字符串转为数字类型的一个转换器。 其中在进行封装之前，会调用isSimpleValueType方法判断是否是简单类型。 如果我们想自定义一个类型转换器，参考源码中类型转换器的写法，我们可以在WebDataBinder里面放入自己定义的Converter. 在配置类中，自定义WebMvcConfigurer组件： 1234567891011121314151617181920212223242526272829303132//1、WebMvcConfigurer定制化SpringMVC的功能@Beanpublic WebMvcConfigurer webMvcConfigurer(){ return new WebMvcConfigurer() { @Override public void configurePathMatch(PathMatchConfigurer configurer) { UrlPathHelper urlPathHelper = new UrlPathHelper(); // 不移除；后面的内容。矩阵变量功能就可以生效 urlPathHelper.setRemoveSemicolonContent(false); configurer.setUrlPathHelper(urlPathHelper); } @Override public void addFormatters(FormatterRegistry registry) { registry.addConverter(new Converter&lt;String, Pet&gt;() { @Override public Pet convert(String source) { // dog,3 if(!StringUtils.isEmpty(source)){ Pet pet = new Pet(); String[] split = source.split(\",\"); pet.setName(split[0]); pet.setAge(Integer.parseInt(split[1])); return pet; } return null; } }); } };} 这样，当我们收到一个字符串dog,3的时候，也能够将其解析并封装到Pet中的name和age中。 四、数据响应与内容协商4.1 响应JSONSpringBoot的Web场景自动引入了JSON场景，可以返回JSON数据 4.2 返回值解析器前面说过，controller的返回值是要经过返回值处理器（解析器）进行处理的： 返回值解析器判断是否支持这种类型返回值—-supportsReturnType 返回值解析器调用handleReturnValue处理 RequestResponseBodyMethodProcessor可以处理标了@ResponseBody注解方法： 利用MessageConverters进行处理，将数据写为JSON： 内容协商：浏览器默认会以请求头的方式告诉服务器能够接收什么类型的数据；服务器根据自己的能力，决定能生产出什么内容类型的数据。 其中，SpringMVC会依次遍历容器底层所有的HttpMessageConverter（消息转换器），看谁能对数据进行处理。比如，MappingJackson2HttpMessageConverter可以将对象转为JSON数据再写出去。 SpringMVC支持的返回值类型 1234567891011121314ModelAndViewModelViewResponseEntity ResponseBodyEmitterStreamingResponseBodyHttpEntityHttpHeadersCallableDeferredResultListenableFutureCompletionStageWebAsyncTask有@ModelAttribute且为对象类型的@ResponseBody 注解,使用RequestResponseBodyMethodProcessor 关于HttpMessageConverter 消息转换器，HttpMessageConverter接口中有canRead()和canWrite()方法，用于判断当前消息转换器能够对数据进行读和写。 默认的消息转换器包括： ByteArrayHttpMessageConverter：支持Byte类型 StringHttpMessageConverter：支持String类型 ResourceHttpMessageConverter：支持Resource类型 ResourceRegionHttpMessageConverter：支持ResourceRegion类型 SourceHttpMessageConverter：支持DOMSource、 SAXSource、 StAXSource、StreamSource、Source类型。 AllEncompassingFormHttpMessageConverter：支持MultiValueMap类型 MappingJackson2HttpMessageConverter：无论什么类都返回true，可以将任何类型的对象转换为浏览器所想要的数据类型； Jaxb2RootElementHttpMessageConverter：支持注解方式xml处理的 4.3 内容协商内容协商指的是，根据客户端接收能力不同，返回不同媒体类型的数据。 SpringBoot中的Web场景引入了JSON依赖，因此可以返回JSON数据，但没有引入XML依赖，如果想要返回XML类型的数据，需要手动引入以下依赖： 1234567&lt;!-- xml数据处理,会使返回数据类型为XML类型添加这个依赖后，系统启动会自动生成MappingJackson2XmlHttpMessageConverter--&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt; &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt;&lt;/dependency&gt; 4.3.1 开启内容协商功能SpringBoot的内容协商功能默认是关闭的，可以手动开启： 1234spring: mvc: contentnegotiation: favor-parameter: true 开启内容协商功能后，可以使用format参数指定要接收的参数类型，方便浏览器通过修改参数的方式完成内容协商。 比如： http://localhost:8080/test/person?format=json请求会返回JSON类型的数据； http://localhost:8080/test/person?format=xml请求会返回XML类型的数据。 4.3.2 内容协商原理1、首先判断当前响应头是否已经有确定的媒体类型（MediaType） 2、获取客户端支持接受的内容类型 3、遍历循环当前系统的MessageConverter，看谁支持操作这个对象 4、找到支持操作当前对象的消息转换器，把这个消息转换器支持的媒体类型统计出来。 5、进行内容协商，选出最佳匹配的媒体类型 6、用这个能够将对象转化为最佳匹配类型的转换器，进行转化 4.3.3 自定义消息转换器参考官方文档：Path Matching and Content Negotiation 如果我们想定义自己的消息转换器，比如我们想要传入format=gg，解析为application/x-guigu类型。 首先需要定义转换器，实现HttpMessageConverter接口： 12345678910111213141516171819202122232425262728293031323334353637public class GuiguMessageConverter implements HttpMessageConverter&lt;Person&gt; { @Override public boolean canRead(Class&lt;?&gt; clazz, MediaType mediaType) { return false; } @Override public boolean canWrite(Class&lt;?&gt; clazz, MediaType mediaType) { return clazz.isAssignableFrom(Person.class); } /* 服务器要统计所有MessageConverter都能写出哪些内容类型。 自定义类型application/x-guigu 将自定义类型添加到能够解析的类型中 */ @Override public List&lt;MediaType&gt; getSupportedMediaTypes() { return MediaType.parseMediaTypes(\"application/x-guigu\"); } @Override public Person read(Class&lt;? extends Person&gt; clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException { return null; } @Override public void write(Person person, MediaType contentType, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException { //自定义协议数据的写出 String data = person.getUserName()+\";\"+person.getAge()+\";\"+person.getBirth(); //写出去 OutputStream body = outputMessage.getBody(); body.write(data.getBytes(StandardCharsets.UTF_8)); }} 然后，我们需要将我们自己的消息转换器添加到底层的消息转换器中， 123456789101112131415161718192021222324252627282930313233343536@Configuration(proxyBeanMethods = false)public class WebConfig { //我们需要自定义WebMvcConfigurer组件 @Bean public WebMvcConfigurer webMvcConfigurer(){ return new WebMvcConfigurer() { /* 扩展MessageConverter，以实现我们自定义的对象写成自定义格式的数据 将我们自己实现的Converter添加进去即可 */ @Override public void extendMessageConverters( List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) { converters.add(new GuiguMessageConverter()); } //重写内容协商器，使客户端能够通过URL参数传递我们自定义的类型 @Override public void configureContentNegotiation(ContentNegotiationConfigurer configurer) { Map&lt;String, MediaType&gt; mediaTypeMap = new HashMap&lt;&gt;(); //这里只添加三种，则参数只能传递这三种类型 mediaTypeMap.put(\"json\",MediaType.APPLICATION_JSON); mediaTypeMap.put(\"xml\",MediaType.APPLICATION_XML); mediaTypeMap.put(\"gg\",MediaType.parseMediaType(\"application/x-guigu\")); //指定支持哪些参数对应的哪些媒体类型 //将基于参数的协商管理器放到里面 ParameterContentNegotiationStrategy parameterStrategy = new ParameterContentNegotiationStrategy(mediaTypeMap); //将基于请求头的协商管理器放入 HeaderContentNegotiationStrategy headerStrategy = new HeaderContentNegotiationStrategy(); configurer.strategies(Arrays.asList(parameterStrategy,headerStrategy)); } }; }} 这样，我们就可以在format参数传入gg关键字，将会调用自定义的转换器转换为x-guigu类型。 注意到，我们如果重写内容协商器，可能会导致一些默认的功能失效，推荐的方式是在配置文件中使用配置，想要自定义什么就配置什么，SpringBoot已经帮我们把能够自定义的内容都绑定到了配置文件中，只需要按需配置即可。 1234spring: mvc: contentnegotiation: media-types: {gg: application/x-guigu} 添加配置，当format参数为gg时，映射为application/x-guigu。 五、视图解析与模版引擎SpringBoot默认不支持JSP，需要引入第三方模版引擎技术实现页面渲染 5.1 视图解析视图解析流程： 1、目标方法处理的过程中，所有数据都会放在ModelAndViewContainer中，包括数据和视图地址 2、任何目标方法执行完成后，都会返回一个ModelAndView 3、processDispatchResult处理派发结果，即页面如何响应 调用render(mv,request,response)方法进行页面渲染： 根据方法的String返回值得到View对象 所有的视图解析器尝试是否能根据当前返回值得到View对象，找到以后就进行渲染。 如果是redirect开头，表示重定向的返回值，则会调用response.sendRedirect()重定向；请求转发也是如此。 总结： 返回值以forward:开始，则调用 new InternalResourceView(forwardUrl); 进行请求转发。 内部调用request.getRequestDispatcher(path).forward(request, response); 返回值以redirect:开始，则调用new RedirectView()进行重定向。 返回值是普通字符串：new ThymeleafView() 5.2 模版引擎-ThymeleafThymeleaf是现代化的服务端Java模版引擎，能够处理HTML、XML、JavaScript、CSS，甚至纯文本数据（Plain Text）。 SpringBoot默认不支持JSP，因此我们使用Thymeleaf模版引擎代替JSP功能。 Thymeleaf的使用方法参考官方Thymeleaf、Thymeleaf的使用 表达式名字 语法 用途 变量取值 ${…} 获取请求域、session域、对象等值 选择变量 *{…} 获取上下文对象值 消息 #{…} 获取国际化等值 链接 @{…} 生成链接 片段表达式 ~{…} jsp:include 作用，引入公共页面片段 SpringBoot为我们自动配置好了Thymeleaf，我们只需要引入Thymeleaf依赖，然后开发页面即可。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 123public static final String DEFAULT_PREFIX = \"classpath:/templates/\";public static final String DEFAULT_SUFFIX = \".html\"; //xxx.html 此外，需要在html页面加入Thymeleaf命名空间： 12345&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"&gt; &lt;head&gt;&lt;/head&gt; ...&lt;/html&gt; 可以看到，我们的controller返回视图名的时候，底层会自动添加前缀和后缀，类似于SpringMVC的视图解析器。 默认情况下我们将页面放到templates文件夹，并且后缀名为.html。 六、拦截器6.1 配置拦截器自定义拦截器的步骤如下 1、编写一个拦截器类，实现HandlerInterceptor接口。 2、将拦截器注册到容器中，即实现WebMvcConfigurer的addInterceptors方法 3、指定拦截规则。如果拦截所有请求(/**)，静态资源也会被拦截。可以使用配置静态资源路径或手动排除静态资源请求两种方式解决。 代码如下： 1、实现接口 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/**使用拦截器实现登录检查的功能。验证用户登陆，保证只有用户登陆才能操作别的页面。 * 1.配置好拦截器要拦截哪些请求 * 2.把这些配置放在容器中 */public class LoginInterceptor implements HandlerInterceptor { /** * 目标方法执行之前，可以在这里写验证是否登陆的逻辑，然后判断是否放行 */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //登录检查逻辑 HttpSession session = request.getSession(); Object loginUser = session.getAttribute(\"loginUser\"); //假设只要session中有登陆用户就算登陆 if(loginUser!=null){ return true; //放行 } /* 如果被拦截，就跳转到登录页面，并将错误信息返回 并根据实际情况，决定将反馈信息放在请求域还是session中 */ //session.setAttribute(\"msg\",\"请登录\"); //response.sendRedirect(\"/\"); //重定向 request.setAttribute(\"msg\",\"请登录\"); request.getRequestDispatcher(\"/\").forward(request,response); return false; } //目标方式执行之后 @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } //页面渲染之后 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {}} 2、放到容器中 12345678910111213141516@Configurationpublic class AdminWebConfig implements WebMvcConfigurer { /** * 配置自定义的拦截器，并设置要拦截的请求和不拦截的请求 */ @Override public void addInterceptors(InterceptorRegistry registry) { //将定义好的拦截器添加到配置中，指定要拦截的请求，排除不需要拦截的请求。 registry.addInterceptor(new LoginInterceptor()) .addPathPatterns(\"/**\") .excludePathPatterns(\"/\",\"/login\",\"/css/**\",\"/js/**\", \"/fonts/**\",\"/images/**\"); //先拦截所有请求，然后排除登陆页面的请求和所有静态资源的请求 }} 排除静态资源： 方式一：排除静态资源请求，比如上述代码。 方式二：设置静态资源的访问路径，比如拦截所有以/static开头的静态资源请求，配置语句为： 1spring.mvc.static-path-pattern=/static/** 6.2 拦截器原理1、根据当前请求，找到HandlerExecutionChain，即可以处理请求的handler以及handler的所有拦截器. 2、先顺序执行每个拦截器的preHandle()方法，根据这个方法的返回值决定下一步： 如果当前拦截器的preHandle()方法返回true，则继续执行下一个拦截器的preHandle()方法 如果任何一个拦截器的preHandle()方法返回false，直接倒序执行所有已经执行了的拦截器的afterCompletion。不会执行目标方法。 3、只有所有的拦截器都返回true的时候，才执行目标方法。 4、然后倒序执行所有拦截器的postHandle()方法。 5、前面的任何步骤出现异常，都会直接倒序执行afterCompletion()`方法。 6、页面渲染完成后，倒序执行afterCompletion()方法。 拦截器执行流程 七、文件上传7.1 实现上传和接收页面表单: 123456789101112&lt;!-- 文件上传的类型一定要是multipart/form-data --&gt;&lt;form role=\"form\" th:action=\"@{/upload}\" method=\"post\" enctype=\"multipart/form-data\"&gt; &lt;input type=\"email\" name=\"email\" placeholder=\"Enter email\"&gt; &lt;input type=\"text\" name=\"username\" placeholder=\"name\"&gt; &lt;!-- 单文件上传 --&gt; &lt;input type=\"file\" name=\"headerImg\"&gt; &lt;!-- 多文件上传 --&gt; &lt;input type=\"file\" name=\"photos\" multiple&gt; &lt;button type=\"submit\"&gt;提交&lt;/button&gt;&lt;/form&gt; 服务端处理： 12345678910111213141516171819202122@PostMapping(\"/upload\")public String upload(@RequestParam(\"email\") String email, @RequestParam(\"username\") String username, @RequestPart(\"headerImg\") MultipartFile headerImg, @RequestPart(\"photos\") MultipartFile[] photos) throws IOException { if(!headerImg.isEmpty()){ //保存到文件服务器，OSS服务器等。这里以保存到本地为例 String originalFilename = headerImg.getOriginalFilename(); headerImg.transferTo(new File(\"H:\\\\cache\\\\\"+originalFilename)); } if(photos.length &gt; 0){ for (MultipartFile photo : photos) { if(!photo.isEmpty()){ String originalFilename = photo.getOriginalFilename(); photo.transferTo(new File(\"H:\\\\cache\\\\\"+originalFilename)); } } } return \"main\";} 服务端使用 @RequestPart注解和MultipartFile类型来处理文件类型的数据。 7.2 文件上传原理1、文件上传配置类MultipartAutoConfiguration自动配置好了文件上传解析器StandardServletMultipartResolver，其组件id为multipartResolver。 2、对于接收到的请求，文件上传解析器判断(isMultipart)并封装（resolveMultipart），返回文件上传请求MultipartHttpServletRequest 3、参数解析器解析请求中的文件内容，并封装成MultipartFile 4、将request中的文件信息封装为Map，即MultiValueMap&lt;String, MultipartFile&gt;，实现文件流的拷贝。 八、异常处理8.1 默认规则默认情况下，Spring Boot提供/error处理所有错误的映射。 对于机器客户端，它将生成JSON响应，其中包含错误，HTTP状态和异常消息的详细信息。 对于浏览器客户端，响应一个“Whitelabel”错误视图，以HTML格式呈现相同的数据。 12345\"timestamp\":\"2020-11-22T05:53: 28.416+00: 00\",\"status\": 404,\"error\":\"Not Found\",\"message\":\"No message available\",\"path\":\"/...\" 如果相对其自定义，可以手动添加一个error视图。 其中，/error目录下的4xx，5xx页面会被自动解析，按照状态码匹配，优先精准匹配，没有就模糊匹配。 8.2 定制错误处理逻辑8.2.1 自定义错误页自定义错误页：将4xx.html和5xx.html错误页放到/templates或/static目录下的error文件夹，即可自动匹配。优先精确匹配，然后模糊匹配。都没有，则返回WhilteLabel 当发生异常时，底层会结束当前请求，并记录错误信息和状态码等信息；然后重新发送一个error请求，将HTTP的状态码作为视图页地址（viewName），找到error/4xx.html等错误页。 8.2.2 自定义异常处理1、使用@ControllerAdvice+@ExceptionHandler处理全局异常 比如处理空指针异常、除数为0时的异常等，可以使用这种方式。当发生指定的错误时，会执行这个方法。 底层是ExceptionHandlerExceptionResolver支持的。 123456789101112// 处理整个Web controller的异常,通常是全局指定类型的异常。@ControllerAdvice //是一种增强的Component注解public class GlobalExceptionHandler { //指定这个方法能够处理的异常类型 @ExceptionHandler({ArithmeticException.class,NullPointerException.class}) public String handlerArithException(Exception e){ ...//进行一些处理 //即使出现异常，也应该返回一个ModelAndView return \"login\"; }} 2、使用@ResponseStatus+自定义异常类 比如处理具体某个方法出现错误时，抛出自定义异常和异常信息。 123456789//表示当发生这个类的异常时，返回给页面什么样的状态码；//以403为例，返回状态码403和错误原因@ResponseStatus(value = HttpStatus.FORBIDDEN,reason=\"用户数量太多\")public class UserTooManyException extends RuntimeException{ public UserTooManyException(){ } public UserTooManyException(String message){ super(message); }} 如果出现这个类的异常，会返回状态码403和错误信息。比如 throw new UserTooManyException()时，就会触发这个异常，然后返回信息。 3、自定义异常解析器 自定义的异常解析器，可以作为默认的全局异常处理规则。 12345678910111213141516171819//使我们自定义的异常解析器处于最高优先级@Order(value = Ordered.HIGHEST_PRECEDENCE) //数字越小，优先级越高@Componentpublic class CustomerHandlerExceptionResolver implements HandlerExceptionResolver { @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { try { //指定状态码的值和错误信息，第一个参数的值就做为状态码 response.sendError (598,\"自定义异常解析器\"); } catch (IOException e) { e.printStackTrace(); } return new ModelAndView(); }} 底层会优先遍历DefaultErrorAttributes和HandlerExceptionResolverComposite这两个，第二个里面又有三个解析器，会处理所有异常。因此想要使我们自定义的生效，必须将其优先级放到默认的两个前面。 sendError()方法表示此次请求立即结束，底层tomcat服务器会抛出error，SpringMVC底层会专门处理这个error，即BasicErrorController处理。 调用response.sendError()，请求会转给controller处理，如果没有解析器能够处理，则tomcat底层会执行这个方法，交给basicErrorController处理。 8.3 异常处理原理1、执行目标方法，目标方法运行期间有任何异常都会被catch，而且标志当前请求结束；并且用 dispatchException保存catch到的异常。 2、进入视图解析流程： 12processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); 有异常时，mv为null，异常信息被保存到dispatchException中 3、mv = processHandlerException;用于处理handler发生的异常，并处理完成返回ModelAndView，具体步骤如下： 遍历所有的handlerExceptionResolvers，找到能处理这个异常的解析器。 系统默认有两个异常解析器，即DefaultErrorAttributes和HandlerExceptionResolverComposite。默认情况下，DefaultErrorAttributes先处理异常，把异常信息保存到请求域，并返回null。 默认情况下，没有解析器能处理异常，因此异常会被抛出： 异常不能处理，则底层会发出/error请求，被底层的BasicErrorController处理 解析错误视图，遍历所有的错误视图解析器，看谁能处理。 默认的DefaultErrorViewResolver，作用是把响应状态码作为错误页的地址，比如error/500.html 模版引擎最终会响应这个页面error/500.html。 错误页面的查找顺序： 1234'/templates/error/500.&lt;ext&gt;''/static/error/500.html''/templates/error/5xx.&lt;ext&gt;''/static/error/5xx.html' 九、原生组件注入与嵌入式Servlet容器9.1 原生组件注入Web原生组件，比如servlet、filter、listener注入，有两种方式。 方式一：使用Servlet API注解 @WebServlet(urlPatterns = \"/my\") `@WebFilter(urlPatterns={\"/css/*\",\"/images/*\"}) @WebListener 12345678@WebServlet(urlPatterns = \"/my\")public class MyServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.getWriter().write(\"hello\"); }} 用在自定义的servlet类中。这样，http://localhost:8080/my就可以返回”hello” /my请求会直接响应，没有被拦截器拦截。 如果使用以上注解，需要在主类中使用@ServletComponentScan进行扫描，用于指定原生Servlet、filter、listener组件的位置。 1234567@ServletComponentScan(basePackages = \"com.kang.admin\")@SpringBootApplicationpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 为什么这里定义的/my没有被拦截器拦截呢？ SpringMVC的请求优先经过DispatcherServlet，需要对其进行分析： 容器中自动配置了DispatcherServlet，属性绑定到WebMvcProperties；对应的配置文件配置项是 spring.mvc 配置spring.mvc.servlet.path为dispatchSerlvet中拦截的路径 配置server.servlet.context-path为上下文路径，请求访问的前缀 也是通过 ServletRegistrationBean&lt;DispatcherServlet&gt;把 DispatcherServlet 配置进来。 默认映射的是/路径 Tomcat-Servlet，如果多个Servlet都能处理到同一层路径，精确优先原则。因此对于/和/my来说，/my请求精准匹配到自定义的servlet，因此不会经过dispatcherServlet处理，所以不会被拦截器拦截。 方式二：使用RegistrationBean 如果不使用注解，还可以手动实现一个配置类，将它们注入。 在配置类中： 1234567891011121314151617181920212223242526272829@Configurationpublic class MyRegistConfig { //注入servlet @Bean public ServletRegistrationBean myServlet(){ MyServlet myServlet = new MyServlet(); //指定要映射的请求，可以指定多个 return new ServletRegistrationBean(myServlet,\"/my\",\"/my01\"); } //注入filter @Bean public FilterRegistrationBean myFilter(){ MyFilter myFilter = new MyFilter(); //方式一：使用过滤现有的servlet请求路径 //return new FilterRegistrationBean(myFilter,myServlet()); //方式二：自定义过滤路径 FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(myFilter); filterRegistrationBean.setUrlPatterns(Arrays.asList(\"/filter\",\"/filter2\")); return filterRegistrationBean; } //注入listener @Bean public ServletListenerRegistrationBean myListener(){ MyServletContextListener myServletContextListener = new MyServletContextListener(); return new ServletListenerRegistrationBean(myServletContextListener); }} 9.2 嵌入式Servlet容器SpringBoot内嵌了web服务器，比如tomcat、Jetty、Undertow。默认使用的是tomcat 在pom.xml中排除tomcat依赖，再将要切换到的服务器的starter导入即可实现切换： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 我们还可以定制servlet容器，根据文档或者仿照源码。 十、定制化总结SpringBoot中的Web项目定制化的几种方式 修改配置文件； xxxxxCustomizer定制器； 编写自定义的配置类，然后用@Bean替换、增加容器中默认组件； 对于Web应用，还可以编写一个配置类实现WebMvcConfigurer接口， 即可定制化web功能；使用@Bean可以给容器中再扩展一些组件；比如： 12@Configurationpublic class AdminWebConfig implements WebMvcConfigurer @EnableWebMvc + WebMvcConfigurer可以全面接管SpringMVC，使用这种方式，所有自动配置的功能会全部失效，需要全部自己重新配置； 配合@Bean实现定制和扩展功能。 @EnableWebMvc会使SpringBoot关于WebMVC的自动配置全部失效，其功能都需要自己写。 一般分析自动配置的流程：场景启动器—&gt;xxxAutoConfiguration—&gt;导入xxx组件，绑定xxxProperies—&gt;其绑定了配置文件中的配置项。","categories":[{"name":"SpringBoot2","slug":"SpringBoot2","permalink":"http://kangshitao.github.io/categories/SpringBoot2/"}],"tags":[{"name":"SpringBoot2","slug":"SpringBoot2","permalink":"http://kangshitao.github.io/tags/SpringBoot2/"},{"name":"Spring","slug":"Spring","permalink":"http://kangshitao.github.io/tags/Spring/"}]},{"title":"SpringBoot2配置与使用","slug":"springboot2-basis","date":"2021-07-10T09:14:03.000Z","updated":"2022-05-22T13:30:54.805Z","comments":true,"path":"2021/07/10/springboot2-basis/","link":"","permalink":"http://kangshitao.github.io/2021/07/10/springboot2-basis/","excerpt":"使用SprintBoot创建Web应用；使用SprintBoot整合MyBatis；","text":"一、SpringBoot介绍1.1 SpringBoot1.1.1 什么是SpringBoot官方文档：Spring Boot Reference Documentation SpringBoot介绍 Spring框架旨在简化J2EE企业应用程序的开发，而SpringBoot旨在简化Spring开发，使用SpringBoot能够快速创建出生产级别的Spring应用。 使用Spring框架虽然代码是轻量级的，但是其仍然需要大量的XML配置。SpringBoot解决了Spring项目配置文件繁多的问题。 SpringBoot是整合Spring技术栈的一站式框架。 SpringBoot是简化Spring技术栈的快速开发脚手架。 1.1.2 SpringBoot的优缺点优点： 创建独立Spring应用 Spring Boot 应用程序提供嵌入式 HTTP 服务器，如 Tomcat 和 Jetty，可以轻松地开发和测试 web 应用程序。 自动starter依赖，简化构建配置 自动配置Spring以及第三方功能 提供生产级别的监控、健康检查及外部化配置 Spring Boot 不需要编写大量样板代码、XML 配置和注释。 缺点： 迭代快，需要时刻关注变化 封装太深，内部原理复杂，不容易精通 1.2 SpringBoot2基于Java8的新特性，比如接口中允许定义默认方法（default方法不强制实现），Spring5的源码架构也重新设计，因此SpringBoot2相比于1版本也有很多升级，比如响应式编程。 SpringBoot2的系统要求，以2.5.2版本为例 Maven 3.5+ Tomcat 9.0，servlet3.1+ JDK8+ 二、SpringBoot2 快速入门2.1 创建工程可以在官网的https://start.spring.io/快速生成一个SpringBoot项目，生成以后下载到本地即可。 也可以使用IDEA自带的Spring Initializr创建，File-&gt;New-&gt;Project-&gt;Spring Initializr，配置好项目名之后，可以根据需求选择依赖，比如我们选择Spring Web依赖，这样创建的项目会自动在配置文件中导入选中的依赖。 选择项目依赖 2.2 编写业务代码创建完成后，Spring Initializr会自动为我们导入启动器依赖并生成目录结构： 初始项目目录结构 其中templates文件存放JSP页面、thymeleaf模版等；static文件夹存放图片、css文件、js文件、欢迎页、网站图标等静态资源。 直接运行启动类DemoApplication就能运行项目： DemoApplicationTests 1234567//注明这是一个SpringBoot应用@SpringBootApplicationpublic class DemoApplicationTests { public static void main(String[] args) { SpringApplication.run(DemoApplicationTests.class, args); }} 我们可以新建一个controller进行测试，比如： com.example.demo.controller.HelloController.java 1234567@RestControllerpublic class HelloController { @RequestMapping(\"/hello\") public String handle01(){ return \"Hello, Spring Boot 2!\"; }} 这样，在浏览器中输入hello请求，就会收到指定的返回值。一个web项目的demo就算搭建成功。 需要特别注意的是，SpringBoot默认会自动扫描主程序所在的包及其下面所有的子包中的组件，因此，我们需要将程序代码写在主程序所在的包及其子包内。 也可以改变扫描路径，比如@SpringBootApplication(scanBasePackages=”com.kang”)表示将扫描的包路径更改为com.kang 2.3 简化配置和部署简化配置 SpringBoot默认的主配置文件是application可以是properties类型，也可以是yaml类型，可以同时使用多个配置文件，生效顺序根据情况判断。 对于SpringBoot简化配置的优势，主要体现在其所有的配置都可以只写在一个配置文件中，即主配置文件application.properties中，配置tomcat的端口号： 1server.port=8888 SpringBoot中，用到的所有配置都可以只在这一个配置文件中修改,包括tomcat参数、mybatis、springmvc配置等。 SpringBoot为我们配置了一些默认值，可以根据需求修改。 简化部署 SpringBoot的简化部署主要体现在它为我们提供了maven插件，这个插件能够在maven打包时递归地将所有jar包和项目文件都打包进去。 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 三、SpringBoot配置3.1 SpringBoot特点3.1.1 依赖管理依赖管理 SpringBoot中是父项目进行依赖管理，所有的SpringBoot项目都会引入这个父项目，这个项目主要是用于资源过滤和插件管理： 1234567&lt;!-- spring-boot-starter-parent是每个SpringBoot项目都要引入的父项目 --&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; 这个父项目的又有一个父项目： 12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt;&lt;/parent&gt; 这个`spring-boot-dependencies项目是真正管理SpringBoot应用里面所有依赖版本的地方，即SpringBoot的版本控制中心。其中自动配置了常用的jar包的版本号（自动版本仲裁机制），因此我们如果显式导入某个依赖，不需要手动写版本号，除非SpringBoot依赖配置中没有这个包。 如果我们对于自动仲裁的版本号不满意，也可以手动指定版本号。首先需要查看spring-boot-dependencies里面规定依赖的版本用的 key，然后在当前项目里面重写配置。 比如要修改MySQL依赖的版本号，我们从底层依赖中查到定义其版本号的key为mysql.version，我们就可以在pom文件中手动修改其版本号： 123&lt;properties&gt; &lt;mysql.version&gt;5.1.43&lt;/mysql.version&gt;&lt;/properties&gt; 启动器（starter） SpringBoot将所有的功能场景都抽取出来，做成一个个的starter （启动器），就是在Maven的pom.xml配置文件中，类似xxx-starter的依赖，比如： 12345&lt;!-- web场景启动器 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 这种starter就称为xx的场景启动器： spring-boot-starter-xxx ： 官方提供的xxx场景启动器 。 xxx-spring-boot-starter： 第三方提供的简化开发的场景启动器。 只要引入starter，这个场景需要的所有常规依赖都自动引入 所有场景启动器最底层的依赖都是spring-boot-starter： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt;&lt;/dependency&gt; SpringBoot官方提供的所有场景，参考Starters 我们只需要在项目中引入这些starter即可，所有相关的依赖都会导入进来 ， 我们要用什么功能就导入什么样的场景启动器即可 ，也可以根据需求自定义自己的 starter。 3.1.2 自动配置自动配置依赖 当我们引入某一个场景启动器的时候，SpringBoot会自动帮我们引入其需要的依赖，这是底层启动器自动引入的。 比如，我们引入web启动器，底层会自动帮我们引入Tomcat依赖、SpringMVC常用组件（比如视图解析器）、字符编码问题等。 默认的包结构 SpringBoot项目中，主程序所在包及其下面的所有子包里面的组件都会被默认扫描进来，无需以前的包扫描配置。 如果想要改变扫描路径，使用SpringBootApplication的scanBasePackages属性，比如将扫描包的范围扩大为com.example： 1@SpringBootApplication(scanBasePackages=\"com.eaxmple\") 或者单独使用@ComponentScan指定扫描路径。 3.2 主启动类SpringBoot项目有一个主启动类，使用@SpringBootApplication标注： 1234567//表明这是一个Spring Boot应用@SpringBootApplicationpublic class SpringbootApplication { public static void main(String[] args) { SpringApplication.run(SpringbootApplication.class, args); }} @SpringBootApplication是SpringBoot的基石，其标注在主程序类上，根据源码可知，其等价于下面三个注解： @SpringBootConfiguration：等价于@Configuration，表明这是一个SpringBoot项目的配置类。 @EnableAutoConfiguration：开启自动配置功能。 @ComponentScan：自动扫描并加载给定的路径中符合条件的组件，注入到IOC容器中。 3.3 容器功能SpringBoot同样可以使用Spring的容器功能，下面介绍配置文件涉及到的常用注解。 3.3.1 组件添加1、@Configuration 这个注解表示将当前类注册为配置类，可以代替Spring的配置文件进行配置，比如注册组件。 在配置类中，使用@Bean在方法上使用用于注册组件。 一种常用的做法是，在配置类的方法中使用@Bean，注册第三方bean。因为第三方组件只能通过这种方式注入。 @Configuration有两种模式： Full模式：proxyBeanMethods = true，保证每个@Bean方法被调用多少次返回的组件都是单实例的。默认情况就是Full模式。 Lite模式：proxyBeanMethods = false，每次调用@Bean标注的方法方法，返回的组件都是新创建的，即每次获取的组件都是不同的。 组件依赖必须使用Full模式。 Full模式每次都要检查容器中是否存在当前组件，因此效率较低。如果非必要情况下，建议使用Lite模式以提高效率。 2、@Bean、@Component、@Controller、@Service、@Repository 这几个注解的作用类似，都是注册组件： @Bean：用在配置类的方法上，方法的返回类型就是要注册组件。如果注册第三方库中的类到IOC容器中，只能使用配置类+@Bean注解的方式。 @Component：用在类上，表示将当前类注册为组件。 @Controller：@Component的衍生注解，功能类似，用在controller层 @Service：@Component的衍生注解，功能类似，用在service层 @Repository：@Component的衍生注解，功能类似，用在dao层 3、@ComponenScan、@Import 这两个注解也是用在配置类中。 @ComponentScan：自动扫描并加载给定的路径中符合条件的组件，注入到IOC容器中。 @Import：可以导入一个或多个组件，比如Bean或者配置类。 12//给容器中自动创建出这两个类型的组件，默认组件的名字就是全类名@Import({User.class, DBHelper.class}) 可以参考：配置类注解 4、@Conditional@Conditional表示条件装配，只有满足一定条件，才会被注册。可以用在配置类上，也可以用在配置类的方法上。 as such, it is strongly recommended to use this condition on auto-configuration classes only. If a candidate bean may be created by another auto-configuration, make sure that the one using this condition runs after. 其衍生注解如下图： @Conditional及其衍生注解 比如在配置类上使用@ConditionalOnMissingBean(name = \"tom\")表示当容器中没有name为tom的组件时，配置类中的组件才会生效。 关于Conditonal注解有时候不起作用的问题的讨论 条件注解的条件是根据当前已经加载的内容来判断是否符合。 Condition相关的处理是在包扫描的时候执行的，所以条件中的判断前后顺序只跟包扫描的顺序有关，而包扫描的顺序是根据包名和类名的字符排序，所以配置类的解析无法保证bean注册的先后顺序，如果在同一个配置类不同的@Bean注解的方法上使用条件注解可能会出现失效的情况。 通过component-scan扫描的方式加载bean，在扫描范围内按照class的命名顺序加载。 在spring的xml文件中，bean的加载顺序按照书写顺序加载，如果不同组件之间有依赖关系，则先创建被依赖的组件。 对于@ConfitionalOnBean和@ConditionalOnMissingBean，官方推荐只在自动配置类中使用，因为自动配置类会在用户定义的bean被添加到容器之后才加载。 3.3.2 原生配置文件引入使用@ImportResource注解，可以在配置类中引入一个或多个.xml配置文件，允许以配置文件的方式对组件进行注册。主要是为了将第三方的配置文件中的组件注入容器。 @ImportResource引入的是资源文件；@Import引入的是组件。 beans.xml 123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;bean id=\"haha\" class=\"com.atguigu.boot.bean.User\"&gt; &lt;property name=\"name\" value=\"zhangsan\"&gt;&lt;/property&gt; &lt;property name=\"age\" value=\"18\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"hehe\" class=\"com.atguigu.boot.bean.Pet\"&gt; &lt;property name=\"name\" value=\"tomcat\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; MyConfig.java 123@ImportResource(\"classpath:beans.xml\")@Configurationpublic class MyConfig {} 可以在主程序中的IOC容器中，测试是否注入成功： 1234567891011public class Springboot01HelloworldApplication { public static void main(String[] args) { //可以根据返回的配置应用上下文对象，获取容器配置 //返回IOC容器 ConfigurableApplicationContext run = SpringApplication.run(Springboot01HelloworldApplication.class, args); boolean haha = run.containsBean(\"haha\"); boolean hehe = run.containsBean(\"hehe\"); System.out.println(\"haha：\"+haha);//true System.out.println(\"hehe：\"+hehe);//true }} 3.3.3 配置绑定配置绑定，指的是将配置文件中的内容，封装到JavaBean中，以供随时使用。 使用原生的Java代码，解析配置文件比较麻烦，在SpringBoot中，我们可以使用注解自动将配置文件中的值绑定到组件中的属性上。 1、@Value 对于简单的属性注入，可以使用@Value注解。可以绑定配置文件中指定的属性到当前的属性。 @Value有三种赋值方式： 直接赋值，比如：@Value(\"name\") 绑定配置文件中的属性，比如：@Value(\"${person.name}\")，绑定配置文件中的person.name到当前属性。还可以指定默认值。 使用SpEL表达式赋值，比如：@Value(\"#{'姓名'}\")，参考：SpEL 1234567@Controllerpublic class HelloController { //使用@Value注解绑定主配置文件中的属性person.name //如果值为空，则指定一个默认值 @Value(\"${person.name:default name}\") private String name;} 2、@Component + @ConfigurationProperties 如果一个类想要绑定配置文件，需要使用@ConfigurationProperties注解，用于指定和核心配置文件中什么属性绑定。 绑定配置文件的前提当前类必须是容器中的组件，因此可以结合使用@Component注解： 12345678//只有在容器中的组件，才会拥有SpringBoot提供的强大功能@Component@ConfigurationProperties(prefix = \"mycar\")public class Car { private String brand; private Integer price; ...//get、set方法等} 在@ConfigurationProperties注解中使用prefix属性，指定要绑定的配置文件中的前缀，比如配置文件中的mycar.price=10000，当前组件中的price属性值就会被注入10000. 3、@EnableConfigurationProperties 和 @ConfigurationProperties 组件绑定配置文件的第二种方式是使用@EnableConfigurationProperties 和@ConfigurationProperties两个注解，其中@EnableConfigurationProperties 注解用在配置类中，有两个功能：开启指定类的配置绑定功能；将这个类注入到IOC容器。 比如： Car.java 1234567//这里只需要指定要绑定的配置类中的属性@ConfigurationProperties(prefix = \"mycar\")public class Car { private String brand; private Integer price; ...//get、set方法等} MyConfig.java 12345//配置类@Configuration //开启Car类的属性配置功能，并把Car注册到容器中@EnableConfigurationProperties(Car.class) public class MyConfig {} 因为@Component不能用在第三方包中，所以如果@ConfigurationProperties在第三方包中，我们想对其进行配置，就必须使用@EnableConfigurationProperties这种方式。 源码中的用法 SpringBoot的底层源码中，常见的一种做法是在自动配置类中使用@EnableConfigurationProperties，并指定一个xxxProperties用于和配置文件中的值进行绑定。 比如：在CacheAutoConfiguration.java中 12@EnableConfigurationProperties(CacheProperties.class)public class CacheAutoConfiguration {...} CacheProperties.java绑定了配置文件: 12@ConfigurationProperties(prefix = \"spring.cache\")public class CacheProperties {...} 这样，我们就能够在配置文件中使用spring.cache对cache相关属性进行配置。 3.4 自动配置SpringBoot默认会在底层配置好所有的组件，自动装配所有能生效的类。我们可以在总配置文件application.properties中对需要修改的属性进行配置。 用户自己配置的参数，会以用户的优先。 自动配置的大概流程总结： SpringBoot先读取所有的自动配置类：xxxxxAutoConfiguration 每个自动配置类按照条件生效，默认都会绑定xxxxProperties类，这个类里面设置了默认的值。 xxxProperties类和配置文件进行了绑定，可以通过配置文件对默认值进行设置。 生效的配置类就会给容器中装配很多组件。只要容器中有这些组件，相当于这些功能就有了 用户可以使用@Bean替换底层的组件。 可以通过底层源码，查看这个组件是获取的配置文件什么值。也可以通过官方文档查看如何进行配置。 xxxxxAutoConfiguration —-&gt; 组件 —-&gt;从 xxxxProperties里面取值 —-&gt;绑定 application.properties 3.5 最佳实践1、引入场景依赖，可以查看官方文档有哪些官方的场景启动器：Starters 2、如果有需求，可以查看自动配置了哪些功能，有两种方式： 通过源码分析 在配置文件中使用debug=true开启自动配置报告，Negative表示不生效，Positive表示生效。 3、判断配置参数是否需要修改： 参照官方文档，查看如何配置：Common Application Properties 或者分析源码，查看如何配置。 4、根据需求自定义或者替换组件。使用@Component或者@Bean注解。 5、也可以使用自定义器：xxxCustomizer","categories":[{"name":"SpringBoot2","slug":"SpringBoot2","permalink":"http://kangshitao.github.io/categories/SpringBoot2/"}],"tags":[{"name":"SpringBoot2","slug":"SpringBoot2","permalink":"http://kangshitao.github.io/tags/SpringBoot2/"},{"name":"Spring","slug":"Spring","permalink":"http://kangshitao.github.io/tags/Spring/"}]},{"title":"Junit5与单元测试","slug":"junit-5","date":"2021-07-10T03:30:06.000Z","updated":"2022-05-22T13:30:54.797Z","comments":true,"path":"2021/07/10/junit-5/","link":"","permalink":"http://kangshitao.github.io/2021/07/10/junit-5/","excerpt":"Junit5的使用","text":"一、JUnit5 介绍1.1 介绍Junit5 = JUnit Platform + JUnit Jupiter + JUnit Vintage JUnit Platform：Junit Platform是在JVM上启动测试框架的基础，不仅支持Junit自制的测试引擎，其他测试引擎也都可以接入。 JUnit Jupiter：JUnit Jupiter提供了JUnit5的新的编程模型，是JUnit5新特性的核心。内部包含了一个测试引擎，用于在Junit Platform上运行。 JUnit Vintage：由于JUint已经发展多年，为了照顾老的项目，JUnit Vintage提供了兼容JUnit4.x,Junit3.x的测试引擎。 SpringBoot2.4以上版本移除了JUnit Vintage的依赖，如果需要兼容JUnit4，需要自行引入依赖。 1.2 JUnit5常用注解与JUnit4的差异：Annotations JUnit5的@Test： 1import org.junit.jupiter.api.Test; JUnit4的@Test 1import org.junit.Test; SpringBoot中使用JUnit5，只需要在测试类上使用@SpringBootTest注解，使用这个注解以后，测试类就具有SpringBoot的功能，比如自动装配、事务功能等。包括@Autowired、@Transactional等。 1234567891011//测试类使用@SpringBootTest标注@SpringBootTestclass Springboot05WebAdminApplicationTest { @Autowired UserMapper userMapper; //测试方法使用@Test标注 @Test public void userMapperTest(){ }} JUnit4中实现上述功能则需要@SpringBootTest+@RunWith(SpringRunner.class) @Test :表示方法是测试方法。但是与JUnit4的@Test不同，他的职责非常单一不能声明任何属性，拓展的测试将会由Jupiter提供额外测试 @ParameterizedTest ：表示方法是参数化测试 @RepeatedTest ：表示方法可重复执行 @DisplayName：为测试类或者测试方法设置展示名称 @BeforeEach ：表示在每个单元测试之前执行 @AfterEach ：表示在每个单元测试之后执行 @BeforeAll ：表示在所有单元测试之前执行；测试方法必须是静态的，或者测试类标注了@TestInstance(Lifecycle.PER_CLASS) @AfterAll ：表示在所有单元测试之后执行；测试方法必须是静态的，或者测试类标注了@TestInstance(Lifecycle.PER_CLASS) @Tag ：表示单元测试类别，类似于JUnit4中的@Categories @Disabled ：表示测试类或测试方法不执行，类似于JUnit4中的@Ignore @Timeout ：表示测试方法运行如果超过了指定时间将会返回错误 @ExtendWith：为测试类或测试方法提供扩展类引用 二、断言断言是测试方法中的核心，用来对测试需要满足的条件进行验证。 如果一个方法有多个断言，如果前边的断言失败，后边的代码都不能执行。 2.1 简单断言用来对单个值进行简单的验证： 方法 说明 assertEquals 判断两个对象或两个原始类型是否相等 assertNotEquals 判断两个对象或两个原始类型是否不相等 assertSame 判断两个对象引用是否指向同一个对象 assertNotSame 判断两个对象引用是否指向不同的对象 assertTrue 判断给定的布尔值是否为 true assertFalse 判断给定的布尔值是否为 false assertNull 判断给定的对象引用是否为 null assertNotNull 判断给定的对象引用是否不为 null 12345678910111213141516@Test@DisplayName(\"simple assertion\")public void simple() { assertEquals(3, 1 + 2, \"simple math\"); assertNotEquals(3, 1 + 1); assertNotSame(new Object(), new Object()); Object obj = new Object(); assertSame(obj, obj); assertFalse(1 &gt; 2); assertTrue(1 &lt; 2); assertNull(null); assertNotNull(new Object());} 2.2 数组断言使用assertArrayEquals方法来判断两个对象或原始类型的数组是否相等： 12345@Test@DisplayName(\"array assertion\")public void array() { assertArrayEquals(new int[]{1, 2}, new int[] {1, 2});} 2.3 组合断言assertAll方法接受多个org.junit.jupiter.api.Executable函数式接口的实例作为要验证的断言，可以通过 lambda表达式很容易的提供这些断言: 12345678@Test@DisplayName(\"assert all\")public void all() { assertAll(\"Math\", () -&gt; assertEquals(2, 1 + 1), () -&gt; assertTrue(1 &gt; 0) );} 2.4 异常断言JUnit5提供了一种新的异常断言方式Assertions.assertThrows()，配合函数式编程就可以进行使用： 12345678@Test@DisplayName(\"异常测试\")public void exceptionTest() { ArithmeticException exception = Assertions.assertThrows( //扔出断言异常 ArithmeticException.class, () -&gt; System.out.println(1 % 0));} 2.5 超时断言Junit5还提供了Assertions.assertTimeout() 为测试方法设置了超时时间 123456@Test@DisplayName(\"超时测试\")public void timeoutTest() { //如果测试方法时间超过1s将会异常 Assertions.assertTimeout(Duration.ofMillis(1000), () -&gt; Thread.sleep(500));} 2.6 快速失败通过fail方法直接使得测试失败： 12345@Test@DisplayName(\"fail\")public void shouldFail() { fail(\"This should fail\");} 三、 前置条件JUnit 5 中的前置条件（assumptions）类似于断言，不同之处在于不满足的断言会使得测试方法失败，而不满足的前置条件只会使得测试方法的执行终止。 前置条件可以看成是测试方法执行的前提，当该前提不满足时，就没有继续执行的必要。 1234567891011121314151617181920@DisplayName(\"前置条件\")public class AssumptionsTest { private final String environment = \"DEV\"; @Test @DisplayName(\"simple\") public void simpleAssume() { assumeTrue(Objects.equals(this.environment, \"DEV\")); assumeFalse(() -&gt; Objects.equals(this.environment, \"PROD\")); } @Test @DisplayName(\"assume then do\") public void assumeThenDo() { assumingThat( Objects.equals(this.environment, \"DEV\"), () -&gt; System.out.println(\"In DEV\") ); }} assumeTrue和assumFalse确保给定的条件为true或false，不满足条件会使得测试执行终止。 assumingThat的参数是表示条件的布尔值和对应的Executable接口的实现对象。只有条件满足时，Executable 对象才会被执行；当条件不满足时，测试执行并不会终止。 四、嵌套测试JUnit5可以通过 Java 中的内部类和@Nested注解实现嵌套测试 嵌套测试情况下，外层的Test不能驱动内层的@BeforeEach、@AfterAll之类的方法提前/之后运行。 而内层的Test可以驱动外层的@BeforeEach、@AfterAll之类的方法。也就是说各个层是从外向内运行的，Before、After之类的方法也只是在本层生效。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@DisplayName(\"A stack\")class TestingAStackDemo { Stack&lt;Object&gt; stack; @Test @DisplayName(\"is instantiated with new Stack()\") void isInstantiatedWithNew() { new Stack&lt;&gt;(); } @Nested @DisplayName(\"when new\") class WhenNew { @BeforeEach void createNewStack() { stack = new Stack&lt;&gt;(); } @Test @DisplayName(\"is empty\") void isEmpty() { assertTrue(stack.isEmpty()); } @Test @DisplayName(\"throws EmptyStackException when popped\") void throwsExceptionWhenPopped() { assertThrows(EmptyStackException.class, stack::pop); } @Test @DisplayName(\"throws EmptyStackException when peeked\") void throwsExceptionWhenPeeked() { assertThrows(EmptyStackException.class, stack::peek); } @Nested @DisplayName(\"after pushing an element\") class AfterPushing { String anElement = \"an element\"; @BeforeEach void pushAnElement() { stack.push(anElement); } @Test @DisplayName(\"it is no longer empty\") void isNotEmpty() { assertFalse(stack.isEmpty()); } @Test @DisplayName(\"returns the element when popped and is empty\") void returnElementWhenPopped() { assertEquals(anElement, stack.pop()); assertTrue(stack.isEmpty()); } @Test @DisplayName(\"returns the element when peeked but remains not empty\") void returnElementWhenPeeked() { assertEquals(anElement, stack.peek()); assertFalse(stack.isEmpty()); } } }} 五、参数化测试参数化测试是JUnit5很重要的一个新特性，它使得用不同的参数多次运行测试成为了可能，也为我们的单元测试带来许多便利。 利用@ValueSource等注解，指定入参，我们将可以使用不同的参数进行多次单元测试，而不需要每新增一个参数就新增一个单元测试，省去了很多冗余代码。 @ValueSource: 为参数化测试指定入参来源，支持八大基础类以及String类型,Class类型 @NullSource: 表示为参数化测试提供一个null的入参 @EnumSource: 表示为参数化测试提供一个枚举入参 @CsvFileSource：表示读取指定CSV文件内容作为参数化测试入参 @MethodSource：表示读取指定方法的返回值作为参数化测试入参(注意方法返回需要是一个流) 参数化测试可以支持外部的各类入参。如CSV、YML、JSON 文件甚至方法的返回值也可以作为入参。只需要去实现ArgumentsProvider接口，任何外部文件都可以作为它的入参。 1234567891011121314151617181920@ParameterizedTest@ValueSource(strings = {\"one\", \"two\", \"three\"})@DisplayName(\"参数化测试1\")public void parameterizedTest1(String string) { System.out.println(string); Assertions.assertTrue(StringUtils.isNotBlank(string));}@ParameterizedTest@MethodSource(\"method\") //指定方法名@DisplayName(\"方法来源参数\")public void testWithExplicitLocalMethodSource(String name) { System.out.println(name); Assertions.assertNotNull(name);}static Stream&lt;String&gt; method() { return Stream.of(\"apple\", \"banana\");} 六、从JUnit4到JUnit5在进行迁移的时候需要注意如下的变化： 注解在org.junit.jupiter.api包中，断言在org.junit.jupiter.api.Assertions类中，前置条件在 org.junit.jupiter.api.Assumptions类中。 把@Before 和@After 替换成@BeforeEach 和@AfterEach。 把@BeforeClass 和@AfterClass 替换成@BeforeAll 和@AfterAll。 把@Ignore 替换成@Disabled。 把@Category替换成@Tag。 把@RunWith、@Rule 和@ClassRule 替换成@ExtendWith。 参考官方文档：Migrating from JUnit 4 参考链接：https://www.yuque.com/atguigu/springboot/ksndgx","categories":[{"name":"Tools","slug":"Tools","permalink":"http://kangshitao.github.io/categories/Tools/"}],"tags":[{"name":"Junit5","slug":"Junit5","permalink":"http://kangshitao.github.io/tags/Junit5/"}]},{"title":"SSM框架整合","slug":"SSM-project","date":"2021-07-04T11:31:36.000Z","updated":"2022-05-22T13:30:54.780Z","comments":true,"path":"2021/07/04/SSM-project/","link":"","permalink":"http://kangshitao.github.io/2021/07/04/SSM-project/","excerpt":"Spring、SpringMVC、MyBatis整合案例","text":"一、环境配置整合SSM框架，实现对书籍的增删查改功能。 运行环境准备，数据库建表，Maven依赖包导入，基本结构搭建。 1、运行环境 IDEA 2020.3 MySQL 5.1.47 TomCat 9.0.46 Maven 3.8.1 2、数据库建表创建数据库ssmbuild和表books： 1234567891011121314151617CREATE DATABASE `ssmbuild`;USE `ssmbuild`;DROP TABLE IF EXISTS `books`;CREATE TABLE `books` ( `bookID` INT(10) NOT NULL AUTO_INCREMENT COMMENT '书id', `bookName` VARCHAR(100) NOT NULL COMMENT '书名', `bookCounts` INT(11) NOT NULL COMMENT '数量', `detail` VARCHAR(200) NOT NULL COMMENT '描述', KEY `bookID` (`bookID`)) ENGINE=INNODB DEFAULT CHARSET=utf8INSERT INTO `books`(`bookID`,`bookName`,`bookCounts`,`detail`)VALUES(1,'Java',1,'Java language'),(2,'MySQL',10,'MySQL database'),(3,'Linux',3,'Linux opereation system'); 3、项目基本环境1、在IDEA中新建Maven项目，并添加web支持（也可以使用web模版创建项目）。 如果先创建Maven项目，后添加的web支持，需要在在Project-Structure-&gt;Artifacts中给web项目在WEB-INF目录下新建lib目录，将所有jar包添加到lib目录。 2、导入相关的pom依赖。 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.kang&lt;/groupId&gt; &lt;artifactId&gt;SSMbuild&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;11&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;11&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;!-- SSM整合需要的依赖 junit，数据库驱动，连接池，servlet，jsp，mybatis，mybatis-spring，spring --&gt; &lt;dependencies&gt; &lt;!--Junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;!--数据库驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 数据库连接池,使用druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.22&lt;/version&gt; &lt;/dependency&gt; &lt;!--Servlet - JSP --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--Mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis-spring，用于整合Spring和MyBatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--Spring-mvc和jdbc--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.1.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.1.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 配置log4j日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 3、Maven资源过滤设置 --&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 3、Maven资源过滤设置，确保所有的配置文件都能够编译到out文件夹。 4、创建项目基本结构和配置文件。文件结构如图： SSM项目基本文件结构 为了配置结构清晰，我们尽量将不同功能的配置文件单独写，使用引入的方式整合多个配置文件。 最后在Spring的总配置文件applicationContext.xml中引入其他三个Spring配置文件。 二、MyBatis相关MyBatis相关的配置，主要是配置数据库连接的配置文件，以及Mapper映射配置文件。 1、数据库配置文件 database.properties 12345# 这里的名字必须加'jdbc.'前缀jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/ssmbuild?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8jdbc.username=rootjdbc.password=123456 2、编写MyBatis核心配置文件 mybatis.config.xml 12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;!--日志工厂实现--&gt; &lt;setting name=\"logImpl\" value=\"LOG4J\"/&gt; &lt;/settings&gt; &lt;!-- 为pojo包配置别名 --&gt; &lt;typeAliases&gt; &lt;package name=\"com.kang.pojo\"/&gt; &lt;/typeAliases&gt; &lt;!-- 配置数据源的语句交给spring,在spring-dao配置文件中 --&gt; &lt;!--Mapper映射，其实也可以交给spring配置--&gt; &lt;mappers&gt; &lt;mapper resource=\"com/kang/dao/BookMapper.xml\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 3、编写数据库对应的实体类 com.kang.pojo.Books.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.kang.pojo;public class Books { private int bookID; private String bookName; private int bookCounts; private String detail; public Books() { } public Books(int bookID, String bookName, int bookCounts, String detail) { this.bookID = bookID; this.bookName = bookName; this.bookCounts = bookCounts; this.detail = detail; } public int getBookID() { return bookID; } public void setBookID(int bookID) { this.bookID = bookID; } public String getBookName() { return bookName; } public void setBookName(String bookName) { this.bookName = bookName; } public int getBookCounts() { return bookCounts; } public void setBookCounts(int bookCounts) { this.bookCounts = bookCounts; } public String getDetail() { return detail; } public void setDetail(String detail) { this.detail = detail; } @Override public String toString() { return \"Books{\" + \"bookID=\" + bookID + \", bookName='\" + bookName + '\\'' + \", bookCounts=\" + bookCounts + \", detail='\" + detail + '\\'' + '}'; }} 4、编写DAO层的Mapper接口 DAO层定义基本的CRUD功能，供service层实现功能使用。 com.kang.dao.BookMapper 1234567891011121314151617181920212223package com.kang.dao;import com.kang.pojo.Books;import java.util.List;public interface BookMapper { //添加一本书 int addBook(Books books); //根据id删除一本书 int deleteBookById(int id); //修改一本书的信息 int updateBook(Books books); //根据id查询 Books queryBookById(int id); //查询全部 List&lt;Books&gt; queryAllBooks(); //根据书名模糊查询 List&lt;Books&gt; queryBookByName(String bookName); } 5、编写Mapper对应的配置文件 BookMapper.xml 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;!--namespace命名空间，用于绑定一个对应的DAO/Mapper接口,这里和UserMapper绑定。这样相当于写了一个实现类来实现此接口。--&gt;&lt;mapper namespace=\"com.kang.dao.BookMapper\"&gt; &lt;insert id=\"addBook\" parameterType=\"Books\"&gt; insert into books(bookName, bookCounts, detail) values (#{bookName},#{bookCounts},#{detail}) &lt;/insert&gt; &lt;delete id=\"deleteBookById\" parameterType=\"int\"&gt; delete from books where bookID=#{bookID} &lt;/delete&gt; &lt;update id=\"updateBook\" parameterType=\"Books\"&gt; update books set bookName=#{bookName}, bookCounts=#{bookCounts},detail=#{detail} where bookID=#{bookID} &lt;/update&gt; &lt;select id=\"queryBookById\" parameterType=\"int\" resultType=\"Books\"&gt; select bookID,bookName,bookCounts,detail from books where bookID = #{bookID} &lt;/select&gt; &lt;select id=\"queryAllBooks\" resultType=\"Books\"&gt; select bookID,bookName,bookCounts,detail from books; &lt;/select&gt; &lt;!-- 根据书名模糊查询。使用concat拼接 --&gt; &lt;select id=\"queryBookByName\" parameterType=\"String\" resultType=\"Books\"&gt; select bookID,bookName,bookCounts,detail from books where bookName like concat('%',#{bookName},'%') &lt;/select&gt; &lt;/mapper&gt; 6、编写Service层的接口和实现类 service根据用户的实际需求，调用DAO层方法实现功能。简单起见，功能和DAO层相同，只是简单的CRUD功能。 com.kang.service.BookService 1234567891011121314151617package com.kang.service;import com.kang.pojo.Books;import java.util.List;public interface BookService { int addBook(Books books); int deleteBookById(int id); int updateBook(Books books); Books queryBookById(int id); List&lt;Books&gt; queryAllBooks(); List&lt;Books&gt; queryBookByName(String bookName);} service接口的实现类com.kang.service.BookServiceImpl 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.kang.service;import com.kang.dao.BookMapper;import com.kang.pojo.Books;import java.util.List;//业务层调用DAO层完成功能public class BookServiceImpl implements BookService{ private BookMapper bookMapper; //提供一个set方法，用于依赖注入 public void setBookMapper(BookMapper bookMapper) { this.bookMapper = bookMapper; } @Override public int addBook(Books books) { return bookMapper.addBook(books); } @Override public int deleteBookById(int id) { return bookMapper.deleteBookById(id); } @Override public int updateBook(Books books) { return bookMapper.updateBook(books); } @Override public Books queryBookById(int id) { return bookMapper.queryBookById(id); } @Override public List&lt;Books&gt; queryAllBooks() { return bookMapper.queryAllBooks(); } @Override public List&lt;Books&gt; queryBookByName(String bookName) { return bookMapper.queryBookByName(bookName); }} 三、Spring相关接下来，需要在Spring中注册bean，并整合MyBatis。这里的数据源使用druid连接池。 1、编写Spring整合MyBatis的相关配置文件 spring-dao.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 此文件用于整合spring和mybatis，在spring中配置数据源。 这里选用第三方数据库连接池，而不是使用Spring原生的DriverManagerDataSource --&gt; &lt;!-- 1.关联数据库配置文件 --&gt; &lt;!-- property-placeholder表示用一个properties文件里的内容来替换spring配置文件 里使用${}的变量定义，比如我们把对数据库的配置信息配置在别的properties文件里， 然后这个文件中引入即可。 --&gt; &lt;context:property-placeholder location=\"classpath:database.properties\"/&gt; &lt;!-- 2.配置数据源（连接池） 常用数据库连接池：dbcp\\c3p0\\druid\\hikari 这里的数据源使用druid数据库连接池 --&gt; &lt;bean id = \"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"${jdbc.driver}\"/&gt; &lt;property name=\"url\" value=\"${jdbc.url}\"/&gt; &lt;property name=\"username\" value=\"${jdbc.username}\"/&gt; &lt;property name=\"password\" value=\"${jdbc.password}\"/&gt; &lt;!-- 根据不同的数据库连接池，还可以设置其他的属性，比如关闭自动提交功能 --&gt; &lt;property name=\"defaultAutoCommit\" value=\"false\"/&gt; &lt;/bean&gt; &lt;!-- 3.获取SqlSessionFactory --&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/&gt; &lt;/bean&gt; &lt;!-- 4.获取SqlSession --&gt; &lt;!--使用MapperScannerConfigurer自动扫描包的方式获取SqlSession--&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;!-- 设置要扫描的包 --&gt; &lt;property name=\"basePackage\" value=\"com.kang.dao\"/&gt; &lt;!-- 注入sqlSessionFactory --&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/&gt; &lt;/bean&gt;&lt;/beans&gt; 关于Spring和MyBatis整合详情可以参考Spring整合MyBatis 2、Spring整合service层 为了配置结构清晰，我们将service层的相关配置单独列为一个配置文件。 spring-service.xml 12345678910111213141516171819202122232425262728&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:comtext=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 此文件主要用于配置声明式事务相关的内容 --&gt; &lt;!-- 扫描service下的包，使其注解生效 --&gt; &lt;comtext:component-scan base-package=\"com.kang.service\"/&gt; &lt;!-- 2.将所有的业务类，注入到Spring，可以通过配置，或者注解实现 --&gt; &lt;bean id=\"bookServiceImpl\" class=\"com.kang.service.BookServiceImpl\"&gt; &lt;!-- bookMapper是MapperScannerConfigurer帮我们自动创建的接口代理实现类 --&gt; &lt;property name=\"bookMapper\" ref=\"bookMapper\"/&gt; &lt;/bean&gt; &lt;!-- 3.声明式事务配置 --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;!-- 注入数据源 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!-- 4.根据需求配置是否注入AOP事务 --&gt;&lt;/beans&gt; 四、SpringMVC相关配置完Spring和MyBatis层，已经可以实现和数据库的连接了。最后是配置SpringMVC的相关配置。 4.1 配置SpringMVC1、配置web.xml web.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"&gt; &lt;!-- 配置DispatcherServlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;!-- 这里引用的配置文件应该是总的applicationContext.xml文件 --&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 启动级别 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 配置过滤器，用于处理乱码 --&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 为了安全起见，可以配置会话的有效期 --&gt; &lt;session-config&gt; &lt;!-- 比如设置会话有效期为15分钟 --&gt; &lt;session-timeout&gt;15&lt;/session-timeout&gt; &lt;/session-config&gt;&lt;/web-app&gt; web.xml配置文件主要是配置web相关的内容，比如请求分发器和过滤器。要注意的是，这里请求分发器关联的文件应该是总的Spring配置文件，在这里是applicationContext.xml配置文件。 2、配置SpringMVC的配置文件 spring-mvc.xml 123456789101112131415161718192021222324252627&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;!-- 1.注解驱动 --&gt; &lt;mvc:annotation-driven/&gt; &lt;!-- 2.静态资源过滤 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 3.扫描包，使注解生效 --&gt; &lt;context:component-scan base-package=\"com.kang.controller\"/&gt; &lt;!-- 4.配置视图解析器 --&gt; &lt;bean id=\"internalResourceViewResolver\" class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!-- 指定视图解析器要匹配的前缀和后缀 --&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/jsp/\"/&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt;&lt;/beans&gt; 最后，别忘了将spring配置文件整合到总的配置文件中： applicationContext.xml 1234567891011&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- 引入其他的三个spring配置文件 --&gt; &lt;import resource=\"classpath:spring-service.xml\"/&gt; &lt;import resource=\"classpath:spring-dao.xml\"/&gt; &lt;import resource=\"classpath:spring-mvc.xml\"/&gt;&lt;/beans&gt; 至此，配置文件已经配置结束，可以编写测试类测试是否连接上数据库，以及各个方法是否正确。 4.2 阶段性测试编写测试类，测试整体是否配置成功： 1234567891011121314151617import com.kang.pojo.Books;import com.kang.service.BookService;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class queryBookByIdTest { @Test public void test(){ ApplicationContext context = new ClassPathXmlApplicationContext (\"applicationContext.xml\"); BookService bookService = context.getBean(\"bookServiceImpl\", BookService.class); Books books = bookService.queryBookById(3); System.out.println(books.toString()); }} 如果正确查询到结果，说明配置成功： 1Books{bookID=3, bookName='Linux', bookCounts=3, detail='Linux operation system'} 可以继续对其他方法进行测试。这里不再列举。 五、编写Controller和前端页面经过上述一系列配置，已经可以在后端完成指定的功能。接下来就要和前端进行交互，即实现SpringMVC框架中的控制器。 控制层和前端页面交互，因此需要结合前端页面，实现功能。以下是简单的增删查改功能的实现。 5.1 编写Controller控制器SpringMVC中的控制器用于处理请求 。controller层调用service层，处理请求。 com.kang.controller.BookController 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package com.kang.controller;import com.kang.pojo.Books;import com.kang.service.BookService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import java.awt.print.Book;import java.util.List;@Controller@RequestMapping(\"/book\")public class BookController { //controller调用service层。设置自动装配 @Autowired @Qualifier(\"bookServiceImpl\") private BookService bookService; //查询全部书籍，并返回书籍展示页面视图 @RequestMapping(\"/allBook\") public String bookList(Model model){ List&lt;Books&gt; books = bookService.queryAllBooks(); model.addAttribute(\"bookList\",books); return \"allBook\"; } //跳转到查询页面 @RequestMapping(\"/toAddBook\") public String toAddBook(Model model){ return \"addBook\"; } //addBook @RequestMapping(\"/addBook\") public String addBook(Books books){ bookService.addBook(books); //添加完后，重定向到书籍展示页面 return \"redirect:/book/allBook\"; } //跳转到修改页面 @RequestMapping(\"/toUpdateBook\") public String toUpdateBook(int id,Model model){ //通过前端传递过来的id查询出来对应的book信息，反馈到前端 Books books = bookService.queryBookById(id); model.addAttribute(\"bookToUpdate\",books); return \"updateBook\"; } //updateBook @RequestMapping(\"/updateBook\") public String updateBook(Books books){ //前端表单的内容提交到这里，会根据name对应Books的属性 bookService.updateBook(books); return \"redirect:/book/allBook\"; } //deleteBook @RequestMapping(\"/deleteBook/{bookId}\") //使用RESTfull风格传递数据 public String deleteBook(@PathVariable(\"bookId\") int id){ bookService.deleteBookById(id); return \"redirect:/book/allBook\"; } //搜索书籍 @RequestMapping(\"/searchBookByName\") public String searchBookByName(String queryBookName,Model model){ List&lt;Books&gt; books = bookService.queryBookByName(queryBookName); //将查询到的结果重新写入到页面 model.addAttribute(\"bookList\",books); return \"allBook\"; }} 控制层的代码是根据客户端的功能一步步编写的，这里一次性列出了全部代码。 这里对基本的功能做简单的实现，仅供参考。 5.2 编写页面5.2.1 首页首页内容： 首页 index.jsp 1234567891011121314151617181920212223242526272829&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;首页&lt;/title&gt; &lt;style&gt; h3{ width: 180px; height: 38px; margin:100px auto; text-align: center; line-height: 38px; background: deepskyblue; border-radius: 10px; } a{ text-decoration: none; color: black; font-size: 18px; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;h3&gt; &lt;a href=\"${pageContext.request.contextPath}/book/allBook\"&gt; 进入书籍展示页面 &lt;/a&gt; &lt;/h3&gt; &lt;/body&gt;&lt;/html&gt; 需要在BookController中编写book/allBook请求的代码。 5.2.2 书籍展示展示页面内容： 书籍展示页面 WEB-INF/jsp/allBook.jsp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %&gt;&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;书籍展示页面&lt;/title&gt; &lt;%--使用BootStrap美化界面，使用CDN加速--%&gt; &lt;link href=\"https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css\" rel=\"stylesheet\"&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 使用BootStrap框架美化页面 --&gt; &lt;div class=\"container\"&gt; &lt;div class=\"row clearfix\"&gt; &lt;div class=\"col-md-12 column\"&gt; &lt;div class=\"page-header\"&gt; &lt;h1&gt; &lt;small&gt;书籍列表----显示所有书籍&lt;/small&gt; &lt;/h1&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"row\"&gt; &lt;div class=\"col-md-4 column\"&gt; &lt;%-- 跳转到toAddBook --%&gt; &lt;a class=\"btn btn-primary\" href=\"${pageContext.request.contextPath}/book/toAddBook\"&gt;新增书籍&lt;/a&gt; &lt;/div&gt; &lt;div class=\"col-md-4 column\"&gt;&lt;/div&gt; &lt;%-- 查询书籍 --%&gt; &lt;div class=\"form-inline\"&gt; &lt;form action=\"${pageContext.request.contextPath}/book/searchBookByName\" method=\"post\" style=\"float: right\"&gt; &lt;input type=\"text\" name=\"queryBookName\" class=\"form-control\" placeholder=\"请输入要查询的书籍名称\"&gt; &lt;input type=\"submit\" value=\"查询\" class=\"btn btn-primary\"&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"row clearfix\"&gt; &lt;div class=\"col-md-12 column\"&gt; &lt;table class=\"table table-hover table-striped\"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;书籍编号&lt;/th&gt; &lt;th&gt;书籍名称&lt;/th&gt; &lt;th&gt;书籍数量&lt;/th&gt; &lt;th&gt;书籍详情&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;%-- 书籍需要从前端遍历出来 --%&gt; &lt;tbody&gt; &lt;c:forEach var=\"book\" items=\"${bookList}\"&gt; &lt;tr&gt; &lt;td&gt;${book.bookID}&lt;/td&gt; &lt;td&gt;${book.bookName}&lt;/td&gt; &lt;td&gt;${book.bookCounts}&lt;/td&gt; &lt;td&gt;${book.detail}&lt;/td&gt; &lt;td&gt; &lt;%-- 跳转到修改页面的时候，传递bookID参数 --%&gt; &lt;a href=\" {pageContext.request.contextPath}/book/toUpdateBook?id= {book.bookID}\"&gt;修改&lt;/a&gt; &amp;nbsp;| &amp;nbsp; &lt;%-- 使用RESTFull风格跳转 --%&gt; &lt;a href=\" {pageContext.request.contextPath}/book/deleteBook/ {book.bookID}\"&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 需要在BookController中编写处理book/toAddBook、book/toUpdateBook、book/deleteBook、book/searchBookByName请求的代码。 5.2.3 添加书籍添加书籍页面： 添加书籍页面 WEB-INF/jsp/addBook.jsp 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %&gt;&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;添加书籍页面&lt;/title&gt; &lt;%--使用BootStrap美化界面，使用CDN加速--%&gt; &lt;link href=\"https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css\" rel=\"stylesheet\"&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 使用BootStrap框架美化页面 --&gt; &lt;div class=\"container\"&gt; &lt;div class=\"row clearfix\"&gt; &lt;div class=\"col-md-12 column\"&gt; &lt;div class=\"page-header\"&gt; &lt;h1&gt; &lt;small&gt;书籍列表----新增书籍&lt;/small&gt; &lt;/h1&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;form action=\"${pageContext.request.contextPath}/book/addBook\" method=\"post\" &gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"bookname\"&gt;书籍名称&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"bookname\" name=\"bookName\" required&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"bookcount\"&gt;书籍数量&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"bookcount\" name=\"bookCounts\" required&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"bookdetail\"&gt;书籍描述&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"bookdetail\" name=\"detail\" required&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;input type=\"submit\" class=\"form-control\" value=\"确认添加\"&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 需要在BookController中编写处理book/addBook请求的代码。 5.2.4 修改书籍修改书籍页面： 修改书籍页面 WEB-INF/jsp/updateBook.jsp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %&gt;&lt;%@ taglib prefix=\"form\" uri=\"http://www.springframework.org/tags/form\" %&gt;&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;修改数据页面&lt;/title&gt; &lt;%--使用BootStrap美化界面，使用CDN加速--%&gt; &lt;link href=\"https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css\" rel=\"stylesheet\"&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 使用BootStrap框架美化页面 --&gt; &lt;div class=\"container\"&gt; &lt;div class=\"row clearfix\"&gt; &lt;div class=\"col-md-12 column\"&gt; &lt;div class=\"page-header\"&gt; &lt;h1&gt; &lt;small&gt;修改书籍&lt;/small&gt; &lt;/h1&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;form action=\"${pageContext.request.contextPath}/book/updateBook\" method=\"post\" &gt; &lt;%-- 设置一个隐藏域来传递id,用于更新内容 --%&gt; &lt;input type=\"hidden\" name=\"bookID\" value=\"${bookToUpdate.bookID}\"&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"bookname\"&gt;书籍名称&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"bookname\" name=\"bookName\" value=\"${bookToUpdate.bookName}\" required&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"bookcount\"&gt;书籍数量&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"bookcount\" name=\"bookCounts\" value=\"${bookToUpdate.bookCounts}\" required&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"bookdetail\"&gt;书籍描述&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"bookdetail\" name=\"detail\" value=\"${bookToUpdate.detail}\" required&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;input type=\"submit\" class=\"form-control\" value=\"确认修改\"&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 需要在BookController中编写处理book/updateBook请求的代码。 5.2.5 删除书籍在书籍展示页面已经添加了删除选项： 1&lt;a href=\" {pageContext.request.contextPath}/book/deleteBook/ {book.bookID}\"&gt;删除&lt;/a&gt; 点击删除的时候，会向服务器发起请求，传递bookID给控制层，控制层接受请求并执行删除功能。 也就是下面的代码： 1234567@RequestMapping(\"/deleteBook/{bookId}\")//使用RESTfull风格传递数据public String deleteBook(@PathVariable(\"bookId\") int id){ bookService.deleteBookById(id); //删除完后会重定向到书籍展示页面 return \"redirect:/book/allBook\";} 5.2.6 搜索功能实现一个简单的根据书名模糊搜索的功能，书籍展示页面中，查询书籍的代码为： 1234567&lt;div class=\"form-inline\"&gt; &lt;form action=\"${pageContext.request.contextPath}/book/searchBookByName\" method=\"post\" style=\"float: right\"&gt; &lt;input type=\"text\" name=\"queryBookName\" class=\"form-control\" placeholder=\"请输入要查询的书籍名称\"&gt; &lt;input type=\"submit\" value=\"查询\" class=\"btn btn-primary\"&gt; &lt;/form&gt;&lt;/div&gt; 对应地，我们应该在控制层写一个处理book/searchBookByName请求的代码，也就是下面的代码： 123456789//搜索书籍@RequestMapping(\"/searchBookByName\")public String searchBookByName( @RequestParam(\"queryBookName\")String queryBookName, Model model){ List&lt;Books&gt; books = bookService.queryBookByName(queryBookName); //将查询到的结果重新写入到页面 model.addAttribute(\"bookList\",books); return \"allBook\";} 六、总结上述只是SSM框架整合的一个最简单的应用，只是基本的配置流程。代码参考： 实际开发中，可以根据需求添加相应的配置。比如： service层的事务管理功能 配置过滤器，解决前端向后端传递数据时的乱码问题。 配置消息转换器，处理控制器返回JSON数据时的乱码问题。 根据项目的实际需求，添加具体的功能。 其中的一些配置方式也有多种，并不是固定的。比如依赖注入的方式，MyBatis中获取SqlSession的方式等，也需要根据实际情况选取实现方式。 参考内容：狂神说SSM框架系列连载","categories":[{"name":"SSM框架","slug":"SSM框架","permalink":"http://kangshitao.github.io/categories/SSM%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://kangshitao.github.io/tags/Spring/"},{"name":"MyBatis","slug":"MyBatis","permalink":"http://kangshitao.github.io/tags/MyBatis/"},{"name":"SSM","slug":"SSM","permalink":"http://kangshitao.github.io/tags/SSM/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://kangshitao.github.io/tags/SpringMVC/"}]},{"title":"SpringMVC总结","slug":"spring-mvc","date":"2021-07-03T08:15:45.000Z","updated":"2022-05-22T13:30:54.804Z","comments":true,"path":"2021/07/03/spring-mvc/","link":"","permalink":"http://kangshitao.github.io/2021/07/03/spring-mvc/","excerpt":"SpringMVC工作原理，Controller，拦截器，RestFul，JSON，Ajax","text":"一、SpringMVC介绍1.1 MVC传统的三层架构： View：视图层，用于接收用户提交请求代码。 Service：服务层，主要是系统的业务逻辑代码。 Dao：持久层，直接操作数据库的代码。 MVC，即 View：视图，主要负责显示数据和提交数据。比如JSP，HTML页面 Model：模型，承载数据，并对用户提交请求进行计算的模块。包括数据承载（bean）和业务处理（service、dao）两部分。 Controller：控制器，用于将用户请求转发给相应的Model进行处理，并处理Model的计算结果向用户提供响应。 MVC也演化出了其他的模式，比如MVP、MVVM等。 MVC架构的工作流程大致如下： 用户通过View页面向服务端发起请求。 服务端Controller控制器接受请求并进行解析，找到相应的Model对用户请求进行处理。 Model处理后，将处理结果交给Controller。 Controller接到结果以后发给View，将渲染后的页面响应给用户。 没有SpringMVC之前的web应用主要经历了两个阶段： Model1时代：主要有视图层和模型层，JSP将控制逻辑和表现逻辑混杂在一起，职责过重，不便于维护。 Model2时代：项目分为模型（bean，dao)、视图（JSP）、控制（Servlet）三部分，但这种模式的抽象和封装程度远远不够，因此有了Struts、SpringMVC等MVC框架。 1.2 SpringMVCSpring MVC是Spring Framework的一部分，是基于Java实现MVC的轻量级Web框架。 SpringMVC功能强大，支持RESTful、数据验证、本地化、国际化、拦截器等功能。 SpringMVC中的DispatcherServlet用于控制所有请求，将请求分发到不同的处理器，而传统的项目中每个servlet只能处理一个请求。 二、SpringMVC的工作原理SpringMVC主要是以DispatcherServlet（前端控制器、请求分发器）为核心。这个类继承于HttpServlet类，本质上是一个servlet。 SpringMVC的主要工作流程如下： SpringMVC工作原理 1、用户发送请求，请求会被 DispatcherServlet接收。 2、DispatcherServlet 根据请求信息，调用 HandlerMapping来解析请求对应的 Handler。 3、解析到对应的 Handler（也叫做 Controller 控制器）后，交给由 HandlerAdapter 适配器处理。 4、HandlerAdapter 会根据 Handler来调用真正的处理器来处理请求，并处理相应的业务逻辑。 5、处理器处理完业务后，会返回一个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的视图（字符串表示的视图逻辑名，比如JSP页面名）。 ModelAndView对象包括了ModelMap和view两个属性，ModelMap用于保存数据，比如请求查询得到的结果对象，view用于保存逻辑视图名。 6、DispatcherServlet 将逻辑View传递给ViewResolver 视图解析器，它会根据 逻辑View 查找实际的 View(即根据名称找到真正的页面)并创建视图，返回给DispatcherServlet 。 视图解析器根据设置好的前缀路径和后缀名，进行拼接，确定视图的位置，然后创建View接口的实现类对象，也就是视图对象，将其返回给请求分发器。 7、DispaterServlet 把视图解析器返回的 View 进行视图渲染，并将模型数据填充到request域。 视图就是html、jsp等页面。在底层源码中视图渲染会将Model里面的键值对数据全部写到requestScope中（前端可以通过EL表达式从域对象中获取数据），然后进行请求转发到指定的页面，最后将这个页面相应给用户。 也就是说，ModelAndView中的数据对象会被放在请求域中。 8、最后，DispaterServlet 向用户响应结果。 将响应数据放到Response中返回给用户。 三、SpringMVC的使用使用SpringMVC创建web项目，需要一个springmvc-servlet.xml配置文件用来配置处理器映射器、处理器适配器和视图解析器。然后在web.xml文件中配置请求分发器。 使用Maven框架，可以使用IDEA的Web模版创建web项目； 也可以先创建普通Maven模块，然后右键Add Framework Support，添加Web框架支持。这种方式创建web项目，需要在Project Structure-&gt;Artifacts中，在WEB-INF目录中创建lib文件夹，然后将用到的所有jar包添加进去。如下图： 在项目发布目录手动添加jar包 创建完项目以后，基本的目录结构如下： SpringMVC项目的基础目录 DispatcherServlet是SpringMVC的核心，其实现方式有两种，分别是实现Controller接口和使用@Controller注解。 无论是哪种方式，web.xml配置文件都是一样的，在其中需要配置请求分发器（前端控制器）。 web.xml 12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"&gt; &lt;!-- 配置dispatcherServlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 通过初始化参数，指定关联的Spring的xml文件位置 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 设置启动级别 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!-- 设置匹配的请求 --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 其中的配置说明： contextConfigLocation表示装入配置文件，这个路径应该是Spring的总配置文件。如果不指定，默认加载/WEB-INF/applicationContext.xml，如果想自定义名称，则需要指定路径。 load-on-startup：用于标记容器是否应该在web应用程序启动的时候就加载这个servlet（实例化并调用init()方法）。值必须是整数，表示servlet被加载的顺序。如果值为负数或者没有设置，则当这个servlet被请求时再加载。如果值为0或正整数，表示容器启动时就加载这个servlet，数值越小优先级越高，数值相同时按照声明顺序加载。 /：匹配所有的请求，但不会匹配JSP、HTML等静态资源。 /*:匹配所有的请求，包括静态资源。这里不能使用/*，因为如果把JSP页面当作请求的话，如果视图解析器的后缀也是JSP，会陷入无限请求中导致请求失败。 3.1 方式一：实现Controller接口其中实现接口的方式需要在Spring配置文件中注册bean，为了能够使映射器根据名字找到对应的Handler。 1、配置springmvc-servlet.xml文件 12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- 映射器和适配器都是默认的，不注册也可以正常使用，这里为了流程清晰将其显式写出来 --&gt; &lt;!-- 配置处理器映射器 --&gt; &lt;bean class=\"org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping\"/&gt; &lt;!-- 配置处理器适配器 --&gt; &lt;bean class=\"org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter\"/&gt; &lt;!-- 配置视图解析器（必须），根据接收的视图名找到视图的真实位置并返回视图 --&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\" id=\"internalResourceViewResolver\"&gt; &lt;!-- 前缀 --&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/jsp/\"/&gt; &lt;!-- 后缀 --&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!-- BeanNameUrlHandlerMapping映射器会根据bean名字，找到对应的handler --&gt; &lt;!-- 注册 Handler，当请求为test的时候，就会执行HelloController --&gt; &lt;bean id=\"/test\" class=\"com.kang.controller.HelloController\"/&gt;&lt;/beans&gt; 说明： Controller的id必须加/ 视图解析器根据视图名，加上前缀和后缀定位视图。 这里的映射器和适配器都是默认的，不注册也可以正常使用，这里为了便于理解，将其显式写出来。 2、创建控制器类，实现Controller接口，在java/com/kang/controller目录下创建控制器类。 HelloController 1234567891011121314151617package com.kang.controller;public class HelloController implements Controller { @Override public ModelAndView handleRequest(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws Exception { ModelAndView mv = new ModelAndView(); //Controller，需要返回一个ModelAndView对象 //1、编写业务代码 String result = \"HelloSpringMVC\"; mv.addObject(\"msg\",result); //将结果写到msg属性中 //2、视图跳转，指定要跳转的jsp页面名字 mv.setViewName(\"test\"); return mv; }} mv.addObject(\"msg\",result);表示添加数据到ModelAndView对象，这个数据最终会被请求转发器添加到requestScope中。在前端页面就可以使用EL表达式从requstScope中取到数据：${requestScope.msg} mv.setViewName(\"test\");用于指定要请求转发的视图名字。 这个ModelAndView对象返回给请求分发器，然后经过视图解析器解析、视图渲染等步骤，最终将带有数据的视图写入response中响应给用户。 3.2 方式二：使用@Controller注解使用注解不需要显式注册bean，而是在类中使用@Controller注解，自动将当前类注册为控制器类。 @Controller效果和@Component注解类似，都表示将当前类交给Spring托管。 与之类似的还有@Service用于service层，@Repository用于dao层。 被@Controller注解的类中的所有方法（公有私有都包括），如果返回值是String，并且有具体的页面与之对应，就会被视图解析器解析。 如果想要方法的返回值不被视图解析器解析，可以使用在方法上使用@ResponseBody注解，表示当前方法的返回值直接写入到HTTP响应（response）体中，一般返回的是JSON或XML形式的数据，是前后端分离情况下常用的情况。详情参见下文JSON章节 使用注解时，配置文件和控制类的内容和方式一不同。 1、配置spring-mvc.xml文件 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring context.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;context:component-scan base-package=\"com.kuang.controller\"/&gt; &lt;mvc:default-servlet-handler/&gt; &lt;mvc:annotation-driven/&gt; &lt;!--视图解析器--&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\" id=\"internalResourceViewResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/jsp/\" /&gt; &lt;property name=\"suffix\" value=\".jsp\" /&gt; &lt;/bean&gt;&lt;/beans&gt; 参数说明： &lt;context:component-scan&gt; 1表示自动扫描包，让指定包下的注解生效，由IOC容器统一管理 &lt;mvc:default-servlet-handler/&gt; 12345用于过滤静态资源，让SpringMVC不处理静态资源，比如.txt、.mp3、.jpg等。配置这个处理器后，会在Spring MVC上下文中定义一个org.springframework.web.servlet.resource.DefaultServletHttpRequestHandler，它像一个检查员，对进入DispatcherServlet的URL进行筛查，如果发现是静态资源的请求，就将该请求转由Web应用服务器默认的Servlet处理；如果不是静态资源的请求，才由DispatcherServlet继续处理。 &lt;mvc:annotation-driven/&gt; 12345678910111213用于配置注解驱动。一方面：在spring中一般采用@RequestMapping注解来完成映射关系要想使@RequestMapping注解生效，必须向上下文中注册DefaultAnnotationHandlerMapping和一个AnnotationMethodHandlerAdapter实例，这两个实例分别在类级别和方法级别处理。annotation-driven配置帮助我们自动完成上述两个实例的注入。另一方面：基础bean只能提供最基础的服务，其它的扩展功能，比如JSON、XML、Valid等等，根据classpath有没有相关的依赖来决定要不要添加对应的bean或者属性，annotation-driven的作用就是提供扩展功能。 2、创建Controller类 12345678@Controllerpublic class HelloController { @RequestMapping(\"/hello1\") public String myController(Model model){ model.addAttribute(\"msg\",\"hello,MVC-Annocation\"); return \"hello\"; }} 我们自定义方法的返回值是视图名，相当于在Spring的XML文件中配置了id为hello的bean，用于映射器查找到对应的控制器。在方法中可以使用Model对象、ModelMap对象、ModelAndView对象三种方式向请求域中传递数据，也就是向前端页面传递数据，具体使用方法见下文。 注解说明： @Controller：将当前类注册为Controller，类似于实现Controller接口。 @RequestMapping：表示映射hello请求到这个方法，也就是说当请求为hello时，会执行这个被其注解的方法。也可以用在类中，表示当前类中的每个方法的共同请求前缀，比如下面的案例，只有当请求为/test/hello时才会执行myController方法。 123456//表示类中每个方法的请求前都要加路径/test@RequestMapping(\"/test\")public class HelloController { @RequestMapping(\"/hello\") public String myController(){}} @RequestMapping默认为任何请求方式，也可以在参数中指定请求方式，比如设置为POST请求方式： 1@RequestMapping(value = \"/hello\",method = RequestMethod.POST) HTTP的几种请求方式参考HTTP请求方法 对于具体的请求方式，还可以使用其对于的注解，比如@GetMapping、@PostMapping @PutMapping、@DeleteMapping等，其作用和@RequestMapping相同，不过是固定了具体的请求方式。 四、SpringMVC的结果跳转使用@Controller方式的控制器，页面跳转可以使用视图解析器，也可以不使用视图解析器。 1.使用视图解析器 使用视图解析器的时候，只需要返回视图名字即可，或者返回带有视图名字属性的ModelAndView对象。 12345678910111213141516171819202122//方式一：直接返回视图名给视图解析器@Controllerpublic class HelloController implements Controller { @RequestMapping(\"/hello\") public String myController(){ //1.做一些数据处理 //2.返回视图名 return \"test\"; }}//方式二：使用ModelAndView设置视图名@Controllerpublic class HelloController implements Controller { @RequestMapping(\"/hello\") public ModelAndView myController(){ ModelAndView mv = new ModelAndView(); //1.做一些数据处理 //2.设置要跳转的视图名，并返回此对象 mv.setViewName(\"test\"); return mv; }} 以上两种方式都是使用视图解析器时的写法，都是将视图名传递给视图解析器。前提是SpringMVC的配置文件中注册了视图解析器。 2.直接返回 如果不使用视图解析器，也可以直接将视图返回。由于没有视图解析器的路径拼接，所以方法的返回值应该是真实不需要拼接的视图地址。 如果不指定前缀，默认表示请求转发。 不指定forward或redirect，则必须保证视图解析器关闭或注释掉，否则视图解析器仍会拼接结果。 如果指定了前缀，则会按照指定的方式转发或重定向，并且不会经过视图解析器（即使开启了视图解析器）。 123456789@Controllerpublic class ModelTest { @RequestMapping(\"/test2\") public String test2(){ //return \"/WEB-INF/jsp/hello.jsp\"; //请求转发 //return \"forward:/WEB-INF/jsp/hello.jsp\"; //请求转发 return \"redirect:/index.jsp\"; //重定向,重定向的页面需要确保能够通过url访问 }} 这里要注意的是，如果是重定向，因为重定向是客户端重新发起请求，因此必须保证此页面可以通过URL直接访问。 3.使用ServletAPI 使用HttpServletRequest进行请求转发或者HttpServletResponse进行重定向。不需要视图解析器. 1234567891011@Controllerpublic class ModelTest1 { @RequestMapping(\"/test3\") public void test3(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { request.setAttribute(\"msg\",\"ModelTest1\"); request.getRequestDispatcher(\"/WEB-INF/jsp/hello.jsp\"). forward(request,response); }} 可以使用ServletAPI进行手动请求转发或者重定向，同样不需要视图解析器。 五、SpringMVC中的数据处理SpringMVC中的数据处理主要是两方面，一个是后端如何接收前端传来的数据，第二个是后端如何向前端传递数据。 在前端页面中，我们可以使用EL表达式从域对象中取出数据；通过表单等方式提交数据。 5.1 控制器接收数据控制器对于前端传来的数据可以直接通过参数进行接收。可以分为以下三种情况。 以下案例以GET请求方式为例 1、传递的参数名和方法的参数名一致 url：http://localhost:8080/SpringMVC_04/user/t1?name=spring 12345678910111213@Controller@RequestMapping(\"/user\")public class UserController { @PostMapping(\"/t1\") public String acceptData(String name, Model model){ //1.接收前端参数 System.out.println(name); //2.做一些处理 model.addAttribute(\"msg\",name); //3.视图跳转 return \"hello\"; }} 可以看到，请求的参数名称和方法的参数名称能够对应起来，因此方法中的name参数可以接收来自请求的数据，然后方法就可以对数据做一些操作。 2、传递的参数名和方法的参数名不一致 当传递的参数名和方法的参数名不一致的时候，需要使用@RequestParam注解指定对应关系。 url：http://localhost:8080/SpringMVC_04/user/t1?username=spring 12345678910111213@Controller@RequestMapping(\"/user\")public class UserController { @GetMapping(\"/t1\") public String acceptData(@RequestParam(\"username\")String name, Model model){ //1.接收前端参数 System.out.println(name); //2.将返回的结果传递给前端 model.addAttribute(\"msg\",name); //3.视图跳转 return \"hello\"; }} @RequestParam是一个参数注解，用到参数前，表示将请求的参数名和方法参数名对应起来，注解中的值为请求的参数名。 比如上述代码的请求参数名是username，则注解中的值也为username，表示name这个参数将接收来自客户端请求中的username参数值。 3、传递的是一个对象 如果提交的表单是一个复杂的对象，则方法参数使用对象类型即可。 比如现在有一个User类定义如下： 12345public class User { private int id; private String name; private int age;} url：http://localhost:8080/SpringMVC_04/user/t1?name=kang&amp;id=1&amp;age=20 123456789101112@Controller@RequestMapping(\"/user\")public class UserController { @GetMapping(\"/t2\") public String test2(User user, Model model){ //1.接收前端参数 System.out.println(user); //2.处理数据 model.addAttribute(\"msg\",\"accept user\"); //3.视图跳转 return \"hello\"; } 这种方法需要保证请求参数的名称和对象属性名一致，如果名称不一致，则属性值为null。 5.2 控制器传递数据前面提到过，控制器有三种方式向请求域中传递数据，即向前端页面传递数据。 这一过程对应于SpringMVC工作原理图中的第6、7步，即控制器返回ModelAndView。 1、使用ModelModel是一个接口。能够满足大部分传递数据的需求。比较简单，只适合用于存储数据。 使用Model传递数据： 123456789@Controllerpublic class MyController { @RequestMapping(\"/hello\") public String test(Model model){ //调用addAttribute方法写入数据 model.addAttribute(\"msg\",\"hello,SpringMVC\"); return \"hello\"; }} 需要注意的是，这种方法需要将Model写在参数中，使用时可以调用addAttribute()方法写入数据。 2、使用ModelMapModelMap是一个类，继承了LinkedHashMap，其除了拥有和Model相同的功能以外，还具有LinkedHashMap的所有功能。 使用ModelMap传递数据的用法和Model相同： 12345678@Controllerpublic class MyController { @RequestMapping(\"/hello\") public String test(ModelMap modelMap){ modelMap.addAttribute(\"msg\",\"hello,SpringMVC\"); return \"hello\"; }} 注意：ModelMap和Model不是实现和被实现的关系，ModelMap可以看作一个增强版的Model。 ModelMap类的源码声明如下： 1234public class ModelMap extends LinkedHashMap&lt;String, Object&gt; { public ModelMap() {} ...} 3、使用ModelAndViewModerAndView是一个类，其属性中包括了一个Object类型的view属性，也包括了一个ModelMap对象model。model是数据对象，view是视图，可以是视图名，也可以是视图对象。 除了在实现Controller接口重写方法时使用ModelAndView，还可以在自定义方法中使用。 12345678910@Controllerpublic class HelloController { @RequestMapping(\"/hello\") public ModelAndView myController(){ ModelAndView mv = new ModelAndView(); mv.addObject(\"msg\",\"hello,SpringMVC\"); //添加数据 mv.setViewName(\"hello\"); //指定视图名 return mv; }} 使用ModelAndView时，方法的返回值必须是ModelAndView类型，就是将ModelAndView对象传递给请求分发器。 ModelAndView源码： 12345678910111213141516171819202122public class ModelAndView { @Nullable private Object view; //视图名 @Nullable private ModelMap model; //保存数据 @Nullable private HttpStatus status; private boolean cleared = false; public ModelAndView() {} //设置要跳转的视图名 public void setViewName(@Nullable String viewName) { this.view = viewName; } //添加数据 public ModelAndView addObject(String attributeName, @Nullable Object attributeValue) { this.getModelMap().addAttribute(attributeName, attributeValue); return this; } ...} 通过源码可以看出，setViewName()方法是设置视图名给view，addObject()方法是调用ModelMap类的方法添加数据。 总结 在使用Model和ModelMap的两种方式中，视图名是使用返回值或者手动重定向/转发来确定的，数据是通过addAttribute()方法添加的。 使用ModelAndView的方法中的视图名是通过setViewName()方法传递的，数据是通过addObject()方法添加的。 我们可以根据实际情况选用三种方式。 5.3 前端向后端传递数据时的乱码问题前端向后端传递数据时，由于客户端浏览器编码方式的问题，传到后端时为乱码，此时可以使用SpringMVC提供的过滤器CharacterEncodingFilter，在web.xml文件中配置过滤器： 12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"&gt; &lt;!-- 配置请求分发器 --&gt; ... &lt;!-- 配置SpringMVC提供的编码过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;!-- 设置编码方式为utf-8 --&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;!-- /*也会过滤jsp页面 --&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; /*过滤所有页面，包括静态资源。 六、JSON6.1 JSON介绍JSON（JavaScript Object Notation, JS 对象标记）是一种轻量级的数据交换格式。JSON采用一种完全独立于编程语言的文本格式来存储和表示数据。语法格式为： 对象保存为键值对，数据由逗号分隔； {}用来保存对象； []用来保存数组。 比如，一个包括三个User对象的JSON： 12[{\"name\":\"Tom\",\"age\":3,\"sex\":\"man\"},{\"name\":\"Jerry\",\"age\":4,\"sex\":\"man\"},{\"name\":\"Rick\",\"age\":20,\"sex\":\"man\"}] 6.2 使用JSON传递数据对于前后端分离的环境，前后端交互一般是传递的JSON数据。 常用的几个JSON处理工具包： Gson：来自谷歌，使用广泛。 FastJson：来自阿里巴巴，速度快。 Jackson：适合数据量较大时使用。 Json-lib：已经不适合现在的需求。 参考各种json工具包的比较 6.2.1 JS中使用JSON从JSON字符串转换为JavaScript对象： 12var obj = JSON.parse('{\"a\": \"Hello\", \"b\": \"World\"}');//结果是 {a: 'Hello', b: 'World'} 从JavaScript 对象转换为JSON字符串： 12var json = JSON.stringify({a: 'Hello', b: 'World'});//结果是 '{\"a\": \"Hello\", \"b\": \"World\"}' 6.2.2 SpringMVC中返回JSON数据以Gson为例，使用时需要先创建Gson对象，然后调用方法，如下： 1、将User对象转化为JSON字符串，使用toJson()方法 1String str = new Gson().toJson(new User(1,\"张三\",24)); 2、将JSON字符串转化为User对象，使用fromJson()方法 1User user = new Gson().fromJson(str,User.class); 在SpringMVC中使用Gson，需要先导入依赖。 pom.xml： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.8.6&lt;/version&gt;&lt;/dependency&gt; 定义User类： 123456public class User { private int id; private String name; private int age; ...} 我们需要控制器的方法直接返回数据，而不是返回视图，这时候就需要使用@ResponseBody注解了。或者直接将当前类注册为RestController。 @ResponseBody：可以用在方法上，也可以用在类上。用在方法上表示当前方法返回值不会被视图解析器解析，返回值会被直接写入到响应体（response body）中，通常为JSON或XML类型的数据。用在类上则对当前类所有方法生效。 @RestController：只能用在类上，效果相当于同时使用 @Controller 和@ResponseBody，表示将当前类注册为控制器，且类中所有方法的返回值都返回的是数据对象，不会被视图解析器解析。 @RestController底层仍然是使用了 @Controller 和@ResponseBody。 更多对比，参考@Controller和@RestController 以下为组合使用 @Controller 和 @ResponseBody，单独使用@ResponseBody两种方式，二者效果相同。 1、使用 @Controller 和 @ResponseBody： 12345678910@Controllerpublic class UserController {} @ResponseBody @RequestMapping(value = \"/json\") public String test(){ User user = new User(1,\"John\",24); String str = new Gson().toJson(user); return str; }} 2、使用@RestController： 123456789@RestControllerpublic class UserController { @RequestMapping(value = \"/json\") public String test(){ User user = new User(1,\"John\",24); String str = new Gson().toJson(user); return str; }} 这样客户端可以从响应数据中接收数据。 6.3 使用HttpMessageConverter处理乱码控制器返回JSON数据时，可能会由于编码不同而出现乱码问题，可以通过配置SpringMVC的StringHttpMessageConverter消息转换器来解决。 在spring的配置文件springmvc-servlet.xml文件的注解驱动中配置消息转换器： 12345678910111213141516171819&lt;!-- annotation-driven的作用就是提供扩展功能 --&gt;&lt;mvc:annotation-driven&gt; &lt;!-- StringHttpMessageConverter转换配置，解决乱码问题 --&gt; &lt;mvc:message-converters register-defaults=\"true\"&gt; &lt;bean class=\"org.springframework.http.converter. StringHttpMessageConverter\"&gt; &lt;constructor-arg value=\"UTF-8\"/&gt; &lt;/bean&gt; &lt;bean class=\"org.springframework.http.converter.json. MappingJackson2HttpMessageConverter\"&gt; &lt;property name=\"objectMapper\"&gt; &lt;bean class=\"org.springframework.http.converter.json. Jackson2ObjectMapperFactoryBean\"&gt; &lt;property name=\"failOnEmptyBeans\" value=\"false\"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; 七、RESTful参考理解RESTful架构 REST（Representational State Transfer），表现层状态转化： 每个URI代表一种资源 客户端和服务器之间传递这种资源的表现层 客户端通过四个HTTP请求方式，对服务器资源进行操作，实现“表现层状态转化”。 GET请求用来获取资源，对应查询操作 POST请求用来新建（或更新）资源，对应添加操作 PUT用来更新资源，对于修改操作 DELETE用来删除资源，对于删除操作 可以简单将RESTful理解为资源定位及资源操作的风格。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。 RESTful风格下，请求和参数值都使用/分隔开，同样的请求地址可以根据不同的请求方式，实现不同的功能： 1234http://127.0.0.1/item/1 查询,GEThttp://127.0.0.1/item/1 新增,POSThttp://127.0.0.1/item/1 更新,PUThttp://127.0.0.1/item/1 删除,DELETE 比如： 12345678910111213141516@Controllerpublic class RestFulController { @RequestMapping(value = \"/add/{a}/{b}\",method = RequestMethod.POST) public String test1(@PathVariable int a, @PathVariable int b, Model model){ int res = a+b; model.addAttribute(\"msg\",\"Result 1:\"+res); return \"restful\"; } //URL相同时，可以根据不同的请求调用不同的方法 @GetMapping(\"/add/{a}/{b}\") public String test2(@PathVariable int a, @PathVariable int b, Model model){ int res = a*b; model.addAttribute(\"msg\",\"Result 2:\"+res); return \"restful\"; }} @PathVariable用于将URI的变量和方法参数对应起来，名称要相同。 对于以上代码，URL为http://localhost:8080/SpringMVC_04/add/3/4时，如果是get请求，会调用第二个方法，结果为12；如果是post请求，调用第一个方法，结果为7。 RESTful风格的优势： 使路径变得更简洁。 获取参数更方便，框架会自动类型转换 通过路径变量的类型约束访问参数，如果类型不对应，会访问不到方法。 八、拦截器SpringMVC中的拦截器（Interceptor）类似于servlet中的过滤器（Filter），不同的是： 过滤器在任何web工程都可以使用。拦截器属于SpringMVC框架，只能在SpringMVC框架工程中使用。 过滤器通过/*可以拦截所有要访问的资源。拦截器只会拦截访问的控制器方法。 拦截器和过滤器的区别：https://www.zhihu.com/question/30212464/answer/1786967139 自定义拦截器需要实现HandlerInterceptor接口，接口中的三个默认方法，可以根据需求进行重写。 在项目中使用自定义拦截器步骤如下： 1、定义一个类实现HandlerInterceptor接口 1234567891011121314151617181920212223242526public class MyInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\"=========处理前要执行的操作=========\"); return true; //true表示放行，执行下一个拦截器 } /* postHandle和afterCompletion一般用于日志处理之类的后续工作 */ @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(\"=========处理后要执行的操作=========\"); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(\"=========清理=========\"); }} HandlerInterceptor接口有三个方法： preHandle()：请求处理前执行，返回值为true表示放行，如果有的话执行下一个拦截器。返回值为false表示不放行。常用于身份验证等需求中。 postHandle()：请求完成后执行，一般用于日志处理等后续操作。如果有多个拦截器，这个方法会按照声明顺序倒着执行。 afterCompletion()：在请求分发器视图渲染之后执行，多用于资源清理。前提是preHandle返回true 2、在SpringMVC配置文件中配置拦截器 1234567891011121314151617&lt;!-- 配置拦截器 --&gt;&lt;mvc:interceptors&gt; &lt;!-- 配置拦截所有请求的拦截器 --&gt; &lt;mvc:interceptor&gt; &lt;!-- /**表示这个请求下的所有请求，包括子请求 --&gt; &lt;mvc:mapping path=\"/**\"/&gt; &lt;!-- 指定拦截器实现类 --&gt; &lt;bean class=\"com.kang.config.MyInterceptor\"/&gt; &lt;/mvc:interceptor&gt; &lt;!-- 配置一个只拦截user下所有请求的拦截器 --&gt; &lt;mvc:interceptor&gt; &lt;!-- /**表示这个请求下的所有请求，包括子请求 --&gt; &lt;mvc:mapping path=\"/user/**\"/&gt; &lt;bean class=\"com.kang.config.LoginInterceptor\"/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 可以配置多个拦截器，满足不同的需求。 /**：当前所有文件，递归包括所有子文件夹，即包括多级目录。即所有请求，包括子请求。 /*：当前所有文件，不包括子文件夹中的内容，即只包括一级目录。即只有当前请求下的请求，不包括子请求下的请求。 使用情景举例：使用拦截器确保用户登录才能进入某个页面。当用户访问某个页面的时候，在拦截器中验证是否登陆，如果登陆，则放行；如果未登录，则请求转发或重定向到登录界面。 九、AjaxAJAX（Asynchronous JavaScript and XML）：异步的 JavaScript 和 XML，是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。 AJAX是一种用于创建更好更快以及交互性更强的Web应用程序的技术。比如搜索栏动态显示搜索建议；网页登陆时不用刷新网页就提示用户名和密码正确性。 Demo：在SpringMVC项目中，使用Ajax实现以下功能： 输入用户名后，动态检测用户名是否存在并提示；输入密码后，动态检测密码是否正确并提示。 1、先定义一个控制器类verifyUsernameAndPwd.java： 1234567891011121314151617181920212223242526/*简单起见，用户名为“admin”，密码为“123456”，模拟从数据库中查询到的结果。*/@RestControllerpublic class AjaxController { //登陆验证处理 @RequestMapping(\"/login\") public String login(String name,String pwd){ String msg = \"\"; if(name !=null){ if(\"admin\".equals(name)){ msg=\"ok\"; }else{ msg = \"用户名不存在\"; } } if(pwd!=null){ if(\"123456\".equals(pwd)){ msg=\"ok\"; }else{ msg = \"密码错误\"; } } return msg; }} 2、前端页面 我们使用jquery提供的Ajax方法实现Ajax请求。使用前需要导入Jquery的jar包，或者使用CDN。 login.jsp： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;ajax&lt;/title&gt; &lt;!-- 需要将jquery包导入 --&gt; &lt;script src=\"${pageContext.request.contextPath}/statics/js/jquery-3.1.1.min.js\"&gt;&lt;/script&gt; &lt;script&gt; //用户名框失焦事件 function verifyName(){ //通过jquery中的post方法调用ajax方法 $.post({ url:\"${pageContext.request.contextPath}/login\", data:{'name':$(\"#name\").val()}, success:function (data) { //如果返回结果为ok,提示信息为绿色,否则为红色 if (data.toString()=='OK'){ $(\"#userInfo\").css(\"color\",\"green\"); }else { $(\"#userInfo\").css(\"color\",\"red\"); } $(\"#userInfo\").html(data); } }); } //密码框失焦事件 function verifyPwd(){ $.post({ url:\"${pageContext.request.contextPath}/login\", data:{'pwd':$(\"#pwd\").val()}, success:function (data) { if (data.toString()=='OK'){ $(\"#pwdInfo\").css(\"color\",\"green\"); }else { $(\"#pwdInfo\").css(\"color\",\"red\"); } $(\"#pwdInfo\").html(data); } }); } &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; 用户名:&lt;input type=\"text\" id=\"name\" onblur=\"verifyName()\"/&gt; &lt;span id=\"userInfo\"&gt;&lt;/span&gt; &lt;/p&gt; &lt;p&gt; 密码:&lt;input type=\"text\" id=\"pwd\" onblur=\"verifyPwd()\"/&gt; &lt;span id=\"pwdInfo\"&gt;&lt;/span&gt; &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 上述JS代码中我们使用的$.post调用的是jquery中的post方法，post方法内部调用了ajax方法，我们也可以直接调用ajax方法，都可以完成Ajax请求。 Ajax方法需要关注的几个参数： url：请求地址。 type：请求方式，比如get、post（1.9.0之后用method）。 data：要发送的数据。 ontentType：发送信息至服务器的内容编码类型。 success：成功之后的回调函数。 在上述的Demo中，url就是login请求地址，data就是当前输入框里的内容，success回调函数的功能定义为显示提示信息，比如用户名是否存在、密码是否正确。 十、文件上传与下载Spring MVC为文件上传提供了直接的支持，这种支持是通过即插即用的MultipartResolver实现的。 Spring MVC使用Apache Commons FileUpload实现了一个MultipartResolver的实现类CommonsMultipartResolver。因此，SpringMVC的文件上传还需要依赖Apache Commons FileUpload的组件。 导入文件上传需要的依赖： 123456&lt;!--文件上传--&gt;&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.3&lt;/version&gt;&lt;/dependency&gt; 10.1 文件上传文件上传需要确保导入了commons-fileupload依赖。 1、配置bean 12345678&lt;!-- 配置CommonsMultipartResolver --&gt;&lt;!--这个bean的id必须为：multipartResolver--&gt;&lt;bean id=\"multipartResolver\" class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\"&gt; &lt;property name=\"defaultEncoding\" value=\"utf-8\"/&gt; &lt;!-- 根据需求确定是否配置上传文件大小限制，单位为字节(10485760=10M)--&gt; &lt;property name=\"maxUploadSize\" value=\"10485760\"/&gt; &lt;property name=\"maxInMemorySize\" value=\"40960\"/&gt;&lt;/bean&gt; 其中defaultEncoding表示请求的编码格式，必须和JSP的pageEncoding属性一致，以便正确读取表单的内容，默认为ISO-8859-1. CommonsMultipartFile类中的常用方法： String getOriginalFilename()：获取上传文件的原名 InputStream getInputStream()：获取文件流 void transferTo(File dest)：将上传文件保存到一个目录文件中 2、前端页面 12345&lt;!-- 上传文件的编码必须是multipart/form-data --&gt;&lt;form action=\"/upload\" enctype=\"multipart/form-data\" method=\"post\"&gt; &lt;input type=\"file\" name=\"file\"/&gt; &lt;input type=\"submit\" value=\"upload\"&gt;&lt;/form&gt; 3、控制器实现功能 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@RestControllerpublic class FileController { //@RequestParam(\"file\") 将name=file控件得到的文件封装成CommonsMultipartFile对象 //批量上传CommonsMultipartFile则为数组即可 @RequestMapping(\"/upload\") public String fileUpload(@RequestParam(\"file\") CommonsMultipartFile file, HttpServletRequest request) throws IOException { //获取文件名 : file.getOriginalFilename(); String uploadFileName = file.getOriginalFilename(); //如果文件名为空，直接回到首页 if (\"\".equals(uploadFileName)) { return \"redirect:/index.jsp\"; } System.out.println(\"上传文件名 : \" + uploadFileName); //上传路径保存设置 String path = request.getServletContext().getRealPath(\"/upload\"); //如果路径不存在，创建一个 File realPath = new File(path); if (!realPath.exists()) { realPath.mkdir(); } System.out.println(\"上传文件保存地址：\" + realPath); InputStream is = file.getInputStream(); //文件输入流 OutputStream os = new FileOutputStream( new File(realPath, uploadFileName)); //文件输出流 //读取写出 int len = 0; byte[] buffer = new byte[1024]; while ((len = is.read(buffer)) != -1) { os.write(buffer, 0, len); os.flush(); } os.close(); is.close(); return \"redirect:/index.jsp\"; } /* * 方式二：采用file.Transto 来保存上传的文件 */ @RequestMapping(\"/upload2\") public String fileUpload2(@RequestParam(\"file\") CommonsMultipartFile file, HttpServletRequest request) throws IOException { //上传路径保存设置 String path = request.getServletContext().getRealPath(\"/upload\"); File realPath = new File(path); if (!realPath.exists()){ realPath.mkdir(); } //上传文件地址 System.out.println(\"上传文件保存地址：\"+realPath); //通过CommonsMultipartFile的方法直接写文件 file.transferTo(new File(realPath +\"/\"+ file.getOriginalFilename())); return \"redirect:/index.jsp\"; }} 10.2 文件下载文件下载步骤： 设 response响应头 读取文件 — InputStream 写出文件 — OutputStream 执行操作 关闭流 （先开的后关） 1、编写控制器类 1234567891011121314151617181920212223242526272829303132333435@RestControllerpublic class FileController { @RequestMapping(value=\"/download\") public String downloads(HttpServletResponse response, HttpServletRequest request) throws Exception{ //要下载的文件地址 String path = request.getServletContext().getRealPath(\"/upload\"); String fileName = \"test.txt\"; //1、设置response 响应头 response.reset(); //设置页面不缓存,清空buffer response.setCharacterEncoding(\"UTF-8\"); //字符编码 response.setContentType(\"multipart/form-data\"); //二进制传输数据 //设置响应头 response.setHeader(\"Content-Disposition\", \"attachment;fileName=\"+ URLEncoder.encode(fileName, \"UTF-8\")); File file = new File(path,fileName); //2、 读取文件--输入流 InputStream input=new FileInputStream(file); //3、 写出文件--输出流 OutputStream out = response.getOutputStream(); byte[] buff =new byte[1024]; int index=0; //4、执行 写出操作 while((index= input.read(buff))!= -1){ out.write(buff, 0, index); out.flush(); } out.close(); input.close(); return null; }} 2、前端页面 1&lt;a href=\"/download\"&gt;点击下载&lt;/a&gt; 参考1、b站-SpringMVC 2、Spring常见问题","categories":[{"name":"SSM框架","slug":"SSM框架","permalink":"http://kangshitao.github.io/categories/SSM%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"http://kangshitao.github.io/tags/SSM/"},{"name":"SprinMVC","slug":"SprinMVC","permalink":"http://kangshitao.github.io/tags/SprinMVC/"}]},{"title":"Spring5配置与使用","slug":"spring-basis","date":"2021-06-27T12:06:31.000Z","updated":"2022-05-22T13:30:54.803Z","comments":true,"path":"2021/06/27/spring-basis/","link":"","permalink":"http://kangshitao.github.io/2021/06/27/spring-basis/","excerpt":"IOC容器，依赖注入，Bean自动装配，动态代理与AOP，声明式事务，Spring与MyBatis整合","text":"一、Spring简介1.1 什么是Spring？Spring 是一种轻量级开发框架（或者说是一种容器），旨在提高开发人员的开发效率以及系统的可维护性。Spring 官网：https://spring.io/ 我们一般说 Spring 框架指的都是 Spring Framework，它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发。这些模块是：核心容器、数据访问/集成,、Web、AOP（面向切面编程）、工具、消息和测试模块。比如：Core Container 中的 Core 组件是Spring 所有组件的核心，Beans 组件和 Context 组件是实现IOC和依赖注入的基础，AOP组件用来实现面向切面编程。 Spring 官网列出的 Spring 的 6 个特征: 核心技术 ：依赖注入(DI)，AOP，事件(events)，资源，i18n，验证，数据绑定，类型转换，SpEL。 测试 ：模拟对象，TestContext框架，Spring MVC 测试，WebTestClient。 数据访问 ：事务，DAO支持，JDBC，ORM，编组XML。 Web支持 : Spring MVC和Spring WebFlux Web框架。 集成 ：远程处理，JMS，JCA，JMX，电子邮件，任务，调度，缓存。 语言 ：Kotlin，Groovy，动态语言。 Spring是一个轻量级的IOC和AOP的框架。 1.2 Spring的组成下图对应的是 Spring4.x 版本。目前最新的5.x版本中 Web 模块的 Portlet 组件已经被废弃掉，同时增加了用于异步响应式处理的 WebFlux 组件。 Spring主要模块 Spring Core： 基础，可以说 Spring 其他所有的功能都需要依赖于该类库。主要提供 IoC 依赖注入功能。 Spring Aspects ： 该模块为与AspectJ的集成提供支持。 Spring AOP ：提供了面向切面的编程实现。 Spring JDBC : Java数据库连接。 Spring JMS ：Java消息服务。 Spring ORM : 用于支持Hibernate等ORM工具。 Spring Web : 为创建Web应用程序提供支持。 Spring Test : 提供了对 JUnit 和 TestNG 测试的支持。 1.3 Spring的优点 Spring是一个开源免费的框架(容器) Spring是一个轻量级的、非入侵式的框架（AOP是非入侵式的，不需要对原有的代码进行修改） 控制反转(Inversion of Control ,IoC)，面向切面编程(Aspect-Oriented Programming，AOP) 支持声明式事务。 1.4 Spring弊端Spring经过长时间的发展，配置十分繁琐，人称”配置地狱”。 直到SpringBoot的出现，解决了这一问题。SpringBoot是一个快速开发的脚手架。 二、IOC控制反转loC(Inversion of Control)，是一种设计思想，DI(依赖注入)是实现loC的一种方法，也有人认为DI只是loC的另一种说法。没有loC的程序中，我们使用面向对象编程，对象的创建与对象间的依赖关系完全硬编码在程序中，对象的创建由程序自己控制，控制反转后将对象的创建转移给第三方，个人认为控制反转就是：获得依赖对象的方式反转了。简而言之就是，对象由Spring创建、管理和装配。 IOC是Spring的核心内容，IOC可以有多种方式实现，比如XML配置，注解，甚至可以零配置实现IOC。 采用XML方式配置Bean的时候，Bean的定义信息是和实现分离的，而采用注解的方式可以把两者合为一体，Bean的定义信息直接以注解的形式定义在实现类中，从而达到了零配置的目的。 控制反转是一种通过描述(XML或注解）并通过第三方去生产或获取特定对象的方式。在Spring中实现控制反转的是loC容器，其实现方法是依赖注入(Dependency Injection,Dl) ，控制反转是一种思想，依赖注入是一种具体实现方式。 2.1 IOC基础以传统的项目为例，假设现在有以下程序： DAO层：UserDao接口；接口的实现类UserDaoImpl Service层：UserService接口；接口的实现类UserServiceImpl 在UserServiceImpl中，有这样的代码： 1234567public class UserServiceImpl implements UserService{ private UserDao userDao = new UserDaoImpl(); @Override public void getUser() { userDao.getUser(); }} UserServiceImpl中通过创建UserDaoImpl对象，完成相应的功能。 Controller层的程序，通过创建UserServiceImpl对象并调用方法完成功能。 12UserService userService = new UserServiceImpl();//然后通过UserService调用方法完成功能 如果现在有第二个UserDao接口的实现类UserDaoImpl2，此时如果想要使用UserDaoImpl2中的方法，必须修改UserServiceImpl中的代码： 1private UserDao userDao = new UserDaoImpl2(); 如果实现类有很多，就需要大量修改底层代码。 如何修改代码使得程序能够自动适应不同的需求呢？可以在UserServiceImpl中添加一个set方法，代替手动new的方式： 123456789101112131415public class UserServiceImpl implements UserService{ private UserDao userDao; //private UserDao userDao = new UserDaoImpl(); //利用set方法,动态实现值的注入 //程序由主动创建对象，变为了被动接收对象。这就是控制反转的思想（IOC） public void setUserDao(UserDao userDao) { this.userDao = userDao; } @Override public void getUser() { userDao.getUser(); }} 这样，只要传入不同的UserDao的实现类，就能完成不同的功能。程序由主动创建对象，变为了被动接收对象。这就是IOC思想的原型。 主动权由原来的业务层(service)，变为了用户层。 2.2 使用IOC创建对象使用Spring的IOC容器，创建并获取对象的基本流程如下，以创建一个HelloSpring程序为例。 1、首先创建POJO类，Hello.java： 1234567public class Hello { private String str; public String getStr() { return str; } ...//} 2、然后创建applicationContext.xml配置文件： 1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- id相当于变量名，根据此id获取对象 class是全限类名，表示获取的是哪个类的对象 property用于设置（注入）对象中属性的值,这里的name必须和属性名相同 --&gt; &lt;bean id=\"hello\" class=\"com.kang.pojo.Hello\"&gt; &lt;property name=\"str\" value=\"Spring\"/&gt; &lt;/bean&gt; &lt;!-- more bean definitions go here --&gt;&lt;/beans&gt; 顾名思义，&lt;bean&gt;标签的class必须是非抽象类，即能够实例化的类，不能是接口和抽象类。因为Spring要实例化这些类。 3、最后实例化容器，并获取对象： 12345678public static void main(String[] args) { //实例化容器，获取Spring的上下文对象 ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); //对象现在都在Spring容器中管理了，使用getBean方法从容器里取对象 Hello hello = context.getBean(\"hello\",Hello.class); System.out.println(hello.toString());}//以上代码打印结果为：Hello{str='Spring'} 在配置文件中注册的bean，当实例化容器的时候，都会生成一个对象保存到容器中，然后使用getBean()方法获取指定的对象实例。 多次获取同一个id的对象，默认是单例模式，得到的都是同一个对象。 ApplicationContext是Spring的一个核心接口（或容器），允许容器通过应用程序上下文环境创建、获取、管理bean，是为应用程序提供配置的中央接口。其有多个实现类，根据不同的使用方式需要实例化不同类型的容器。 上述例子是使用Spring的一个简单案例，从中我们可以得出： hello对象是由Spring创建的，而不是我们手动创建的（使用&lt;bean&gt;) hello对象的属性是由Spring容器设置的（使用&lt;property&gt;） 这个过程就是控制反转。 2.3 IOC创建对象的方式1、如果不显式指定使用有参构造器，IOC默认使用无参构造器创建对象。 使用无参构造器的前提是bean类中必须有无参构造器。 2、如果想要使用有参构造器创建对象，有以下几种方式传参： a. 通过索引为参数赋值，创建对象 1234&lt;!-- 索引从0开始 --&gt;&lt;bean id=\"user\" class=\"com.kang.pojo.User\"&gt; &lt;constructor-arg index=\"0\" value=\"usernamevalue\"/&gt; &lt;/bean&gt; 这里的索引从”0”开始。 b. 通过类型为参数赋值，创建对象 123&lt;bean id=\"user\" class=\"com.kang.pojo.User\"&gt; &lt;constructor-arg type=\"java.lang.String\" value=\"usernamevalue\"/&gt;&lt;/bean&gt; 要想使用这种方法，必须保证各个参数可以通过类型区分开。基本类型可以直接用，引用类型必须使用全限类名。 c. 通过参数名称赋值，创建对象 123&lt;bean id=\"user\" class=\"com.kang.pojo.User\"&gt; &lt;constructor-arg name=\"name\" value=\"usernamevalue\"/&gt;&lt;/bean&gt; d. 通过引用赋值，创建对象。 123456package x.y;public class ThingOne { public ThingOne(ThingTwo thingTwo, ThingThree thingThree) { // ... }} 对应的配置文件： 12345678&lt;beans&gt; &lt;bean id=\"thingOne\" class=\"x.y.ThingOne\"&gt; &lt;constructor-arg ref=\"thingTwo\"/&gt; &lt;constructor-arg ref=\"thingThree\"/&gt; &lt;/bean&gt; &lt;bean id=\"thingTwo\" class=\"x.y.ThingTwo\"/&gt; &lt;bean id=\"thingThree\" class=\"x.y.ThingThree\"/&gt;&lt;/beans&gt; 三、Spring配置文件详解下面介绍Spring核心配置文件中的常用标签，后面的使用到再介绍。 3.1 alias&lt;alias起别名，比如： 12345&lt;bean id=\"user\" class=\"com.kang.pojo.User\"&gt; &lt;constructor-arg name=\"name\" value=\"kangkang\"/&gt;&lt;/bean&gt;&lt;!--给user起别名，和直接通过id获取效果是一样的--&gt;&lt;alias name=\"user\" alias=\"userAlias\"/&gt; 其中在&lt;bean&gt;标签中的name属性也能够为对象起别名： 1234&lt;!-- 通过name属性起别名，可以同时起多个别名，用逗号隔开 --&gt;&lt;bean id=\"user\" class=\"com.kang.pojo.User\" name=\"user2,user3\"&gt; &lt;constructor-arg name=\"name\" value=\"kangkang\"/&gt;&lt;/bean&gt; 3.2 BeanSpring中将需要实例化的类使用&lt;bean&gt;注册为容器中的bean： 123&lt;bean id=\"user\" class=\"com.kang.pojo.User\" name=\"user2,user3\"&gt; &lt;constructor-arg name=\"name\" value=\"kangkang\"/&gt;&lt;/bean&gt; 其中常用的变量有： id: bean的唯一标识，相当于对象名。 class：bean对象所对应的全限类名，包名+类名。必须是普通的类，不能是抽象类或者接口，因为容器要创建对象，抽象类和接口无法创建对象。 name：可以省略。也是别名，并且可以同时取多个别名，可以空格或,分隔。通过这些别名获取对象时，得到的都是同一个对象。 scope：指定该bean的作用域，官方给定了六种作用域，比如prototype/sigleton等，具体参考下文内容。 autowire：用于指定自动装配的方式，具体参考下文内容。 如果使用property对属性进行配置，其中有两个用于赋值的参数需要注意： value：表示一个字符串，当参数类型为String时需要使用value进行赋值。 ref：传递一个引用类型的变量，当参数的类型为引用类型时，必须使用ref进行传值。 3.3 importimport一般用于团队开发，用于将多个配置文件导入合并在一起。 假设有一个总配置文件applicationContext.xml，每个开发人员都有自己的一个配置文件，则可以在总配置文件中将各个配置文件导入，合并为一个配置文件。这样在实例化容器时，只需要传入总配置文件，就可以创建导入的所有配置文件中的bean对象。 总配置文件applicationContext.xml引入多个配置文件： 123&lt;import resource=\"beans1.xml\"/&gt;&lt;import resource=\"beans2.xml\"/&gt;&lt;import resource=\"beans3.xml\"/&gt; 实例化容器： 1ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); 如果不同配置文件中，存在相同id的bean对象，则会根据导入的顺序依次进行覆盖，以最后一个为准。 四、依赖注入依赖注入(Dependency Injection，DI)是一个过程，通过该过程，对象只能通过构造函数参数，工厂方法的参数或在构造或创建对象实例后在对象实例上设置的属性来定义其依赖关系（即其需要的其他对象），从工厂方法返回。然后，容器在创建 bean 时注入那些依赖项。从根本上讲，此过程是通过使用类的构造器或服务定位器模式来自己控制其依赖关系的实例化或位置的 Bean 本身的逆过程（因此称为控制反转）。 依赖注入使得代码更简洁，当为对象提供依赖项时，去耦会更有效。该对象不查找其依赖项，也不知道依赖项的位置或类。 DI主要有两种方式：基于构造器的依赖注入和基于Setter的依赖注入。 4.1 构造器注入使用构造器实现依赖注入，可以参考前面2.1中IOC创建对象的例子。 1、基于无参构造器的依赖注入，是在调用无参数构造函数或无参数static工厂方法以实例化 bean 之后，然后在bean上调用 set 方法来给属性赋值。 比如： 1234&lt;!-- 通过反射调用无参构造器创建对象，然后调用set方法为name属性赋值 --&gt;&lt;bean id=\"student\" class=\"com.kang.pojo.Student\"&gt; &lt;property name=\"name\" value=\"Jack\"/&gt;&lt;/bean&gt; 这种方式要求类中必须有对应的setXxx()方法 2、基于有参构造器的依赖注入，通过有参构造器给属性赋值。 主要是在&lt;bean&gt;中使用&lt;constructor-arg&gt;标签表示使用有参构造器。 a. 通过索引为参数赋值，创建对象。 这里的索引从”0”开始。 b. 通过类型为参数赋值，创建对象。 要想使用这种方法，必须保证各个参数可以通过类型区分开。基本类型可以直接用，引用类型必须使用全限类名。 通过参数名称赋值，创建对象。 123&lt;bean id=\"user\" class=\"com.kang.pojo.User\"&gt; &lt;constructor-arg name=\"name\" value=\"usernamevalue\"/&gt;&lt;/bean&gt; 通过引用赋值，创建对象。 12345678&lt;beans&gt; &lt;bean id=\"thingOne\" class=\"x.y.ThingOne\"&gt; &lt;constructor-arg ref=\"thingTwo\"/&gt; &lt;constructor-arg ref=\"thingThree\"/&gt; &lt;/bean&gt; &lt;bean id=\"thingTwo\" class=\"x.y.ThingTwo\"/&gt; &lt;bean id=\"thingThree\" class=\"x.y.ThingThree\"/&gt;&lt;/beans&gt; 4.2 通过Setter方式注入通过setter方式注入，也就是通过无参构造器创建对象后，调用set方法注入，因此使用setter方式注入，要求bean中必须要有set方法和一个无参构造器。 使用Setter方式注入： 123&lt;property name=\"id\" value=\"1\"/&gt;&lt;property name=\"name\" value=\"Java\" /&gt;&lt;property name=\"age\" value=\"18\" /&gt; 复杂类型的依赖注入 举例： 1、定义类Address： 1234567891011121314public class Address { private String address; public String getAddress() {return address;} public void setAddress(String address) {this.address = address;} @Override public String toString() { return \"Address{\" + \"address='\" + address + '\\'' + '}'; }} 2、实体类Student： 1234567891011public class Student { private String name; private Address address; private String[] books; private List&lt;String&gt; hobbies; private Map&lt;String,String&gt; card; private Set&lt;String&gt; games; private Properties info; private String wife; ...//} 3、applicationContext.xml配置文件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"address\" class=\"com.kang.pojo.Address\"&gt; &lt;property name=\"address\" value=\"xx省xx市xx区\"/&gt; &lt;/bean&gt; &lt;bean id=\"student\" class=\"com.kang.pojo.Student\"&gt; &lt;!-- 1、普通值注入 --&gt; &lt;property name=\"name\" value=\"kangst\"/&gt; &lt;!--另一种写法--&gt; &lt;!-- &lt;property name=\"name\"&gt;--&gt; &lt;!-- &lt;value&gt;kangst&lt;/value&gt;--&gt; &lt;!-- &lt;/property&gt;--&gt; &lt;!-- 2、Bean注入 --&gt; &lt;property name=\"address\" ref=\"address\"/&gt; &lt;!--另一种写法--&gt; &lt;!-- &lt;property name=\"address\"&gt;--&gt; &lt;!-- &lt;ref bean=\"address\"/&gt;--&gt; &lt;!-- &lt;/property&gt;--&gt; &lt;!-- 3、数组注入 --&gt; &lt;property name=\"books\"&gt; &lt;array&gt; &lt;value&gt;红楼梦&lt;/value&gt; &lt;value&gt;西游记&lt;/value&gt; &lt;value&gt;三国演义&lt;/value&gt; &lt;value&gt;水浒传&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;!-- 4、list注入 --&gt; &lt;property name=\"hobbies\"&gt; &lt;list&gt; &lt;value&gt;hobby1&lt;/value&gt; &lt;value&gt;hobby2&lt;/value&gt; &lt;value&gt;hobby3&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 5、map注入 --&gt; &lt;property name=\"card\"&gt; &lt;map&gt; &lt;entry key=\"身份证\" value=\"12345678\"/&gt; &lt;entry key=\"银行卡\" value=\"6345112384034\"/&gt; &lt;/map&gt; &lt;/property&gt; &lt;!-- 6、set注入 --&gt; &lt;property name=\"games\"&gt; &lt;set&gt; &lt;value&gt;Game1&lt;/value&gt; &lt;value&gt;Game2&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; &lt;!-- 7、Properties注入 --&gt; &lt;property name=\"info\"&gt; &lt;props&gt; &lt;prop key=\"username\"&gt;root&lt;/prop&gt; &lt;prop key=\"password\"&gt;123456&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;!-- 8、null值注入 (和空串不同,空串直接赋值为\"\"即可)--&gt; &lt;property name=\"wife\"&gt; &lt;null/&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 4、测试 123456789101112131415public void test1(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); Student student = (Student) context.getBean(\"student\"); System.out.println(student.toString()); /*输出结果 Student{name='kangst', address=Address{address='xx省xx市xx区'}, books=[红楼梦, 西游记, 三国演义, 水浒传], hobbies=[hobby1, hobby2, hobby3], card={身份证=12345678, 银行卡=6345112384034}, games=[Game1, Game2], info={password=123456, username=root}, wife='null'} */} 4.3 其他方式注入p-命名空间p表示properties，允许使用bean元素的属性(而不是嵌套的&lt;property&gt;元素)来声明 Bean的属性值，或同时使用这两者。 要求类中必须有setXxx()方法。 如下，可以同时使用p-命名空间和&lt;property&gt;两种方式。 1234567891011&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:p=\"http://www.springframework.org/schema/p\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--p-命名方式和传统方式结合使用--&gt; &lt;bean id=\"user\" class=\"com.kang.pojo.User\" p:name=\"用户名\"&gt; &lt;property name=\"age\" value=\"20\"/&gt; &lt;/bean&gt;&lt;/beans&gt; 注意，使用p-命名空间时，需要导入xmlns:p=\"http://www.springframework.org/schema/p\"约束 c-命名空间c表示constructor，构造器。表示使用有参构造器注入属性值。要求类中必须有有参构造器。 123456789101112131415161718192021&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:c=\"http://www.springframework.org/schema/c\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"beanTwo\" class=\"x.y.ThingTwo\"/&gt; &lt;bean id=\"beanThree\" class=\"x.y.ThingThree\"/&gt; &lt;!-- 传统使用构造器的声明方式 --&gt; &lt;bean id=\"beanOne\" class=\"x.y.ThingOne\"&gt; &lt;constructor-arg name=\"thingTwo\" ref=\"beanTwo\"/&gt; &lt;constructor-arg name=\"thingThree\" ref=\"beanThree\"/&gt; &lt;constructor-arg name=\"email\" value=\"something@somewhere.com\"/&gt; &lt;/bean&gt; &lt;!-- c-命名空间声明方式 --&gt; &lt;bean id=\"beanOne\" class=\"x.y.ThingOne\" c:thingTwo-ref=\"beanTwo\" c:thingThree-ref=\"beanThree\" c:email=\"something@somewhere.com\"/&gt;&lt;/beans&gt; 同样，需要导入xmlns:c=\"http://www.springframework.org/schema/c\"约束 4.4 理解IOC和DIIOC：当某个角色(比如一个Java实例，调用者)需要另一个角色(另一个Java实例，被调用者)的协助时，在 传统的程序设计过程中，通常由调用者来创建被调用者的实例。但在Spring里，创建被调用者的工作不再由调用者来完成，因此称为控制反转 DI：创建被调用者实例的工作通常由Spring容器来完成，然后注入调用者，这个操作称为依赖注入。 控制反转是一种思想，依赖注入是实现IOC的一种行为。 控制反转（IOC） 传统程序中，我们在类内部通过new的方式，主动创建其依赖对象，导致类和类之间高耦合。在Spring中，将创建和查找依赖对象的控制权交给了IOC容器，由容器负责控制对象的创建和注入组合对象，程序想要什么资源必须从容器中获取，即对资源的控制权转变了，这就是控制反转。IOC有效降低了耦合性。 谁控制谁？ IOC容器控制对象； 控制什么？ 控制了外部资源的获取（比如依赖对象，文件资源等） 为何是反转？ 传统应用程序是由我们自己在对象中主动控制去直接获取依赖对象，也就是正转；而反转则是由容器来帮忙创建及注入依赖对象；因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转； 哪些方面反转了？ 依赖对象的获取被反转了。 举个例子？ 比如用户类需要依赖用户信息类，传统做法是程序（比如客户端类）创建用户类和用户信息类，然后将用户信息类主动注入得到用户类。而在Spring中，使用IOC容器，IOC容器创建用户类，发现用户类需要有依赖对象注入，然后创建用户信息类，并将其注入到用户类。此时的客户端类直接从容器中获取用户类即可。 依赖注入 组件之间的依赖关系由容器在运行期决定，即由容器动态的将某个依赖关系注入到组件中。即动态的向某个对象提供它所需要的其他对象。 谁注入谁？ IOC容器注入将对象所依赖的对象或资源注入到这个对象中。 注入什么？ 注入某个对象所需要的外部资源，或者说是属性，比如对象、资源、常量数据等。 五、Bean作用域与生命周期5.1 Bean 作用域Bean Scope（Bean作用域），即Bean对象的作用范围。Spring官方规定了Bean的六种作用域。 1、singleton，单例模式（默认）： 1&lt;bean id=\"user\" class=\"com.kang.pojo.User\" scope=\"singleton\"/&gt; ​ IOC容器仅创建一个Bean实例，并且IOC容器每次返回的都是同一个Bean实例，singleton是默认的作用域。 2、prototype，原型模式： 1&lt;bean id=\"user\" class=\"com.kang.pojo.User\" scope=\"prototype\"/&gt; ​ IOC容器可以创建多个Bean实例，每次返回的都是一个新的实例。 3、request ​ 仅对HTTP请求产生作用，每次HTTP请求都会创建一个自己的Bean。 4、session ​ 每个Session中只有一个共享的Bean实例。不同Session使用不同的实例。 5、application ​ 作用域为整个web应用，即ServletContext 6、websocket ​ 作用域为WebSocket 其中后四种仅在web应用中有效。 Spring还支持自定义范围。 5.2 Spring 中的单例 bean 的线程安全问题当多个线程操作同一个对象的时候，对这个对象的成员变量的写操作会存在线程安全问题。 但是，一般情况下，我们常用的 Controller、Service、Dao 这些 Bean 是无状态的。无状态的 Bean 不能保存数据，因此是线程安全的。 无状态的bean只有普通的对数据的操作方法，没有数据存储的功能，比如UserDao 有状态的bean具有数据存储功能，比如User 常见的有两种解决办法： 在类中定义一个 ThreadLocal 成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。 改变Bean的作用域为 prototype，保证每次请求都会创建一个新的 bean 实例，避免线程安全问题。 5.3 Bean的生命周期简单来说，Bean的生命周期有四个阶段： 实例化：容器通过获取BeanDefinition对象中的信息进行实例化，仅仅是简单的实例化，并未进行依赖注入。 对于BeanFactory容器，当客户向容器请求一个尚未初始化的bean时，或初始化bean的时候需要注入另一个尚未初始化的依赖时，容器就会调用createBean进行实例化。 对于ApplicationContext容器，当容器启动结束后，便实例化所有的bean。 实例化对象被包装在BeanWrapper对象中（可以认为是Bean的原生态） 属性赋值：也就是依赖注入的过程。Spring根据BeanDefinition中的信息，通过populateBean()方法为属性赋值。 初始化：比如 如果实现了BeanNameAware接口，就调用它的setBeanName()方法，传入Bean的名字。 如果实现了其他的*Aware接口，同样调用其方法。 如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessBeforeInitialization() 方法 如果Bean实现了InitializingBean接口，执行afterPropertiesSet()方法。 如果 Bean 在配置文件中的定义包含init-method 属性，执行指定的方法。 如果有和加载这个 Bean的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessAfterInitialization() 方法 销毁：容器关闭时销毁bean。销毁时，如果实现了DisposableBean接口，就执行destroy()方法，如果配置文件中包含destroy-method属性，就调用指定方法。 Bean声明周期 这里涉及到了两个主要的接口： BeanPostProcessor接口，自定义处理，该接口提供了两个方法，即前置处理和后置处理方法。这个接口可以影响多个Bean。 *Aware相关接口，只会调用一次。主要是用于从Spring容器中拿到一些资源，增强Bean的能力。 详细内容参考Bean的生命周期、Spring中的bean生命周期是怎样的 六、Bean的自动装配6.1 介绍自动装配是Spring满足bean依赖的一种方式，自动装配就是实现对Java类属性的自动注入，也就是说为当前类中的类型为bean的属性自动注入值。 Spring会在上下文中自动寻找，并自动给bean装配属性。 Spring中bean的三种装配方式： xml中手动配置。（第四节依赖注入，使用ref） java中使用注解显式配置。 隐式自动装配。 本章使用到的测试类：Person类、Dog类、Cat类。 12345678910111213//Person类public class Person { private Cat cat; private Dog dog; private String name; ...//}//Dog类public class Dog {}//Cat类public class Cat {} 首先看一下xml手动装配时的配置： 12345678&lt;bean id=\"cat\" class=\"com.kang.pojo.Cat\"/&gt;&lt;bean id=\"dog\" class=\"com.kang.pojo.Dog\"/&gt;&lt;bean id=\"person\" class=\"com.kang.pojo.Person\"&gt; &lt;property name=\"name\" value=\"kang\"/&gt; &lt;property name=\"dog\" ref=\"dog\"/&gt; &lt;property name=\"cat\" ref=\"cat\"/&gt;&lt;/bean&gt; 以上通过ref为Dog类型和Cat类型属性注入值的方式称为手动装配。 对bean类型的属性注入需要使用ref手动注入，他们的代码是相似的，有没有可能将这些相似的代码精简掉呢？这就需要使用bean的自动装配功能了。 bean的自动装配有两种方式，一种是在xml中配置（组件扫描），另一种是在Java代码中使用注解（比如@Autowired）。 这两种方式具体使用哪一种需要视情况而定(“it depends”)，二者各有优缺点。使用注解更简洁，但会造成配置分散难以控制；使用XML配置的方式不需要在源代码上改动，但配置代码繁琐。 两种方式可以同时使用，要注意的是，注解注入会在XML注入之前执行，XML注入会覆盖@Autowired注解已经注入的内容。 6.2 使用xml自动装配xml中的自动装配使用的参数为autowire，有以下5种类型，其中常用的是byName和byType： byName·：在应用上下文中自动查找和自己对象的set方法后的值对应的bean id。比如setDog()，会自动将Dog的首字母变为小写，查找id为dog的bean。 只有命名符合驼峰命名规范的才会将首字母小写然后匹配，如果不符合规范，则会直接匹配，比如setDOG()，会去查找id为DOG的bean 123456&lt;!-- byName，通过set方法的方法名查找bean的id，为属性注入值 --&gt;&lt;bean id=\"cat\" class=\"com.kang.pojo.Cat\"/&gt;&lt;bean id=\"dog\" class=\"com.kang.pojo.Dog\"/&gt;&lt;bean id=\"person\" class=\"com.kang.pojo.Person\" autowire=\"byName\"&gt; &lt;property name=\"name\" value=\"kang\"/&gt;&lt;/bean&gt; 这种方法要求bean的id唯一，并且bean应该和自动注入的属性的set方法的值（set方法名）一致。 byType：在容器上下文中自动查找和自己对象属性类型相同的bean。 123456&lt;!-- 使用byType的方式，会自动查找和属性类型对应的bean并注入。 --&gt;&lt;bean id=\"cat\" class=\"com.kang.pojo.Cat\"/&gt;&lt;bean id=\"dog\" class=\"com.kang.pojo.Dog\"/&gt;&lt;bean id=\"person\" class=\"com.kang.pojo.Person\" autowire=\"byTpye\"&gt; &lt;property name=\"name\" value=\"kang\"/&gt;&lt;/bean&gt; 这种方式要求所有bean类型必须唯一，并且该bean应该和自动注入的属性的类型一致。 constructor：根据构造方法的参数的数据类型，进行byType模式的自动装配。 default：由上级标签&lt;beans&gt;的default-autowire属性确定。 no：默认情况。即不使用自动装配。 6.3 通过注解自动装配JDK 5.0开始支持注解，Spring 2.5开始支持注解。使用注解注入不需要set方法 使用注解前，需要在配置文件中导入约束并配置注解支持： 1234567891011&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;context:annotation-config/&gt;&lt;/beans&gt; 和自动装配相关的注解有三个，分别是@Autowired、@Qualifier、@Resource 。其中@Autowired和@Qualifier是Spring中的注解，@Resource 是Java中的注解。 1、@Autowired 默认按类型匹配（byType），如果找不到则报错，如果有多个，则通过属性名找，如果通过名字也无法找到则报错。 例如，一个接口如果有多个实现类，按仅按照类型查找会找到多个结果，Spring不知道使用哪一个，这时必须使用byName的方式，可以结合使用@Autowired和@Qualifier两种注解完成注入。也可以单独使用@Resource注解。 默认情况下要求依赖对象必须存在，如果要允许null值，可以设置这个注解的required属性为false，即@Autowired(required = false) 使用@Nullable注解，也能表示属性值可以为null。 可以用于构造方法、set方法、普通方法、字段上。 @Autowired注解进行注入的方式，是不通过set方法进行注入的，因此set方法可以省略。 @Autowired是三种注解中比较常用的。 2、@Qualifier 按名称注入（byName），即在容器中查找和指定value值相同id的bean。 3、@Resource 是Java的注解。可以通过 byName 和 byType的方式注入， 默认先按 byName的方式进行匹配，如果匹配不到，再按 byType的方式进行匹配。 通过几个例子理解一下，这三个注解的用法。 情况1、通过类型可以唯一确定bean，可以忽略名字，装配(注入)成功： Person类中的注解情况： 123456789public class Person { @Autowired private Cat cat; @Autowired private Dog dog; private String name; ...} xml中的&lt;bean&gt;: 123&lt;bean id=\"cat2\" class=\"com.kang.pojo.Cat\"/&gt;&lt;bean id=\"dog2\" class=\"com.kang.pojo.Dog\"/&gt;&lt;bean id=\"person\" class=\"com.kang.pojo.Person\"/&gt; 上述情况下，可以通过类型唯一确定bean，因此可以注入成功。此时将id为cat2和id为dog2的bean分别注入到Person类的cat和dog属性中。 情况2、查找出多个类型，但可以通过名称找到唯一的值，也能注入成功。 Person： 123456789public class Person { @Autowired private Cat cat; @Autowired private Dog dog; private String name; ...} xml中的&lt;bean&gt;: 12345&lt;!-- 将id为cat的bean注入到Person中，因为按名字查找，和属性名cat匹配 --&gt;&lt;bean id=\"cat\" class=\"com.kang.pojo.Cat\"/&gt; &lt;bean id=\"cat2\" class=\"com.kang.pojo.Cat\"/&gt;&lt;bean id=\"dog\" class=\"com.kang.pojo.Dog\"/&gt;&lt;bean id=\"person\" class=\"com.kang.pojo.Person\"/&gt; 观察上述情况，对于Cat类型，通过byType的方式可以找到两个bean，然后再通过byName的方式，查找和属性名(Person中的属性名为cat)相同的id，可以找到id为cat的&lt;bean&gt;，因此也可以注入成功。 情况3、查找出多个类型，通过byName的方式也没找到，则注入失败。 Person： 123456789public class Person { @Autowired private Cat cat; @Autowired private Dog dog; private String name; ...} xml中的&lt;bean&gt;: 12345&lt;!-- 有两个Cat类型的bean，根据变量名cat找不到对应id的bean --&gt;&lt;bean id=\"cat1\" class=\"com.kang.pojo.Cat\"/&gt; &lt;bean id=\"cat2\" class=\"com.kang.pojo.Cat\"/&gt;&lt;bean id=\"dog\" class=\"com.kang.pojo.Dog\"/&gt;&lt;bean id=\"person\" class=\"com.kang.pojo.Person\"/&gt; 此时根据byType找到两个Cat类型的bean，然后根据变量名cat以byName的方式查找，仍然找不到，因此注入失败。 这种情况下，就需要使用@Qualifier 注解： 1234567891011//使用@Qualifier注解，指明查找的id名，即根据这个value在容器中查找beanpublic class Person { @Autowired @Qualifier(value = \"cat2\") private Cat cat; @Autowired private Dog dog; private String name; ...} 同时使用 @Autowired和@Qualifier(value = \"cat2\")两个注解，并指定按名称查找时的id，可以在容器中找到id为cat2的bean，因此可以注入成功，可以通过代码验证这一点： 1234567891011@Testpublic void test2(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext2.xml\"); Person person = context.getBean(\"person\", Person.class); System.out.println(person.toString()); System.out.println(context.getBean(\"cat1\")+\" \"+context.getBean(\"cat2\"));}/*运行结果Person{cat=com.kang.pojo.Cat@2177849e, dog=com.kang.pojo.Dog@40cb8df7, name='kang'}com.kang.pojo.Cat@13b13b5d com.kang.pojo.Cat@2177849e*/ 可以看到，person实例中的cat属性被注入了值，并且这个对象确实是@Qualifier指定的id为cat2的bean。 @Resource注解可以使用byName和 byType的方式注入，优先使用byName的方式，具体使用案例不再赘述。 七、使用注解开发使用注解开发，就是在Java代码中使用注解的方式，取代xml文件中配置的方式。使用注解和XML配置是Spring开发的两种主要的方式。 在Spring4之后，要使用注解开发，必须要保证已经导入了aop的包。 确保导入aop包 使用注解，需要在applicationContext.xml配置文件的头部添加注解对应的支持，使用&lt;contex&gt;指定需要使用的注解相关的配置： 1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--指定要扫描的包，这个包下的注解就会生效 这个标签也包括了annotation-config的功能 所以如果使用了这个标签，就可以不使用annotation-config了 --&gt; &lt;context:component-scan base-package=\"com.kang\"/&gt; &lt;!-- 使用context:annotation-config 可以隐式地自动向Spring容器注册4个BeanPostProcessor： AutowiredAnnotationBeanPostProcessor CommonAnnotationBeanPostProcessor PersistenceAnnotationBeanPostProcessor RequiredAnnotationBeanPostProcessor 这样就可以使用@Resource 、@PostConstruct、@PreDestroy、 @PersistenceContext、@Autowired、@Required等注解了，就可以实现自动注入。 注册这4个 BeanPostProcessor的作用，就是为了系统能够识别相应的注解。 --&gt; &lt;context:annotation-config/&gt; &lt;!-- &lt;bean id=\"user\" class=\"com.kang.pojo.User\"&gt;--&gt; &lt;!-- &lt;property name=\"name\" value=\"kangst\"/&gt;--&gt; &lt;!-- &lt;/bean&gt;--&gt;&lt;/beans&gt; 7.1 注册bean@Componet：组件，用于类上，说明这个类被Spring管理了，就是bean，等价于在xml配置文件中使用&lt;bean&gt;标签注册。默认的id为类名的小写。也可以显式指定id名。 12345//@Component等价于&lt;bean id=\"user\" class=\"com.kang.pojo.User\"/&gt;@Componentpublic class User { public String name;} @Component注解等价于xml配置文件中的： 1&lt;bean id=\"user\" class=\"com.kang.pojo.User\"/&gt; 7.2 属性注入使用@Value注解可以为属性注入值： 123456789101112@Componentpublic class User { //@Value用于给属性赋值。相当于&lt;property name=\"name\" value=\"Jarry\"/&gt; @Value(\"kangst\") public String name; //@Value也可以用在set方法上 @Value(\"Jarry\") public void setName(String name) { this.name = name; }} @Value注解等价于xml配置文件中的： 1&lt;property name=\"name\" value=\"Jarry\"/&gt; 7.3 @Component的衍生注解@Component的几个衍生注解，比如在dao层、service层、controller层有各自的注解，在功能上和@Component是一样的。 这几个衍生注解可以解释为@Component的具体形式，他们在Spring中的功能是相同的，都是用于将其注解的类注册到Spring容器中，让容器托管。在不同的层使用不同的注解可以增加程序的可读性。 @Repository：用于dao层，标注dao组件 12@Repositorypublic class UserDao {} @Service：用于service层 12@Servicepublic class UserService {} @Controller：用于controller层 12@Controllerpublic class UserController {} 7.4 自动装配自动装配相关的注解，第六节已经详细介绍过了： @Autowired @Qualifier @Resource 还有其他的注解，比如@Nullable注解标记的属性或字段允许为null。 7.5 作用域使用@Scope注解可以指定当前bean的作用域，效果等价于配置文件中的scope属性。 123@Component@Scope(value = \"prototype\")public class User {} 7.6 小结XML文件配置和注解两种方式对比 XML适用性更好，适用于各种情况；便于维护。 注解只能在当前类使用；维护起来更复杂。 最佳实践：XML文件用来管理bean，注解只负责完成属性的注入。 使用注解时，需要注意要在配置文件中让注解生效，开启注解的支持。 八、基于Java的容器配置8.1 使用Java配置类上述使用注解的方式，仍然需要使用XML配置文件写一部分内容。这一节讲述如何使用Java代码完全代替XML配置文件，对Spring容器进行配置。 完全使用Java程序进行容器配置主要依赖于JavaConfig，其是Spring的一个子项目，在Spring之后它成为了核心功能。 使用Java类作为配置文件，实现XML配置文件的功能，完全取代了XML配置文件。 比如，创建一个配置类MyConfig: 12345678910111213141516171819package com.kang.config;import com.kang.pojo.User;//@Configuration代表这是一个配置类，就和applicationContext.xml配置文件一样//将当前类交给Spring容器托管，注册到容器中，因为它底层本质也是一个Component@Configuration//相当于配置文件中的&lt;context:component-scan base-package=\"com.kang.pojo\"/&gt;//@ComponentScan(\"com.kang.pojo\") //引入另一个配置类//@Import(MyConfig2.class) public class MyConfig { //@Bean就相当于配置文件中的&lt;bean&gt;标签，注册一个bean； //这个方法的名字就相当于bean标签中的id //方法的返回值就是bean标签中的class，表示要注册的类 @Bean public User getUser(){ return new User(); //返回要注入到容器中的对象 }} 配置类中使用注解替代XML文件的功能，比如： @Configuration：代表这是一个配置类，就和applicationContext.xml配置文件一样。同时这个注解表示将当前类交给Spring容器托管，注册到容器中，因为其底层也是@Component。 @Bean：类似于&lt;bean&gt;标签，功能是在容器中注册一个bean，其id默认是方法名（可以指定别名），返回类型就是要注册的bean。 还有其他的一些注解： @ComponentScan：相当于配置文件中的&lt;context:component-scan base-package=\"xxx.xxx\"/&gt;扫描包，使这个包下文件的注解生效。 @Import：可以用于引入另一个配置类，也可以用来注册其他类的bean，相当于XML文件中的&lt;import&gt;标签。 有了配置类和bean以后，我们就可以实例化容器，获取注册好的bean对象： 123456789@Testpublic void test1(){ //如果完全使用配置类，只能通过AnnotationConfigApplicationContext来获取容器 //通过配置类的class对象加载。 ApplicationContext context = new AnnotationConfigApplicationContext(MyConfig.class); //默认id为方法名 User getUser = context.getBean(\"getUser\", User.class); System.out.println(getUser.toString());} 要注意的是，如果我们完全使用Java配置类，实例化容器用的是AnnotationConfigApplicationContext类。 ApplicationContex接口有很多实现类，AnnotationConfigApplicationContext也只是其中一种。 8.2 @Component和@Bean对比相同点 二者都是注册bean。 不同点 作用对象不同：@Component 注解作用于类，而@Bean注解作用于方法。 @Component通常是通过类路径扫描来自动侦测以及自动装配到Spring容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是在标有该注解的方法中定义产生这个 bean，@Bean告诉了Spring这是某个类的示例，当我们需要用它的时候容器会将其传递给我们。 @Bean 注解比 Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册bean。比如当我们引用第三方库中的类需要装配到 Spring容器时，则只能通过 @Bean来实现。 只能使用 @Bean而不能使用 Component 的案例： 1234567891011@Beanpublic OneService getService(int status) { switch (status) { case 1: return new serviceImpl1(); case 2: return new serviceImpl2(); case 3: return new serviceImpl3(); }} 九、代理模式Spring的AOP底层实现原理就是使用的代理模式。 使用代理模式能够在不改变原有代码的情况下，添加一些其他功能，符合“开闭原则”，即“对扩展开放，对修改封闭”。举个例子，比如说希望在当前程序的某个方法执行前后添加一个功能，直接修改源代码的做法是不提倡的，正确做法是使用一个代理类，将其功能代理过来然后添加新的功能。 这种不改变原有代码，使用横向切入的开发方式，就是AOP（面向切面编程）的思想。 代理模式的优势： 使被代理类的操作更加纯粹，不用关注一些额外功能。 额外功能交给代理类来实现，实现了业务的分工。 额外功能发生扩展时，方便集中管理。 9.1 静态代理代理模式一般有以下三种角色： 接口：代理类和被代理类共同实现的接口。这样用户只需要对接口操作，不需要关心实现类是真实对象还是代理类对象。 虽然代理类不实现这个接口，使用组合的方式也能完成同样的功能，但是那样扩展性差。 JDK接口实现的动态代理模式中，要求必须实现共同的接口，因为它就是代理的接口。 Cglib实现的动态代理不需要实现接口，它是通过自动创建子类来实现代理的。 被代理类：实现接口，被代理类不直接和用户交互。 代理类：用于代理被代理类，供客户调用，完成被代理类的功能的同时，有一些扩展的功能。直接和用户交互。 静态代理的缺点：一个代理类只能代理一个接口，当被代理的接口增加的时候，会导致代理类翻倍。另外，如果接口中的功能修改了，会导致代理类也会修改。 9.2 动态代理什么是动态代理 动态代理能够动态生成代理类，而不需要我们手动去写代理类。动态代理和静态代理的代理角色是一样的。 动态代理的实现方式 动态代理主要有基于接口的动态代理和基于类的动态代理两种方式： 基于接口：JDK的动态代理，代理类和被代理类实现共同的接口，动态代理返回的代理类类型就是这个接口类型。 基于类：Cglib。如果没有实现接口，则需要使用Cglib，生成被代理对象的子类来作为代理。 实现接口的情况下也能用Cglib，只不过是代理的不是接口，而是使用子类来实现。 还有一种Java字节码实现：Javassist，是一个创建Java字节码的类库，可以直接编辑和生成Java生成的字节码。 动态代理的优势 动态代理除了具有传统代理模式的优势以外，还有其特有的优势： 动态代理类代理的同样是接口，但可以同时代理一个或多个接口，一般对应的是一类业务。 一个动态代理类可以代理多个类，前提是这些类都是同一个接口的实现类。也就是说，对于这些被代理类，代理类做的额外工作是相同的，这样这些被代理类都可以使用这一个代理类完成代理。 基于接口的动态代理具体实现 基于接口的动态代理是指JDK动态代理，代理的是接口。因此这种方式要求代理类和被代理类必须实现同一个接口。 JDK动态代理主要使用Proxy类和InvocationHandler两个接口。主要步骤是： 实现InvocationHandler接口和其中的invoke()方法，主要是用于动态地调用被代理类中的同名方法。这一步中需要被代理类的实例。 调用Proxy类的newProxyInstance方法，生成代理类对象，其中需要InvocationHandler实现类对象作为参数。这一步主要是用于动态生成代理类对象。 详情可以参考反射的应用-动态代理。 下面是一种动态代理的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class DynamicProxyTest { public static void main(String[] args) { //创建一个UserService实现类的对象，即被代理类对象 UserService userService = new UserServiceImpl(); //根据这个被代理类对象，生成一个代理类对象的实例 //根据这里可以看出，被代理类必须也要实现接口，不然无法实现代理功能 UserService proxyInstance = (UserService) ProxyFactory.getProxyInstance(userService); //调用代理类实例的方法，可以完成被代理类的功能和一些额外的方法。 proxyInstance.addUser(); }}//步骤1，需要实现InvocationHandler接口class InvocationHandlerImpl implements InvocationHandler { private Object obj; //被代理类的对象 public void setObj(Object obj) { this.obj = obj; } //当通过代理类的对象调用某个方法时，就会自动调用这个invoke()方法。 //我们将代理类要执行的额外的方法写在里面，就可以完成代理的功能。 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //proxy参数好像没用？ System.out.println(\"调用方法之前，代理类执行一些额外方法\"); //调用被代理类对象的同名方法，args表示传入的参数，此返回值就是原方法的返回值 Object result = method.invoke(obj, args); System.out.println(\"调用方法之后，代理类执行一些额外方法\"); return result; }}//步骤2，创建一个类，用来获取被代理类的实例class ProxyFactory { //obj表示被代理类的对象 //这里可以使用泛型，避免使用时类型强转。 public static Object getProxyInstance(Object obj) { InvocationHandlerImpl handler = new InvocationHandlerImpl(); handler.setObj(obj); //调用Proxy类的newProxyInstance方法获取被代理类的实例 //需要将InvocationHandler实现类的对象作为参数 return Proxy.newProxyInstance( obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), handler); }}/*运行结果调用方法之前，代理类执行一些额外方法执行UserServiceImpl类的addUser()方法调用方法之后，代理类执行一些额外方法*/ 可以看到，当一个接口有多个实现类的时候，使用以上动态代理的方法，只要将被代理的对象传入，就可以自动生成一个代理类的对象，通过这个代理类对象完成代理功能。 如果使用了代理模式，因为要返回一个代理类对象，所以容器的getBean()方法的传入参数必须是共同实现的接口class对象。 如果没有使用代理模式，就是一般的IOC，则容器中返回的依旧是原生对象。 动态代理代理的是接口，返回的代理类对象必须使用接口类型接收，否则无法判断具体的类型，就不能调用相关方法。这也是代理类必须要和被代理类实现同一个接口的原因。 十、AOP10.1 AOP介绍10.1.1 简介官方文档中关于AOP的介绍：Aspect Oriented Programming with Spring AOP(Aspect Oriented Programming)，面向切片编程，通过预编译方式（比如AspectJ）和运行期动态代理（比如Spring AOP）实现程序功能的统一维护的一种技术。利用AOP可以对业务逻辑各个部分进行隔离，使业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高开发效率。 AOP能够将那些与业务无关却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码、降低模块间的耦合度，并有利于未来的可扩展性和可维护性。 通俗点说，AOP提供声明式事务，允许用户自定义切面，在不改变原来代码的情况下，增加新的功能。 AOP示意图 10.1.2 相关概念AOP的相关概念，参考官方文档：AOP Concepts： 横切关注点：跨越应用程序多个模块的方法或功能，和业务逻辑无关但需要关注的地方，比如安全（验证）、事务、日志、缓存等。 Aspect：切面，是Advice和PointCut的集合，通知和切入点共同定义了切面的全部功能，即它是什么，在何时何处完成其功能。切面是横切关注点被模块化的类。 Advice：通知，增强。即切面中要完成的工作，一般为切面类中的方法。共有五种类型。定义了“切入什么”和“何时切入“。 Target：目标，相当于被代理类，即被通知的对象。 Proxy：代理，相当于代理类，向target对象应用通知后创建的对象。 JointPoint：连接点。指应用执行过程中能够插入切面的点，或者说能够应用通知的所有点，Spring AOP中的连接点指的是方法。 PointCut：切入点。实际要切入的位置，定义了在”何处“切入。是一个具体确定的连接点。 Introduction：引入。向现有的类中添加方法或属性。 Weaving：织入。就是把切面连接到应用程序类型或者对象上，并创建代理对象的过程。 在目标对象的生命周期里有多个点可以进行织入： 1、编译期织入：切面在目标类编译时期被织入。AspectJ采用的织入方式。 2、类加载期织入：目标类被引入之前增强该目标类的字节码。AspectJ5采用的方式 3、运行期织入：切面在应用运行期间的某个时刻被织入。Spring AOP采用这种方式，在织入切面的时候，AOP容器会为目标对象动态的创建代理对象。 Advice的五种类型： Before advice：前置通知。在连接点前面执行，前置通知不会影响连接点的执行，除非此处抛出异常。 After returning advice：正常返回通知。在连接点正常执行完成后执行，如果连接点抛出异常，则不会执行。 After throwing advice： 异常返回通知。在连接点抛出异常后执行。 After (finally) advice：返回通知。在连接点执行完成后执行，不论连接点有没有抛出异常，都会执行。 Around advice：环绕通知。围绕在连接点前后，比如一个方法调用的前后。这是最强大的通知类型，能在方法调用前后自定义一些操作。环绕通知还需要负责决定是继续处理连接点（调用ProceedingJoinPoint的proceed方法）还是中断执行。 环绕通知能够在前置通知之前，和返回通知之前执行一些操作，并且能够控制连接点是否继续执行。 AOP执行示意图 10.2 AOP实现原理String AOP的实现是基于动态代理的，如前面所述，如果被代理对象实现了某个接口，则会使用JDK的Proxy接口创建代理对象，实现动态代理；否则，如果被代理对象没有实现接口，此时必须使用Cglib来生成被代理对象的子类作为代理。 关于开启CGLIB代理的配置，可以参考官方文档：Mixing Aspect Types 下图展示了两种代理模式的实现原理（参考JavaGuide）： JDK Proxy和CGLib代理 10.3 Spring AOP和AspectJ AOPAOP有多种实现框架，在Spring中主要是Spring AOP实现和AspectJ AOP两种实现方式。 AspectJ AOP也是一种AOP编程扩展框架，其内部使用BCEL框架完成其功能。 Spring AOP基于代理模式，属于运行时增强；而AspectJ基于字节码操作(Bytecode Manipulation)，是编译时增强。 Spring中集成了AspectJ，AspectJ 的AOP功能相比于Spring AOP功能更加强大，但Spring AOP使用起来更简单。 关于Spring AOP和AspectJ的选择问题 官方说明：Choosing which AOP Declaration Style to Use 如果切面较少，两者性能差异不大。如果切面太多时，AspectJ比Spring AOP快很多。 如果只需要在Spring bean上执行通知，建议使用Spring AOP即可 如果需要通知不受Spring 容器管理的对象，比如域对象，则需要使用AspectJ 如果希望通知连接点，而不是仅通知简单的方法（比如set、get方法等），则需要使用AspectJ 10.4 AOP在Spring 中的实现参考官方文档Aspect Oriented Programming with Spring Spring中实现AOP需要导入AOP织入包： 123456&lt;!-- https://mvnrepository.com/artifact/org.aspectj/aspectjweaver --&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.6&lt;/version&gt;&lt;/dependency&gt; Spring中实现AOP可以通过三种方式，其中前两种都是Spring AOP，第三种是AspectJ AOP： 实现Spring提供的接口，比如MethodBeforeAdvice、AfterReturningAdvice等接口。 自定义切面类，然后在XML配置文件中使用&lt;aop:config&gt;标签。 使用注解，借助内部集成的AspectJ实现AOP。在切面类中使用@Aspect、@Before、@After、@Around等注解。 10.4.1 方式一：实现Spring接口Spring中给定了一些相关的接口，用于定义通知，比如MethodBeforeAdvice、AfterReturningAdvice等接口。我们需要实现这些接口，完成通知的具体功能。 通过实现Spring接口实现AOP的方法，主要是使用&lt;aop:advisor&gt;标签，具体实现如下： 1、定义接口的实现类，实现对象通知方法 可以用一个实现类同时实现多个通知接口，也可以创建多个类各自实现一个接口。 这里创建一个Log类，在目标方法执行前后输出一些信息： 1234567891011121314151617181920public class Log implements MethodBeforeAdvice,AfterReturningAdvice{ /**实现before方法 * @param method 反射方法 * @param args 方法的参数 * @param target 方法调用的目标对象，可以为空 */ @Override public void before(Method method, Object[] args, Object target) { System.out.println(\"Before:\"+target.getClass().getName()+ \"类的\"+method.getName()+\"方法被执行\"); } //实现afterReturning方法 @Override public void afterReturning(Object returnValue, Method method, Object[] args, Object target) { System.out.println(\"After:\"+\"执行了\"+method.getName()+ \",返回结果为：\"+returnValue); }} 2、在配置文件中注册bean，然后配置AOP： 1234567891011&lt;!-- 将Log类注册为bean --&gt;&lt;bean id=\"log\" class=\"com.kang.log.Log\"/&gt;&lt;!-- 配置AOP --&gt;&lt;aop:config&gt; &lt;!--配置切入点--&gt; &lt;aop:pointcut id=\"pointcut\" expression= \"execution(* com.kang.service.UserServiceImpl.*(..))\"/&gt; &lt;!-- advisor，定义通知器，类似于切面，包括了通知和切点 --&gt; &lt;!-- 如果有多个实现类，就写多个标签 --&gt; &lt;aop:advisor advice-ref=\"log\" pointcut-ref=\"pointcut\"/&gt;&lt;/aop:config&gt; 其中advisor表示定义一个通知器，通知器的概念类似于切面，包括了通知和切入点。 为了可读性，建议一个实现类对应一个通知接口，这样一个类就可以表示一个通知，结构清晰。 3、配置完后，可以测试是否生效： 123456789101112@Testpublic void test1(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); // 动态代理是代理的接口，因此这里必须传入的是接口的class对象 UserService userService = context.getBean(\"userService\",UserService.class); userService.queryUser();}/*执行结果Before:com.kang.service.UserServiceImpl类的queryUser方法被执行执行queryUser()方法After:执行了queryUser,返回结果为：null*/ 补充：关于切点表达式 切点表达式主要用于定位连接点。详细用法可以参考切点表达式、Spring AOP AspectJ 切入点表达式示例 表达式中有三种通配符： *：匹配任何数量字符 ..：用在路径中表示任何数量子包，用在参数中则表示任何数量参数。 +：匹配指定类型的子类型，仅能作为后缀放在类型模式后边。 格式如下： 12//[]内的内容可以省略execution([方法修饰符] 返回值类型 [包路径]方法名(参数类型列表)[throws 异常类型]) execution表达式主要由三部分组成 方法修饰符，比如public、private等；可以省略 返回值类型，可以用*表示所有类型。 [包路径]方法名及其参数类型的列表。其中*表示所有方法或所有类，参数类型列表中填的是参数的类型。其中包路径可以省略，表示表示所有包下和这个方法同名的方法。 此外，在AspectJ中，切入点表达式可以通过&amp;&amp;、||、!来组合切入点表达式，由于在XML中使用&amp;&amp;需要使用转义字符来代替，因此Spring AOP 使用and、or、not来代替。 表达式举例： 1、全通配 1execution(* *..*.*(..)) 2、匹配所有目标类以xxx开头的方法，第一个*代表返回任意类型，参数类型为任意数量的任意类型。 1execution(* xxx* (..)) 3、匹配Service接口及其实现子类中的所有方法 1execution(* com.xxx.Service.*(..)) 4、匹配service包下的所有类的所有方法，但不包括子包 1execution(* com.xxx.service.*(..)) 5、匹配aop_part包下的所有类的所有方法，包括子包。 12# 注意 （当\"..\"出现在类名中时，后面必须跟\" * \",表示包、子孙包下的所有类**）execution(* com.xxx.service..*(..)) 6、匹配所有方法名为add，且有两个参数，其中，第一个的类型为int 第二个参数是String 1execution(* add(int, String)) 7、匹配所有方法名为add，且至少含有一个参数，并且第一个参数为int的方法 1execution(* add(int, ..)) 10.4.2 方式二：自定义切面类自定义切面主要借助于&lt;aop:aspect&gt;来实现。我们只需要在切面类中定义通知方法，不需要实现接口。 1、定义切面类 123456789//定义两个通知方法public class MyAspect { public void before(){ System.out.println(\"before：方法执行前\"); } public void after(){ System.out.println(\"after：方法执行后\"); }} 2、在配置文件中注册bean，然后配置AOP 1234567891011121314&lt;!--方式二：自定义切面--&gt;&lt;!-- 将切面类注册为bean --&gt;&lt;bean id=\"myAspect\" class=\"com.kang.diy.MyAspect\"/&gt;&lt;!-- 配置AOP --&gt; &lt;aop:config&gt; &lt;aop:aspect ref=\"myAspect\"&gt; &lt;!--定义切入点--&gt; &lt;aop:pointcut id=\"pointcut\" expression= \"execution(* com.kang.service.UserServiceImpl.*(..))\"/&gt; &lt;!--定义通知，这里定义了before和after两种类型--&gt; &lt;aop:before method=\"before\" pointcut-ref=\"pointcut\"/&gt; &lt;aop:after method=\"after\" pointcut-ref=\"pointcut\"/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 我们在配置文件中，使用&lt;aop:aspect&gt;定义切面类，然后定义切入点和通知的类型。 3、测试是否生效： 1234567891011@Testpublic void test2(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); UserService userService = context.getBean(\"userService\", UserService.class); userService.deleteUser();}/*运行结果before：方法执行前执行deleteUser()方法after：方法执行后*/ 可以看到，这种方法和第一种方法比较相似，对比&lt;aop:aspect&gt;和&lt;aop:advisor&gt;： aspect和advisor都是定义切面，二者最终的原理基本上是一样的。 aspect定义切面时，只需要定义一般的bean，而advisor中引用的通知，必须实现相应的通知接口。 advisor大多用于事务管理。 10.4.3 方式三：使用AspectJ的注解前两种方法都是基于XML配置使用Spring AOP的实现，这种注解方式是使用AspectJ的注解实现AOP。 1、创建类，并使用注解标记为切面类 123456789101112131415161718192021222324252627282930@Aspect //标注这个类是一个切面类public class AnnotationAspect { //将当前方法标记为前置通知，并指明切入点 @Before(value=\"execution(* com.kang.service.UserServiceImpl.*(..))\") public void before(){ System.out.println(\"注解Before：方法执行前\"); } @After(value = \"execution(* com.kang.service.UserServiceImpl.*(..))\") public void after(){ System.out.println(\"注解After：方法执行后\"); } /* 环绕通知会在前置通知和返回通知之前执行一些东西，并且控制连接点是否继续执行 */ @Around(value = \"execution(* com.kang.service.UserServiceImpl.*(..))\") public void around(ProceedingJoinPoint pjp){ System.out.println(\"注解Around：方法执行前\"); try { // 执行目标方法，如果不调用此方法，则会中断执行目标方法。 pjp.proceed(); // pjp还可以获取目标方法的签名 System.out.println(pjp.getSignature()); } catch (Throwable throwable) { throwable.printStackTrace(); } System.out.println(\"注解Around：方法执行后\"); }} 2、注册bean并开启AspectJ注解 123&lt;bean id=\"annotationAspect\" class=\"com.kang.anno.AnnotationAspect\"/&gt;&lt;!-- 使AspectJ注解生效，默认使用JDK接口动态代理 --&gt;&lt;aop:aspectj-autoproxy/&gt; 其中Spring的动态代理默认使用的是JDK动态代理。也可以通过参数设置为使用cglib： 12&lt;!-- proxy-target-class默认为false，表示使用JDK动态代理接口 --&gt;&lt;aop:aspect-autoproxy proxy-target-class=\"true\"&gt; 如果使用的是Java配置类，开启AspectJ需要使用@EnableAspectJAutoProxy注解： 1234@Configuration@EnableAspectJAutoProxypublic class AppConfig {} 3、测试是否织入成功 1234567891011121314@Testpublic void test3(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); UserService userService = context.getBean(\"userService\", UserService.class); userService.queryUser();}/*执行结果注解Around：方法执行前注解Before：方法执行前query a uservoid com.kang.service.UserService.queryUser()注解Around：方法执行后注解After：方法执行后*/ 使用注解的方式，如果每个通知的切入点相同，可以定义一个方法写切入点。 10.4.4 总结选用XML配置还是AspectJ注解，需要视情况而定，官方说明：@AspectJ or XML for Spring AOP?，官方文档提供了一个例子，只能使用AspectJ注解而无法使用XML的例子： 12345678@Pointcut(\"execution(* get*())\")public void propertyAccess() {}@Pointcut(\"execution(org.xyz.Account+ *(..))\")public void operationReturningAnAccount() {}@Pointcut(\"propertyAccess() &amp;&amp; operationReturningAnAccount()\")public void accountPropertyAccess() {} 上述这种情况，只有前两种能用XML配置： 12345&lt;aop:pointcut id=\"propertyAccess\" expression=\"execution(* get*())\"/&gt;&lt;aop:pointcut id=\"operationReturningAnAccount\" expression=\"execution(org.xyz.Account+ *(..))\"/&gt; 对于第三种这样结合使用过的方式，是XML无法完成的，这也是XML配置方式的一个缺陷。 十一、整合MyBatis整合主要是将MyBatis中需要手动创建对象的地方，交给Spring容器去做。我们最后只需要通过容器获取实现类的对象，然后调用相关的方法即可。 我们主要使用MyBatis-Spring来整合。 一般来说Spring和MyBatis有三种整合方式： 使用MapperScannerConfigurer，它会查找类路径下的映射器并自动将它们创建为MapperFactoryBean。 使用org.mybatis.spring.SqlSessionTemplate类获取SqlSession实现类类对象，它是SqlSession接口的一个实现类 使用org.mybatis.spring.support.SqlSessionDaoSupport获取SqlSession实现类对象。相比于第二种方法，这中方法省略了在Spring容器中注册SqlSessionTemplate的步骤。 org.apache.ibatis.session.SqlSession类是MyBatis中和一个核心接口，它的实现类用于获取Mapper接口的实现类对象。 首先我们需要在Maven配置中导入MyBatis-Spring依赖和spring-jdbc依赖： 1234567891011121314&lt;!-- spring整合mybatis需要用的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.6&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Spring操作数据库，还需要一个spring-jdbc --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 我们需要准备一个POJO类，和一个对应的Mapper接口，以及对应的Mapper配置类。 User 12345678public class User { private int id; private String name; private String pwd; public User() {} ...} userMapper 1234public interface UserMapper { public List&lt;User&gt; selectUser(); ...} UserMapper.xml 12345678910&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.kang.mapper.UserMapper\"&gt; &lt;select id=\"selectUser\" resultType=\"User\"&gt; select * from user &lt;/select&gt;&lt;/mapper&gt; 目录结构如下： Spring-MyBatis整合目录 11.1 方式一：使用SqlSessionTemplate主要思路是将MyBatis中需要手动创建对象的地方交给Spring容器处理。 参考mybatis-spring官方文档，详细步骤如下： 1、配置数据源 1234567891011&lt;!-- DataSource 使用Spring的数据源替换Mybatis的dataSource配置 这个数据源可以使用任意的数据源，这里使用的是Spring提供的JDBC. 需要导入spring-jdbc依赖。 --&gt;&lt;bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/mybatis?useSSL=false&amp;amp;characterEncoding=UTF-8&amp;amp;serverTimezone=UTC\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt;&lt;/bean&gt; 2、获取SqlSessionFactory对象 123456789&lt;!-- 注册SqlSessionFactory --&gt;&lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref = \"dataSource\"/&gt; &lt;!-- 还可以绑定Mybatis配置文件和注册Mapper --&gt; &lt;property name=\"configLocation\" value= \"classpath:mybatis-config.xml\"/&gt; &lt;property name=\"mapperLocations\" value= \"classpath:com/kang/mapper/UserMapper.xml\"/&gt;&lt;/bean&gt; 其中dataSource属性是必须的。 关于SqlSessionFactoryBean的详细介绍可以参考SqlSessoinFactoryBean 值得注意的是，mapperLocations也可以接受多个资源位置，即注册多个映射器，比如下面的配置表示会从类路径下加载所有在sample.config.mappers包和它的子包中的映射器xml文件。 1&lt;property name=\"mapperLocations\" value=\"classpath*:sample/config/mappers/**/*.xml\" /&gt; 3、获取SqlSessionTemplate对象 SqlSessionTemplate是SqlSession的一个实现类，可以无缝代替SqlSession 12345&lt;!-- SqlSessionTemplate 就和SqlSession类似 --&gt;&lt;bean id=\"sqlSession\" class=\"org.mybatis.spring.SqlSessionTemplate\"&gt; &lt;!-- 只能使用构造器注入sqlSessionFactory，因为SqlSessionTemplate没有set方法 --&gt; &lt;constructor-arg index=\"0\" ref=\"sqlSessionFactory\"/&gt;&lt;/bean&gt; 4、给接口编写实现类 为了将MyBatis中手动获取Mapper对象的过程由Spring IOC容器接管，我们需要定义一个Mapper实现类，然后将其注入到Spring容器： 123456789101112131415161718package com.kang.mapper;public class UserMapperImpl implements UserMapper{ //我们的所有操作，原来都是用sqlSession来执行， //现在mybatis-spring整合，使用SqlSessionTemplate代替SqlSession private SqlSessionTemplate sqlSession; public void setSqlSession(SqlSessionTemplate sqlSession) { this.sqlSession = sqlSession; } @Override public List&lt;User&gt; selectUser() { //获取UserMapper的一个实现类对象 UserMapper mapper = sqlSession.getMapper(UserMapper.class); return mapper.selectUser(); }} 这个实现类相当于连接了MyBatis和Spring，将MyBatis获取Mapper实现类对象的步骤封装到一个类中，这个实现类虽然继承了接口，但它是借用MyBatis完成的功能，因此我们将这个实现类注册到Spring容器中。 之后从容器中获取这个实现类的对象就可以完成功能。 5、将实现类注入到Spring中 123&lt;bean id=\"userMapper\" class=\"com.kang.mapper.UserMapperImpl\"&gt; &lt;property name=\"sqlSession\" ref=\"sqlSession\"/&gt;&lt;/bean&gt; 6、通过Spring容器获取实现类对象，调用方法，完成功能 12345678910@Testpublic void selectUser() { ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); //直接从容器中获取实现类对象，调用方法就可以完成功能。 UserMapper userMapper = context.getBean(\"userMapper\", UserMapper.class); List&lt;User&gt; users = userMapper.selectUser(); for(User user:users){ System.out.println(user); }} 汇总 我们在Spring的配置文件中，可以实现对数据源的配置，也可以注册Mapper映射器，因此可以完全取代MyBatis配置文件，这里象征性地保留MyBatis配置文件mybatis-config.xml，里面保留了起别名的配置语句。 mybatis-config.xml 123456789&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;typeAliases&gt; &lt;package name=\"com.kang.pojo\"/&gt; &lt;/typeAliases&gt;&lt;/configuration&gt; 我们可以将上述的获取数据源、获取SqlSessionFactory对象、获取SqlSessionTemplate对象这三个和数据库相关的配置语句单独放到一个配置文件spring-dao.xml中，在applicationContext.xml核心配置文件中用来注册bean，并负责将引入spring-dao.xml。 spring-dao.xml，用于获取SqlSessionTemplate对象： 12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- 1、DataSource --&gt; &lt;bean&gt;...&lt;/bean&gt; &lt;!-- 2、获取SqlSessionFactory对象 --&gt; &lt;bean&gt;...&lt;/bean&gt; &lt;!-- 3、获取SqlSessionTemplate对象 --&gt; &lt;bean&gt;...&lt;/bean&gt;&lt;/beans&gt; applicationContext.xml，引入spring-dao.xml，注册bean： 1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- 引入spring-dao --&gt; &lt;import resource=\"spring-dao.xml\"/&gt; &lt;!-- 注册bean，即userMapper实现类对象 --&gt; &lt;bean id=\"userMapper\" class=\"com.kang.mapper.UserMapperImpl\"&gt; &lt;property name=\"sqlSession\" ref=\"sqlSession\"/&gt; &lt;/bean&gt;&lt;/beans&gt; 测试 通过上述配置以后，我们可以测试是否配置成功。 12345678910@Testpublic void selectUser() { ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); //现在我们只需要从Spring容器中获取UserMapper实现类对象即可 UserMapper userMapper = context.getBean(\"userMapper\", UserMapper.class); List&lt;User&gt; users = userMapper.selectUser(); for(User user:users){ System.out.println(user); }} 11.2 方式二：SqlSessionDaoSupport第一种方式中，我们需要将SqlSessionFactory注入到SqlSessionTemplate类来获取SqlSessionTemplate对象。 现在我们将UserMapperImpl类继承SqlSessionDaoSupport类，就可以直接获得SqlSessionTemplate对象。 UserMapperImpl 12345678910package com.kang.mapper;public class UserMapperImpl extends SqlSessionDaoSupport implements UserMapper{ @Override public List&lt;User&gt; selectUser() { //getSqlSession()方法会创建并返回一个SqlSessionTemplate对象 SqlSession sqlSession = getSqlSession(); return sqlSession.getMapper(UserMapper.class).selectUser(); }} 我们可以使用getSqlSession()方法，其内部为我们创建了一个SqlSessionTemplate对象并返回，因此我们不需要在Spring容器中注册SqlSessionTemplate类。 此时的spring-dao.xml省略了一个bean内容： 1234567891011&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- 1、DataSource --&gt; &lt;bean&gt;...&lt;/bean&gt; &lt;!-- 2、获取SqlSessionFactory对象 --&gt; &lt;bean&gt;...&lt;/bean&gt;&lt;/beans&gt; 同时，我们在applicationContext.xml配置文件中注册UserMapperImpl的时候，需要将SqlSessionFactory依赖注入: 12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"userMapperImpl\" class=\"com.kang.mapper.UserMapperImpl\"&gt; &lt;property name=\"sqlSessionFactory\" ref=\"sqlSessionFactory\" /&gt; &lt;/bean&gt;&lt;/beans&gt; 11.3 方式三：使用MapperScannerConfigurerMapperScannerConfigurer基于反射原理，会自动查找类路径下的映射器（DAO接口）并自动将它们创建为MapperFactoryBean。也就是说它会扫描指定包下的所有接口，然后创建各自接口的动态代理类。 MapperFactoryBean的出现为了代替手工使用SqlSessionDaoSupport或SqlSessionTemplate编写数据访问对象(DAO)的代码,使用动态代理实现。所以使用MapperScannerConfigurer的方式省略了前两种方法中手动创建UserMapper的步骤。 此时的spring-dao.xml文件内容如下： 12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- 1、DataSource --&gt; &lt;bean&gt;...&lt;/bean&gt; &lt;!-- 2、获取SqlSessionFactory对象 --&gt; &lt;bean&gt;...&lt;/bean&gt; &lt;!-- 3、配置MapperScannerConfigurer --&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;!-- a.设置要扫描的包 --&gt; &lt;property name=\"basePackage\" value=\"com.kang.dao\"/&gt; &lt;!-- b.注入sqlSessionFactory --&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/&gt; &lt;/bean&gt;&lt;/beans&gt; 在上述配置中，我们设置自动扫描com.kang.dao这个包，假如这个包内有一个UserMapper接口，则MapperScannerConfigurer会使用动态代理自动为我们创建一个id为userMapper的代理bean对象，在同一个ApplicationContext中（或者是通过import引入）我们就可以直接使用这个bean。 十二、声明式事务参考Spring事务总结 Spring中的事务有两种： 编程式事务：在代码中管理事务，即使用 TransactionTemplate类或者TransactionManager接口手动编码管理事务。（不推荐使用） 声明式事务：使用AOP，在配置文件中配置。 Spring中实现声明式事务同样也包括XML配置和注解两种方式，其中XML配置主要使用的时&lt;tx&gt;标签，注解主要使用的是@Transactional注解。 一般我们需要处理事务是在service层。 首先我们需要准备POJO类，对应的接口以及接口实现类。 User 123456789public class User { private int id; private String name; private String pwd; public User() { } ...} UserMapper 123456public interface UserMapper { public int addUser(User user); public int deleteUser(int id); public int updateUser(int id); public List&lt;User&gt; querytUser();} UserMapperImpl内容和十一节用到的相似。 12.1 使用声明式事务12.1.1 使用tx和aop命名空间实现声明式事务前面说过，advisor多用于事务管理。我们可以结合使用&lt;tx&gt;和&lt;aop&gt;配置声明式事务。我们将事务配置语句写在spring-dao.xml文件中，内容如下。 spring-dao.xml 12345678910111213141516171819202122232425&lt;!-- 配置声明式事务的步骤 --&gt;&lt;!-- 1.开启事务处理功能，配置事务管理器 --&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;!-- 注入数据源 --&gt; &lt;constructor-arg ref=\"dataSource\"/&gt;&lt;/bean&gt;&lt;!-- 2.使用AOP织入 --&gt;&lt;!-- 默认使用transactionManager --&gt;&lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;!-- 给切入点中指定的方法配置事务 --&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"addUser\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"deleteUser\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"updateUser\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"queryUser\" propagation=\"REQUIRED\"/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!-- 配置事务切入点和通知器 --&gt;&lt;aop:config&gt; &lt;!-- 一般处理事务在service层，这里只是做个示例 --&gt; &lt;aop:pointcut id=\"txPointcut\" expression=\"execution(* com.kang.mapper.*.*(..))\"/&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"txPointcut\"/&gt;&lt;/aop:config&gt; 其中，propagation表示事务的传播行为，默认是REQUIRED，下文详细讲解，还可以根据需求配置其他属性。 &lt;tx:method&gt;中的name要注入事务的方法名，可以用*表示所有方法。 注意：为事务管理器指定的 DataSource 必须和用来创建 SqlSessionFactoryBean 的是同一个数据源，否则事务管理器无法工作。 除了使用AOP的方式，还可以直接使用JtaTransactionManager，不用上面手动配置事务管理器和AOP织入等，直接配置事务管理器，参考mybatis-spring官方-交由容器管理事务： 1&lt;tx:jta-transaction-manager /&gt; JTA: Java Transaction API 12.1.2 使用@Transactional配置声明式事务使用注解的方式配置声明式事务，主要步骤： 1.开启事务处理功能，配置事务管理器 2. 开启Spring对注解事务的支持，使类中事务注解生效 3.在需要事务的方法上使用@Transactional注解即可 示例，spring-dao.xml： 12345678&lt;!-- 1、开启事务处理功能，配置事务管理器 --&gt;&lt;bean id=\"transactionManager\" class= \"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;constructor-arg ref=\"dataSource\"/&gt;&lt;/bean&gt;&lt;!-- 2、开启Spring对注解事务的支持，指定事务管理器id --&gt;&lt;tx:annotation-driven transaction-manager=\"transactionManager\"/&gt; 在实现类中的方法上使用@Transactional注解： 12345678910111213141516public class UserMapperImpl implements UserMapper{ private SqlSessionTemplate sqlSession; public void setSqlSession(SqlSessionTemplate sqlSession) { this.sqlSession = sqlSession; } @Override @Transactional(propagation = Propagation.REQUIRED) //使用注解配置事务，还可以指定参数 public List&lt;User&gt; queryUser() { UserMapper mapper = sqlSession.getMapper(UserMapper.class); return mapper.queryUser(); } ...} @Transactional的工作原理是基于AOP实现的，AOP 是使用动态代理实现的。如果目标对象实现了接口，默认情况下会采用 JDK 的动态代理，如果目标对象没有实现了接口，会使用 CGLIB 动态代理。 @Transactional的作用范围 方法 ：推荐将注解使用于方法上，不过该注解只能应用到 public 方法上，否则不生效。 类 ：如果这个注解使用在类上的话，表明该注解对该类中所有的 public 方法都生效。 接口 ：不推荐在接口上使用。因为在接口上使用时只有基于接口的代理（比如JDK接口代理）才会生效。因为注解是不能继承 的，这就意味着如果正在使用基于类（比如CGlib）的代理时，那么事务的设置将不能被基于类的代理所识别，而且对象也将不会被事务代理所包装。 @Inherited使注解能够继承，只能控制对类名上注解是否可以被继承。不能控制方法上的注解是否可以被继承。 @Transactional的常用参数 propagation：事务的传播行为，默认值为REQUIRED isolation：事务的隔离级别，默认值采用DEFAULT timeout：事务的超时时间，默认值为-1，表示不会超时。如果超过改时间限制但事务还没有完成，则自动回滚事务。 readOnly：指定事务是否是只读事务，默认值为false rollbackFor：用于指定能够触发事务回滚的异常类型，并且可以指定多个异常类型。默认为RuntimeException.class，表示在遇到RuntimeException异常时才回滚。 @Transactional的使用注意事项 @Transactional 注解只有作用到 public 方法上事务才生效，不推荐在接口上使用； 避免同一个类中调用 @Transactional 注解的方法，这样会导致事务失效； 也就是说，同一个类中，方法A调用使用了@Transactional注解的方法B，会导致方法B事务失效。这是由于Spring采用动态代理(AOP)实现对bean的管理和切片，它为我们的每个class生成一个代理对象。只有在代理对象之间进行调用时，可以触发切面逻辑。而在同一个class中，方法A调用方法B，调用的是原对象的方法，而不通过代理对象。所以Spring无法切到这次调用，也就无法通过注解保证事务性了。 正确的设置 @Transactional 的rollbackFor和propagation属性，否则事务可能会回滚失败. 12.2 事务属性Spring中事务的常用属性包括以下几种。 12.2.1 事务传播行为事务传播行为是为了解决业务层方法之间互相调用的事务问题。 当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行。不同的事务导致回滚时的行为也会不同。事务的传播行为就是解决这种问题的。 事务的传播行为共有以下7种： 支持当前事务的情况 TransactionDefinition.PROPAGATION_REQUIRED(0)：默认。如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。 TransactionDefinition.PROPAGATION_SUPPORTS(1)：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_MANDATORY(2)：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。 不支持当前事务的情况 TransactionDefinition.PROPAGATION_REQUIRES_NEW(3)：创建一个新的事务，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED(4)：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER(5)：以非事务方式运行，如果当前存在事务，则抛出异常。 其他情况 TransactionDefinition.PROPAGATION_NESTED(6)：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行（外部主事务回滚的话，子事务也会回滚，而内部子事务可以单独回滚而不影响外部主事务和其他子事务）；如果当前没有事务，则该取值等价于REQUIRED。 12.2.2 事务隔离级别TransactionDefinition 接口中定义了五个表示隔离级别的常量，除了默认级别以外，其余四种和SQL中的四种隔离级别一一对应： TransactionDefinition.ISOLATION_DEFAULT: 使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别，Oracle 默认采用的 READ_COMMITTED隔离级别. TransactionDefinition.ISOLATION_READ_UNCOMMITTED: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读 TransactionDefinition.ISOLATION_READ_COMMITTED: 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生 TransactionDefinition.ISOLATION_REPEATABLE_READ: 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 TransactionDefinition.ISOLATION_SERIALIZABLE: 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 12.2.3 事务超时属性事务超时，指一个事务所允许执行的最长时间。如果超过该时间限制但事务还没有完成，则自动回滚事务。 在 TransactionDefinition 中以 int 的值来表示超时时间，其单位是秒，默认值为-1，表示无限制。 12.2.4 事务只读属性readOnly为只读属性，对于只有读取数据查询的事务，可以指定事务类型为 readonly，即只读事务。只读事务不涉及数据的修改，数据库会提供一些优化手段，适合用在有多条数据库查询操作的方法中。 MySQL 默认对每一个新建立的连接都启用了autocommit模式。在该模式下，每一个发送到 MySQL 服务器的sql语句都会在一个单独的事务中进行处理，执行结束后会自动提交事务，并开启一个新的事务。 如果给方法加上了Transactional注解的话，这个方法执行的所有sql会被放在一个事务中。如果声明了只读事务的话，数据库就会去优化它的执行，并不会带来其他的什么收益。 如果不加Transactional，每条sql会开启一个单独的事务，中间被其它事务改了数据，都会实时读取到最新值。会导致一个方法中的多次查询可能出现数据不一致的结果。 比如在一次执行多条查询语句，例如统计查询，报表查询的场景下，多条查询 SQL 必须保证整体的读一致性，否则，如前条 SQL 查询之后，后面的 SQL 查询之前，数据被改变了，则该次整体的统计查询将会出现读数据不一致的状态。 12.2.5 事务回滚规则事务的回滚规则定义了哪些异常会导致事务回滚而哪些不会。 默认情况下，事务只有遇到运行期异常（RuntimeException 的子类）时才会回滚，Error也会导致事务回滚，在遇到检查型（Checked）异常时不会回滚。 可以自定义特定的异常类型，只需要为rollbackFor赋不同的值。 十三、其他问题13.1 Spring的启动过程 创建beanFactory，加载xml配置文件。 解析配置文件转化beanDefination，获取到bean的所有属性、依赖及初始化用到的各类处理器等。 刷新beanFactory容器，初始化所有单例bean。 注册所有的单例bean并返回可用的容器，一般为扩展的applicationContext。 13.2 Spring的BeanFactory和ApplicationContex容器Bean 工厂(com.springframework.beans.factory.BeanFactory)是 Spring框架最核心的接口，它提供了高级IoC的配置机制。BeanFactory使管理不同类型的Java对象成为可能，com.springframework.context.ApplicationContext建立在 BeanFactory基础之上，提供了更多面向应用的功能，它提供了国际化支持和框架事件体系，更易于创建实际应用。我们一般称BeanFactory为IoC容器，而称ApplicationContext为应用上下文。但有时为了行文方便，我们也将ApplicationContext称为Spring容器。 二者的主要区别是，BeanFactory是延迟加载，比如说，如果Bean没有完全注入，BeanFacotry加载后，会在第一次调用getBean方法才会抛出异常；而ApplicationContext会在初始化的时候就加载并且检查，这样的好处是可以及时检查依赖是否完全注入。通常来说我们会选择使用ApplicationContext。 对于二者的用途，我们可以进行简单的划分： BcanFactory是 Spring框架的基础设施，面向Spring本身； ApplicationContext面向使用 Spring框架的开发者，几乎所有的应用场合都可以直接使用ApplicationContext而非底层的 BeanFactory。 13.3 Spring是如何解决循环依赖的参考Spring如何解决循环依赖，源码解析、Spring如何解决循环依赖 循环依赖：bean对象直接互相依赖，比如A中依赖B，同时B中也依赖A，就构成了循环依赖，在注册Bean时就要考虑先后的问题。 Spring中的循环依赖有三种情况： 构造器注入形成的循环依赖。也就是beanB需要在beanA的构造函数中完成初始化，beanA也需要在beanB的构造函数中完成初始化，这种情况的结果就是两个bean都不能完成初始化，循环依赖难以解决。 setter注入构成的循环依赖。beanA需要在beanB的setter方法中完成初始化，beanB也需要在beanA的setter方法中完成初始化，Spring设计的机制主要就是解决这种循环依赖 prototype作用域bean的循环依赖。这种循环依赖同样无法解决，因为spring不会缓存prototype作用域的bean，而Spring中循环依赖的解决正是通过缓存来实现的。 Spring只能解决setter注入构成的依赖，使用三级缓存结构，提前曝光的思想： singletonObjects：一级缓存，用于保存实例化、注入、初始化完成的bean实例，即完全初始化好的bean，即成品bean对象。从该缓存中取出的bean可以直接使用。 earlySingletonObjects：二级缓存，用于保存实例化完成的bean实例，尚未填充属性，即半成品的bean对象。用于解决循环依赖。 singletonFactories：三级缓存，用于保存bean工厂对象，实例化半成品bean并放到二级缓存，用于解决循环依赖。 没有循环依赖的情况下，创建好完成品bean之后，才创建对应的代理。但是Spring并不知道有没有循环依赖，因此其选择了不提前创建代理对象，在出现循环依赖被其他对象注入时，才实时生成代理对象。 在对象外面包一层ObjectFactory，做到了提前曝光又不生成代理。在被注入时才使用ObjectFactory.getObject方法生成代理对象，并将生成好的代理对象放到二级缓存中。 具体步骤： 首先 A 完成初始化第一步并将自己提前曝光出来（通过ObjectFactory 将自己提前曝光，将其包装为ObjectFactory对象然后存放到三级缓存），在初始化的时候，发现自己依赖对象 B，此时就会去尝试 get(B)，这个时候发现 B 还没有被创建出来 。 然后创建 B，在 B 初始化的时候，同样发现自己依赖A，于是尝试 get(A)，这个时候由于 A 已经被包装为工厂类对象并被添加至缓存（三级缓存 ）中，所以可以通过 ObjectFactory.getObject() 方法来拿到 A 对象（A的半成品，同时也是代理对象，然后半成品A会被放到二级缓存），B拿到 A 对象后顺利完成初始化，然后将自己添加到一级缓存中。 回到 A，A 也可以拿到 B 对象，完成初始化，到这里整个链路就已经完成了初始化过程了。 Spring是通过递归的方式获取目标bean及其所依赖的bean的 Spring实例化一个bean的时候，是分两步进行的，首先实例化目标bean，然后为其注入属性。 另外，为什么需要三级缓存，而不是二级缓存，也就是bean构造完成后就生成代理对象？ 因为没有出现循环依赖的情况下，Spring的初衷就是在Bean生命周期的最后一步完成代理，而不是实例化之后马上生成代理对象。 二级缓存便于存放半成品bean对象，二级缓存和三级缓存就是为了解决循环依赖问题才设置的，三级缓存的实现提供了提前生成代理的口子，而不是直接生成代理，只有发生循环依赖执行getObject才会执行代理，从而达到了只有循环依赖发生时，才提前代理，而没有循环依赖，则代理方式不变，依然是初始化以后代理的目的。Spring循环依赖及三级缓存 13.4 Spring框架中用到了哪些设计模式参考Spring中都用到了那些设计模式? 工厂模式：比如Spring使用BeanFactory、ApplicationContext创建bean对象。 代理模式：AOP的核心就是代理模式 单例模式：Spring中的Bean默认就是单例模式 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式 ：Adapter Pattern，将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。Spring AOP 的增强或通知(Advice)使用到了适配器模式，Spring MVC 中也是用到了适配器模式适配Controller。 参考：JavaGuide-Spring常见问题总结","categories":[{"name":"SSM框架","slug":"SSM框架","permalink":"http://kangshitao.github.io/categories/SSM%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://kangshitao.github.io/tags/Spring/"},{"name":"SSM","slug":"SSM","permalink":"http://kangshitao.github.io/tags/SSM/"}]},{"title":"MyBatis配置与使用","slug":"mybatis-basis","date":"2021-06-21T14:30:22.000Z","updated":"2022-05-22T13:30:54.798Z","comments":true,"path":"2021/06/21/mybatis-basis/","link":"","permalink":"http://kangshitao.github.io/2021/06/21/mybatis-basis/","excerpt":"MyBatis配置文件解析，MyBatis的基本使用","text":"一、MyBatis介绍MyBatis是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。 总结：MyBatis使用XML 或注解替代了传统的DAO实现，开发人员只需要关注SQL语句的编写，不需要花费大量代码去获取数据库连接和处理结果集。 官方文档：https://mybatis.org/mybatis-3/zh/index.html 表现层、业务层、持久层三层框架。 二、MyBatis实现CRUD使用环境： IDEA Ultimate 2020.3 MyBatis 3.4.6 MySQL 5.1.47 Maven 3.8.1 练习代码参考：Mybatis_study 2.1 基本步骤Maven项目中使用MyBatis的大致步骤，和常用的文件目录结构如图： Maven项目中配置MyBatis 2.2 步骤详情2.2.1 pom文件配置要使用MyBatis，首先需要导入其jar包，在mvnrepository网站找到MyBatis依赖，将其放入Maven配置文件中的依赖中即可。同时还需要导入MySQL依赖，其余的根据需求导入。 pom.xml文件是Maven项目的配置文件，其配置了项目的组id，部署id，版本号，依赖包等内容。 这里将Mybatis_study作为父工程，其中包括了多个子模块，只需要在父工程的配置文件中添加依赖，子模块的pom.xml就不再需要额外引入依赖了。 父工程的pom.xml文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--作为父工程--&gt; &lt;groupId&gt;com.kang&lt;/groupId&gt; &lt;artifactId&gt;Mybatis_study&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--子模块--&gt; &lt;modules&gt; &lt;module&gt;mybatis-01&lt;/module&gt; &lt;module&gt;mybatis-02&lt;/module&gt; &lt;module&gt;mybatis-03&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;!--源代码使用的JDK版本--&gt; &lt;maven.compiler.source&gt;15&lt;/maven.compiler.source&gt; &lt;!--编译源代码使用的JDK版本--&gt; &lt;maven.compiler.target&gt;15&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!--在dependencies中添加需要的依赖--&gt; &lt;dependencies&gt; &lt;!--mybatis依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;!--junit依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- log4j依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt;&lt;!--资源插件，使maven在编译时将src/main/java下的指定的文件拷贝到target/classes中--&gt; &lt;resources&gt; &lt;resource&gt; &lt;!--directory，指定要拷贝的目录--&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt;&lt;!--指定目录下的文件，将所有properties后缀和xml后缀的文件都拷贝到target/classes中--&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt;&lt;!-- false表示不启用过滤器，因为上面*.properties已经起到过滤作用了--&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 因为Maven在编译时，默认只会将resource目录下的配置文件添加到target/classes文件夹下，如果使用了Mapper配置文件，则需要在Maven配置文件中使用&lt;resources&gt;标签，使Maven编译时将指定目录下的配置文件也拷贝到target/classes文件夹下。 另一种做法是，在resource目录下，创建和DAO接口相同的目录，将配置文件添加到这个目录下。 项目中这些路径，都是编译后的文件所在的位置，所以原则是保证编译后，能够根据代码中写的路径找到相应的文件。 Maven会将resource目录下的配置文件编译到target/classes目录下，将java目录下的文件也编译到target/classes目录。 如果resource目录下存在一个和java目录相同的子目录，编译后，这两个目录中的内容都会存放在target/classes的同一个目录中，这个路径就是原来的相同的子目录（就是说两个相同的子目录编译后只会存在一个） 2.2.2 MyBatis配置文件mybatis-config.xml配置文件位于resource文件目录下，其包含了对MyBatis系统的核心设置，包括获取数据库连接实例的数据源（DataSource）以及决定事务作用域和控制方式的事务管理器（TransactionManager）等。 mybatis-config.xml的简单示例： 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!--环境配置，可以配置多个环境，并指定一个默认的环境--&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;!--这里需要使用转义字符代替&amp;符号--&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/mybatis?characterEncoding=UTF-8&amp;amp;serverTimezone=UTC\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt;&lt;!--数据库用户--&gt; &lt;property name=\"password\" value=\"123456\"/&gt;&lt;!--密码--&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--Mapper映射--&gt; &lt;mappers&gt; &lt;mapper resource=\"com/kang/dao/UserMapper.xml\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; MyBatis的XML配置文件的按照严格的结构配置，配置文件中的标签书写顺序要严格按照下面的顺序。参考MyBatis官方文档： configuration（配置） properties（属性）：属性可以在外部进行配置，将配置信息写在另外的配置文件然后引入即可。或者可以定义全局变量，在dataSource中的property根据name使用${}获取即可。 settings（设置）：可以设置缓存开启、执行器类型、驼峰命名映射、日志实现等功能。 typeAliases（类型别名）：为Java类型设置别名，仅用于XML文件，使用简短的类名代替全限类名，降低冗余书写。起别名的方式也有多种，可以为一个单独类起别名，可以给一个包起别名，也可以使用注解的方式给类起别名。 typeHandlers（类型处理器） objectFactory（对象工厂） plugins（插件） environments（环境配置）：MyBatis可以配置多种环境，每个SqlSessionFactory实例只能选择一种环境。 environment（环境变量） transactionManager（事务管理器） dataSource（数据源） databaseIdProvider（数据库厂商标识） mappers（映射器）：映射器的作用是告诉MyBatis去哪里找SQL语句执行，填写Mapper配置文件的地址。项目中每个Mapper配置文件都要在这里注册。有四种方式指定资源路径，其中class和package的方式要求配置文件和mapper接口要同名，package还要求配置文件和接口在同一个包下。 2.2.3 获取SqlSession对象使用MyBatis实现CRUD操作，主要是通过SqlSession对象进行的，其类似于传统JDBC中的数据库Connection对象。MyBatis中使用Mapper的概念替换了DAO的概念。 获取SqlSession对象的主要过程如下： 通过SqlSessionFactoryBuilder对象获取SqlSessionFactory对象。（建造者模式） 通过SqlSessionFactory对象获取SqlSession对象。（工厂模式） 通过SqlSession对象生成相应的Mapper实现类对象。 通过Mapper实现类对象调用Mapper中的方法实现CRUD操作。 在java/com/kang/utils路径下，创建MybatisUtils工具类，用户获取SqlSession对象： 1234567891011121314151617181920212223242526272829package com.kang.utils;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import java.io.IOException;import java.io.InputStream;public class MybatisUtils { private static SqlSessionFactory sqlSessionFactory; static { //编译后的文件路径，即target/classes下的路径 String resource = \"mybatis-config.xml\"; InputStream inputStream = null; try { inputStream = Resources.getResourceAsStream(resource); } catch (IOException e) { e.printStackTrace(); } //获取sqlSessionFactory对象 sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); } //根据sqlSessionFactory获取SqlSession对象 public static SqlSession getSqlSession() { //带参的openSession方法可以显式开启和关闭自动提交功能。 //MyBatis默认是关闭自动提交功能的，因此DML语句需要手动提交。 return sqlSessionFactory.openSession(); }} 关于SqlSessionFactoryBuilder、SqlSessionFactory、SqlSession对象的生命周期 SqlSessionFactoryBuilder：一旦创建了 SqlSessionFactory，就不再需要SqlSessionFactoryBuilder了。 因此它的最佳作用域是方法作用域（也就是局部方法变量）。 可以重用 SqlSessionFactoryBuilder 来创建多个 SqlSessionFactory 实例，但最好还是不要一直保留着它，以保证所有的 XML 解析资源可以被释放给更重要的事情。 SqlSessionFactory：SqlSessionFactory 一旦被创建就应该在应用的运行期间一直存在，没有任何理由丢弃它或重新创建另一个实例。 使用 SqlSessionFactory 的最佳实践是在应用运行期间不要重复创建多次，因此 SqlSessionFactory 的最佳作用域是应用作用域。 有很多方法可以做到，最简单的就是使用单例模式或者静态单例模式。 SqlSession：每个线程都应该有自己的 SqlSession 实例。SqlSession 的实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。 绝对不能将 SqlSession 实例的引用放在一个类的静态域，甚至一个类的实例变量也不行。 也绝不能将 SqlSession 实例的引用放在任何类型的托管作用域中，比如 Servlet 框架中的 HttpSession。 如果现在正在使用一种 Web 框架，考虑将 SqlSession 放在一个和 HTTP 请求相似的作用域中。 换句话说，每次收到 HTTP 请求，就可以打开一个 SqlSession，返回一个响应后，就关闭它。 这个关闭操作很重要，为了确保每次都能执行关闭操作，应该把这个关闭操作放到 finally 块中。 2.2.4 编写Bean类和Mapper接口创建pojo或bean目录，然后在其中创建JavaBean类，比如User类： 12345678910111213141516171819202122232425262728293031323334353637package com.kang.pojo;//定义id，name，pwd三个属性public class User { private int id; private String name; private String pwd; public User() {} public User(int id, String name, String pwd) { this.id = id; this.name = name; this.pwd = pwd; } public int getId() {return id;} public void setId(int id) {this.id = id;} public String getName() {return name;} public void setName(String name) {this.name = name;} public String getPwd() {return pwd;} public void setPwd(String pwd) {this.pwd = pwd;} @Override public String toString() { return \"User{\" + \"id=\" + id + \", name='\" + name + '\\'' + \", pwd='\" + pwd + '\\'' + '}'; }} 创建dao目录，在其中编写User类对应的Mapper接口，定义一些操作。比如UserMapper: 12345678910111213141516171819202122232425package com.kang.dao;import com.kang.pojo.User;import java.util.List;import java.util.Map;public interface UserMapper { // 查询全部用户 List&lt;User&gt; getUserList(); // 根据id查询用户 User getUserById(int id); //添加一个用户 int addUser(User user); // 更新用户信息 int updateUser(User user); // 删除用户 int deleteUser(int id);} 2.2.5 Mapper配置文件传统JDBC需要对每个DAO接口创建一个实现类，以供service层使用。在MyBatis中，对每个Mapper接口创建一个配置文件即可，甚至可以不需要Mapper映射文件，直接在Mapper接口中使用注解功能，执行相应的SQL语句。 这里先讨论Mapper映射文件的配置。 创建UserMapper.xml映射文件，内容如下： 1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;!--namespace命名空间，用于绑定一个对应的DAO/Mapper接口,这里和UserMapper绑定。这样相当于写了一个实现类来实现此接口。--&gt;&lt;mapper namespace=\"com.kang.dao.UserMapper\"&gt; &lt;select id=\"getUserList\" resultType=\"com.kang.pojo.User\"&gt; select * from user &lt;/select&gt; &lt;!-- #{id}会被预编译成？号，只有一个参数时参数名称可以随便写 --&gt; &lt;select id=\"getUserById\" resultType=\"com.kang.pojo.User\"&gt; select * from user where id=#{id} &lt;/select&gt; &lt;!--参数是类或者map时，参数名称必须和类中的属性名/map中的key相同--&gt; &lt;insert id=\"addUser\" parameterType=\"com.kang.pojo.User\"&gt; insert into user(id,name,pwd) values(#{id},#{name},#{pwd}) &lt;/insert&gt; &lt;update id=\"updateUser\" parameterType=\"com.kang.pojo.User\"&gt; update user set name=#{name},pwd=#{pwd} where id=#{id} &lt;/update&gt; &lt;delete id=\"deleteUser\"&gt; delete from user where id=#{id} &lt;/delete&gt;&lt;/mapper&gt; 上述映射文件，实现了Mapper接口中每个方法的功能。每个映射文件，都需要写到MyBatis配置文件（即mybatis-config.xml）的&lt;mapper&gt;标签中进行绑定。 2.2.6 执行CRUD语句在以上几步都完成以后，就可以编写代码实施具体的操作，主要步骤为： 从工具类中获取SqlSession对象。 调用SqlSession类的getMapper()方法获取Mapper接口的一个实现类对象。 根据获取的Mapper实现类对象，调用具体的方法完成操作。 关闭SqlSession。 以查询和添加用户为例 1234567891011121314151617181920212223242526272829303132333435363738394041// 查询所有用户@Testpublic void getUserList() { SqlSession sqlSession = null; try { // 1.获取SqlSession对象 sqlSession = MybatisUtils.getSqlSession(); // 2.获取UserMapper接口实现类对象。 UserMapper mapper = sqlSession.getMapper(UserMapper.class); // 3.通过mapper调用方法完成功能 List&lt;User&gt; userList = mapper.getUserList(); for (User user : userList) { System.out.println(user); } } catch (Exception e) { e.printStackTrace(); } finally { //关闭SqlSession if(sqlSession != null){ sqlSession.close(); } }}//添加一名用户@Testpublic void addUser() { SqlSession sqlSession = null; try { sqlSession = MybatisUtils.getSqlSession(); UserMapper mapper = sqlSession.getMapper(UserMapper.class); mapper.addUser(new User(1, \"test\", \"test\")); sqlSession.commit(); //提交事务 } catch (Exception e) { e.printStackTrace(); } finally { if(sqlSession != null){ sqlSession.close(); } }} 这样，使用MyBatis进行CRUD的基本流程就大致完成了，下面讨论其中的详细配置和要注意的问题。 三、XML映射文件Mapper映射文件中，一共有9个顶级元素，每个顶级元素有自己的参数配置，可以参考官方文档-XML映射器 cache – 该命名空间的缓存配置。 cache-ref – 引用其它命名空间的缓存配置。 resultMap – 结果映射，描述如何从数据库结果集中加载对象，是最复杂也是最强大的元素。 parameterMap – 参数映射。已被废弃，将来可能被移除，建议使用行内参数映射。 sql – 可被其它语句引用的可重用语句块。类似于JSP中的common元素，在别的语句中通过include标签引入，提高代码可重用性。 insert – 映射插入语句。 update – 映射更新语句。 delete – 映射删除语句。 select – 映射查询语句。 3.1 一些参数说明select元素的参数和insert/update/delete参数有区别。下面重点说明几个重要的参数。 id：命名空间中唯一的标识符，可以被用来引用这条语句，值为Mapper接口的方法名 resultType：select元素特有。 期望从这条语句中返回结果的类全限定名或别名。 如果返回的是集合，那应该设置为集合包含的类型，而不是集合本身的类型。 resultType 和 resultMap 之间只能同时使用一个。 resultMap：select元素特有。 对外部 resultMap 的命名引用。结果映射是 MyBatis 最强大的特性。 parameterType：将会传入这条语句的参数的类全限定名或别名。这个属性是可选的，因为MyBatis 可以通过类型处理器（TypeHandler）推断出具体传入语句的参数，默认值为未设置（unset）。 关于parameterType的@Param 参考自：http://www.mybatis.cn/archives/920.html 1、简单类型不需要设置parameterType。 2、复杂的参数类型需要设置parameterType，比如传入一个对象时，需要使用，比如： 1234&lt;insert id=\"insertUser\" parameterType=\"User\"&gt; insert into users (id, username, password) values (#{id}, #{username}, #{password})&lt;/insert&gt; 此时，User 类型的参数对象传递到了语句中，会查找 id、username 和 password 属性，然后将它们的值传入预处理语句的参数中。 此外，parameterType的值还可以使用map(这里是别名)传递，表示参数类型是Map，参数的名称为Map中的key： 12345&lt;select id=\"selectUsers\" resultType=\"User\" parameterType=\"map\"&gt; select id, username, password from users where id = #{id} and age = #{age}&lt;/select&gt; 3、复杂类型也可以使用@Param的方式，此时不需要设置parameterType。 Mapper接口中： 1public List&lt;Users&gt; getUsers(@Param(\"name\") String name, @Param(\"age\") int age); 映射文件中的语句： 12345&lt;select id=\"selectUsers\" resultType=\"User\"&gt; select id, username, password from users where id = #{id} and age = #{age}&lt;/select&gt; 使用@Param注解的方式，不需要设置参数类型，参数名称为注解定义的名称，这种方式只适用于参数较少的情况。 3.2 结果映射resultMap用于对结果集进行映射。其和resultType只能同时一个。简单情况下，可以直接使用resultType=\"map\"实现简单的映射，比如： 12345&lt;select id=\"getUserById\" resultType=\"map\"&gt; select id, username, pwd from user where id = #{id}&lt;/select&gt; 这种情况下，语句简单地将所有的列映射到 HashMap 的键上，这由 resultType 属性指定。虽然在大部分情况下都够用，但是 HashMap 并不是一个很好的领域模型。实际情况下更可能会使用 JavaBean 或POJO（Plain Old Java Objects）作为resultType，比如： 12345&lt;select id=\"getUserById\" resultType=\"com.kang.pojo.User\"&gt; select id, username, pwd from user where id = #{id}&lt;/select&gt; 对于一些复杂情况，比如联表查询，或者属性名和表字段名不一致时，必须使用resultMap进行映射。 3.2.1 使用resultMap解决列名和属性名不一致问题对于User表，数据库中属性是id，name，pwd，而Javabean中属性为id，name，password。二者的密码属性名称不一致，会导致查出来结果为null。 其中一种解决方法是在SQL语句中给列名起别名，使其和属性名保持一致： 12345&lt;select id=\"getUserById\" resultType=\"com.kang.pojo.User\"&gt; select id, username, pwd as password from user where id = #{id}&lt;/select&gt; 第二个方法是使用resultMap进行结果集映射： 12345678910&lt;select id=\"getUserById\" parameterType=\"int\" resultMap=\"UserMap\"&gt; select id,name,pwd from user where id=#{id};&lt;/select&gt;&lt;resultMap id=\"UserMap\" type=\"com.kang.pojo.User\"&gt; &lt;result column=\"id\" property=\"id\"/&gt; &lt;result column=\"name\" property=\"name\"/&gt; &lt;result column=\"pwd\" property=\"password\"/&gt;&lt;/resultMap&gt; resultMap中有两个重要的参数，主要用于多表查询： association：一个复杂类型的关联；许多结果将包装成这种类型。用于一对一或多对一查询，查询结果是对于一个对象时使用。比如多个学生和同一个老师关联。 collection：一个复杂类型的集合。用于一对多或多对多查询，查询结果是多个对象时使用。比如一个老师和多个不同的学生的关系，查询一个老师教的多个不同的学生，应该使用collection。 其他标签和属性，比如： id标签： 将一个列的值映射到一个简单数据类型的属性或字段。id元素对应的属性会被标记为对象的标识符，在比较对象实例时使用。 这样可以提高整体的性能，尤其是进行嵌套结果映射的时候。 result标签：也是将一个列的值映射到一个简单数据类型的属性或字段。 column属性：数据库中的列名，或者是列的别名。类似于resultSet.getString(columnName) 方法的参数。 property属性：映射到列结果的Java类中的字段或属性。如果用来匹配的 JavaBean 存在给定名字的属性，那么它将会被使用。否则 MyBatis 将会寻找给定名称的字段。 3.2.2 N对1查询如果多个表，例如两个表进行一对一或者多对一查询，就需要使用resultMap，具体来说是使用resultMap的association 。 比如，多个学生对应一个老师，类定义如下： Student.java： 123456public class Student { private int id; private String name; private Teacher teacher; ...//get，set方法等} StudentMapper: 12345public interface StudentMapper { //查询所有的学生信息，以及对应的老师的信息 //这个表的所有学生对应一个老师，此时是多对一的关系 List&lt;Student&gt; getStudent();} teacher.java： 12345public class Teacher { private int id; private String name; ...//get，set方法等} 假设当前数据库中，所有的学生的老师都是同一位，即多对一的情况，有两种查询方式，第一种类似于子查询，第二种是结果嵌套（常用）。 查询语句如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;!-- 多对一 思路一：子查询 1.查询所有的学生信息 2.根据结果中的tid，查询老师信息--&gt;&lt;select id=\"getStudent\" resultMap=\"StudentTeacher\"&gt; select * from student;&lt;/select&gt;&lt;resultMap id=\"StudentTeacher\" type=\"com.kang.pojo.Student\"&gt; &lt;result property=\"id\" column=\"id\"/&gt; &lt;result property=\"name\" column=\"name\"/&gt;&lt;!--association 关联column表示调用该查询语句时传入的参数是什么--&gt; &lt;association property=\"teacher\" column=\"tid\" javaType=\"com.kang.pojo.Teacher\" select=\"getTeacherName\"/&gt;&lt;/resultMap&gt;&lt;select id=\"getTeacherName\" resultType=\"com.kang.pojo.Teacher\"&gt; select * from teacher where id=#{id};&lt;/select&gt;&lt;!--==========================================--&gt;&lt;!-- 思路二：按照结果嵌套查询 --&gt;&lt;select id=\"getStudent2\" resultMap=\"StudentTeacher2\"&gt; select s.id as sid, s.name as sname, t.id as tid, t.name as tname from student s,teacher t where s.tid=t.id;&lt;/select&gt;&lt;resultMap id=\"StudentTeacher2\" type=\"com.kang.pojo.Student\"&gt; &lt;id property=\"id\" column=\"sid\"/&gt; &lt;result property=\"name\" column=\"sname\"/&gt; &lt;association property=\"teacher\" javaType=\"com.kang.pojo.Teacher\"&gt; &lt;id property=\"id\" column=\"tid\"/&gt; &lt;result property=\"name\" column=\"tname\"/&gt; &lt;/association&gt;&lt;/resultMap&gt; 3.2.3 N对多查询一个老师对应多个学生，查询老师和其学生，就是一对多/多对多的问题。 Teacher.java 123456public class Teacher { private int id; private String name; private List&lt;Student&gt; students; //一个老师教多名学生 ...//get，set方法等} TeacherMapper 1234public interface TeacherMapper { //获取指定老师的信息及其教的所有学生信息 Teacher getTeacherById(int id);} Student.java 123456public class Student { private int id; private String name; private int tid; ...//get，set方法等} 多对多和一对多的查询是相似地，都是使用collection，同样有两种方式： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;select id=\"getTeacherById\" resultMap=\"getTeacherStudent\"&gt; select t.id as tid, t.name as tname, s.id as sid, s.name as sname, s.tid as stid from student s, teacher t where t.id=#{id} and s.tid=t.id;&lt;/select&gt;&lt;resultMap id=\"getTeacherStudent\" type=\"com.kang.pojo.Teacher\"&gt; &lt;id property=\"id\" column=\"tid\"/&gt; &lt;result property=\"name\" column=\"tname\"/&gt; &lt;collection property=\"students\" ofType=\"com.kang.pojo.Student\"&gt; &lt;id property=\"id\" column=\"sid\"/&gt; &lt;result property=\"name\" column=\"sname\"/&gt; &lt;result property=\"tid\" column=\"stid\"/&gt; &lt;/collection&gt;&lt;/resultMap&gt;&lt;!-- 方式二：嵌套子查询 1.先查询指定id的老师 2.根据指定老师id查询所有符合条件的学生 --&gt;&lt;select id=\"getTeacherById2\" resultMap=\"getTeacherStudent2\"&gt; select * from teacher where id=#{id};&lt;/select&gt;&lt;resultMap id=\"getTeacherStudent2\" type=\"com.kang.pojo.Teacher\"&gt; &lt;id property=\"id\" column=\"id\"/&gt; &lt;result property=\"name\" column=\"name\"/&gt; &lt;!--结果是一个List对象，集合中的元素是Student类--&gt; &lt;!-- 这里的javaType可以省略 --&gt; &lt;collection property=\"students\" column=\"id\" javaType=\"List\" ofType=\"com.kang.pojo.Student\" select=\"getStudentsByTid\" /&gt;&lt;/resultMap&gt;&lt;select id=\"getStudentsByTid\" resultType=\"com.kang.pojo.Student\"&gt; select * from student where tid=#{tid};&lt;/select&gt; 注意到，在association和collection标签中，出现了ofType和javaType两种类型，二者都是用来指定对象类型的，区别如下： javaType用来指定pojo类中属性的类型，如果property标签的值不是集合，就使用javaType。一般用于association标签中。 比如N对一查询中，Student类中的teacher属性，只是一个对象，不是集合，类型是Teacher类，因此使用javaType，值为com.kang.pojo.Teacher。 在N对多的查询中，Teacher类中的students属性，是一个List类型，因此其值为List。 ofType用来指定集合中存储元素的类型。当property标签的值是集合的时候使用ofType，值为集合中元素的类型。 比如在N对多查询中，Teacher类中的students属性，是一个List类型，List中的元素类型是Student类型，因此ofType=\"com.kang.pojo.Student\"。 四、注解4.1 使用方法前面说过，MyBatis有两种方式实现SQL语句，可以通过XML映射文件实现SQL语句，也可以使用注解的方式，直接在Mapper接口的方法上用注解： 12@Select(\"select * from user where ${column} = #{value}\")User findByColumn(@Param(\"column\") String column, @Param(\"value\") String value); 其中@Param为参数注解，指定参数的值应该对应到SQL语句中的哪个参数。 上述使用注解的方法不需要XML映射文件，使用时直接传入参数即可： 123User userOfId1 = userMapper.findByColumn(\"id\", 1L);User userOfNameKid = userMapper.findByColumn(\"name\", \"kid\");User userOfEmail = userMapper.findByColumn(\"email\", \"noone@nowhere.com\"); 其中 ${column} 会被直接替换，而 #{value} 会使用 ? 预处理，从而实现根据不同列查询。 但是使用${}存在SQL注入的问题。 关于@Param注解： 其和parameterType的对比可以参考3.1节的内容。 @Param注解的作用是给参数命名，命名后的参数可以根据名字将其值传入到SQL语句中，一般使用#{}的方式。 如果方法有多个参数，如果使用参数注解，则每个参数都必须使用@Param注解。只有一个参数时可以不用写@Param注解，但建议加上。 SQL语句中参数#{name}取的就是@Param{\"name\"}中的name。 在不使用@Param注解的时候，函数的参数只能为一个，并且在查询语句取值时只能用#{}。如果想传递多个参数，parameterType参数类型为map（此处为别名，对应类型为Map）或者为JavaBean类。 而使用@Param注解则可以使用多个参数，无需再设置parameterType，并且在查询语句中使用时可以使用#{}或者${}。 4.2 ${} 和 #{}的区别${}和#{}是两种取变量的方式，二者的区别如下： ${}是 Properties 文件中的变量占位符，它可以用于标签属性值和 sql 内部，属于静态文本替换。 比如${driver}会被静态替换为com.mysql.jdbc.Driver。 使用${}存在SQL注入的问题。 #{}是 sql 的参数占位符，MyBatis 会将 sql 中的#{}预编译为?号，在 sql 执行前会使用PreparedStatement的参数设置方法，按序给SQL语句的?号占位符设置参数值。#{}没有SQL注入的问题。 五、动态SQL动态SQL能够根据不同的条件自动拼接SQL语句，MyBatis中借用OGNL（对象图导航语言）的表达式实现动态SQL。主要有以下四种元素： if choose ( when, otherwise ) trim ( where, set ) foreach 5.1 if使用if可以根据条件判断是否要添加条件： 123456789&lt;select id=\"queryBlogIf\" resultType=\"com.kang.pojo.Blog\"&gt; select * from blog where state = ‘ACTIVE’ &lt;if test=\"title != null\"&gt; and title like concat('%',#{title},'%') &lt;/if&gt; &lt;if test=\"author != null\"&gt; and author = #{author} &lt;/if&gt;&lt;/select&gt; 根据传入的参数，判断是否满足对应的条件，如果满足条件，会将语句加上。 这里的模糊查询，使用了concat函数，能够防止SQL注入。同时参数只需要传入value值即可，否则参数中还需要传入%。 5.2 choose、when、otherwiseif条件只要满足，就会使用，如果只想使用一个条件，可以使用choose结构： 123456789101112131415&lt;select id=\"findActiveBlogLike\" resultType=\"Blog\"&gt; SELECT * FROM BLOG WHERE state = ‘ACTIVE’ &lt;choose&gt; &lt;when test=\"title != null\"&gt; AND title like #{title} &lt;/when&gt; &lt;when test=\"author != null\"&gt; AND author_name like #{author.name} &lt;/when&gt; &lt;otherwise&gt; AND featured = 1 &lt;/otherwise&gt; &lt;/choose&gt;&lt;/select&gt; choose最多只会匹配一个条件，即使有多个条件满足，也只会从上到下匹配到最先满足条件的语句。 otherwise表示如果所有的when条件没有一个满足的，则使用otherwise中的语句。 5.3 trim、where、set以上条件的where是固定的，如果将where改为动态的，就需要考虑一个问题，即条件中的and什么时候添加，或者where改写在哪个条件中。 使用where可以完美解决这个问题： 123456789101112131415&lt;select id=\"findActiveBlogLike\" resultType=\"Blog\"&gt; SELECT * FROM BLOG &lt;where&gt; &lt;if test=\"state != null\"&gt; state = #{state} &lt;/if&gt; &lt;if test=\"title != null\"&gt; AND title like #{title} &lt;/if&gt; &lt;if test=\"author != null and author.name != null\"&gt; AND author_name like #{author.name} &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; where 元素只会在子元素返回任何内容的情况下才插入 “WHERE” 子句。而且，若子句的开头为 “AND” 或 “OR”，where 元素也会将它们去除。 同样地，set元素可以用于”INSERT”中动态插入： 12345678910&lt;update id=\"updateAuthorIfNecessary\"&gt; update Author &lt;set&gt; &lt;if test=\"username != null\"&gt;username=#{username},&lt;/if&gt; &lt;if test=\"password != null\"&gt;password=#{password},&lt;/if&gt; &lt;if test=\"email != null\"&gt;email=#{email},&lt;/if&gt; &lt;if test=\"bio != null\"&gt;bio=#{bio}&lt;/if&gt; &lt;/set&gt; where id=#{id}&lt;/update&gt; set元素会动态地在行首插入”SET”关键字，并会删掉额外的逗号。 where和set都可以看作是trim的特例。 其中上述的where用trim元素写为： 1234&lt;!-- AND和OR后面的空格要加上，保证SQL语句拼接正确 --&gt;&lt;trim prefix=\"WHERE\" prefixOverrides=\"AND |OR \"&gt; ...&lt;/trim&gt; prefixOverrides属性会忽略通过管道符分隔的文本序列（空格是必要的）。上述例子会移除所有 prefixOverrides属性中指定的内容，并且插入 prefix属性中指定的内容。 上述的set用trim元素写为： 123&lt;trim prefix=\"SET\" suffixOverrides=\",\"&gt; ...&lt;/trim&gt; 5.4 foreachforeach用于对集合进行遍历，比如IN条件语句： 123456789&lt;select id=\"selectPostIn\" resultType=\"domain.blog.Post\"&gt; SELECT * FROM POST P WHERE ID in &lt;foreach item=\"item\" index=\"index\" collection=\"list\" open=\"(\" separator=\",\" close=\")\"&gt; #{item} &lt;/foreach&gt;&lt;/select&gt; 其中item表示本次迭代的项，index表示索引，collection表示集合对象，这里为list，可以传入List、Map、SET等任何可迭代对象。 上述语句对应的SQL语句为：SELECT * FROM POST P WHERE ID in (?,?,...,?)，其中参数的个数为集合中项的个数。 5.5 script在带注解的映射器接口类中使用动态SQL，可以使用script元素，比如： 1234567891011@Update({\"&lt;script&gt;\", \"update Author\", \" &lt;set&gt;\", \" &lt;if test='username != null'&gt;username=#{username},&lt;/if&gt;\", \" &lt;if test='password != null'&gt;password=#{password},&lt;/if&gt;\", \" &lt;if test='email != null'&gt;email=#{email},&lt;/if&gt;\", \" &lt;if test='bio != null'&gt;bio=#{bio}&lt;/if&gt;\", \" &lt;/set&gt;\", \"where id=#{id}\", \"&lt;/script&gt;\"})void updateAuthorValues(Author author); 六、MyBatis缓存MyBatis的缓存分为一级缓存(本地缓存)和二级缓存： 一级缓存：作用域为一个SqlSession域，即一次请求。默认开启。SqlSession关闭后，一级缓存的内容会存放到二级缓存。 比如，同一个SqlSession中，对象中有一个HashMap存放缓存数据。第一次查询操作执行完毕后，会将查询到的数据写到缓存，第二次尝试从缓存中获取数据，如果能够命中，则没必要去查询数据库，可以提高效率。 二级缓存：作用域是整个namespace，即同一个命名空间的所有SqlSession共享二级缓存。默认关闭。 如果两个SqlSession执行相同的查询操作，第二次会直接从二级缓存中获取数据，避免了从数据库中查询。 查询缓存过程：第一次查询时，回去缓存中查找数据，如果没有，则查询数据库，然后将查询的数据放入一级缓存。之后的同一个SqlSession域（类似于同一个请求）中的相同查询能够命中缓存，从缓存中获取数据。当SqlSession关闭时，将一级缓存的内容放入二级缓存。 开启二级缓存，需要在MyBatis核心配置文件的&lt;settings&gt;元素中，设置： 1234&lt;!-- 全局性地开启或关闭所有映射器配置文件中已配置的任何缓存 --&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; 然后在XML映射文件中加入： 12345&lt;!-- 为当前Mapper开启二级缓存 参数都可以省略，使用默认值 --&gt;&lt;cache eviction=\"FIFO\" flushInterval=\"6000\" size=\"512\" readOnly=\"true\"/&gt; 也可以单独为某个方法开启是否使用缓存。 开启二级缓存后，还需要将要缓存的pojo实现Serializable接口，为了将缓存数据取出执行反序列化操作，因为二级缓存数据存储介质多种多样，不一定只存在内存中，有可能存在硬盘中。 二级缓存可用的清除策略有： LRU – 最近最少使用：移除最长时间不被使用的对象。（默认策略） FIFO – 先进先出：按对象进入缓存的顺序来移除它们。 SOFT – 软引用：基于垃圾回收器状态和软引用规则移除对象。 WEAK – 弱引用：更积极地基于垃圾收集器状态和弱引用规则移除对象。 insert/delete/update 语句的flushCache参数默认为true，意味着这几种语句会自动刷新缓存。 二级缓存是事务性的。这意味着，当 SqlSession 完成并提交时，或是完成并回滚，但没有执行DML语句时，缓存也会获得更新。 七、日志Mybatis 通过使用内置的日志工厂提供日志功能。内置日志工厂将会把日志工作委托给下面的实现之一： SLF4J Apache Commons Logging Log4j 2 Log4j JDK logging MyBatis 内置日志工厂会基于运行时检测信息选择日志委托实现。它会（按上面罗列的顺序）使用第一个查找到的实现。当没有找到这些实现时，将会禁用日志功能。 可以在MyBatis核心配置文件的&lt;settings&gt;元素中，开启日志工厂，比如log4j： 12&lt;!--日志工厂实现--&gt;&lt;setting name=\"logImpl\" value=\"LOG4J\"/&gt; 使用log4j的前提是需要导入其jar包，在Maven配置文件中导入log4j的依赖。 使用log4j需要使用配置文件，在resources文件夹中创建log4j.preperties配置文件，配置log4j的具体信息。可以参考log4j官方文档：https://logging.apache.org/log4j/2.x/javadoc.html 一个可供参考的log4j配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# Loggers :日志记录器，控制日志的输出级别和日志是否输出# Appenders：输出端，指定日志的输出方式（比如到控制台、文件、远程服务器、数据库等）# Layout：控制日志信息的输出格式# 日志级别：# OFF 最高日志级别，关闭所有日志# FATAL 将会导致应用程序退出的错误# ERROR 发生错误事件，但仍不影响系统的继续运行# WARN 警告，即潜在的错误情形# INFO 一般用于粗粒度级别上，强调应用程序的运行全程# DEBUG 一般用于细粒度级别上，对调试应用程序非常有帮助# ALL 最低等级，打开所有日志记录# 常用Error、Warn、INFO、Debug四种### 根设置#### 用于设置制定级别以上的日志输出到指定输出端,名字和个数可以任意，但是需要和后面的设置对应。# 输出DEBUG级别以上的日志到控制台和文件log4j.rootLogger=DEBUG,console,file### 输出到控制台的相关设置 #### 调用ConcoleAppender类，输出到控制台log4j.appender.console=org.apache.log4j.ConsoleAppender# 默认值是System.outlog4j.appender.console.Target=System.out# 指定日志的最低输出级别，默认是DEBUGlog4j.appender.console.Threshold=DEBUGlog4j.appender.console.layout=org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern=[%c]-%m%n### 输出到文件的相关设置 #### 调用RollingFileAppender，文件大小到达指定尺寸的时候产生一个新文件log4j.appender.file=org.apache.log4j.RollingFileAppender# 输出到指定文件log4j.appender.file.File=./log/kang.log# 默认为true，表示添加到末尾，如果是false则表示覆盖log4j.appender.file.Append=true# 设置单个日志文件大小。KB、MB、GBlog4j.appender.file.MaxFileSize=10MBlog4j.appender.file.Threshold=DEBUG# PatternLayout，灵活指定布局模式log4j.appender.file.layout=org.apache.log4j.PatternLayoutlog4j.appender.file.layout.ConversionPattern=[%p][%d{yy-MM-dd}][%c]%m%n### 日志输出级别 ###log4j.logger.org.mybatis=DEBUGlog4j.logger.java.sql=DEBUGlog4j.logger.java.sql.Statement=DEBUGlog4j.logger.java.sql.ResultSet=DEBUGlog4j.logger.java.sql.PreparedStatement=DEBUG 八、其他问题参考JavaGuide","categories":[{"name":"SSM框架","slug":"SSM框架","permalink":"http://kangshitao.github.io/categories/SSM%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://kangshitao.github.io/tags/MyBatis/"},{"name":"SSM","slug":"SSM","permalink":"http://kangshitao.github.io/tags/SSM/"},{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"SQL","slug":"SQL","permalink":"http://kangshitao.github.io/tags/SQL/"}]},{"title":"MySQL数据库高级篇-索引和性能优化","slug":"mysql-advance","date":"2021-06-07T04:00:31.000Z","updated":"2022-05-22T13:30:54.799Z","comments":true,"path":"2021/06/07/mysql-advance/","link":"","permalink":"http://kangshitao.github.io/2021/06/07/mysql-advance/","excerpt":"MySQL索引的使用，索引优化，性能优化；MySQL锁机制，MVCC，主从复制。","text":"首先需要了解MySQL的逻辑架构： MySQL逻辑架构 还可以参考这篇：一条 SQL 语句在 MySQL 中如何执行的 什么原因会导致SQL执行速度变慢呢？ 1、查询语句写的有问题。 2、索引失效。 3、由于设计缺陷或者不得已的需求，导致关联查询有太多join连接。 4、服务器各个参数设置问题。 如果想要提高SQL语句执行效率，就要从以上几个方面入手，其中索引是主要的关注点。 一、索引介绍1.1 索引简介索引（Index）是帮助MySQL高效获取数据的数据结构。除数据本身之外，数据库还维护着一个满足特定查找算法的数据结构，这些数据结构以某种方式指向数据，这样就可以在这些数据结构的基础上实现高级查找算法，这种数据结构就是索引。 索引的本质是数据结构。可以简单理解为“排好序的快速查找数据结构”。也就是说索引不仅可以用于查找，也可以用于排序。 常见的索引结构有：B树（B+树是一种扩展的B树）、Hash、R-Tree等 B-Tree，即B树，B+Tree是一种扩展的B-Tree，读作B+树，B-Tree不是B-树。:-) 1.2 索引底层结构索引的底层数据结构有B树、哈希、R-Tree(空间数据索引)等。 MySQL使用的B树结构作为索引的数据结构，具体来说是使用B+树的结构实现的。这里主要讨论MySQL数据库的InnoDB引擎的B+树结构。 使用show index from 表名;可以查看指定表的索引情况，其中index_type为BTREE说明MySQL确实使用的是B树实现的索引结构，更具体点来说是用的扩展的B树，即B+树。 索引信息 Hash哈希索引 （Hash index）基于哈希表实现，只有精确匹配索引所有列的查询才有效#4。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码(hash code)，哈希码是一个较小的值，并且不同键值的行计算出来的哈希码也不一样。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。 在MySQL中，只有Memory引擎显式支持哈希索引。这也是 Memory引擎表的默认索引类型，Memory引擎同时也支持B-Tree索引。值得一提的是，Memory引擎是支持非唯一哈希索引的，这在数据库世界里面是比较与众不同的。如果多个列的哈希值相同，索引会以链表的方式存放多个记录指针到同一个哈希条目中。 Hash索引最大的优点就是能够在很短的时间内，根据 Hash 函数定位到数据所在的位置，也就是说 Hash索引检索指定数据的时间复杂度可以接近 O(1)。 MySQL 并没有使用 Hash 索引而是使用 B+树作为索引的数据结构的原因： Hash 冲突问题。 Hash 索引不支持顺序和范围查询。这是Hash索引最大的缺点*，假如我们要对表中的数据进行排序或者进行范围查询，那 Hash 索引就无效了，会导致全表扫描。 试想一种情况: 1SELECT * FROM tb1 WHERE id &lt; 500; Hash 索引是根据 hash 算法来定位的，在这种范围查询中，Hash索引无法处理的，而B树结构优势很大，直接遍历比500小的叶子节点即可。 B-TreeB-Tree，即B树，多路平衡查找树，B+树是B树的一种变体。MySQL使用B树作为索引结构，但是没有直接使用B树的结构，而是使用B树的变体B+树，不同的存储引擎对于B+树的具体实现是不同的。 B树和B+树结构对比，参考自[MySQL索引背后的数据结构及算法原理]： B树每个非叶子节点由n-1个key和n个指针组成，这n-1个key划分出了n个范围。这些key限定了其子节点中的最值。所有叶子节点具有相同的深度，等于树高h。 B+树的每个非叶子节点的key和指针个数相等，即n个key，n个指针，key表示子节点元素中的最大（或最小）元素。 B 树的所有节点既存放键(key)也存放数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。 B 树的叶子节点都是独立的，在MySQL中为了提高区间访问的性能，在经典B+树的叶子节点中额外添加了一条引用链，指向与它相邻的叶子节点。（是双向指针，可以用来正序排序和逆序排序） 一般所说的B+树都是MySQL这种叶子节点带顺序访问指针的B+树。 B树和B+树的结构图如下，来自知乎： B-Tree结构图 B+树 上图的B+树的结点值，表示子节点元素的最大值，也可以是表示子节点元素的最小值，两种方式均可。 对于B+树在MySQL中的实现索引的结构，可以参考下图： 建立在B-Tree结构（从技术上来说是B+Tree）上的索引 B-Tree对索引是顺序组织存储的，因此很适合查找范围数据，比如一个包含last_name、first_name和dob列的索引，其B树结构（使用B+树实现）如下： B-Tree(技术上来说是B+Tree)索引树中BUFF条目示例 MySQL使用的是B+树作为索引结构的实现，而没有直接使用B树，这是为什么呢？ 索引往往以索引文件的形式存储在磁盘上，这样索引的查找过程要产生磁盘I/O消耗，而I/O操作很耗时，I/O次数越多，查询的效率也就越低。因此索引的结构要尽量减少磁盘I/O操作次数。 对于查询单个值：B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了，查询性能不稳定。而 B+树的任何查找都是从根节点到叶子节点的过程，查询次数就是树的高度，检索效率稳定。 对于查询连续数据：由于B树在非叶子节点中存储了数据，导致查询连续数据时可能会带来更多额外I/O操作，因为叶子节点的不连续，可能会多次I/O查找目标节点，因此查询时间很长。而B+树只在叶子节点存储键和数据，其他非叶子节点只存储了键（以及指向子树的指针），并且所有叶子节点可以通过指针相互连接，减少了顺序遍历时产生的额外I/O操作，从而大大提升了效率。因此对于区间查询，B+树更简便实用。 对于连续数据（范围）查找的举例，对于上图的B树和B+树，比如要查询[45,70]区间的所有节点： B树中的查找过程： ①加载根节点所在的页，发现59大于45； ②根据根节点指针加载左节点所在的页，发现44小于45； ③继续加载右节点所在的页，找到节点51； ④然后从51开始，进行中序遍历，重新加载44所在的节点，发现没有70，再向上加载根节点59，然后加载节点72，最后找到63。如果每次加载算一次随机I/O操作的话，一共需要7次I/O操作。如果重复加载不算次数，至少也需要5次I/O B+树中的过程：加载[59,97]节点-&gt;加载[15,44,59]节点-&gt;加载[51,59]节点所在的页，利用叶子节点指针顺序遍历，加载[63,72]节点所在的页。最多需要4次I/O操作。减少了额外的I/O操作 R-Tree（空间数据索引）以下内容来自《高性能MySQL 第3版》： MyISAM表支持空间索引，可以用作地理数据存储。和B-Tree索引不同，这类索引无须前缀查询。空间索引会从所有维度来索引数据。查询时，可以有效地使用任意维度来组合查询。必须使用MySQL 的GIS相关函数如MBRCONTAINS()等来维护数据。MySQL的GIS支持并不完善，所以大部分人都不会使用这个特性。开源关系数据库系统中对GIS的解决方案做得比较好的是 PostgresQL的PostGIS。 1.3 MyISAM和InnoDB索引对比不同的存储引擎对于B+树的实现方式不同，以MyISAM和InnoDB引擎为例。 MyISAM存储引擎 使用前缀压缩技术使得索引更小。 MyISAM的索引文件和数据文件是分离的，属于“非聚簇索引（或非聚集索引）”。B+树叶子节点的 data 域存放数据记录的地址。在索引检索的时候，首先按照 B+树搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。 InnoDB存储引擎 InnoDB按照原数据格式进行存储索引。 而InnoDB则根据主键引用被索引的行。 InnoDB 引擎中，表数据文件本身就是按B+树组织的一个索引文件，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键id，因此InnoDB表数据文件本身就是主键索引。这被称为“聚簇索引（或聚集索引）”，而其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据。而根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。 1.4 索引种类从逻辑上，根据索引列是否是主键，索引可以分为主键索引（primary key）和二级索引（辅助索引）。 1.4.1主键索引数据表的主键列使用的就是主键索引。 InnoDB的主键索引叶子节点存放的是数据本身，即的形式，id是主键，可以通过id找到该行的全部列数据。 一张数据表只能有一个主键，并且主键不能为null，不能重复。 在 MySQL 的InnoDB引擎的表中，当没有显式地指定表的主键时，InnoDB会自动先检查表中是否有唯一索引的字段，如果有，则选择该字段为默认的主键，否则 InnoDB将会自动创建一个 6Byte 的自增主键。 对于InnoDB来说，其主键索引是聚簇索引，data域存储数据本身。而MyISAM的索引属于非聚簇索引，因此其主键索引的叶子节点存放的是数据地址。 1.4.2 二级索引二级索引又叫辅助索引，二级索引的叶子节点存储的数据是主键。即的形式。 二级索引属于非聚集索引。 通过二级索引，可以定位主键的位置，有需要的话再根据主键找当前行的数据。 唯一索引、普通索引、前缀索引等都属于二级索引： 唯一索引（Unique key）：唯一索引也是一种约束（唯一键）。唯一索引的属性列不能有重复的数据，允许数据为null，一张表允许创建多个唯一索引。一般来说，唯一索引的目的是为了保证数据的唯一性，而不是为了查询效率。 普通索引（index）：普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。 前缀索引（Prefix）：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。 全文索引（Full Text)：全文索引是一种特殊类型的索引，主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。 其中，如果一个索引只包含单个列，这样的索引为单值索引，一张表可以有多个单列索引。 类似的，复合索引指的是一个索引包含多个列。 1.5 聚集索引和非聚集索引从存储结构上，索引分为聚集索引和非聚集索引。 聚集索引和非聚集索引决定了数据库的物理存储结构，即索引结构和数据是否一起存放，主键只是逻辑上的组织方式，不同引擎的主键索引存储结构也不同。 1.5.1 聚集索引聚集索引是指索引结构和数据一起存放的索引。InnoDB的主键索引属于聚集索引。 MySQL中InnoDB 引擎表的 .ibd文件就包含了该表的索引和数据，对于 InnoDB 引擎表来说，该表的索引(B+树)的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据。 聚集索引的优点聚集索引的查询速度非常的快，因为整个 B+树本身就是一棵多叉平衡排序树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。 聚集索引的缺点 依赖于有序的数据 ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序。数据是整型的还好，如果是类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。 更新代价大 ： 如果对索引列的数据修改时，那么对应的索引也将会被修改， 聚集索引的叶子节点存放着数据本身，修改代价较大， 所以对于主键索引来说，主键一般都是不可被修改的。 1.5.2 非聚集索引非聚集索引即索引结构和数据分开存放的索引。 二级索引属于非聚集索引。 MySQL中MyISAM引擎的表的.MYI文件包含了表的索引， 该表的索引(B+树)的每个叶子非叶子节点存储索引， 叶子节点存储索引和索引对应数据的指针，指向.MYD文件的数据。 非聚集索引的data域除了存储数据地址（指针）以外，还可以存放主键，比如二级索引属于非聚簇索引，其叶子节点的data域存放的是主键，根据主键回表查询数据。 非聚集索引的优点由于非聚集索引的叶子节点不存放数据本身（叶子节点的data域是数据地址或主键），因此非聚集索引的更新代价比聚集索引小。 非聚集索引的缺点 非聚集索引也依赖于有序的数据 可能会二次查询(回表查询) ：这是非聚集索引最大的缺点。当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询，也就是回表操作。 非聚集索引不一定会导致回表查询，比如覆盖索引情况下就不会回表查询： 如果要查询的字段正好建立了索引（无论是单值索引还是复合索引，只要索引字段包括要查询的字段就可以），就属于覆盖索引，不会回表查询： 1SELECT name FROM table WHERE name='john'; 索引字段包括了name列，查询的时候，索引的key本身就是name，查到对应的name直接返回就行，无需回表查询数据。 对于MyISAM引擎中的主键索引，虽然其主键索引的叶子节点存放的是指针。但是如果 SQL 查的就是主键，也算是覆盖索引，不会导致回表查询： 1SELECT id FROM table WHERE id=1; 1.6 覆盖索引如果一个索引包含（或者说覆盖）所有需要查询的字段的值，称为“覆盖索引（Covering Index）”。 就是说select的数据列只从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件，换句话说，查询列要被所建的索引覆盖。 比如在 InnoDB存储引擎中，如果不是主键索引，叶子节点存储的是key+主键。最终还是要“回表”，也就是要通过主键再查找一次，这样就会比较慢。覆盖索引就是要查询的列和索引是对应的，不做回表操作！ 覆盖索引即需要查询的字段正好是索引的字段，直接根据该索引就可以查到数据， 无需回表查询。 例如： 如果需要查询name，name字段有索引，那么直接根据索引就可以查找到name的值，无需回表查询。 1.7 索引优缺点1.7.1 索引的优点 索引可以加快数据的检索速度，提高检索效率，降低数据库的IO成本。 通过索引对数据进行排序，降低排序成本。 唯一性索引可以保证数据库表中每一行数据的唯一性。 1.7.2 索引的缺点 索引也是一张表，需要耗费物理空间。 创建索引和维护索引耗费时间长，对表中数据更改时，如果数据有索引，也要修改索引，会降低SQL执行效率。 使用索引不一定会提高性能。多数情况下，索引查询比全表扫描要快，如果数据量不大，索引带来的提升也不大。 1.8 索引的使用1.8.1 适合使用索引的情况创建的索引应该尽量符合以下条件，即适合建立索引的情况： 不为null的字段：索引字段的数据应该尽量不为 NULL，因为对于数据为 NULL 的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为 NULL，建议使用 0,1,true,false 这样语义较为清晰的短值或短字符作为替代。 频繁查询的字段。 频繁作为查询条件的字段：即经常出现在where条件里的字段。 频繁需要排序的字段：因为索引是排好序的，这样查询的时候可以利用索引的排序，加快排序查询时间。 频繁用于和其他表关联的字段：频繁用于和其他表连接的字段可能是外键列（不同于外键），对于频繁被连接查询的字段，建立索引可以提高多表连接查询的效率。 一般情况下考虑创建组合索引而不是单列索引。索引是B+树结构，多个单列索引占用空间比一个组合索引的占用空间要大，且维护成本更高。 查询中统计或分组的字段适合建索引。 考虑在字符串类型的字段上使用前缀索引代替普通索引。前缀索引仅限于字符串类型，比普通索引占用更小的空间。 1.8.2 不适合使用索引的情况以下情况不适合使用索引： 表记录太少。 频繁更新的字段，或者频繁增删改的表，不适合建立索引。因为数据更新也必须更新索引，维护索引的成本也不小，会导致更新表速度下降。 包含大量重复内容的字段不适合建立索引。索引的选择性越高，索引的效率越高。 索引的选择性指索引列中不同值/记录总数的比值，比如100条数据，只有两种值，其选择性是0.5，如果有99种不同的值，选择性是0.99，选择性越接近于1，索引效率越高。 where条件里面用不到的字段不创建索引。 1.9 索引创建和删除查看索引1SHOW INDEX FROM 表名; 创建索引为了可读性，索引名一般命名为idx_表名_列名的格式，比如student表中的学号age的索引名：idx_student_age 1、添加主键索引（primary key） 1ALTER TABLE 表名 ADD PRIMARY KEY (列名); # 指定列作为主键，会自动创建主键索引。 2、添加唯一索引（UNIQUE） 1ALTER TABLE 表名 ADD UNIQUE (列名); 3、添加普通索引（INDEX） 12345# 写法1ALTER TABLE 表名 ADD INDEX 索引名 (列名);# 写法2CREATE INDEX 索引名 ON 表名 (列名); 4、添加全文索引（FULLTEXT） 1ALTER TABLE 表名 ADD FULLTEXT (列名); 5、添加复合索引 12345# 写法1ALTER TABLE 表名 ADD INDEX 索引名 (列名1,列名2,...);# 写法2CREATE INDEX 索引名 ON 表名 (列名1,列名2,...); 删除索引1、删除主键索引 1ALTER TABLE stuinfo DROP PRIMARY KEY; 2、删除一般索引 12345# 写法1ALTER TABLE 表名 DROP INDEX 索引名;# 写法2DROP INDEX 索引名 ON 表名; 二、索引优化分析2.1 性能分析2.1.1 MySQL Query OptimizerMySQL Query Optimizer是MySQL中专门负责优化SELECT语句的优化器，其主要功能是通过计算分析系统中收集到的统计信息，为客户端请求的Query提供它认为最优的执行计划（优化器认为最优的数据检索方式，不一定是开发人员认为是最优的，这部分最耗费时间)。 当客户端向MySQL请求一条Query，命令解析器模块完成请求分类，区别出是SELECT并转发给查询优化器，MySQL Query Optimizer首先会对整条Query进行优化，处理掉一些常量表达式的预算，直接换算成常量值。并对Query中的查询条件进行简化和转换，如去掉一些无用或显而易见的条件、结构调整等。然后分析Query 中的 Hint 信息(如果有)，看显示Hint信息是否可以完全确定该Query 的执行计划。如果没有Hint 或Hint信息还不足以完全确定执行计划，则会读取所涉及对象的统计信息，根据 Query进行写相应的计算分析,然后再得出最后的执行计划。 2.1.2 MySQL常见瓶颈 CPU：数据装入内存或从磁盘上读取数据的时候，可能会导致CPU饱和。 IO：磁盘I/O瓶颈发生在装入数据远大于内存容量的时候。 服务器硬件的性能瓶颈：可以通过top，free，iostat，vmstat指令查看系统的性能状态。 2.1.3 Explain简介使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理SQL查询语句的。 Explain关键字用于分析查询语句或是表结构的性能瓶颈。官网介绍：链接 使用方法为： 1234EXPLAIN 查询语句;# 举例：EXPLAIN SELECT * FROM staffs WHERE name='july' AND age=20 AND pos='dev'; Explain的作用 可以得知表的读取顺序。 可以得知数据读取操作的操作类型 可以得知哪些索引可以使用、实际使用了哪些索引。 可以得知表之间的引用。 可以得知每张表有多少行被优化器查询。 可以得知是否使用filesort或者temporary（临时表）等操作。 Explain结果分析执行Explain+SQL语句以后，输出的结果有以下几种类型： Explain结果类型 每一行表示一张表的查询，包括实际存在的表和临时表（子查询重命名的表）。 其中各字段的含义如下。 id 表示select查询的序列号，表示查询中执行select子句或操作表的顺序。 如果id相同，则执行顺序从上往下依次执行， 如果id不同，id越大执行优先级越高，一般是最里层的子查询id最大，最先执行。 如果id既有相同的也有不同的，则可以认为相同id的为一组，按照前两条规则执行 例如： 既有相同id，也有不同id的情况 上图的例子中，可以看到，先执行id为2的语句，再依次往下执行id为1的语句。 select_type 表示查询的类型，主要是用于区别普通查询、联合查询、子查询等复杂查询。包括以下集中状态： SIMPLE：表示简单的select查询，查询中不包含子查询或UNION。 PRIMARY：查询中若包含任何复杂的子部分，最外层的查询就会被标记为PRIMATY。 SUBQUERY：子查询，出现在select或where列表中的子查询会被标记为SUBQUERY。 DERIVED：在FROM列表中包含的子查询被标记为DERIVED（衍生），MySQL会递归执行这些子查询，把结果放在临时表里。 UNION：出现在UNION之后的select语句就会被标记为UNION。 UNION RESULT：从UNION表中获取结果的SELECT。 如图中的例子 select_type举例 table 表示这一行是关于哪张表的。 type 展示了查询使用了何种类型。 type的结果值从好到坏依次是：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL。 其中常见的几种类型，从好到坏依次是： system：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现，可以忽略不计。 const：表示通过索引一次就找到了，const用于比较PRIMARY KEY和UNIQUE索引，因为只匹配一行数据，所以很快。比如where条件中是主键，MySQL能将该查询转换为一个常量。 举例：explain select * from t1 where id = 1; eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配，常见于主键或唯一索引扫描。 举例：explain select * from t1,t2 where t1.id = t2.id;，t2中只有一条数据与之对应，因此类型是eq_ref. ref：非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以它应该属于查找和扫描的混合体。 举例：explain select * from t1 where col1='ac';，其中t1中的索引为idx_t1_clo1_col2。t1中符合条件的数据有多条，因此类型为ref。 range：只检索给定范围的行，使用一个索引来选择行。一般在where语句中出现了between、&lt;、&gt;、in等关键字的查询语句中会出现range类型。这种范围扫描索引扫描比全表扫描要好，因为它只需要开始于索引的某一点，而结束于另一点，不用扫描全部索引。 举例：explain select * from t1 where id between 30 and 60; index：Full Index Scan，index和ALL的区别是index类型只遍历索引树。这通常比ALL快，因为索引文件通常比数据文件小。就是说虽然index和ALL都是读全表，但是index是从索引中读取的，而ALL是从硬盘中读取的。 举例：explain select id from t1;，id为主键。 ALL：Full Table Scan，遍历全表找到匹配的行。 举例：explain select * from t1 where column_without_index = ' ';，对于没有索引的查询条件，需要扫描全表，效率最差。 一般来说，得保证查询至少达到range级别，最好能达到ref级别。 possible_keys 显示可能应用在这张表中的索引，一个或多个。 如果查询涉及的字段上存在索引，则该索引将被列出，但不一定被查询实际使用。 key 实际使用的索引。如果为NULL，表明没有用到索引。 如果查询中使用了覆盖索引，则该索引仅出现在key列表中，不会在possible_keys中出现。 比如下面的例子，对col1和col2建立了复合索引，查询内容为col1和col2，是覆盖索引。因此，possible_keys的值为NULL，索引idx_col1_col2只出现在key列表中。 覆盖索引的例子 key_len 表示索引中使用的字节数，可通过该列计算出查询中使用的索引长度（即使用了几列的索引）。 在不损失精确性的情况下，长度越短越好。key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。 如下图的例子，使用到一个列索引时key_len值为13字节，使用到两个索引列时，key_len的值为26字节。 key_len例子 ref 表示哪些列或常量被用于查找索引列上的值。 如图中的例子，第二行ref的shared.t2.col1表示使用t1中的索引查询时，使用到了t2的col1这一列，const表示使用到了常量，即常量’ac’。 ref例子 rows 根据表统计信息和索引选用情况，大致估算出找到所需记录需要读取的行数。 如下面的例子： rows优化案例 第一条查询语句是没有索引时查询的情况，可以看到表t2需要读取的行数为640；第二条查询语句在t2上建立了索引，这时表t2使用到了索引，所需读取的行数从640优化到了142。 Extra 包含不适合在其它列中显示但十分重要的额外信息。 Extra包括以下几个值： Using filesort：说明MySQL会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。MySQL无法利用索引完成的排序操作称作”文件排序“。出现这种情况会严重拖慢效率。比如对col1和col2两列建立复合索引，但是select中的ORDER BY子句不是按照col1和col2的顺序排序，就会导致索引失效，并出现using filesort。 Using temporary：说明使用了临时表保存中间结果，MySQL对查询结果排序时使用临时表。常见于排序ORDER BY和分组GROUP BY。这种情况比Using filesort还要糟糕。 Using index：表示相应的select操作中使用了索引覆盖，避免了访问表的数据行，是我们希望看到的。其中，如果同时出现了using where，表示索引被用来根据索引键值查找数据（即根据索引值判断数据是否是符合条件的值）。如果没有同时出现using where，表示索引用来读取数据（仅读取索引值），而非执行查找动作。 Using where：表明使用了where过滤。 using join buffer：使用了连接缓存。 impossible where：表明where子句的值总是false，不会有符合条件的数据。 select tables optimized away：没有GROUP BY子句的情况下，基于索引优化MIN、MAX操作或者对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。 distinct：优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作。 Explain例题 Explain例题 对以上信息，分析如下： 分析内容 2.2 索引优化2.2.1 索引分析单表案例建表： 1234567891011121314CREATE TABLE IF NOT EXISTS article(id INT(10) UNSIGNED NOT NULL PRIMARY KEY AUTO_INCREMENT,author_id INT(10) UNSIGNED NOT NULL,category_id INT(10) UNSIGNED NOT NULL,views INT(10) UNSIGNED NOT NULL,comments INT(10) UNSIGNED NOT NULL,title VARBINARY(255) NOT NULL,content TEXT NOT NULL);INSERT INTO article(author_id,category_id,views,comments,title,content)VALUES(1,1,1,1,'1','1'),(2,2,2,2,'2','2'),(1,1,3,3,'3','3'); article表 逐步优化过程： 1、初始时，表格没有普通索引，执行下列语句： 123EXPLAIN SELECT id,author_id FROM article WHERE category_id=1 AND comments&gt;1 ORDER BY views DESC\\G 末尾的\\G表示以键值对的形式显示内容，不需要加分号。 结果为： 123456789101112*************************** 1. row *************************** id: 1 select_type: SIMPLE table: article type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 3 Extra: Using where; Using filesort1 row in set (0.00 sec) 可以看到type为ALL，表示全表扫描，并且出现了Using filesort。 接下来尝试对其优化。 2、第一次优化：尝试对where条件和order by中设计的三个列都建立索引： 123456# 对三个列建立索引CREATE INDEX idx_article_ccv ON article(category_id,comments,views);# 再次执行SQL语句EXPLAIN SELECT id,author_id FROM article WHERE category_id=1 AND comments&gt;1 ORDER BY views DESC\\G 初步优化后，Explain语句运行结果为： 123456789101112*************************** 1. row *************************** id: 1 select_type: SIMPLE table: article type: rangepossible_keys: idx_article_ccv key: idx_article_ccv key_len: 8 ref: NULL rows: 1 Extra: Using index condition; Using filesort1 row in set (0.00 sec) 可见，第二次运行用到了我们建立的索引，并且type变为了range，表示范围内查找，比ALL效率提升了，但是Using filesort还在。 为什么建立了索引，还出现了Using filesort呢？ 根据B+树索引的结构分析可知，对category_id、comments、views三列建立复合索引，在B+树中是先根据category_id排序，category_id相同时，根据comments排序，views同理，这样就建立起一个排好序的索引B+树结构。 查询条件中，由于第二个条件是comments&gt;1，是个范围，因此会导致其后面的列，即views列的索引失效。因为第二列是个范围，查询时需要遍历所有范围内的索引，因此第三列的索引用不到了，根据views排列时用不到索引就需要使用文件排序。 经过以上分析，可知，假如第二个条件也是常量，索引就不会失效，从而也不会导致Using filesort: 123EXPLAIN SELECT id,author_id FROM article WHERE category_id=1 AND comments=1 ORDER BY views DESC\\G 上述语句的结果为： 123456789101112*************************** 1. row *************************** id: 1 select_type: SIMPLE table: article type: refpossible_keys: idx_article_ccv key: idx_article_ccv key_len: 8 ref: const,const rows: 1 Extra: Using where1 row in set (0.00 sec) 可以看到，type变为了ref，根据ref可知用到了两个常量，即前两个索引值都是固定的常量，因此根据索引的第三个列进行排列（正序倒序都可以）时，可以用到索引，因此没有了Using filesort。 如果针对第一次的SQL语句优化，可以考虑不对第二列建立索引。 3、第二次优化，删除第一次建的索引，重新只对category_id和views两列建立索引： 12345678# 删除第一次建立的索引DROP INDEX idx_article_ccv ON article;# 只对category_id和views建立索引CREATE INDEX idx_article_cv ON article(category_id,views);# 再次执行SQL语句EXPLAIN SELECT id,author_id FROM article WHERE category_id=1 AND comments&gt;1 ORDER BY views DESC\\G 这次的结果： 123456789101112*************************** 1. row *************************** id: 1 select_type: SIMPLE table: article type: refpossible_keys: idx_article_cv key: idx_article_cv key_len: 4 ref: const rows: 2 Extra: Using where1 row in set (0.00 sec) 可以看到，这次用到索引的同时，没有了Using filesort，因为两列的索引都用到了。 总结：经过第一个案例可知，如果索引遇到范围，则其后面列的索引全部失效。 两表案例class表： 1234567891011121314151617181920212223242526mysql&gt; select * from class;+----+------+| id | card |+----+------+| 1 | 18 || 2 | 18 || 3 | 16 || 4 | 7 || 5 | 5 || 6 | 3 || 7 | 19 || 8 | 5 || 9 | 7 || 10 | 20 || 11 | 20 || 12 | 19 || 13 | 16 || 14 | 3 || 15 | 6 || 16 | 19 || 17 | 16 || 18 | 3 || 19 | 5 || 20 | 17 |+----+------+20 rows in set (0.00 sec) book表： 1234567891011121314151617181920212223242526mysql&gt; select * from book;+--------+------+| bookid | card |+--------+------+| 11 | 1 || 14 | 3 || 8 | 4 || 15 | 4 || 6 | 5 || 18 | 7 || 19 | 7 || 7 | 8 || 17 | 9 || 1 | 10 || 4 | 10 || 16 | 13 || 20 | 13 || 10 | 15 || 3 | 16 || 2 | 17 || 13 | 17 || 9 | 18 || 5 | 19 || 12 | 20 |+--------+------+20 rows in set (0.00 sec) 1、第一次查询，没有任何索引： 1EXPLAIN SELECT * FROM class LEFT JOIN book ON class.card=book.card; 执行结果为： 1234567891011121314151617181920212223*************************** 1. row *************************** id: 1 select_type: SIMPLE table: class type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 20 Extra: NULL*************************** 2. row *************************** id: 1 select_type: SIMPLE table: book type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 20 Extra: Using where; Using join buffer (Block Nested Loop)2 rows in set (0.00 sec) 可以看到，在两个表上的查询，type都是ALL，rows都是20。 2、如果仅在左连接的右边的表中对应列建立索引： 1234# 在book表的card列上建立索引 Y，此时表中仅有一个普通索引YALTER TABLE book ADD INDEX Y (card);# 此时左连接的右表，type变为ref，且rows是1EXPLAIN SELECT * FROM class LEFT JOIN book ON class.card=book.card; 执行结果为： 1234567891011121314151617181920212223*************************** 1. row *************************** id: 1 select_type: SIMPLE table: class type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 20 Extra: NULL*************************** 2. row *************************** id: 1 select_type: SIMPLE table: book type: refpossible_keys: Y key: Y key_len: 4 ref: db01.class.card rows: 1 Extra: Using index2 rows in set (0.01 sec) 可以看到，在class表中的rows仍然是20，但是book表中的rows从20变为了1，且type也从ALL变为了ref，因为用到了建立的索引Y，说明索引Y起到了优化作用。因为有了索引，每次内循环从book表中查询时，只需要根据索引遍历一行数据即可，所以rows是1。 3、如果仅在左连接的左边的表中对应列建立索引 12345#将上一步的索引删掉，然后对表class的card建立索引XDROP INDEX Y ON book;ALTER TABLE class ADD INDEX X (card);# 此时book表中无索引，class表的card列有一个索引xEXPLAIN SELECT * FROM class LEFT JOIN book ON class.card=book.card; 执行结果为: 1234567891011121314151617181920212223*************************** 1. row *************************** id: 1 select_type: SIMPLE table: class type: indexpossible_keys: NULL key: X key_len: 4 ref: NULL rows: 20 Extra: Using index*************************** 2. row *************************** id: 1 select_type: SIMPLE table: book type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 20 Extra: Using where; Using join buffer (Block Nested Loop)2 rows in set (0.00 sec) 可以看到，class表中虽然用到了索引，type是index，但是rows仍然是20，book表中没有索引因此也是20。 通过以上实验可知，对于左连接，如果对右表的对应列建立索引，优化效果更好。 同理，对于右连接，对左表的对应列建立索引，优化效果更好。 因此，左连接的右表和右连接的左表是优化的重点。 三表案例这次我们使用三表连接： 12345678# 对三个表的card列都建立索引ALTER TABLE class ADD INDEX X(card);ALTER TABLE book ADD INDEX Y(card);ALTER TABLE phone ADD INDEX Z(card);# 执行三表连接查询语句EXPLAIN SELECT * FROM class LEFT JOIN book ON class.`card`=book.`card` LEFT JOIN phone ON book.`card`=phone.`card`; 执行结果： 三表连接查询 与两表案例类似，无论是否用到索引，最外层的表，即这里的class表，rows一直是20，而book和phone可以通过索引将row降到1。 结论1、通过单表案例可以总结出：如果索引遇到范围，则其后面列的索引全部失效。 2、根据两表和三表案例，可以总结出优化建议： 对于多表连接查询，优化的重点是内层的表，即优化被驱动表带来的效率提升较大。应尽可能减少Join语句中嵌套循环的总次数。（通过被驱动表建立索引，可以降低循环次数）。 永远要用小结果集驱动大结果集，即小表驱动大表，就是说，要将小表作为驱动表，大表作为被驱动表。 在被驱动表上的Join的字段建立索引，可以降低总循环次数，从而提升效率。 无法保证被驱动表的Join条件字段被索引且内存资源充足的前提下，不要太吝啬JoinBuffer的设置。 左连接中，左表是驱动表，右表是被驱动表。 右连接中，右表是驱动表，左表是被驱动表。 内连接时，MySQL自动选择数据量小的表作为驱动表，即小表驱动大表。 为什么要用小表驱动大表？或者说为什么小表驱动大表效率较高？ 解答这个问题前，需要了解嵌套循环的效率对比。 嵌套循环的连接次数是取决于外层循环的，循环体的循环次数不变，如果连接次数越少，则效率越高。 比如： 123456789101112//循环1for(int i=0;i&lt;10;i++){ for(int j=0;j&lt;1000;j++){ //循环体 }}//循环2for(int i=0;i&lt;1000;i++){ for(int j=0;j&lt;10;j++){ //循环体 }} 两个循环的循环体执行次数相同的，但是循环1的执行速度要比循环2快，因为循环1中，i和j初始化的初始化次数分别为1、10次，而循环2中i和j的初始化次数分别是1,、1000次，且循环1的连接次数是10，循环2的连接次数是1000，因此循环1速度快于循环2。参考 MySQL中的连接查询，正是类似于嵌套循环。 以左查询为例，比如SQL语句： 1SELECT * FROM A LEFT JOIN B ON A.c=B.c; 以上连接查询语句可以理解为一个双重for循环，即： 123456for(循环次数为A的行数){ select * from A where 第i行; for(循环次数不确定，直到找到B中符合条件的行位置){ select * from B where B.c=A.c }} 可以看到，驱动表相当于多重for循环的外层循环，被驱动表相当于内层循环。因此驱动表（外层循环）小于被驱动表（内层循环）时，效率较高。 为什么要在被驱动表建立索引？ 驱动表无论是否有索引，都要遍历所有行，而被驱动表则不是这样。从上述for循环的例子可知，对于驱动表A中的当前行，从被驱动表B中查询的次数和是否用到了索引有关。如果没有索引，则会遍历被驱动表B的所有行，找到所有符合当前A.c值的行；如果表B的c行建立了索引，则会根据索引，直接找到所有符合当前A.c值的行，不必遍历所有行。 上述案例中，建立索引之后的rows从20（没有索引，需要遍历所有行）降为了1（有了索引，只需根据索引进行查找）。 2.2.2 避免索引失效从上一节的例子中可以看到，有时候虽然建立了索引，但是遇到了范围，导致了索引失效。有哪些情况会导致索引失效呢？ 下面以staff表说明各种索引失效的情况： staff表格内容 对staff表的name,age,pos三列建立复合索引idx_staffs_nameAgePos： 1ALTER TABLE staffs ADD INDEX idx_staffs_nameAgePos(name,age,pos); 索引失效的情况以下几种情况，会导致索引失效。 1、违反最佳左前缀法则（或全值匹配，最左匹配），导致索引失效（或部分失效） 如果where条件缺少了（即不在where条件中）索引中的某个列，则这个列后面的列都无法使用索引。如果是索引的第一列不在查询条件中，则会导致索引完全失效，如果是中间的某一列不在查询条件中，导致索引部分失效。 MySQL优化器会自动调整where条件的顺序，多个条件的书写顺序对于结果无影响。但还是推荐按照顺序写。 1234567891011121314# 以下四种情况，都正常使用到了索引。EXPLAIN SELECT * FROM staffs WHERE name ='july';EXPLAIN SELECT * FROM staffs WHERE name ='july' AND age=25;EXPLAIN SELECT * FROM staffs WHERE name ='july' AND age=25 AND pos='dev';# 正常使用索引。匹配顺序和书写顺序无关，只要调整顺序以后覆盖即可。EXPLAIN SELECT * FROM staffs WHERE age=25 AND name ='july' AND pos='dev';# 由于缺少了索引的第一列，因此索引完全失效EXPLAIN SELECT * FROM staffs WHERE age=25 AND pos='dev';/* 由于缺少了中间的age列，age列后面的pos列的索引失效,但name列的索引正常使用。这种情况属于索引部分失效。*/EXPLAIN SELECT * FROM staffs WHERE name ='july' AND pos='dev'; 2、在索引上做操作（计算、函数、自动或手动类型转换），导致操作列和之后列索引失效 如果在索引上做任何操作，都会导致操作列及其后面列的索引失效。 123456789# 以下操作，在name上取子串，导致索引全部失效，因为name是索引的第一列EXPLAIN SELECT * FROM staffs WHERE SUBSTRING(name,1,4) ='july';# age列的索引失效，只使用了name列的索引。EXPLAIN SELECT * FROM staffs WHERE name='july' AND age+5=28;# 在中间列age上操作，导致age和之后的pos列索引都失效，只使用了name列索引EXPLAIN SELECT * FROM staffs WHERE name ='july' AND age+5=28 AND pos='dev'; 3、范围条件右边的列索引会失效 如果某一索引列的查询条件是一个范围，会导致其后面的所有列的索引都失效。 1234# 索引的中间列age，因为是范围查找，导致后面的pos列的索引失效。# age列本身的索引不会失效，索引用于排序。EXPLAIN SELECT * FROM staffs WHERE name='july' AND age&gt;20 AND pos='dev'; # 用2个索引 4、使用不等于号(!=或&lt;&gt;)时，导致索引全部失效。 如果索引列的任一列使用了!=或&lt;&gt;，就会导致索引全部失效，造成全表扫描。 123456# 索引全部失效EXPLAIN SELECT * FROM staffs WHERE name &lt;&gt;'july';# 索引全部失效EXPLAIN SELECT * FROM staffs WHERE name ='july' AND age!=21;# 索引全部失效EXPLAIN SELECT * FROM staffs WHERE name ='z3' AND age=22 AND pos&lt;&gt;'dev'; 5、使用is null、is not null，导致当前列和之后列的索引失效 如果索引列的某一列使用了is null或is not null，会导致当前列和其后面所有列的索引都失效。 123456789# 索引完全失效。EXPLAIN SELECT * FROM staffs WHERE name IS NULL;# 索引部分失效，只使用了name列的索引EXPLAIN SELECT * FROM staffs WHERE name = 'july' AND age IS NOT NULL;# 索引部分失效，只使用了name列的索引EXPLAIN SELECT * FROM staffs WHERE name = 'july' AND age IS NOT NULL AND pos='dev'; 6、LIKE条件中，%放在开头，导致当前列和之后列的索引失效 在使用了LIKE的条件语句中，如果将%号放在了开头位置，会导致当前列和之后所有列的索引失效。 12345678910# 索引全部失效EXPLAIN SELECT * FROM staffs WHERE name LIKE '%july'; # 索引全部失效EXPLAIN SELECT * FROM staffs WHERE name LIKE '%july' AND age = 25; # 索引失效# 索引部分失效，只使用了name和age列的索引，pos列的索引失效。EXPLAIN SELECT * FROM staffs WHERE name = 'july' AND age = 23 AND pos LIKE '%dev'; 如果SQL语句中必须要将%写在开头，则可以使用覆盖索引避免索引失效： 1234567891011121314151617# 索引未失效EXPLAIN SELECT name FROM staffs WHERE name LIKE '%july';# 索引未失效EXPLAIN SELECT name,pos,age FROM staffs WHERE name LIKE '%july%';# 索引未失效EXPLAIN SELECT name,pos,age FROM staffs WHERE name = 'july' AND age = 23 AND pos LIKE '%dev';# 索引未失效,id是主键，主键索引为primary，自动创建。也是覆盖索引。EXPLAIN SELECT id,name,pos,age FROM staffs WHERE name LIKE '%july%'; # 索引失效，不是索引覆盖，且%开头。EXPLAIN SELECT name,add_time FROM staffs WHERE name LIKE '%july'; 7、字符类型的字段，查询时常量值不加单引号而触发类型转换，导致当前列和之后列的索引失效 如果某一字段类型是字符类型，比如varchar类型，如果查询语句写的是整型数字（如果是字符串不写引号是语法错误），会触发自动类型转换（同第2条），导致当前列和之后所有列的索引失效。 12345# 索引失效。name列是varchar型，2000会自动转换为varchar型，导致索引失效。EXPLAIN SELECT * FROM staffs WHERE name=2000;# 索引全部失效EXPLAIN SELECT * FROM staffs WHERE name=2000 AND age=23; # 失效 8、使用or时，如果其中一个列没有索引，导致索引全部失效 使用or时，只要其中一个列没有索引，就会导致索引全部失效，其他字段有索引也不会使用。 因为如果其中的列没有索引，必然会导致一次全表扫描，如果带索引的列使用索引，那么总操作就是全表扫描+索引查找+合并，共三部分。于是干脆就不使用索引，直接全表扫描。 1234567891011# 使用全部索引EXPLAIN SELECT name FROM staffs WHERE name = 'july' OR pos ='dev';# 索引全部失效。因为add_time没有索引。EXPLAIN SELECT name FROM staffs WHERE name = 'july' OR add_time = NOW();# 正常使用索引，该使用几个使用几个。# 因为有带索引的列，and条件，一定不会导致全部扫描，先根据索引查找，再判断即可。EXPLAIN SELECT name FROM staffs WHERE name = 'july' AND add_time = NOW(); 索引优化总结根据以上索引分析和索引失效的情况，可以总结出避免索引失效的优化建议： 遵守全值匹配（最左匹配）和最左前缀的规则。 尽量避免缺失索引首列或中间列，以防发生索引全部失效或部分失效的情况 尽量避免在索引列上计算，以防索引失效。 尽量使用覆盖索引，少用*查询，以避免因二次查询非索引列数据导致效率下降。 LIKE条件中，尽量避免将%号写在开头。如果%必须写在开头，可以使用覆盖索引的方式避免索引失效。 一般来说，%越往后，查询效率越高。 尽量避免使用is null、is not null、!=、&lt;&gt;和or，以免导致索引失效。 字符类型的单引号一定要写。 口诀： 123456全值匹配我最爱，最左前缀要遵守;带头大哥不能死，中间兄弟不能断;索引列上少计算，范围之后全失效;LIKE百分写最右，覆盖索引不写星;不等空值还有or，索引失效要少用；VAR引号不可丢，SQL高级也不难！ 2.2.3 一般性建议对于单键索引，尽量选择针对当前query过滤性更好的索引。 在选择组合索引的时候，当前Query中过滤性最好的字段在索引字段顺序中，位置越靠前越好。 在选择组合索引的时候，尽量选择可以能够包含当前query中的where字句中更多字段的索引。 尽可能通过分析统计信息和调整query的写法来达到选择合适索引的目的。 三、查询截取分析SQL优化分析的大致流程： 1、慢查询日志的开启并捕获。 2、explain+慢SQL分析。 3、使用Show Profile查询SQL在MySQL服务器里面的执行细节和生命周期情况。 4、SQL数据库服务器的参数调优（一般是DBA来操作）。 3.1 查询优化3.1.1 永远小表驱动大表小表驱动大表是一个重要的优化原则，即小的数据集驱动大的数据集。 上文已经讨论过小表驱动大表在join时的效率情况，这里讨论的是关于in和exist两种子查询中，使用小表驱动大表的优化情况。 in和exists使用及对比：子查询 使用in关键字的子查询案例： 123456select * from A where id in (select id from B);/*等价于：for (select id from B){ for (select * from A where A.id = B.id)}*/ 使用exists关键字的子查询案例： 123456select * from A where exists (select 1 from B where B.id=A.id);/*等价于for(select * from A){ for(select * from B where B.id=A.id)}*/ 通过以上案例可知，当子查询的数据集（表B）小于主查询（表A）的数据集时，根据小表驱动大表原则，使用in关键字要优于exists，反之，主查询数据集小于子查询数据集时，用exists优于in。 这是由exists和in子查询的执行顺序决定的： 使用in的SQL语句，会先执行子查询语句，然后执行主查询，再判断。 使用exists的SQL语句，会先执行主查询，然后将主查询得到的数据，放到子查询中做条件验证，根据验证结果（TRUE或FALSE)来决定主查询的数据结果是否得以保留。 1、exists子句只返回TRUE或FALSE。子查询中可以是SELECT *，也可以是SELECT 1或其他，实际执行时会忽略 SELECT清单，因此SELECT后写什么都没有区别。 2、exists子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比，如果担忧效率问题，可进行实际检验以确定是否有效率问题。 3、exists子查询往往也可以用条件表达式、其他子查询或者JOIN来替代，何种最优需要具体问题具体分析。 3.1.2 ORDER BY关键字优化优化建议一：ORDER BY子句，尽量使用Index方式排序，避免使用FileSort方式排序。 如果使用order by进行排序，则尽量保证在Explain结果的Extra列，出现Using index而不出现Using filesort。 案例： 12345678910111213141516171819202122# 建表CREATE TABLE tblA(id INT PRIMARY KEY NOT NULL AUTO_INCREMENT, age INT, birth TIMESTAMP NOT NULL);INSERT INTO tblA(age,birth) VALUES(22,NOW());INSERT INTO tblA(age,birth) VALUES(23,NOW());INSERT INTO tblA(age,birth) VALUES(24,NOW());# 在age和birth两列上建立复合索引。CREATE INDEX idx_A_ageBirth ON tblA(age,birth);/*表的内容如下:+----+------+---------------------+| id | age | birth |+----+------+---------------------+| 1 | 22 | 2021-06-02 22:22:43 || 2 | 23 | 2021-06-02 22:22:43 || 3 | 24 | 2021-06-02 22:22:43 |+----+------+---------------------+*/ 在表tblA中，分析以下几个案例，只关注Extra列： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 1.Extra: Using where; Using indexEXPLAIN SELECT * FROM tblA WHERE age&gt;20 ORDER BY age;# 2.Extra: Using where; Using indexEXPLAIN SELECT * FROM tblA WHERE age&gt;20 ORDER BY age,birth;# 3.Extra: Using where; Using index; Using filesort# 由于排序条件缺少复合索引的第一列，并且where中的age是个范围，# 导致birth列的索引失效，MySQL不得不采用filesort方式排序EXPLAIN SELECT * FROM tblA WHERE age&gt;20 ORDER BY birth;# 4.Extra: Using where; Using index# 虽然排序条件缺少了age列，但是where中age是确定的，# 这样就保证了根据birth排序时，将第一列当成常数，birth列可以正常使用索引EXPLAIN SELECT * FROM tblA WHERE age=20 ORDER BY birth;# 5.Extra: Using where; Using index; Using filesort# 虽然根据索引的两个列排序，但是不是按照索引建立的顺序，# 因此也会导致排序时索引失效，出现filesortEXPLAIN SELECT * FROM tblA WHERE age&gt;20 ORDER BY birth,age;# 6.Extra: Using index; Using filesort# 出现了firesort，因为不符合最左覆盖原则，age列是缺失的，导致索引失效EXPLAIN SELECT * FROM tblA ORDER BY birth;# 7.Extra: Using where; Using index; Using filesort# 同样索引失效，因为没有age列EXPLAIN SELECT * FROM tblA WHERE birth &gt; '2021-05-29 16:24:38' ORDER BY birth;# 8.Extra: Using where; Using index# 索引可以使用，因此使用了索引排序EXPLAIN SELECT * FROM tblA WHERE birth &gt; '2021-05-29 16:24:38' ORDER BY age;# 9.Extra: Using index; Using filesort# 因为索引建立时，是根据从小到大排序的，复合索引也是如此，类似于基数排序。# 复合索引的两个列排列规则不一致，会导致排序时索引失效，从而触发filesortEXPLAIN SELECT * FROM tblA ORDER BY age ASC,birth DESC;# 10.Extra: Using index# 这两条都没有触发filesort，因为B+树叶子节点有指向左右叶子节点的指针# 所以无论是从小到大还是从大到小，都可以借助索引排序，前提是多个列的排序规则要一致。EXPLAIN SELECT * FROM tblA ORDER BY age DESC;EXPLAIN SELECT * FROM tblA ORDER BY age DESC,birth DESC; MySQL支持两种排序方式：Index和FileSort，对应于Using index和Using filesort。 Using index扫描索引本身就能完成排序，因此使用索引的效率比使用文件排序的效率要高。 当ORDER BY子句满足以下两种情况时，会使用Index方式排序： ORDER BY语句使用索引最左前列。 使用Where子句与ORDER BY子句条件列组合，满足了索引最左前列的要求，比如上述第4个例子。 优化建议二：尽可能在索引列上完成排序操作，遵照索引建的最佳左前缀条件 ORDER BY之后的列如果没有建立索引，就会导致Using filesort。 ORDER BY之后的列虽然建立索引，但是没有符合最左前缀原则，同样会导致索引失效，触发Using filesort。 如果两个排序列排序规则不一致(比如一个降序一个升序)，也会导致索引失效，出现Using filesort 优化建议三：MySQL的filesort算法的介绍和优化 如果要排序的字段不在索引列上，那么MySQL使用filesort算法排序，filesort算法有两种，包括双路排序和单路排序： 双路排序：MySQL 4.1之前使用的是双路排序，即两次扫描磁盘，最终得到数据。具体来说，读取行指针和orderby 列，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出。简言之，就是从磁盘取排序字段，在buffer中排序，然后根据排序好的字段再从磁盘中读取其他字段的数据。 单路排序：MySQL 4.1之后对双路排序改进。从磁盘读取查询需要的所有列，按照order by列在buffer对它们进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了第二次读取数据。并且把随机IO变成了顺序IO,但是它会使用更多的空间。因为它把每一行都保存在内存中了。 虽然单路排序总体而言好于多路排序，但是其也有缺点： 单路排序比多路排序多占用很多排序缓存(sort_buffer)空间。因为单路排序排序时，把所有字段都取出，所以有可能取出数据的总大小超出了排序缓存的容量，导致每次只能取sort_buffer容量大小的数据进行排序（创建tmp文件，多路合并)，排完再取sort_buffer容量大小，重复这两步，从而导致多次IO，得不偿失。 对filesort单路排序的优化策略： 使用Order by时，只查询需要的字段，避免使用select *'。 这点非常重要。因为：1、当Query的字段大小总和小于max_length_for_sort_data而且排序字段不是TEXTIBLOG类型时，会使用单路排序，否则会用多路排序算法。2、两种算法算法的数据都有可能超出sort_buffer的容量（超出之后，会创建tmp文件进行合并排序，导致多次IO），但是用单路排序算法的风险会更大一些，所以要提高sort_buffer_size。 尝试提高sort_buffer_size。 无论那种算法，提高这个参数都会提高效率，要根据系统能力去提高，这个参数是针对每个进程的。 尝试提高max_length_for_sort_data。 提高这个参数，会提高用单路排序的概率。但如果设置的太高，数据容量超出sort_buffer_size的概率就会增大，明显症状是提高磁盘I/O活动和处理器使用率变低。 3.1.3 GROUP BY关键字优化GROUP BY的实质是先排序后分组，同样遵照索引建的最佳左前缀。 因此GRUOP BY的优化策略和ORDER BY一致，唯一不同的是，where高于having，能写在where中的就不要写在having中。 3.2 慢查询日志3.2.1 慢查询日志介绍MySQL的慢查询日志是MySQL提供的一种日志记录，用来记录在MySQL中响应时间超过阈值的语句，具体指运行时间大于long_query_time（默认是10秒）值的SQL语句，会被记录到慢查询日志中。 比如long_query_time的值为5时，执行时间大于5秒的SQL就会被记录到慢查询日志中。 3.2.2 慢查询日志的使用默认情况下，MySQL数据库没有开启慢查询日志，需要手动开启。 如果不是调优需要，不建议开启慢查询日志，因为开启慢查询日志或带来一定的性能影响。 查看慢查询日志是否开启： 1SHOW VARIABLES LIKE '%slow_query_log%'; 开启慢查询日志： 12SET GLOBAL slow_query_log=1; # 1或TRUE都表示TRUE# 只对当前数据库生效；MySQL重启后失效。 如果想要使开启状态永久生效，需要修改配置文件my.cnf(其他系统变量也是如此)： 修改my.cnf文件，在mysqld下增加或修改参数： 12345# 设置开启状态slow_query_log=1;# 设置慢查询日志文件路径。# 如果没有指定，系统会默认给一个名为host_name-slow.log文件slow_query_log_file=/var/lib/mysql/localhost-slow.log 设置完以后，需要重启MySQL服务器。 查看记录到慢查询日志中的阈值时间： 12# 默认是10秒SHOW VARIABLES LIKE '%long_query_time%'; 同样地，可以使用SET命令修改，或者在my.cnf配置文件里修改。 注意：大于long_query_time才会记录到慢查询日志中，等于这个时间的SQL语句不会被记录。 查询当前系统中有多少条慢查询记录： 1SHOW GLOBAL STATUS LIKE '%Slow_queries%'; 慢查询日志文件的内容举例： 慢查询日志文件内容 3.2.3 日志分析工具mysqldumpslow实际生产环境中，可以使用日志分析工具mysqldumpslow，用来分析日志，查找、分析SQL。 在Linux服务器中使用mysqldumpslow命令可以使用mysqldumpslow工具的各种功能。 查看帮助信息： 1mysqldumpslow --help help信息的部分内容，详细参考mysqldumpslow命令： -s：表示按照何种方式排序，其后可跟以下几个参数，表示不同的排序方式 aI：平均锁定时间 ar：平均返回记录数 at：平均查询时间 c：次数 l：锁定时间 r：查询行数 t：查询时间 -r：反转排序顺序 -t NUM：展示前NUM条查询 -l：从总时间中不减去锁定时间 -g：后面跟正则表达式，大小写不敏感 实例参考 得到返回记录集最多的10个SQL： 1mysqldumpslow -s r -t 10 /usr/local/mysql/data/localhost-slow.log 得到访问次数最多的10个SQL： 1mysqldumpslow -s c -t 10 /usr/local/mysql/data/localhost-slow.log 得到按照时间排序的前10条里面含有左连接的查询语句： 1mysqldumpslow -s t -t 10 /usr/local/mysql/data/localhost-slow.log 3.3 批量数据脚本案例：往表里插入1000万条数据。 1、建表 创建dept表： 123456CREATE TABLE dept( id INT UNSIGNED PRIMARY KEY AUTO_INCREMENT, deptno MEDIUMINT UNSIGNED NOT NULL DEFAULT 0, dname VARCHAR(20) NOT NULL DEFAULT \"\", loc VARCHAR(13) NOT NULL DEFAULT \"\") ENGINE = INNODB DEFAULT CHARSET=GBK; 创建emp表： 1234567891011CREATE TABLE emp( id INT UNSIGNED PRIMARY KEY AUTO_INCREMENT, empno MEDIUMINT UNSIGNED NOT NULL DEFAULT 0, ename VARCHAR(20) NOT NULL DEFAULT \"\", job VARCHAR(9) NOT NULL DEFAULT \"\", mgr MEDIUMINT UNSIGNED NOT NULL DEFAULT 0, hiredate DATE NOT NULL, sal DECIMAL(7,2) NOT NULL, comm DECIMAL(7,2) NOT NULL, deptno MEDIUMINT UNSIGNED NOT NULL DEFAULT 0) ENGINE = INNODB DEFAULT CHARSET=GBK; 2、设置参数 由于开启过慢查询日志，开启了bin-log，必须为我们的function指定一个参数，即使log_bin_trust_function_creators出于开启状态。 1SET GLOBAL log_bin_trust_function_creators =1; 同样地，如果想永久有效，必须将其写入my.cnf配置文件。 3、创建函数，用于随机生成内容，保证每条数据都不同 12345678910111213141516171819202122232425# 功能为返回一个长度为n的随机字符串DELIMITER $$CREATE FUNCTION rand_string(n INT) RETURNS VARCHAR(255)BEGIN DECLARE chars_str VARCHAR(100) DEFAULT 'abcdefghijk1mnopgrstuvwxyzABCDEFJHIJKIMNOPQRSTUVWXYZ'; DECLARE return_str VARCHAR(255) DEFAULT ''; DECLARE i INT DEFAULT 0; WHILE i &lt; n DO # 随机选取一个字符 SET return_str =CONCAT(return_str,SUBSTRING(chars_str,FLOOR(1+RAND()*52),1)); SET i = i +1; END WHILE; RETURN return_str; #最终长度为nEND $$DELIMITER ;#用于随机产生部门编号DELIMITER $$CREATE FUNCTION rand_num() RETURNS INT(5)BEGIN DECLARE i INT DEFAULT 0; SET i = FLOOR(100+RAND()*10); RETURN i;END $$DELIMITER ; 4、创建存储过程，插入数据 12345678910111213141516171819202122232425262728293031# 创建向emp表中插入数据的存储过程DELIMITER $$CREATE PROCEDURE insert_emp(IN START INT(10),IN max_num INT(10))BEGIN DECLARE i INT DEFAULT 0; SET autocommit = 0; #关闭自动提交autocommit REPEAT SET i=i+ 1; INSERT INTO emp(empno, ename ,job ,mgr ,hiredate ,sal ,comm ,deptno) VALUES((START+i),rand_string(6),'SALESMAN',0001,CURDATE(),2000,400,rand_num()); UNTIL i = max_numEND REPEAT;COMMIT;END $$DELIMITER ;# 创建向dept表中插入数据的存储过程DELIMITER $$CREATE PROCEDURE insert_dept(IN START INT(10),IN max_num INT(10))BEGIN DECLARE i INT DEFAULT 0; SET autocommit = 0; #关闭自动提交autocommit REPEAT SET i=i+ 1; INSERT INTO dept(deptno, dname,loc) VALUES((START+i),rand_string(10),rand_string(8)); UNTIL i = max_numEND REPEAT;COMMIT;END $$DELIMITER ; 5、调用存储过程 12345# 向dept表批量插入10条部门数据CALL insert_dept(100,10); # 向emp表批量插入50万条数据CALL insert_emp(100001,500000); 3.4 Show Profile3.4.1 Show Profile介绍Show Profile是MySQL提供的可以用来分析当前会话中语句执行的资源消耗情况的工具，可以用于SQL的调优的测量。 官网介绍：https://dev.mysql.com/doc/refman/8.0/en/show-profile.html 3.4.2 Show Profile使用使用步骤： 1、查看是否支持 1show variables like 'profiling'; 2、开启Show Profile 1set profiling = 1; 3、运行SQL 4、查看结果 1show profiles; 结果中可以查看profile中保存的查询记录的运行时间和SQL语句。 profile中保存的结果 5、诊断SQL：show profile [option,...] for query SQL语句id号; 其中可选的参数有： ALL：显示所有的开销信息。 BLOCK IO：显示块IO相关开销。 CONTEXT SWITCHES：上下文切换相关开销。 CPU：显示CPU相关开销信息。 IPC：显示发送和接收相关开销信息 MEMORY：显示内存相关开销信息 PAGE FAULTS：显示页面错误相关开销信息 SOURCE：显示和Source_function，Source_file，Source_line相关的开销信息 SWAPS：显示交换次数相关开销的信息 使用诊断指令，展示具体SQL的执行过程以及每个步骤消耗的资源信息。比如查询id为15的那条SQL的cpu和block io的使用情况：show profile cpu,block io for query 15;，结果如下： 查询第15个语句的资源消耗情况 日常开发需要注意的结论： 1、converting HEAP to MyISAM：查询结果太大，内存不够用了 2、Creating tmp table：创建临时表，复制数据到临时表，用完再删除。 3、Copying to tmp table on disk：把内存中临时表复制到磁盘。危险信号。 3.5 全局查询日志 永远不要在生产环境开启此功能。 同样的，有两种开启方式，如果想要永久生效，必须写在配置文件中。 3.5.1 编码启用开启全局查询日志： 1set global general_log=1; 设置文件输出格式： 12# 比如，将输出格式设置为TABLE类型set global log_output='TABLE'; 开启并设置输出为TABLE类型以后，所有的SQL语句，都会记录到MySQL库里的general_log表，可以使用以下命令查看： 1select * from mysql.`general_log`; 3.5.2 配置启用在MySQL的配置文件my.cnf中，设置如下： 123456# 开启general_log=1# 记录日志文件的路径general_log_file=/path/logfile# 输出格式log_output=FILE 如果将输出格式设置为FILE，则记录会保存到指定的文件目录，默认路径和慢查询日志相同，默认文件名为localhost.log，比如MySQL 5.6中，/usr/local/mysql/data/localhost.log。 四、MySQL锁机制4.1 锁的定义和分类4.1.1 定义锁是计算机协调多个进程或线程并发访问某一资源的机制。 4.1.2 锁分类1、MySQL中的锁，根据对数据的操作粒度，分为表锁（表级锁，table-level locking）和行锁（行级锁，row-level locking）： 表锁：对当前操作的整张表加锁 行锁：只针对当前操作的行进行加锁。 扩展： MyISAM引擎仅支持表锁。InnoDB引擎支持表锁和行锁，默认采用行锁。 InnoDB引擎的行锁实现算法有三种： Record lock：记录锁，单个行记录上的锁。列必须是唯一索引或者主键列，否则加的锁会变成临键锁。查询语句必须为=，不能是&gt;或&lt;，否则也会变为临键锁。 Gap lock：间隙锁，锁定一个范围，但不包括记录（表中有的边界）本身。基于非唯一索引。比如查询区间为[1,5]，则间隙锁会锁定(1,5)。防止间隙中被其他事务插入数据。 Next-key lock：临键锁，record+gap锁的组合，锁定一个范围和记录本身。临键锁只在非唯一索引列。临键锁是加锁的基本单位。锁定的是左开右闭区间，即(a,b]。如果最后一个值不满足条件（即表中没有），则临键锁退化为间隙锁(a,b)。临键锁解决幻读问题。 MySQL只有在可重复读的隔离级别下才有间隙锁和临键锁 2、根据对数据操作的类型(读/写)，分为读锁和写锁： 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响。 写锁（排它锁）：当前写操作没有完成前，会阻断其他写锁和读锁。 4.2 表锁4.2.1 特点MySQL中锁定粒度最大的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。由于锁定粒度大，导致触发锁冲突的概率最高，并发度最低。 4.2.2 案例分析例一：添加表级读锁假设目前有一个表mylock，两个会话（或者是事务）：session 1和sessoin 2，会话1表示加锁的会话，会话2代表其他会话。 在session 1种对mylock表添加表级锁，读锁： 1lock table mylock read; 一个会话同时只能对一个表加锁 加锁后，对于读操作： session 1只可以查询该表记录，但不能查询其他没有被session 1锁定的表。session 2既可以查询表mylock，也可以查询其他表。 对于写操作： session 1无法对当前表写入或更新数据，也无法对其他表进行写入或更新操作，会提示错误。session 2如果对当前表插入或更新，会一直处于阻塞状态，直到session 1释放锁，session 2的操作才会执行；对于其他表，session 2正常对他们进行操作。 释放锁的指令： 12# 释放当前会话持有的锁unlock tables; 总结：当前会话对某个表添加表级读锁后，只能对其添加表级读锁的表进行读操作，不能写，也不能对没被它锁定的表进行任何操作。其他会话只有对这个表写操作时会阻塞，但可以读，同时对其他表的操作不会受影响。 例二：添加表级写锁session 1对mylock表添加写锁： 1lock tables mylock write; 此时session 1只能对当前表（加写锁的表）进行读和写操作，不能对其他表进行任何操作。 session 2对mylock表进行读写操作都会进入阻塞状态，直到锁释放才会执行。对其他表的操作不受影响。 释放锁： 1unlock tables; 结论MyISAM引擎在执行查询语句前，会自动给涉及的所有表加读锁，在执行增删改操作前，会自动给涉及的表加写锁。MySQL的表级锁有两种模式： 表共享读锁（Table Read Lock） 表独占写锁（Table Write Lock） 根据上述案例，可以总结出两个结论： 对MyISAM表的读操作(加读锁），不会阻塞其他进程对同一表的读请求，但会阻塞对同一表的写请求（包括自己也不能写）。只有当读锁释放后，才会执行其它进程的写操作。 对MyISAM表的写操作(加写锁)，会阻塞其他进程对同一表的读和写操作，只有当写锁释放后，才会执行其它进程的读写操作。 4.2.3 表锁分析查看哪些表被加锁： 1show open tables; 查看表相关状态： 1show status like'table%'; 其结果中，变量Table_locks_immediate表示产生表级锁定的次数（即可以立即获取锁的查询次数，每立即获取锁，值加1）。 Table_lock_waited表示出现表级锁争用而发生等待的次数（即不能立即获取锁的次数，每等待一次，锁值+1)，此值高则说明存在着较严重的表级锁争用情况。 此外，MyISAM引擎的读写锁调度是写优先，这也是MyISAM不适合做写为主表的引擎的原因，因为添加写锁后，其他线程不能做任何操作，大量的更新会使查询很难得到锁，从而造成永远阻塞。因此，要保证MyISAM引擎的表偏读，避免堵塞。 4.3 行锁4.3.1 特点MySQL中锁定粒度最小 的一种锁，只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。由于锁定粒度小，因此并发度高。但加锁的开销也最大，加锁慢，容易出现死锁。 4.3.2 案例分析以下案例的前提当前表使用的是InnoDB引擎，且使用行锁。 1、行锁基本案例情景一：会话1对某一行进行修改操作，但还未提交，此时会话2如果要对同一行进行操作，会被阻塞，直到会话1提交以后，会话2才会被执行。 情景二：会话1对某一行进行修改操作，同时会话2对另一行进行操作，二者互不影响。 2、无索引行锁升级为表锁如果会话1的操作导致索引失效，或者没有使用索引，会导致行锁变为表锁，导致会话1操作时，会话2不能进行写操作（比如update和insert），处于阻塞状态。 和MyISAM的表锁不同的是，这里的其他会话虽然不能进行写操作，但是可以进行读操作。MyISAM中的表锁，其他会话对于此表既不能读也不能写。 例如，表test_innodb_lock中的a和b两列都有单独的索引，且a的类型是INT，b的类型是VARCHAR，此时会话1对其中的一行进行更新，由于自动类型转换，导致了索引失效，从而行锁变为表锁。 12345# 会话1进行更新操作，未提交：update test_innodb_lock set a=44 where b=4000;# 会话2进行写操作,即使不是同一行，也会阻塞，因为行锁升级为了表锁update test_innodb_lock set a=5 where b='5000'; 3、间隙锁的危害关于InnoDB引擎的行锁，有三种实现算法，分别为记录锁、间隙锁、临键锁。根据4.1.2节的介绍，间隙锁锁定的是一个范围，不包括边界值。 间隙锁锁住的是索引记录中的间隔。间隙锁的主要目的，是为了防止其他事务在间隔中插入数据。 如果一个事务使用范围查找，会锁定一个范围，具体范围是什么，需要根据表内容和索引确定。 间隙锁的致命弱点就是，锁定一个范围后，即使某些不存在的键值也会被无辜的锁定，而造成在锁定的时候无法插入锁定键值范围内的任何数据，在某些场景下，可能会对性能造成很大的危害。 关于间隙锁的详细讲解，可以参考链接1、链接2 4、如何锁定某一行如果想要单独锁定某一行，可以在事务中，在语句后面添加for update: 1234begin; # 开启事务，也可以使用set autocommit=0;# 假如想要单独锁定a=8的这一行,在执行语句后面加for updateselect * from test_innodb_lock where a=8 for update;commit; 5、案例结论InnoDB存储引擎实现了行锁，虽然在实现行锁所带来的性能损耗可能比表锁更高，但是在整体并发处理能力方面要远远优于MyISAM的表锁的。当系统并发量较高的时候，Innodb的整体性能和MyISAM相比就会有比较明显的优势。但是，Innodb的行级锁定同样也有其脆弱的一面，当我们使用不当的时候，可能会让Innodb的整体性能表现不仅不能比MyISAM高，甚至可能会更差。 4.3.3 行锁分析使用以下指令查看行锁争夺相关的状态信息： 1show status like 'innodb_row_lock%'; 其结果中，各个状态说明如下： Innodb_row_lock_current_waits：表示当前正在等待锁定的数量。 Innodb_row_lock_time：表示从系统启动到现在，等待的总时间。 Innodb_row_lock_time_avg：表示每次等待所花的平均时间。 Innodb_row_lock_time_max：表示从系统启动到现在，等待最长的一次时间。 Innodb_row_lock_waits：表示系统启动到现在，总共等待的次数。 如果等待次数很高，且每次平均等待时长也很高的时候，就说明系统可能存在问题，需要对系统进行分析，然后优化。 4.3.4 优化建议1、尽可能让所有数据检索都通过索引完成，避免无索引行为导致行锁升级为表锁。 2、合理设计索引，尽量缩小锁的范围。 3、尽可能减少检索条件，避免间隙锁。 4、尽量控制事务大小，减少锁定的资源量和时间。 5、尽可能低级别事务隔离。 4.4 页锁开销和加锁时间介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁和行锁之间，并发度一般。 五、MVCC以下内容参考链接1、链接2 5.1 MVCC介绍MVCC(Mutil-Version Concurrency Control)，多版本并发控制。它使得大部分支持行锁的事务引擎，不再单纯的使用行锁来进行数据库的并发控制，取而代之的是把数据库的行锁与行的多个版本结合起来，只需要很小的开销，就可以实现非锁定读，从而大大提高数据库系统的并发性能。可以将MVCC看成是乐观锁的一种实现。 MVCC主要是对于InnoDB引擎来说的。 5.2 相关概念乐观锁（Optimistic Lock）：总是假设最好的情况，假设一般情况下不会造成冲突，所以取数据时不会上锁。在提交更新时，才会判断是否有冲突。乐观锁适用于多读的情况，可以提高吞吐量。 乐观锁的实现方式主要有两种：CAS（比较并替换）算法、版本号控制。 比如，Java中的util.concurrent.atomic包下面的原子变量类就是使用了CAS实现的。 悲观锁（Pessimistic Lock）：总是假设最坏的情况。对数据操作之前，总是认为会发生冲突，因此会上锁，其他线程如果想操作数据就会进入阻塞状态。悲观锁具有强烈的独占和排他性，共享锁（读锁）和排它锁（写锁）是悲观锁的两种情况。 悲观锁的实现：数据库中的锁机制，比如表锁、行锁等，都是在操作之前先上锁；Java中的synchronized的实现、ReentrantLock的实现。 参考乐观锁和悲观锁、什么是乐观锁、悲观锁 快照读：快照读的实现是基于多版本并发控制，即MVCC的，快照读读取到的数据不一定是最新的数据，好比对某一个版本生成了一个快照，这个快照一旦生成了其中的数据就不会发生改变。MVCC是“维持一个数据的多个版本，使读写操作没有冲突”的一个抽象概念，这个概念的具体实现就是快照读。 比如不加锁的select操作。 当前读：总是读取当前最新版本的数据，会对当前读的数据进行加锁。是悲观锁的一种操作。 比如共享锁、排它锁。 5.3 解决的问题数据库并发场景 读-读：不存在任何问题，也不需要并发控制。 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读。 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失。 MVCC解决并发哪些问题？ MVCC是用来解决读写冲突的无锁并发控制，就是为事务分配单向增长的时间戳。为每个数据修改保存一个版本，版本与事务时间戳相关联。 读操作只读取该事务开始前的数据库快照。 解决问题如下： 并发读-写时：可以做到读操作不阻塞写操作，同时写操作也不会阻塞读操作。 解决脏读、幻读、不可重复读等事务隔离问题，但不能解决上面的写-写 更新丢失问题。 因此有了下面提高并发性能的组合拳： MVCC + 悲观锁：MVCC解决读写冲突，悲观锁解决写写冲突 MVCC + 乐观锁：MVCC解决读写冲突，乐观锁解决写写冲突 5.4 MVCC的实现原理MVCC的实现原理主要是版本链、undo日志、ReadView来实现的。 5.4.1 版本链数据库每行数据中，除了可见数据，还包括了几个隐藏字段，分别是： db_trx_id：6B，最近修改事务id，记录创建或最后一次修改这条记录的事务id db_roll_pointer：7B，回滚指针，指向这条记录的上一个版本 db_row_id：6B，隐含的自增id，如果数据表没有主键，InnoDB会自动以db_row_id生成一个聚簇索引。 还有一个删除flag字段，删除或更新字段时，只是删除flag改变了。 每次对数据库记录进行改动，都会记录一条undo日志，每条undo日志都有一个roll_pointer属性，可以将这些undo日志连起来串成一个链表，对该记录每次更新后，都会将旧值放到一条undo日志中，算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被roll_pointer属性连接成一个链表，这个链表称之为版本链，版本链的头节点就是当前记录最新的值。 每个版本中还包含生成该版本时对应的事务id，用于Read View中判断版本可见性。 5.4.2 undo日志undo log主要用于记录数据被修改之前的日志，在表信息被修改之前会先把数据拷贝到undo log中。 事务进行回滚时，可以通过undo log里的日志进行数据还原。 undo日志的作用： 保证事务进行回滚时的原子性和一致性，当事务进行回滚的时候可以用undo log的数据进行恢复。 用于MVCC快照读的数据，在MVCC多版本控制中，通过读取undo log的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据版本。 InnoDB中，用undo日志保证原子性和一致性，redo日志保证持久性，锁机制保证隔离性。 undo日志的分类 undo日志主要有两种： insert undo log：代表事务在insert新记录时产生的undo log , 只在事务回滚时需要，并且在事务提交后可以被立即丢弃。 update undo log（主要）：事务在进行update或delete时产生的undo log ; 不仅在事务回滚时需要，在快照读时也需要；不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除。 5.4.3 Read View（读视图）事务进行快照读操作的时候生成读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照。 每个事务开启时，都会被分配一个ID，这个ID是递增的，越新的事务ID值越大。其中没有commit的事务称为活跃事务。 Read View记录并维护着系统当前活跃事务的id，是系统中当前不应该被本事务看到的其他事务id列表。 Read View主要是用来做可见性判断，当某个事务执行快照读的时候，对该记录创建一个Read View读视图，根据这个读视图，用来判断当前事务能够看到哪个版本的数据，可能是当前最新版本的数据，也可能是该行记录的undo log里的某个版本的数据。 Read View的几个属性 trx_ids：当前系统活跃（未提交）事务版本号（id）集合 low_limit_id：创建当前读视图时的当前系统最大事务版本号+1 up_limit_id：创建当前读视图时，系统活跃事务的最小版本号。 creator_trx_id：创建当前读视图的事务版本号。 Read View可见性判断 对于某条记录，其对于当前事务的可见性根据以下条件逐步进行判断。 1、db_trx_id&lt;up_limit_id || db_trx_id==creator_trx_id 显示内容。包括两种情况。 第一种，如果当前数据的最近修改事务id，小于读视图中最小活跃事务id，说明该数据肯定是当前事务开启之前就存在了，可以显示给当前事务。 第二种，如果当前数据的最近修改事务id，就是创建当前读视图的事务，说明这个数据就是当前事务自己创建的，自己创建的数据当然可以显示。 2、db_trx_id &gt;= low_limit_id 不显示。 如果当前数据的最近修改事务id，比生成读视图时候的最大事务id还大，说明这个数据是创建当前读视图之后才生成的，所以此数据不显示。 如果不满足此条件，则进行下一步判断。 3、db_trx_id是否在trx_ids（活跃事务）中 不在其中：显示。如果当前数据的最近修改事务id，不在创建读视图时的活跃事务中，说明创建读视图的时候，这个事务已经提交了（因此不是活跃事务），则此数据可以显示。 存在其中：不显示。说明创建读视图的时候，这个事务还在活跃，处于未提交状态，因此不予显示。 5.5 MVCC和事务隔离级别根据MVCC的实现原理，可以知道，Read View用于RC（Read Commited，读提交）和RR（Repeatable Read，可重复读）这两种隔离级别的实现，解决了脏读和不可重复读的问题。 解决脏读和不可重复读 在不同的隔离级别下，MVCC中Read View的创建是不同的。 对于RC隔离级别：每个快照读都会生成并获取最新的Read View，因此只能解决脏读问题，不能解决不可重复读的问题。 对于RR隔离级别：对于同一个事务来说，只有第一个快照读才会创建Read View，之后的快照读获取的都是同一个Read View，不会重复生成，因此其他事务的修改对于当前事务来说是不可见的，所以每次查询的结果都是一样的，解决了不可重复读的问题。 解决幻读问题 快照读：对于快照读来说，直接用MVCC控制就可以，不需要加锁。根据MVCC中的规则进行增删查改操作，就可以避免幻读。 当前读：对于当前读来说，使用next-key(临键锁)来控制，避免幻读。 六、主从复制参考MySQL高级 MySQL主从复制及读写分离实战 6.1 复制的基本原理主从复制的基本原理：slave机器会从master机器读取binlog文件来进行数据同步，主要有三步： master将改变记录到二进制文件（binlog）中，这些记录过程叫做二进制日志事件（binary log events）； slave将master的二进制文件中的内容（二进制日志事件）拷贝到自己的中继日志（relay log）； salve重做中继日志中的事件，将改变应用到自己的数据库中，MySQL复制是异步的且串行化的。 MySQL 的二进制文件，即常说的binlog文件，是MySQL执行改动产生的二进制日志文件，其主要作用有两个： 1、Replication（主从数据库）：在master端开启binlog文件后，log会记录所有数据库的改动，然后slave端获取这个日志文件内容就可以在slave端进行同样的操作。 2、备份（数据恢复 ）：在某个时间点a做了一次备份，然后利用二进制日志文件记录从这个时间点a后的所有数据库的改动，然后下一次还原的时候，利用时间点a的备份文件和这个二进制日志文件，就可以将数据还原。 6.2 复制的基本原则主从复制的基本原则： 每个slave只有一个master 每个slave只有一个唯一的服务器ID 每个master可以有多个slave 6.3 复制的最大问题延时问题是主从复制最大的问题。 6.4 一主一从常见配置以一个Windows主机，一个Linux从机为例。 要求： ①MySQL版本尽量一致，且后台以服务运行。版本不同容易导致兼容问题。 ②主从都配置在mysqld节点下 步骤： 一、主机修改my.ini配置文件（Windows中是ini后缀，linux中是cnf后缀） 假设本地安装路径为D:/MySQLServer5.7 设置主服务器唯一ID（必须） 1server-id=1 启用二进制日志（必须） 123log-bin=本地路径/data/mysqlbin# 即log-bin=D:/MySQLServer5.7/data/mysqlbin 启用错误日志（可选） 1log-err=本地路径/data/mysqlerr 根目录（可选） 1basedir=\"D:/MySQLServer5.7\" 临时目录（可选） 1tmpdir=\"D:/MySQLServer5.7\" 数据目录（可选） 1datadir=\"D:/MySQLServer5.7/Data/\" 设置read-only=0，意为主机可以读写。 设置不要复制的数据库（可选） 12# 比如设置mysql这个数据库不复制binlog-ignore-db=mysql 设置需要复制的数据库（可选） 12# 比如需要复制student数据库binlog-do-db=student 二、从机修改my.cnf配置文件 设置从服务器唯一ID（必须） 12# 需要和主机id号不同service-id=2 启用二进制文件（可选） 1log-bin=mysql-bin 修改完配置文件后，主机和从机必须重启MySQL服务。 三、主机和从机都关闭防火墙 CentOS 7关闭防火墙 1systemctl stop firewalld.service Windows关闭防火墙 123456# cmd窗口# 查看防火墙状态netsh advfirewall show allprofiles# 关闭防火墙netsh advfirewall set allprofiles state off 四、主机上建立账户并授权slave 授权给指定ip的从机账户名和密码： 12345# 比如从机ip为192.168.168.168，给从机建立的账户名为kang，密码为123456# 192.168.168.168从机就可以根据此用户名和密码进行复制。# replication slave表示给从机赋予复制的权限，*.*表示所有数据库。# ip如果为%则表示任意ip都可以使用此账号密码登陆grant replication slave on *.* to 'kang'@'192.168.168.168' identified by '123456'; 刷新一下权限，使权限立即生效：flush privileges; 查询master状态 12show master status;# 记录下File和Position的值，slave需要从File文件的Position位置开始复制。 执行完此步骤后，不要操作主机MySQL，防止主服务器发生变化。 重置master二进制文件：reset master;，会删除所有binlog文件，慎用。 五、从机配置需要复制的主机信息 配置账户名和File和Position： 123456789# 需要指定主机ip，账户名和密码就是主机授权的账户名和密码# File和Position是从File文件的Positon位置开始复制change master to master_host='主机ip',master_user='kang',master_password='123456',master_log_file='File名字',master_log_pos=Position数字;# 如果之前做过同步，需要停止同步：stop slave; 启动从机的复制功能：start slave; 显示状态： 12show slave status;# 可以在指令后面使用\\G代替分号，表示按照键值对的方式显示内容 如果Slave_IO_Running: Yes，Slave_SQL_Running: Yes说明配置成功。 配置成功后，主机的新建库、新建表、插入数据等相关操作就会被从机复制下来，从而实现数据同步。 如果需要同步的时主机中已有，但从机中没有的数据库，需要先手动将此数据库备份到从机，才能完成此数据库的同步。 使用mysqldump指令可以导出数据。 六、停止从主机复制数据的功能 1stop slave; 6.5 故障排除常见故障排除方法： 1、网络问题。 确保主机和从机可以互相ping通，才能够保证主从复制正常使用。 2、检查账号密码 仔细检查账号密码是否有误。 3、防火墙 主机和从机的防火墙都要关闭。 4、MySQL文件配置问题 检查文件配置，确保主机开启二进制日志文件，确保主机和从机的server-id不同 5、检查语法问题 6、检查账号权限 在主机服务器中，检查授权账号的权限和登陆主机限制。 12# host限制了此账号在哪个主机上可以登录。如果是%表示任何主机。select user,host from mysql.user; 遇到的问题 问题1、问题描述 配置完后，发现Slave_IO_Running状态一直处于Connecting状态。说明一直在连接主机数据库。 尝试手动使用授权的账号密码登陆主机数据库，正常情况下应该能够登录成功，结果登陆不成功，因此导致了从机的Slave_IO_Running状态一直处于Connecting状态。如下： 从机无法使用授权账号登陆到主机 Slave_IO_Running 解决方法： ERROR 1130错误，说明在当前ip下，此账号没有权限登录到主机的MySQL数据库。在主机中可以查看用户以及允许登陆的主机： 12# 查看用户和host信息select user,host from mysql.user; 可以看到，slave账号允许登陆的主机ip，我使用的是Vmware虚拟机CentOS7作为从机，Windows作为主机，网络模式是NAT模式，虽然从机ip确实是192.168.198.198，主机和从机也能互相ping通，但是就不允许登陆。可能是和NAT模式有关？（没搞清楚为什么会这样，按理说应该可以登陆。。。）如果换成桥接模式是不是就可以了？（以后有空再试吧） 使用update语句将slave账号的host改为%后，就可以登录了，Slave_IO_Running变为正常。 主机服务器查看用户信息 问题2、问题描述 上个问题解决了以后，看起来没问题了，但是数据只能同步执行一次。主机创建一个数据库以后，从机可以同步创建，但是主机再进行操作，从机就不继续同步了，用show slave status查看状态，Read_Master_Log_Pos一直和主机状态中的保持同步，但是就不同步执行主机相应命令:-( 可能是因为MySQL数据库版本不同？主机用的MySQL 5.7，从机用的MySQL 5.6，不知道是不是因为版本的问题。等有空再将版本统一一下，重新配置一遍试试。 七、其他内容补充7.1 数据库范式第一范式（1NF）：属性不可分割，即表中的字段不能再划分为多个字段 第二范式（2NF）：满足1NF的同时，必须有主键，且其他字段都依赖于主键（或者是候选码），保证唯一性。即每个非主属性完全依赖于候选码。 第三范式（3NF）：每个非主属性既不传递依赖于主码，也不部分依赖于主码。即属性不依赖于其他非主属性，直接依赖于主键。主要是用于避免冗余，同一个属性不能存在于多个表中，即一个表中的属性不能依赖于其他表的主键，否则这个属性在多个表中都有，就出现了冗余。 参考链接 MySQL数据库优化 JavaGuide-MySQL数据库索引总结 一条 SQL 语句在 MySQL 中如何执行的 为什么 MySQL 使用 B+树 B+树看这一篇就够了 MySQL索引背后的数据结构及算法原理 《高性能 MySQL第3版》","categories":[{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://kangshitao.github.io/tags/MySQL/"},{"name":"SQL","slug":"SQL","permalink":"http://kangshitao.github.io/tags/SQL/"}]},{"title":"操作系统复习","slug":"computer-os-review","date":"2021-05-21T12:12:05.000Z","updated":"2022-05-22T13:30:54.782Z","comments":true,"path":"2021/05/21/computer-os-review/","link":"","permalink":"http://kangshitao.github.io/2021/05/21/computer-os-review/","excerpt":"进程和线程、死锁、内存管理、虚拟内存","text":"计算机操作系统本文参考JavaGuide 一、操作系统基础1.1 什么是操作系统？ 操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的程序，是计算机的基石。 操作系统本质上是一个运行在计算机上的软件程序 ，用于管理计算机硬件和软件资源。 举例：运行在你电脑上的所有应用程序都通过操作系统来调用系统内存以及磁盘等等硬件。 操作系统存在屏蔽了硬件层的复杂性。 操作系统就像是硬件使用的负责人，统筹着各种相关事项。 操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理。 内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。 1.2 系统调用根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别： 用户态(user mode) : 用户态运行的进程可以直接读取用户程序的数据。 内核态(kernel mode)：系统态，管态。可以简单的理解内核态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。特权指令比如I/O指令、清内存、设置时钟指令等只能在内核态由操作系统内核执行。用户态可以通过系统调用、异常、外围设备中断3种方式切换到内核态。 用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。也就是说，用户程序如果需要调用操作系统提供的内核态级别的子功能，就需要系统调用。 系统调用按功能大致可分为如下几类： 设备管理。完成设备的请求或释放，以及设备启动等功能。 文件管理。完成文件的读、写、创建及删除等功能。 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。 进程通信。完成进程之间的消息传递或信号传递等功能。 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。 二、进程与线程2.1 进程和线程的区别进程 进程是一段程序的执行过程，是计算机资源分配的基本单位，进程是程序的基本执行实体。同时进程拥有自己的进程控制块，系统可以利用这个进程的控制块(PCB)来控制对应的进程。 线程 线程是操作系统进行调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。 线程和进程的比较 调度：线程是独立调度的基本单位，进程是资源分配的基本单位。 拥有资源：进程是拥有资源的基本单位，而线程则不拥有系统的资源，但是线程可以访问其所属进程的资源。 系统开销：系统创建和回收进程是需要对进程进行资源回收的。因此创建和回收进程的损耗要大于创建和回收线程的损耗。 地址空间和其他资源：进程间各自的地址空间是独立的，线程间的地址空间是共享的。 通信方面：进程间通信主要通过进程同步和互斥手段，而线程间可以直接读写进程数据段（如全局变量）进行通信。 程序：程序是一组指令的集合，是静态的代码。 JVM中，多个线程共享进程的堆和方法区，每个线程有自己的程序计数器、虚拟机栈、本地方法栈。参考Java中程序、进程、线程的区别 2.2 协程和管程协程 协程（Coroutine）是用户级别的轻量级线程。一个线程可以包含多个协程，可以对比一个进程包含多个线程。协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程。协程相对独立，有自己的上下文，协程的切换由程序员控制，在用户态执行，切换的代价比线程从用户态到内核态的代价小很多。 纤程(Fiber)与协程类似，是Windows操作系统实现的一种轻量化线程上的一个执行结构，是Windows上的协程，通常多个fiber共享一个固定的线程, 然后他们通过互相主动切换到其他fiber来交出线程的执行权， 各个子任务之间的关系非常强。 管程 管程（Monitor）在功能上和信号量及PV操作类似，属于一种进程同步互斥工具，但是具有与信号量及PV操作不同的属性。 一个管程是一个由过程、变量及数据结构等组成的一个集合，它们组成一个特殊的模块或软件包。进程可在任何需要的时候调用管程中的过程，但它们不能在管程之外声明的过程中直接访问管程内的数据结构。 管程很像一个类，将共享资源封装起来，并且，如果想要访问资源的话，只能通过类里面的方法来进行访问。同时，每次只允许一个进程进入管程，从而实现互斥， 管程的提出是为了更好的解决同步和互斥的问题。进程对共享资源的申请，释放等操作，都通过管程定义的过程来实现。这个过程还可以根据资源的情况，或接受或者阻塞进程访问，确保每次仅有一个进程使用共享资源，这样就可以统一管理对共享资源的所有访问，从而实现进程互斥。 2.3 进程的生命周期进程大致分为 5 种状态，和线程类似： 创建状态(new) ：进程正在被创建，尚未到就绪状态。 就绪状态(ready) ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。 运行状态(running) ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。 阻塞状态(waiting) ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。 结束状态(terminated) ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。 进程的3种基本状态 2.4 进程通信/同步方式：每个进程都有各自的用户地址空间，进程之间交换数据必须通过内核中的缓冲区，这种机制称为进程间通信IPC（InterProcess Communication），IPC有以下几种方式，参考进程间通信： 共享内存(Shared memory) ：使得多个进程共享一块内存，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。是速度最快的IPC方式。 管道/匿名管道(Pipes) ：先进先出，只能具有亲缘关系的父子进程间或者兄弟进程之间的通信。 管道只存在于内存中的文件，实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据。管道只支持单向数据流，只能用于具有亲缘关系的进程之间，没有名字，且缓冲区是有限的，传送的是无格式字节流，必须事先约定数据格式。 命名管道(Names Pipes) : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了命名管道。命名管道严格遵循先进先出(first in first out)。命名管道名字存放在文件系统中，内容存放在内存中，可以实现本机任意两个进程通信。 命名管道提供了一个路径名与之关联，以命名管道的文件形式存在于文件系统中，这样，即使与命名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过命名管道相互通信，因此，不相关的进程通过命名管道也能交换数据。 消息队列(Message Queuing) ：消息队列是消息的链表，具有特定的格式，存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道不同的是消息队列存放在内核中，只有在内核重启(即操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取,也可以按消息的类型读取，比 FIFO 更有优势。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺陷。 套接字(Sockets) : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。 信号量(Semaphores) ：信号量是一个计数器，用于多进程对共享数据的访问，取值为非负整数，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。 信号量用于同步，互斥量用于互斥。多数情况下，同步已经实现了互斥。 进程为了获取共享资源，需要执行三个操作，都是原子操作，在内核中实现： ①创建信号量 ②等待信号量，即P操作 ③释放信号量，即V操作 信号(Signal) ：信号用于通知接收进程某个事件已经发生，是Linux系统用于进程间通信或者操作的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。比如程序终止信号SIGING、程序退出信号SIGQUIT等。 2.5 线程通信/同步方式：操作系统中，有三种线程同步的方式： 互斥量（Mutex）：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。 信号量（Semphares）：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量 事件（Event）：使用通知操作的方式来保持多线程同步，比如Java中的wait()、notify()、notifyAll()方法。 互斥量的加锁和解锁必须由同一个线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。 2.6 进程的调度算法进程调度算法是为了确定首先执行哪个进程以及最后执行哪个进程来实现最大CPU利用率，包括以下几种： 先到先服务(FCFS)调度算法 : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。 短作业优先(SJF)的调度算法 : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。 时间片轮转调度算法 : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。 多级反馈队列调度算法 ：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。 优先级调度 ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。 基于公平原则的调度算法 2.7 死锁死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象。 如果一组进程中的每一个进程都在等待仅由该组进程中的其它进程才能引发的事件，那么该组进程是死锁的(Deadlock)。 产生死锁的四大必要条件： 互斥访问：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。 不可抢占：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。 请求和保持：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。 循环等待：有一组等待进程 {P0, P1,..., Pn}， P0 等待的资源被 P1 占有，P1 等待的资源被 P2 占有，……，Pn-1 等待的资源被 Pn 占有，Pn 等待的资源被 P0 占有。 以上条件必须同时满足才会造成死锁。 进程死锁和线程死锁满足的条件是一致的，只是死锁的资源分别是进程和线程。 2.8 死锁处理死锁的处理包括死锁预防、死锁避免、死锁检测、死锁解除四种方法。 死锁预防： 只有四个条件同时满足才会产生死锁，预防死锁的方法对应就是破坏四大必要条件，由于互斥条件是非共享设备所必须的，不仅不能改变，还应该加以保持，因此主要是破坏另外三个条件： 破坏“不可抢占性”条件：当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源 破坏“请求和保持”条件：一次性分配进程在整个运行过程中所需的全部资源，破坏了“请求”的条件。分配资源时，只要有一个资源得不到分配，就不给这个进程分配其他的资源，让其等待，破坏了“保持”的条件。 破坏“循环等待”条件：给每类资源赋予一个编号，并规定每一个进程必须按编号递增的顺序请求资源，释放则相反。 这种方式与前两种相比，资源利用率和系统吞吐量都有较明显的改善。但也存在下述问题: 首先，为系统中各类资源所规定的序号必须相对稳定，这就限制了新类型设备的增加。 其次，尽管在为资源的类型分配序号时，已经考虑到大多数作业在实际使用这些资源时的顺序，但也经常会发生这种情况：作业使用各类资源的顺序与系统规定的顺序不同，造成对资源的浪费。 第三，为方便用户，系统对用户在编程时所施加的限制条件应尽量少，然而这种按规定次序申请资源的方法必然会限制用户简单、自主地编程。 死锁避免： 死锁避免方法中，把系统状态分为安全状态和不安全状态。系统处于安全状态时可避免发生死锁，反之，系统处于不安全状态时，可能进入死锁状态。 安全状态指系统能按某种进程推进顺序 (P_1,P_2,...,P_n) 为每个进程 P_i 分配其所需资源，直至满足每个进程对资源的最大需求，是每个进程都可以顺利完成。如果系统无法找到这样的安全序列，则处于不安全状态，有可能发生死锁。 避免死锁应该在资源分配时，使系统不进入不安全状态。 具体方法有： 银行家算法。每个新进程进入系统时，必须申明在运行过程中，可能需要每种资源类型的最大单元数目，其数目不应超过系统所拥有的资源总量。当进程请求一组资源时，系统必须首先确定是否有足够的资源分配给该进程。若有，再进一步计算将这些资源分配给进程后，是否会使系统处于不安全状态。如果不会，才将资源分配给它，否则让进程等待。 死锁检测：Java中可以使用JConsole、JStack工具检测死锁 死锁解除：常采用解除死锁的两种方法为抢占资源和终止进程法。 抢占资源：从一个或多个进程中抢占足够数量的资源，分配个死锁进程，以解除死锁状态。 终止(或撤销)进程法：终止（或撤销）系统中的一个或多个死锁进程，直至打破循环环路，使系统从死锁状态解脱出来。 三、内存管理计算机存储系统 3.1 内存管理介绍内存管理的工作主要是内存的空间分配和回收（malloc和free）、地址转换（将逻辑地址转换成相应的物理地址）、内存空间的扩充、存储保护。 3.2 内存管理机制内存管理主要有连续分配管理方式和非连续分配管理方式两种 连续分配主要指为一个用户程序分配一个连续的内存空间，连续分配的方式包括单一连续分配、固定分区分配、动态分区分配。 单一连续分配，只用于单用户单进程的操作系统， 固定分区分配，其将内存划分为多个固定大小的分区，当有空闲分区的时候，再从后续的作业队列中选择合适大小的作业装入。 动态分区分配，OS根据程序需要，分给每个程序所需要的内存大小，但会出现内存碎片的问题。通常需要采用紧凑技术进行解决。可变分区的分配策略有以下几种： 首次适应算法，空闲分区以地址递增次序连接，找到大小能满足要求的第一个分区。 循环首次适应算法，与首次适应类似，只不过每次都从上一次的位置开始查找。 最佳适应算法，空闲分区按容量递增次序连接，找到第一个能满足要求的空闲分区。 最坏适应算法，空闲分区以容量递减次序连接，挑选第一个最大的分区。 连续分配方式会形成许多“碎片”，虽然可通过“紧凑”方法将许多碎片拼接成可用的大块空间，但须为之付出很大开销 ，因此产生了非连续分配方式。 非连续分配允许一个程序使用的内存分布在离散或者说不相邻的内存中，主要包括分页式存储管理、分段式存储管理、段页式存储管理三种方式： 分页式存储管理：主要将内存划分成大小固定的页面，在程序申请内存的时候，分配适合大小的页面。这种方式可以有效减少内存的碎片，同时不需要数据连续存放。同时内存中会维护一张页表，用于对内存地址进行转换。作业的逻辑地址：页号+页内偏移。 分段式存储管理：页式管理其中的页实际并无任何实际意义，而将内存分段中的每一段是有实际意义的。段式管理主要是从用户的角度出发，按照程序的自然段划分为逻辑空间。同样内存中会维护一张段表，每个段表项对应内存中的一段。内存地址借助于段表寄存器进行转换，作业的逻辑地址为：段号+段内偏移 段页式存储管理：结合了上述两种方法的优点，首先会对作业进行分段，分段之后再保存到对应的每个页中。内存管理仍然和分页式存储一致。作业的逻辑地址分为三部分：段号+页号+逻辑地址。 3.3 快表和多级页表在分页内存管理中，有两个问题需要解决： 保证虚拟地址到物理地址的转换速度要快。 解决虚拟地址空间大，页表也会很大的问题。 为了提高内存的空间性能，提出了多级页表的概念；但是提高空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即 TLB）的概念。 不论是快表还是多级页表实际上都利用到了程序的局部性原理。 快表快表为了提高虚拟地址到物理地址转换速度。操作系统在页表方案基础之上，引入了快表加速虚拟地址到物理地址的转换。 可以把快表理解为一种特殊的高速缓存，其中的内容是页表的一部分或者全部内容。作为页表的Cache，它的作用与页表相似，但是提高了访问速率。由于使用页表做地址转换，读写内存数据时CPU要访问两次主存（第一次访问存放在主存（属于内存）的页表，第二次访问主存中指定的地址）。有了快表，有时只需要访问一次缓存，一次主存，这样可以加速查找并提高指令执行速度。 使用快表的地址转换流程： 根据虚拟地址中的页号查快表； 如果该页在快表中，直接从快表中读取相应的物理地址； 如果该页不在快表中，就访问内存中的页表，从页表中得到物理地址，同时将页表中的该映射表项添加到快表中； 当快表填满后，又要登记新页时，按照一定的淘汰策略淘汰掉快表中的一个页。 多级页表引入多级页表的目的是为了避免把全部表页一直放在内存中占用过多空间，特别是那些根本不需要的页表，不需要保留在内存中。多级页表属于时间换空间的典型场景。参考多级页表如何节约内存 3.4 分页机制和分段机制对比共同点： 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。 页和段都是离散存储的，所以两者都是离散分配内存的方式，但是每个页和段中的内存是连续的。 区别： 页的大小是固定的，由操作系统决定；段的大小不固定，取决于当前运行的程序。 页是信息的物理单位，分页仅仅是为了满足操作系统内存管理的需求；段是逻辑信息的单位，在程序中可以体现为代码段、数据段，能够更好地满足用户的需要。 3.5 逻辑(虚拟)地址和物理地址逻辑地址由操作系统决定，是访问指令给出的地址，比如C语言里的指针，可以理解为内存里的一个地址。逻辑地址需要经过寻址方式的计算或变换才得到物理地址。 物理地址指的是真实物理内存中的地址，即内存地址寄存器中的地址，物理地址是内存单元真正的地址。 3.6 CPU寻址？为什么需要虚拟地址空间？CPU寻址 现代处理器使用的是一种称为虚拟寻址(Virtual Addressing)的寻址方式。使用虚拟寻址，CPU需要将虚拟地址转换为物理地址，这样才能访问到真实物理内存。CPU中称为内存管理单元(Memory Management Unit,MMU)的硬件用于将虚拟地址转换物理地址。如下图所示： 为什么要有虚拟地址空间？ 如果没有虚拟地址空间，直接访问和操作物理内存，这样直接把物理地址暴露出来会带来严重问题，可能对操作系统造成伤害以及给同时运行多个程序造成困难： 用户程序可以访问任意内存，寻址内存的每个字节，容易破坏操作系统，造成操作系统崩溃。 如果同时运行多个程序，两个程序都可以对同一个地址上的数据进行修改，造成应用程序崩溃。 使用虚拟地址访问内存的优势： 程序可以使用相邻的虚拟地址访问物理内存中不相邻的大内存缓冲区。 程序可以使用虚拟地址访问大于可用物理内存的内存缓冲区（使用硬盘空间扩展内存），实际物理内存不变，让程序认为其独占内存。当物理内存供应量变小时，内存管理器将物理内存页保存到磁盘。程序运行时，数据和代码页会根据情况在物理内存和磁盘移动（比如从磁盘读取到内存中，长时间不用又会被保存到磁盘），按需缓存，只在主存中缓存活动区域。 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。 四、虚拟内存4.1 什么是虚拟内存(Virtual Memory)？虚拟内存使得应用程序认为它拥有连续的可用内存(一个连续完整的地址空间)，而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。使用虚拟内存技术的系统使得大型程序的编写变得更容易，对真正的物理内存的使用也更有效率。 虚拟内存不仅仅是“使用硬盘空间扩展内存”这么简单，其重要意义在于虚拟内存定义了一个连续的虚拟地址空间，使程序的编写难度降。并且，把内存扩展到硬盘空间只是使用虚拟内存的必然结果，虚拟内存空间会存在硬盘中，并且会根据需要被内存缓存，有的操作系统还会在内存不够的情况下，将某一进程的内存全部放入硬盘空间中，并在切换到该进程时再从硬盘读取（这也是为什么Windows会经常假死的原因）。 虚拟内存的意义： 它把主存看作为一个存储在硬盘上的虚拟地址空间的高速缓存，并且只在主存中缓存活动区域（按需缓存）。 它为每个进程提供了一个一致的地址空间，从而降低了程序员对内存管理的复杂性 它还保护了每个进程的地址空间不会被其他进程破坏。 4.2 局部性原理局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。 局部性原理体现在两个方面： 时间局部性：如果程序中的某条指令一旦执行，不久后该指令可能再次执行；如果某数据被访问过，不久后该数据可能再次被访问。产生时间局部性的原因，是因为程序中存在大量的循环操作。 空间局部性：一旦程序访问了某个存储单元，不久后其附近的存储单元也将被访问，即程序在一段时间内访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表的形式存储的。 时间局部性通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。 空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。 虚拟内存技术实际上就是建立了“内存-外存”的两级存储器的结构，利用局部性原理实现高速缓存。 基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上可以比系统实际内存大小大的。 程序执行过程中，当所访问的信息不在内存中时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样计算机好像为用户提供了一个比实际内存大得多的存储器，即虚拟存储器（虚拟内存） 4.3 虚拟内存的技术实现虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。实现方式有三种： 请求分页存储管理。建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。 请求分段存储管理。建立在分段存储管理之上，增加了请求调段、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。 请求段页式存储管理 请求分页存储管理和分页存储管理的不同：请求分页是建立在分页管理之上的，根本区别是是否将作业的全部地址空间同时装入主存，请求分页存储管理不要求将作业全部地址空间同时装入主存，因此请求分页存储管理可以提供虚拟内存，而分页存储管理则不能。 请求分页和分页的实现都需要具备以下条件： ①一定容量的内存和外存，载入程序时，只需要将程序的一部分装入内存，将其他部分留在外存，然后程序就可以执行了。 ②缺页中断：如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序。 ③虚拟地址空间：逻辑地址到物理地址的变换。 4.4 页面置换算法当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统必须在内存中选择一个页面将其移出内存，以便为即将调入的页面让出空间。页面置换算法就是用来选择淘汰哪一页，主要有以下几种算法： OPT算法（最佳页面置换算法，Optimal,OPT)：选择被淘汰的页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，可以保证获得最低的缺页率。但是由于人们无法预知一个页面多长时间不再被访问，因此该算法无法实现，一般作为衡量其他置换算法的方法。 FIFO算法（先进先出页面置换算法，First In First Out）：淘汰最先进入的页面，即选择内存中驻留时间最久的页面淘汰。该算法实现简单，但会将那些经常被访问的页面也被换出，从而使缺页率升高。 FIFO算法还会产生当分配的物理块数增大而缺页率不减反增的异常现象，称为Belady异常。只有FIFO算法可能出现Belady异常，而LRU和OPT算法永远不会。 LRU算法（最近最久未使用页面置换算法，Least Currently Used）：LRU 淘汰最近最久未使用的页面，其思想是过去一段时间内未使用的页面，在最近的将来也不会被访问。有两种实现方式： 方式一：在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。 方式二：为每个页面设置一个访问字段，记录页面自上次被访问以来所经历的时间T，淘汰页面时将现有页面中T值最大的页面淘汰。 LRU性能较好，但需要寄存器和栈的硬件支持，LRU是堆栈类的算法，理论上可以证明，堆栈类算法不可能出现Belady异常，FIFO算法基于队列实现，不是堆栈类算法。 LRU算法题 LFU（最少使用页面置换算法，Least Frequently Used）：选择最近时期使用最少的页面进行淘汰。 LFU算法题 Clock算法（时钟置换算法，或最近未用算法NRU）：LRU的一种近似算法。简单Clock 算法，只需为每页设置一位访问位，再将内存中的所有页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位被置1。置换算法在选择一页淘汰时，只需检查页的访问位。如果是0，就选择该页换出;若为1，则重新将它置0，暂不换出，给予该页第二次驻留内存的机会，再按照FIFO算法检查下一个页面。当检查到队列中的最后一个页面时，若其访问位仍为 1，则再返回到队首去检查第一个页面。进阶的Clock算法需要考虑置换代价。 由于该算法是循环地检查各页面的使用情况，故称为Clock算法。但因该算法只有一位访问位，只能用它表示该页是否已经使用过，而置换时是将未使用过的页面换出去，故又把该算法称为最近未用算法或NRU(Not Recently Used)算法。","categories":[{"name":"CS基础","slug":"CS基础","permalink":"http://kangshitao.github.io/categories/CS%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://kangshitao.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"计算机网络汇总","slug":"computer-network-review","date":"2021-05-19T03:02:16.000Z","updated":"2022-05-22T13:30:54.781Z","comments":true,"path":"2021/05/19/computer-network-review/","link":"","permalink":"http://kangshitao.github.io/2021/05/19/computer-network-review/","excerpt":"计算机网络高频知识点总结","text":"一、网络分层模型1、总体概述OSI的七层模型和TCP/IP的四层模型： OSI的七层模型和TCP/IP的四层模型 2、各层概述物理层物理层主要解决用何种信号传输比特0和1的问题。 物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流。物理层为数据链路层屏蔽了各种传输媒体的差异，使数据链路层只需要考虑如何完成本层的协议和服务，而不必考虑网络具体的传输媒体是什么。 物理层协议的主要任务：机械特性、电气特性、功能特性、过程特性。 传输数据格式：比特流 主要协议：RJ45、CLOCK 涉及设备：中继器；集线器；网关 涉及技术：编码与调制、信道复用 数据链路层数据链路层主要解决分组在一个网络（或一段链路）上传输的问题。 涉及MAC地址及网卡地址。当一台设备连接到路由器，路由器连接到光猫上，而光猫则连通电信网络。当你从这台设备发出信息时，首先数据到达路由器，在通过路由器数据到达光猫，然后到达电信公网。在数据从设备到达路由器这一过程中是通过识别MAC地址完成的。也就是从一个节点到达另一个节点。而IP则是直接标识源和目的地。(即你的设备地址，和你所发送的设备地址)。 传输数据格式：帧（framing），在上层交付的数据单元添加帧头和帧尾，构成数据帧。 主要协议：PPP、FR、HDLC、VLAN、MAC 、CSMA/CD（载波监听多址接入/碰撞检测） 涉及设备：网桥；交换机 集线器（HUB）和交换机（SWITCH）的区别： 1.集线器是早期的以太网互联设备，已被淘汰，现使用交换机替代。 2.集线器工作在物理层；交换机工作在数据链路层和物理层 3.集线器对收到的信号进行放大、转发；交换机根据MAC地址，对帧进行转发 4.使用集线器作为互连设备的以太网仍然属于共享总线式以太网。集线器互连起来的所有主机共享总线带宽，属于同一个碰撞域和广播域；使用交换机作为互连设备的以太网，称为交换式以太网。交换机可以根据MAC地址过滤帧，即隔离碰撞域。 5.交换机的每个接口是一个独立的碰撞域；交换机隔离碰撞域但不隔离广播域(VLAN除外) 涉及技术：封装成帧、差错控制、可靠传输；媒体接入控制；虚拟局域网VLAN（使用交换机划分VLAN） 封装成帧：数据链路层给上层交付的协议数据单元添加帧头和帧尾使之成为帧。数据链路层对上层交付的传输数据没有任何限制，好像数据链路层不存在一样，这称为透明传输。 差错控制：奇偶校验、循环冗余校验（CRC） 可靠传输：使用停止-等待协议SW、回退N帧协议GBN、选择重传协议SR三种可靠协议实现可靠传输 网络层网络层主要解决在多个网络上传输（路由）的问题。 网络层的主要任务是实现网络互连，进而实现数据包在各网络之间的传输，这一层开始实现设备到设备之间的通信。 网络层提供的是无连接、不可靠的数据报服务，可靠通信应当由用户主机来保证。 传输数据格式：IP数据报 主要协议：IP、ICMP、ARP（根据IP地址获取MAC地址）、RARP、路由选择协议（RIP、OSPF、BGP） 路由器和交换机的区别：路由器可以隔离广播域和冲突域，交换机只能隔离冲突域。 涉及设备：路由器（ROUTER），路由器涉及到网络层及以下的各层。 涉及技术：IP地址，路由选择，虚拟专用网VPN，网络地址转换NAT 运输层运输层主要解决进程之间基于网络的通信问题。 （1）运输层为应用程序提供端口供应用层使用，运输层的协议又称为端到端协议。 （2）当传输较大的文件时会将文件分段，那么为了保证这些数据正常的顺序，还要对数据进行重组，包括流量控制、差错控制，这些都由传输层完成控制。 传输数据格式：UDP用户数据报/TCP报文段 主要协议：TCP、UDP、SPX 涉及技术：端口号，TCP的流量控制、拥塞控制、连接的建立和释放（三次握手和四次挥手） 会话层会话层解决进程之间进行会话问题 会将不同的应用程序的数据隔离起来。比如QQ与微信的隔离，使两个应用程序之间的数据进行隔离，防止串流。当然，如果想要共享两个软件之间的数据，可以通过应用层对应的接口进行共享。 主要协议：NFS、SQL、NETBIOS、RPC 表示层表示层解决通信双方交互信息的表示问题 对应用数据转换。比如在QQ聊天时，音频通过对应软件的接口，传递给声卡，声卡把这些数据进行一个编码，变成比特数据传送到另一个人的设备上，然后在这台设备进行解码转化成语音。 主要协议：JPEG、MPEG、ASII 应用层应用层解决通过应用进程之间的交互来实现特定网络应用的问题 最接近用户的一层。提供接口，使应用程序能够使用一些网络协议。 传输数据格式：数据包/HTTP请求报文 主要协议：HTTP、FTP、DNS、DHCP、Telnet、SMTP、POP3、 WWW、NFS 设计技术：域名、HTTP、文件传送协议FTP、电子邮件、万维网WWW 二、知识点详解1、网络层ICMP协议ICMP（Internet Control Message Protocol），网际控制报文协议。为了更有效地转发IP数据报和提高交付成功的机会，在网际层使用ICMP协议。 主机或路由器使用ICMP来发送差错报告报文和询问报文。ICMP报文被封装在IP数据报中发送。 ICMP是IPv4协议族中的一个子协议，用于IP主机、路由器之间传递控制消息。 ICMP差错报告报文有以下五种： 终点不可达：当路由器或主机不能交付数据报时，就向源点发送终点不可达报文。具体可再根据ICMP的代码字段细分为目的网络不可达、目的主机不可达、目的协议不可达、目的端口不可达、目的网络未知、目的主机为止等13种错误。 源点抑制：当路由器或主机由于拥塞而丢弃数据报时，就向源点发送源点抑制报文，使源点知道应当把数据报的发送速率放慢。 时间超过：当路由器收到一个目的IP地址不是自己的IP数据报，会将其生存时间TTL字段的值减1，若结果不为0，则将该IP数据报转发出去；若结果为0，除丢弃该IP数据报外，还要向源点发送时间超过报文。另外，当终点在预先规定时间内不能收到一个数据报的全部数据报片时，就把已收到的数据报片都丢弃，也会向源点发送时间超过报文。 参数问题：当路由器或目的主机收到IP数据报后，根据其首部中的检验和字段发现首部在传输过程中出现了误码，就丢弃该数据报，并向源点发送参数问题报文。 改变路由（重定向）：路由器把改变路由报文发送给主机，让主机知道下次应将数据报发送给另外的路由器（可通过更好的路由）。 ICMP询问报文有两种： 回送请求和回答：ICMP回送请求报文是由主机或路由器向一个特定的目的主机发出的询问。收到此报文的主机必须给源主机或路由器发送ICMP回送回答报文。这种询问报文用来测试目的站是否可达及了解其有关状态。 时间戳请求和回答：ICMP时间戳请求报文是请某个主机或路由器回答当前的日期和时间。在ICMP时间戳回答报文中有一个32位的字段，其中写入的整数代表从1900年1月1日起到当前时刻一共有多少秒。这种询问报文用来进行时钟同步和测量时间。 ICMP报文信息： ICMP报文包含在IP数据报中，IP报头在ICMP报文的最前面。一个ICMP报文包括IP报头（至少20字节）、ICMP报头（至少8字节）和ICMP报文（属于ICMP报文的数据部分）。当IP报头中的协议字段值为1时，就说明这是一个ICMP报文。ICMP报头如下图所示。 ICMP报头格式 各字段说明 类型：占一字节，标识ICMP报文的类型，目前已定义了14种，从类型值来看ICMP报文可以分为两大类。第一类是取值为1~127的差错报文，第2类是取值128以上的信息报文。 代码：占一字节，标识对应ICMP报文的代码。它与类型字段一起共同标识了ICMP报文的详细类型。 校验和：这是对包括ICMP报文数据部分在内的整个ICMP数据报的校验和，以检验报文在传输过程中是否出现了差错。其计算方法与在我们介绍IP报头中的校验和计算方法是一样的。 标识：占两字节，用于标识本ICMP进程，但仅适用于回显请求和应答ICMP报文，对于目标不可达ICMP报文和超时ICMP报文等，该字段的值为0。 2、传输层TCP和UDP对应的应用层协议和端口号如下： TCP/IP体系的应用层常用协议所使用的运输层熟知端口号 TCPTCP（控制传输协议），是一种面向连接的、可靠的、基于字节流的传输层通信协议。是为了在不可靠的互联网络上提供可靠的端到端字节流而专门设计的一个传输协议。 TCP报头信息TCP报头信息 TCP报文是TCP层传输的数据单元，也叫报文段。TCP在发送数据时，从发送缓存中取出一部分或全部字节并给其添加一个首部使之成为TCP报文段后进行发送： TCP报文段由首部和数据载荷两部分构成。 TCP的全部功能都体现在它首部中各字段的作用。 TCP报文段的首部内容： 端口号：用来标识同一台计算机的不同的应用进程。 源端口：占16比特，源端口用来标识发送该TCP报文段的应用进程，即报文的返回地址。 目的端口：占16比特，目的端口指明接收方计算机上的应用程序接口。 TCP报头中的源端口号和目的端口号，与IP数据报中的源IP和目的IP唯一确定一条TCP连接。 序号和确认号：占32比特，是TCP可靠传输的关键部分。序号是本报文段发送的数据组的第一个字节的序号。在TCP传送的流中，每一个字节一个序号。比如一个报文段的序号为300，此报文段数据部分共有100字节，则下一个报文段的序号为400。所以序号确保了TCP传输的有序性。确认号占32bit，即ACK，指明期待收到的下一个字节序号的值，同时也是对之前收到的所有数据的确认。比如N表明序号N之前的所有数据已经正确无误的收到。确认号只有当ACK标志为1时才有效。比如建立连接时，SYN报文的ACK标志位为0。 TCP规定，连接建立后，所有传送的TCP报文段都必须把ACK置为1 数据偏移／首部长度：占4比特，并以4字节为单位。用来指出数据载荷部分的起始处距离TCP报文段的起始处有多远。首部长度也叫数据偏移，是因为首部长度实际上指示了数据区在报文段中的起始偏移值（最小为0101，最大为1111）。由于首部可能含有可选项内容，因此TCP报头的长度是不确定的，报头不包含任何任选字段则长度为20字节，4位首部长度字段所能表示的最大值为1111，转化为10进制为15，15*4B= 60B，故报头最大长度为60字节。 保留：占6比特，为将来定义新的用途保留，现在一般置0。 控制位：URG ACK PSH RST SYN FIN，共6个，每一个标志位表示一个控制功能。 URG：紧急指针标志，为1时表示紧急指针有效，为0则忽略紧急指针。 ACK：确认序号标志，为1时表示确认号有效，为0表示报文中不含确认信息，忽略确认号字段。 PSH：push标志位，为1表示是带有push标志的数据，指示接收方在接收到该报文段以后，应尽快将这个报文段交给应用程序，而不是在缓冲区排队。 RST：重置连接标志，置为1时，用于重置由于主机崩溃或其他原因而出现错误的连接，或者用于拒绝非法的报文段和拒绝连接请求。 SYN：同步序号，用于建立连接过程，在连接请求中，SYN=1和ACK=0表示该数据段没有使用捎带的确认域，而连接应答捎带一个确认，即SYN=1和ACK=1。 FIN：finish标志，用于释放连接，为1时表示发送方已经没有数据发送了，即关闭本方数据流。 窗口：占16比特，滑动窗口大小，指发送端的接受窗口大小，窗口值作为接收方让发送方设置其发送窗口的依据，以此控制发送端发送数据的速率，从而达到流量控制。窗口最大为65535。 校验和：占16比特，奇偶校验，此校验和是对整个的 TCP 报文段，包括 TCP 头部和 TCP 数据。由发送端计算和存储，并由接收端进行验证。 紧急指针：占16比特，只有当 URG 标志置 1 时紧急指针才有效。紧急指针是一个正的偏移量，表明本报文字段数据载荷部分包含了多长的紧急数据。 TCP 的紧急方式是发送端向另一端发送紧急数据的一种方式。 选项和填充：选项长度不一定是32位的整数倍，所以要加填充位，即在这个字段中加入额外的零，以保证TCP头是32的整数倍。常见的选项有： 最长报文段长度，又称为MSS（Maximum Segment Size），每个连接方通常都在通信的第一个报文段（为建立连接而设置SYN标志为1的那个段）中指明这个选项，它表示本端所能接受的最大报文段的长度。 窗口扩大选项：为了扩大窗口，提高吞吐率 时间戳选项：用于计算往返时间RTT；用于处理序号超出范围的情况，又称为防止序号绕回PAWS 选择确认选项：用于实现选择确认功能。 数据部分： TCP 报文段中的数据部分是可选的。在一个连接建立和一个连接终止时，双方交换的报文段仅有 TCP 首部。如果一方没有数据要发送，也使用没有任何数据的首部来确认收到的数据。在处理超时的许多情况中，也会发送不带任何数据的报文段。 TCP元组这些元组主要是用于端口复用的，对于一个连接来说，只要其中一个存在不同则可以区别这是一个不同的连接。 四元组： 1源IP地址、目的IP地址、源端口、目的端口 五元组: 1源IP地址、目的IP地址、协议号、源端口、目的端口 七元组: 1源IP地址、目的IP地址、协议号、源端口、目的端口，服务类型以及接口索引 三次握手主动发起连接建立的应用进程叫做TCP客户端。 被动等待连接建立的应用进程叫做TCP服务端。 （1）第一次握手：客户端给服务端发一个 SYN 报文，这是一个并指明客户端的初始化序列号 ISN。客户端进入 SYN_SENT 状态。发送内容：SYN=1，seq=x。 SYN=1，表明这是一个TCP连接请求报文段。 TCP规定，SYN=1的报文段不能携带数据，但要消耗掉一个序号。 （2）第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)。同时会把客户端的 ISN + 1 作为ACK 的值（即x+1），表示自己已经收到了客户端的 SYN，服务器进入 SYN_RCVD 的状态。确认报文段内容为：SYN=1，ACK=1，确认号ack=x+1，初始序号seq=y。 （3）第三次握手：客户端收到 SYN 报文之后，会发送一个普通的确认报文段。。同样把服务器的 ISN + 1 作为 ACK 的值（即y+1），表示已经收到了服务端的 SYN 报文，客户端进入ESTABLISHED 状态。服务器收到 ACK 报文之后，也进入ESTABLISHED 状态，此时，双方已建立起了连接。确认报文段内容：ACK=1，确认号ack=y+1，序号seq=x+1（初始为seq=x，第二个报文段所以要+1）。 普通的ACK报文段可以携带数据，不携带数据则不消耗序号。 发送第一个SYN的一端为主动打开（active open），接收这个SYN并发回下一个SYN的另一端为被动打开（passive open）。 在socket编程中，客户端执行connect()时，将触发三次握手。 第三次握手的情况下，ACK数据包如果丢失，有两种情况: 1、客户端接着发送数据包，服务器端收到数据包，这个时候数据包带有和ACK一样的信息，因此不需要进行重传。 2、如果客户端没有发送数据包，那么过了2ms，服务器端会认为自己的ACK数据包丢失了，进行重传，这个时候客户端才重传对应的数据包。 三次握手过程 三次握手的目的 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。因此，需要三次握手才能确认双方的接收与发送能力是否正常。 采用三次握手而不是两次握手的原因：为了防止已经失效的连接请求报文段突然又传到了TCP服务器，因而导致错误。 具体来说，客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，如果只采用两次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一直等待客户端发送数据，浪费资源。 初始序列号，ISN(Initial Sequence Number)： 当一端为建立连接而发送它的SYN时，它为连接选择一个初始序号。ISN随时间而变化，因此每个连接都将具有不同的ISN。ISN可以看作是一个32比特的计数器，每4ms加1 。这样选择序号的目的在于防止在网络中被延迟的分组在以后又被传送，而导致某个连接的一方对它做错误的解释。三次握手的其中一个重要功能是客户端和服务端交换 ISN，以便让对方知道接下来接收数据的时候如何按序列号组装数据。如果 ISN 是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的。 泛洪攻击： ​ SYN泛洪攻击属于Dos攻击的一种，该攻击是借助于TCP的三次握手实现的。攻击者发送TCP SYN，SYN是TCP三次握手中的第一个数据包，而当服务器返回ACK后，该攻击者就不对其进行再确认，那这个TCP连接就处于挂起状态，也就是所谓的半连接状态，服务器收不到再确认的话，还会重复发送ACK给攻击者。这样更加会浪费服务器的资源。攻击者就对服务器发送非常大量的这种TCP连接，由于每一个都没法完成三次握手，所以在服务器上，这些TCP连接会因为挂起状态而消耗CPU和内存，最后服务器可能死机，就无法为正常用户提供服务了。 解决措施： ​ 对于SYN泛洪攻击的防范，优化主机系统设置是常用的手段。如降低SYN timeout时间，使得主机尽快释放半连接的占用；又比如采用SYN cookie设置，如果短时间内连续收到某个IP的重复SYN请求，则认为受到了该IP的攻击，丢弃来自该IP的后续请求报文。此外合理地采用防火墙等外部网络安全设施也可缓解SYN泛洪攻击。 四次挥手客户端和服务端都可以在数据传送结束后发出连接释放的通知，即主动关闭。 以客户端主动发起连接释放申请为例： （1）第一次挥手：客户端想断开连接时，主动发送一个 FIN 报文（即连接释放报文段），并停止再发送数据，主动关闭TCP连接，进入FIN_WAIT1（终止等待1）状态，等待服务端的确认。连接释放报文段内容为：FIN=1，ACK=1，seq=u，ack=v， FIN=1，ACK=1，表明这是一个TCP连接释放报文段，同时也对之前收到的报文段进行确认。 TCP规定，终止位FIN等于1的报文段即使不携带数据，也要消耗掉一个序号。连接释放报文段可以携带数据也可以不携带数据。 （2）第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文。服务端发出确认报文段后进入CLOSE_WAIT（关闭等待）状态，此时从TCP客户端到服务端的连接就关闭了，TCP处于半关闭状态（服务端到客户端的连接没有关闭，服务端仍可以向客户端发送数据）。客户端收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。确认报文段内容ACK=1，seq=v，ack=u+1 （3）第三次挥手：如果服务端没有数据发送，也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。服务端处进入LAST_ACK （最后确认）状态，等待客户端的确认。连接释放报文段内容为：FIN=1，ACK=1，seq=w，ack=u+1，u+1是对之前收到的TCP连接释放报文段的重复确认。 第三次挥手是多出的一次挥手，主要原因在于可能双方连接断开的时候，服务端到客户端的数据传输还没有完成，因此需要多一次等待数据传输完成。一旦服务端没有数据发送了，就可以发送FIN报文。 （4）第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 作为自己 ACK 报文的序列号值，客户端进入 TIME_WAIT 状态。客户端需要等待2MSL时间，确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态，而服务端收到 ACK 报文之后，就关闭连接，进入 CLOSED 状态。确认报文段内容为：ACK=1，seq=u+1，ack=w+1 四次挥手过程 TIME_WAIT状态：服务端发送最后一次释放连接请求后（即第三次挥手），可能由于网络比较阻塞，该数据帧在传送过程中丢失了。服务器可能会再次进行确认，但是此时如果客户端已经进入CLOSE状态，不会理会其他的请求。因此，采用TIME_WAIT来保障如果网络比较阻塞，可以保证最后一次的ACK报文段能够到达服务端，正常关闭TCP连接。TIME_WAIT是主动断开链接发起者的状态，在发送最后一次ACK后进入TIME_WAIT状态。经过2MSL时长，可以使本次连接持续时间内所产生的所有报文段都从网络中消失，可以使下一次新的TCP连接中，不会出现旧连接中的报文段。 CLOSE_WAIT状态：在被动关闭连接情况下，在已经接收到FIN，但是还没有发送自己的FIN的时刻，连接处于CLOSE_WAIT状态。在这个状态下，出于被动关闭的服务端可以继续将未发送完的数据发送给客户端。 MSL（Maximum Segment Lifetime）：最长报文寿命，RFC793建议为2分钟。TCP允许不同的实现可以根据具体情况使用更小的MSL的值。 保活计时器：为了保证TCP客户端出现故障时，服务端不再白白等待下去，TCP服务器使用保活计时器。TCP服务器进程每收到一次TCP客户进程的数据，就重新设置并启动保活计时器（2小时定时）。若保活计时器定时周期内未收到TCP客户进程发来的数据，则当保活计时器到时后，TCP服务器进程就向TCP客户进程发送一个探测报文段，以后则每隔75秒钟发送一次。若一连发送10个探测报文段后仍无TCP客户进程的响应，TCP服务器进程就认为TCP客户进程所在主机出了故障，接着就关闭这个连接。 流量控制所谓流量控制(flow control)，就是让发送方的速率不要太快，要让接收方来得及接收。 TCP的流量控制通常采用滑动窗口实现。(滑动窗口的大小取决于接收方的窗口大小和信道大小)： TCP接收方利用自己的接收窗口的大小来限制发送方发送窗口的大小。 TCP发送方收到接收方的零窗口通知后，应启动持续计时器。持续计时器超时后，向接收方发送零窗口探测报文。 滑动窗口有以下几种方法： （1）停止等待协议，当发送窗口和接收窗口都等于1时，就是停止等待协议。发送端给接收端发送数据，等待接收端确认回复ACk，并停止发送新的数据包，开启计时器。数据包在计时器超时之前得到确认，那么计时器就会关闭，并发送下一个数据包。如果计时器超时，发送端就认为数据包丢失或被破坏，需要重新发送之前的数据包，说明数据包在得到确认之前，发送端需要存储数据包的副本。停止等待协议是发出一个帧后得到确认才发下一个，降低了信道的利用率。 （2）后退N帧协议，在发送完一个帧后，不用停下来等待确认，而是可以连续发送多个数据帧。收到确认帧时，任可发送数据，这样就减少了等待时间，整个通信的通吞吐量提高。如果前一个帧在超时时间内未得到确认，就认为丢失或被破坏，需要重发出错帧及其后面的所有数据帧。这样有可能有把正确的数据帧重传一遍，降低了传送效率。线路很差时，使用退后N帧的协议会浪费大量的带宽重传帧。 （3）选择重传协议，NAK：非确认帧，当在一定时间内没有收到某个数据帧的ACK时，回复一个NACK。在发送过程中，如果一个数据帧计时器超时，就认为该帧丢失或者被破坏，接收端只把出错的的帧丢弃，其后面的数据帧保存在缓存中，并向发送端回复NAK。发送端接收到NAK时，只发送出错的帧。如果落在窗口的帧从未接受过，那么存储起来，等比它序列号小的所有帧都按次序交给网络层，那么此帧才提交给网络层。接收端收到的数据包的顺序可能和发送的数据包顺序不一样。因此在数据包里必须含有顺序字符来帮助接受端来排序。选择重传协议可以避免重复传送那些正确到达接收端的数据帧。但是接收端要设置具有相当容量的缓存空间，这在许多情况下是不够经济的。 拥塞控制拥塞，即对资源的需求超过了该资源所能提供的可用部分。若网络中许多资源同时供应不足，即出现拥塞，如果不进行控制，网络的性能就要明显变坏，整个网络的吞吐量随之负荷的增大而下降。 计算机网络中的链路容量（即带宽）、交换结点中的缓存和处理机等，都是网络的资源。 拥塞避免的方式主要包括慢开始，拥塞避免，快重传，快恢复。 前提 发送方维护一个叫做拥塞窗口cwnd的状态变量，其值取决于网络的拥塞程度，并且动态变化。 拥塞窗口cwnd的维护原则：只要网络没有出现拥塞，拥塞窗口就再增大一些；但只要网络出现拥塞，拥塞窗口就减少一些。 判断出现网络拥塞的依据：没有按时收到应当到达的确认报文（即发生超时重传)。 发送方将拥塞窗口作为发送窗口swnd，即swnd = cwnd。 发送方的窗口的上限值应当取为接收方窗口rwnd和拥塞窗口cwnd这两个变量中较小的一个. 维护一个慢开始门限ssthresh状态变量： 当cwnd &lt; ssthresh时，使用慢开始算法; 当cwnd &gt; ssthresh时，停止使用慢开始算法而改用拥塞避免算法; 当cwnd = ssthresh时，即可以使用慢开始算法，也可以使用拥塞避免算法。 1、慢开始（slow-start）： ​ 慢开始指的是一开始向网络中注入的报文段少。当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。 2、拥塞避免（congestion avoidance）： ​ 让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。 TCP Tahoe版本 3、快重传(fast retransmit)： 如果传输时出现了超时，发送方会误以为发生了拥塞，从而将cwnd重新置为1，这样会降低效率，因此1990年增加了快重传和快恢复两个改进的算法。 所谓快重传，就是使发送方尽快进行重传，而不是等超时重传计时器超时再重传： 要求接收方不要等待自己发送数据时才进行捎带确认，而是要立即发送确认（ACK）。 即使收到了失序的报文段，也要立即发出对已收到的报文段的重复确认。 发送方一旦收到3个连续的重复确认，就将相应的报文段立即重传，而不是等该报文段的超时重传计时器超时再重传。 对于个别丢失的报文段，发送方不会出现超时重传，也就不会误以为出现了拥塞（进而降低拥塞窗口cwnd为1）。使用快重传可以使整个网络的吞吐量提高约20%。 收到3个重复确认后，知道是丢失了个别的报文段，于是不启动慢开始算法，而执行快恢复算法，具体做法为： 快重传 4、快恢复(fast recovery)： 使用快重传算法，收到3个重复确认时，会执行快恢复算法，具体做法为： 把ssthresh设置为cwnd的一半； 把cwnd再设置为ssthresh的值； 有些快恢复实现将cwnd重置为ssthresh+3，理由是3个重复确认说明有3个数据报文段离开了网络，这3个报文段不在消耗网络资源，而是停留在接收方的接收缓存中。网络中不是堆积了报文段，而是减少了3个报文段，因此可以适当把拥塞窗口再扩大些。 重新进入拥塞避免阶段。 慢开始和拥塞避免算法是1988年提出的TCP拥塞控制算法，称为TCP Tahoe版本。 1990年提出了快重传和快恢复算法，称为TCP Reno版本。 超时重传时间超时重传计算公式 例如： 超时重传时间计算例题 可靠传输通过以上TCP的内容，可以总结出TCP实现可靠传输，主要依靠以下机制： 连接管理：三次握手和四次挥手机制。 数据分块传输。数据被分为TCP认为合适的数据块进行传输。 使用校验和校验：将发送的数据段都当作一个16位的整数，相加，进位不丢弃补在后面，最后取反得到校验和 确认应答和序列号：TCP传输时对每个字节的数据都进行了编号，每次接收方收到数据后，都会对传输方进行确认应答(ACK)，其中带有对应的确认序列号，告诉发送方已经接收到了哪些数据，下一次希望接收的数据的序列号。 流量控制：滑动窗口 拥塞控制：慢开始、拥塞避免、快重传、快恢复 超时重传机制。 粘包问题粘包指的是由于连续的数据传送，导致多个数据包混合在一起，没有办法有效的区分开。TCP是基于字节流的，只维护发送出去多少，确认了多少，并没有维护消息与消息之间的边界，因而极有可能导致粘包问题： 发送端，TCP为提高传输效率，发送方要收集到足够多的数据后才发送一包数据。若连续几次发送的数据都很少，通常TCP会根据优化算法把这些数据合成一包后一次发送出去，这样接收方就收到了粘包数据。 接收方引起的粘包是由于接收方用户进程不及时接收数据，或者当发送内容较大时，由于服务器端的recv(buffer_size)方法中的buffer_size较小，不能一次性完全接收全部内容，因此在下一次请求到达时，接收缓冲区还有上一次的内容，取出的数据包括了上一次没有完全接收完的内容，从而造成粘包现象 UDP方案不会出现粘包，因为其有对应的数据分割。 解决方法： 对于发送方引起的粘包现象，用户可通过编程设置来避免，TCP提供了强制数据立即传送的操作指令push，TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满。 对于接收方引起的粘包，则可通过优化程序设计、精简接收进程工作量、提高接收进程优先级等措施，使其及时接收数据，从而尽量避免出现粘包现象；发送端可以在发送数据之前向接收端告知发送内容的大小 UDPInternet 协议集支持一个无连接的传输协议，该协议称为用户数据报协议（UDP，User Datagram Protocol）。UDP 为应用程序提供了一种无需建立连接就可以发送封装的 IP 数据包的方法。 UDP传输的可靠性由应用层负责。常用的UDP端口号有：53（DNS）、69（TFTP）、161（SNMP），使用UDP协议包括：TFTP、SNMP、DNS、DHCP、RIP（路由信息协议） UDP报头由4个域组成，其中每个域各占用2个字节，具体包括源端口号、目标端口号、数据包长度、校验值。 TCP与UDP的区别1、连接方面区别 TCP面向连接（如打电话要先拨号建立连接）。有三次握手建立连接，四次挥手释放连接。 UDP是无连接的，即发送数据之前不需要建立连接。 2、安全方面的区别 TCP提供可靠的服务，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达。 UDP尽最大努力交付，即不保证可靠交付。 3、传输效率的区别 TCP传输效率相对较低。 UDP传输效率高，适用于对高速传输和实时性有较高的通信或广播通信。 4、连接对象数量的区别 TCP连接只能是点到点、一对一的，是全双工的。 UDP支持一对一，一对多，多对一和多对多的交互通信。 5、运输过程的区别 TCP面向字节流，这正是TCP实现可靠传输、流量控制、拥塞控制的基础。TCP将应用进程交付下来的数据块看作是无结构的字节流，更具发送策略，提取一定量的字节构建TCP报文并发送。 UDP面向报文，对应用进程交下来的报文即不合并也不拆分，而是保留这些报文的边界。 6、结构方面的区别 TCP首部最小20字节，最大60字节。因为其要提供可靠传输，因此首部字段包含固定部分20字节和可变部分最大40字节。 UDP首部开销小，仅8个字节。 7、应用场景 TCP的可靠性，决定了其适用于准确率要求高，效率要求低的场景，例如文件传输。 UDP的不可靠性，决定了其适用于效率要求高，准确率要求低的场景，例如IP电话、视频会议、直播等。 3、HTTP与HTTPSHTTP特点HTTP协议的五大特点：支持客户/服务器模式、简单快速、灵活、无连接、无状态。无连接指的是请求时建立连接，请求完释放连接。 无状态是指： 协议对于事务处理没有记忆能力。 对同一个url请求没有上下文关系。 每次的请求都是独立的，它的执行情况和结果与前面的请求和之后的请求是无直接关系的，它不会受前面的请求应答情况直接影响，也不会直接影响后面的请求应答情况。 服务器中没有保存客户端的状态，客户端必须每次带上自己的状态去请求服务器。 Cookies/Session这两个主要用于解决HTTP无状态连接的问题，服务器会给每个会话创建对应的SessionID，会根据SessionID判断当前登陆的用户。 Session是服务端用来记录用户状态的一种机制，或者说是存放在服务端用于跟踪用户状态的一个数据结构（对象）。服务端为每个特定的用户创建特定的Session，用于标识用户，记录用户的行为，这个Session有唯一的标识Session Id。Session Id一般存放在Cookie中，每次HTTP请求的时候，客户端会发送相应的Cookie信息到服务端，用于识别用户身份，然后从Session中查找用户状态。Cookie是Session的一种实现，Session实现会话管理机制时，利用了Cookie技术。Session默认存放在服务器的文件里，也可以存放在数据库、内存中。 Cookie是一小段的文本信息，用于客户端保存用户信息，将无状态的HTTP进行状态化。当用户客户端通过 HTTP 协议访问一个服务器的时候，如果服务器需要记录该用户的状态，就为该用户生成一个唯一的Cookie识别码，并以此为索引在服务器后端数据库中创建一个项目，用来记录该用户访问该网站的各种信息，并将HTTP响应内容和 Key/Value 键值对返回给客户端浏览器。客户端浏览器会把Cookier保存起来。当浏览器再次请求该网站时，浏览器就会把请求地址和Cookie 一同给服务器。服务器检查该Cookie ，从而判断用户的状态。服务器还可以根据需要修改Cookie 的内容。Cookie一般会存放Session Id和用户名等其他用户信息。 服务器将Cookie添加到response里一并返回给客户端，然后客户端会自动把response里的cookie接收下来，并且保存到本地，下次发出请求的时候，就会把cookie附加在request里，服务器在根据request里的cookie遍历搜索是否有与之符合的信息。 如果禁用Cookie，就无法获取Session Id，这时可以使用URL地址重写技术，将用户Session的id信息重写到URL地址中，这样即使客户端不支持Cookie，也可以使用Session来记录用户状态。 使用Cookie在服务器上记录用户信息 Session和Cookie区别： 存储位置：Cookie保存在客户端浏览器中的，而Session保存在服务器上。 安全性：与Session相比，Cookie由于保存在客户端，安全性较低。 存储容量：Session存储容量可以很大，Cookie存储容量很小。 如果说cookie机制是检查客户身上的“通行证”，那么session机制就是通过检查服务器上的“客户明细表”来确认客户身份。 利用cookie和session登录的流程 客户输入账号密码进行首次登录，服务器端进行验证，验证成功则生成唯一的Session Id，并且在session对象中存储当前用户信息。服务器端将Session Id写入客户端Cookie中，当客户端下次访问服务器端时Cookie会被自动发送给服务器端，服务器端在Cookie中拿到Session Id然后在服务器端的Session对象中查找Session Id进行验证，验证成功说明用户是登陆状态，则可以为其响应只有在登陆状态才能响应的数据，还原用户上次的浏览状态或提供其他个性化服务。 HTTP状态码1、消息(1XX)： 100 Continue，客户端应当继续发送请求。这个临时响应是用来通知客户端它的部分请求已经被服务器接收，且仍未被拒绝。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。 2、成功(2XX): 200 OK，请求已成功 201 Created，请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随Location 头信息返回。 3、重定向(3XX)： 300 Multiple Choices，被请求的资源有一系列可供选择的回馈信息，每个都有自己特定的地址和浏览器驱动的商议信息。用户或浏览器能够自行选择一个首选的地址进行重定向。 301: 永久重定向，表示本网页永久性转移到另一个地址。 302：重定向，当响应码为302时，表示服务器要求浏览器重新再发一个请求，服务器会发送一个响应头Location，它指定了新请求的URL地址； 304: 服务器端会获取If-Modified-Since值，与index.html 的当前最后修改时间比对，如果相同，服务器会发响应码304，表示index.html与浏览器上次缓存的相 同，无需再次发送，浏览器可以显示自己的缓存页面，如果比对不同，那么说明index.html已经做了修 改，服务器会响应200。 4、请求错误（4XX）: 400 Bad Request： a.语义有误，当前请求无法被服务器理解。除非进行修改，否则客户端不应该重复提交这个请求。 b.请求参数有误。 403 Forbidden，服务器已经理解请求，但拒绝执行它。 404 Not Found，请求失败，请求所希望得到的资源未被在服务器上发现。 5、服务器错误（5XX）: 500 Internal Server Error，服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器端的源代码出现错误时出现。 503 Service Unavailable，由于临时的服务器维护或者过载，服务器当前无法处理请求。 504 Gateway Timeout，作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应。 505 HTTP Version Not Supported，服务器不支持，或者拒绝支持在请求中使用的 HTTP 版本。这暗示着服务器不能或不愿使用与客户端相同的版本。响应中应当包含一个描述了为何版本不被支持以及服务器支持哪些协议的实体。 HTTP方法 GET，GET 用于从指定资源请求数据。是幂等的，GET请求的参数数量是有限的，且参数暴露在URL中，安全性没有POST高 POST，POST 用于将数据发送到服务器来创建/更新资源，是不幂等的。 post请求几种常见content-type类型： application/x-www-form-urlencoded：原生form表单 multipart/form-data：许多文件类型，比如文件 application/json：告诉服务端消息主体是JSON text/xml：传输和存储数据 binary：二进制文件类型 PUT，PUT 用于将数据发送到服务器来创建/更新资源。POST 和 PUT之间的区别在于 PUT 请求是幂等的（idempotent）。也就是说，多次调用相同的 PUT 请求将始终产生相同的结果。相反，重复调用POST请求具有多次创建相同资源的副作用。 HEAD，HEAD 与 GET 几乎相同，但没有响应主体。换句话说，如果 GET /users 返回用户列表，那么 HEAD /users 将发出相同的请求，但不会返回用户列表。HEAD 请求对于在实际发出 GET 请求之前（例如在下载大文件或响应正文之前）检查 GET 请求将返回的内容很有用。 DELETE，删除指定的资源。 PATCH，对PUT方法的补充，用来对已知资源进行局部更新。 OPTIONS，请求一些选项信息。 长连接与短连接当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问的 HTML 页面资源，还会请求图片资源。如果每进行一次 HTTP 通信就要新建一个 TCP 连接，那么开销会很大。 长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。 从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close； 在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 Connection : Keep-Alive。 HTTP1.0、1.1、2.0的区别HTTP1.X：线程阻塞，同一时间同一域名的请求有一定数量限制，超过限制数目的请求会被阻塞 HTTP1.0和HTTP1.1主要区别：HTTP1.0默认使用短连接，HTTP1.1默认使用长连接 HTTP2.0： 采用二进制格式而非文本格式 完全多路复用，而非有序并阻塞的、只需一个连接即可实现并行 使用报头压缩，降低开销 服务器推送 ​ HTTPSHTTPS 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信。通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。 SSL/TLS加密过程： （1） 客户端向服务器端索要并验证公钥。 （2） 双方协商生成”对话密钥”。 （3） 双方采用”对话密钥”进行加密通信。 HTTPS HTTPS的缺点： 相同环境下HTTPS的响应时间和需要的资源相比HTTP都大幅上升 HTTPS的安全范围有限，在黑客攻击和服务器劫持等情况几乎起不到作用 HTTP/HTTPS的区别 HTTP 信息是明文传输，内容可能会被窃听，不安全，HTTPS 的数据是加密传输的（HTTP+SSL/TLS），且可进行身份认证，安全性较好。 HTTP响应速度比HTTPS快，因为HTTPS多了一层加密层。 HTTP端口号为80，而HTTPS端口号为443，二者使用完全不同的连接方式。 HTTPS 协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。 4、加密对称密钥加密对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。 优点：运算速度快； 缺点：无法安全地将密钥传输给通信方。 对称密钥加密 非对称密钥加密非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。 公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。 非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。 优点：可以更安全地将公开密钥传输给通信发送方； 缺点：运算速度慢。 非对称密钥加密 HTTPS的加密方式上面提到对称密钥加密方式的传输效率更高，但是无法安全地将密钥 Secret Key 传输给通信方。而非对称密钥加密方式可以保证传输的安全性，因此我们可以利用非对称密钥加密方式将 Secret Key 传输给通信方。HTTPS 采用混合的加密机制，正是利用了上面提到的方案： 先使用非对称密钥加密方式传输对称密钥加密方式所需要的 Secret Key，从而保证安全性; 获取到 Secret Key 后，再使用对称密钥加密方式进行通信，从而保证效率。 三、常见问题1、输入URL后发生了什么？1、应用层DNS解析域名。 ​ 浏览器会根据输入的URL去查找对应的IP，寻找的过程遵循就近原则，依次是：浏览器缓存 -&gt; 系统缓存 -&gt; 路由器缓存-&gt;本地（ISP）域名服务器缓存 -&gt; 根域名服务器。 2、TCP连接（三次握手）。 ​ 浏览器得到IP以后，向服务器发送TCP连接请求，三次握手建立TCP连接。 3、浏览器发送HTTP请求。 ​ 浏览器向web服务器发送一个HTTP请求。HTTP的请求方式为get，这个get请求包含了主机（Host）、用户代理(User-Agent)，用户代理就是自己的浏览器，它是你的”代理人”，Connection（连接属性）中的keep-alive表示浏览器告诉对方服务器在传输完现在请求的内容后不要断开连接，不断开的话下次继续连接速度就很快了。可能还会有Cookies，Cookies保存了用户的登陆信息，一般保存的是用户的SessionId，在每次向服务器发送请求的时候会重复发送给服务器，服务器就知道是哪个浏览器。 如果有重定向，则会执行服务器的永久重定向—&gt;浏览器跟踪对应的重定向地址。 4、服务器处理并发回请求。服务器返回响应头（包含状态码）和具体的要请求的页面内容。 5、浏览器解析对应的HTML响应内容： 6、关闭TCP连接（四次挥手）。","categories":[{"name":"CS基础","slug":"CS基础","permalink":"http://kangshitao.github.io/categories/CS%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://kangshitao.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"JVM垃圾回收相关概念补充","slug":"gc-related-concepts-supplement","date":"2021-05-11T10:09:54.000Z","updated":"2022-05-22T13:30:54.783Z","comments":true,"path":"2021/05/11/gc-related-concepts-supplement/","link":"","permalink":"http://kangshitao.github.io/2021/05/11/gc-related-concepts-supplement/","excerpt":"内存溢出、内存泄露、STW、GC的并行与并发、强引用、软引用、弱引用、虚引用","text":"一、System.gc()的理解默认情况下，调用System.gc()或者Runtime.getRuntime().gc()（System.gc()的底层方法）方法，会显式触发Full GC，同时对老年代和新生代进行回收，尝试释放被丢弃对象占用的内存。 System.gc()调用附带一个免责声明，无法保证对垃圾收集器的调用，也就是说，这个方法只是提醒垃圾收集器进行垃圾回收，具体什么时候会进行垃圾回收就不一定了，此方法不保证一定会回收。 JVM实现者可以通过System.gc()调用来决定JVM的GC行为。而一般情况下，垃圾回收应该是自动进行的，无须手动触发，否则就太麻烦了。在一些特殊情况下，如我们正在编写一个性能基准，我们可以在运行之间调用System.gc()。 例一： 12345678910111213141516171819public class SystemGCTest { public static void main(String[] args) { new SystemGCTest(); System.gc();//提醒jvm的垃圾回收器执行gc,但是不确定是否马上执行gc //与Runtime.getRuntime().gc();的作用一样。 //此方法会强制调用失去引用对象的finalize()方法 //System.runFinalization(); } @Override protected void finalize() throws Throwable { System.out.println(\"SystemGCTest 重写了finalize()\"); }}/*如果不使用System.runFinalization()方法，由于System.gc()不保证一定执行垃圾回收，因此执行上述代码，finalize()方法可能会被调用，也可能不会被调用*/ 例二，调用System.gc()进行垃圾回收： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class LocalVarGC { //buffer不会被回收 public void localvarGC1() { byte[] buffer = new byte[10 * 1024 * 1024];//10MB System.gc(); } //buffer会被回收 public void localvarGC2() { byte[] buffer = new byte[10 * 1024 * 1024]; buffer = null; System.gc(); } /*buffer不会被回收。 查看字节码文件可知，局部变量表中存放了this和buffer两个变量, 垃圾回收时发现buffer在变量表中，属于GC roots，因此不会被回收 */ public void localvarGC3() { { byte[] buffer = new byte[10 * 1024 * 1024]; } System.gc(); } /*buffer会被回收。 查看字节码文件可知，首先局部变量表中存放了this和buffer两个变量, 然后，在代码块执行完后，超出了buffer的作用范围，value重用了buffer的变量槽 因此垃圾回收时，buffer会被回收。 可以参考《深入理解JVM 第三版》P296 */ public void localvarGC4() { { byte[] buffer = new byte[10 * 1024 * 1024]; } int value = 10; System.gc(); } //在localvarGC1中时，buffer没有被回收，localvarGC5中，buffer被回收。 public void localvarGC5() { localvarGC1(); System.gc(); } public static void main(String[] args) { LocalVarGC local = new LocalVarGC(); local.localvarGC1(); }} 二、内存溢出与内存泄漏1、内存溢出内存溢出（OutOfMemoryError）：没有空间内存，并且垃圾收集器也无法提供更多内存。 JVM堆、方法区、虚拟机栈和本地方法栈都可能出现OOM问题，其中堆内存溢出的情况最为常见 栈除了存在OOM的情况，当还存在StackOverflow的情况。如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常；如果虚拟机的栈内存允许动态扩展，当扩展栈容量无法申请到足够的内存时，将抛出OOM异常。也就是说，如果栈不支持扩展，除非在创建线程申请内存时就因无法获得足够内存而出现OOM异常，否则在线程运行时是不会因为扩展而导致内存溢出的，只会因为栈容量无法容纳新的栈帧而导致StackOverflowError异常。 导致OOM的原因有： Java虚拟机的堆内存设置不够。可以通过-Xms、-Xmx参数来调整 代码中创建了大量大对象，并且长时间不能被垃圾收集器收集（存在被引用）。比如JDK6之前的永久代，空间很小，且使用的是JVM内存，容易出现OOM问题。 在抛出OOM之前，通常会触发一次GC，尽其所能去清理出空间。例如在引用机制分析中，涉及到JVM会去尝试回收软引用指向的对象等。在java.nio.BIts.reserveMemory()方法中，我们能清楚的看到，System.gc()会被调用，以清理空间。 不是在任何情况下垃圾收集器都会被触发。比如，当分配一个超大对象，其所需空间超过堆的最大值时，JVM可以判断出垃圾收集并不能解决这个问题，所以直接抛出OutOfMemoryError。 2、内存泄漏内存泄露（Memory Leak），也称作“存储渗漏”，严格上来讲，内存泄漏指的是对象不会被程序使用了，但是GC又不能回收他们。比如不使用的对象没有断开和GC Roots引用链的连接，所以这些对象还是可达状态，无法被回收。 Java中会出现的内存泄漏情况： 单例模式。单例的生命周期和应用程序是一样长的，所以单例程序中，如果持有对外部对象的引用的话，那么这个外部对象是不能被回收的，则会导致内存泄漏的产生。java.lang.Runtime类就是单例模式。 一些提供close的资源未关闭导致内存泄漏。比如数据库连接（dataSourse.getConnection())，网络连接(socket)和IO连接必须手动close，否则是不能被回收的。 引用计数算法无法解决循环引用问题，会导致内存泄露，但是Java中不会出现这种内存泄漏，因为Java没有使用引用计数算法。 实际情况中，一些不太好的实践或疏忽导致对象的生命周期变得很长甚至导致OOM，也可以叫做宽泛意义上的“内存泄漏”。 尽管内存泄漏并不会立刻引起程序崩溃，但是一旦发生内存泄漏，程序中的可用内存就会被逐步蚕食，直至耗尽所有内存，最终出现OOM异常，导致程序崩溃。 这里的存储空间并不是指物理内存，而是指虚拟内存大小，这个虚拟内存大小取决于磁盘交换区设定的大小。 内存泄露并不一定会（或者说立即）导致内存溢出。 三、Stop The WorldStop-The-World，简称STW，指的是GC事件发生过程中，会产生应用程序的停顿。停顿产生时整个应用程序所有工作线程都会被暂停，没有任何响应，有点像卡死的感觉，这个停顿称为STW。比如： 可达性分析算法中枚举根节点(GC Roots)会导致所有Java执行线程停顿。 分析工作必须在一个能确保一致性的快照中进行。 一致性指整个分析期间整个执行系统看起来像被冻结在某个时间点上。 如果出现分析过程中对象引用关系还在不断变化，则分析结果的准确性无法保证。 被STW中断的应用程序线程会在完成GC之后恢复，频繁中断会让用户感觉像是网速不快造成电影卡带一样，影响用户体验。所以我们需要减少STW的发生。 STW的发生和采用哪款GC无关，所有的GC都有这种情况。即使是号称停顿时间可控，或者（几乎）不会发生停顿的CMS、G1、ZGC收集器也不能完全避免STW情况发生，枚举根节点时也必须要停顿的。只能说垃圾回收器越来越优秀，回收效率越来越高，尽可能地缩短了暂停时间。 STW是JVM在后台自动发起和自动完成的。在用户不可见的情况下，把用户正常的工作线程全部停掉。 开发中不要用system.gc ();，这个方法会触发Full GC，进而导致STW的发生。 四、垃圾回收的并行与并发1、并发并发(Concurrent)是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理器上运行。 并发不是真正意义上的同时进行，只是CPU把一个时间段划分成几个时间片段(时间区间)，然后在这几个时间区间之间来回切换，由于CPU处理的速度非常快，只要时间间隔处理得当，即可让用户感觉是多个应用程序同时在进行。 在某个时刻，实际只有一个程序正在运行。 比如： 2、并行并行(Parallel)是指当系统有一个以上CPU时，当一个CPU执行一个进程时，另一个CPU可以执行另一个进程，两个进程互不抢占CPU资源，可以同时进行。 决定并行的因素不是CPU的数量，而是CPU的核心数量，比如一个CPU多个核也可以并行。 并行适合科学计算，后台处理等弱交互场景。 并行和并发的对比： 并发指的是多个事件在同一时间段内同时发生。并行指的是多个事件在同一时刻同时发生。 并发的多个任务之间是互相抢占资源的。并行的多个任务之间是不互相抢占资源的。 只有在多CPU或者一个CPU多核的情况中，才会发生并行。否则，看似同时发注的事情，其实都是并发执行的。 3、垃圾回收的并行和并发对于垃圾收集器来说，并行和并发的概念具体指的是： 并行(Parallel)：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。如ParNew、Parallel scavenge、Parallel old收集器。 串行(Serial)：相较于并行的概念，单线程收集。如果内存不够，则程序暂停，启动JVM垃圾回收器进行垃圾回收。回收完，再启动程序的线程。比如Serial、Serial Old收集器。 并发(Concurrent)：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行)，垃圾回收线程在执行时不会停顿用户程序的运行。用户程序在继续运行，而垃圾收集程序线程运行于另一个CPU上。比如CMS、G1收集器。 五、再谈引用JDK1.2之前，Java对象只有“被引用”和“未被引用”两种状态，这些对象要么被回收，要么不能被回收。对于那些“食之无味弃之可惜”的对象，比如我们希望能描述这样一种对象：当内存空间足够时，能保存在内存中，如果内存空间在进行垃圾回收后仍然非常紧张，那就可以抛弃这些对象，类似于缓存功能，这种情况下只有“被引用”和“未被引用”两种状态是不够的。 JDK 1.2之后，Java对引用的概念进行了扩充，将引用分为强引用(Strongly Reference)、软引用(Soft Reference)、弱引用(Weak Reference)和虚引用(Phantom Reference)4种，这4种引用强度依次逐渐减弱。 如图（其中FinalReference表示终结器引用）： 4种引用关系概述： 强引用(StrongReference)：最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，即类似Object obj=new O bject()这种引用关系。无论任何情况下只要强引用关系还存在，垃圾收集器永远不会回收掉被强引用的对象。不回收 软引用(SoftReference)：用于描述一些“还有用，但非必须的对象”。被软引用关联着的对象，在系统将要发生内存溢出之前，将会把这些对象列入回收范围之中进行第二次回收。如果这次回收后还没有足够的内存，才会抛出内存溢出异常。内存不足即回收 弱引用（weakReference)：用于描述非必须对象。被弱引用关联的对象只能生存到下一次垃圾收集之前。当垃圾收集器工作时，无论内存空间是否足够，都会回收掉被弱引用关联的对象。发现即回收 虚引用(PhantomReference)：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来获得一个对象的实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。对象回收跟踪 1、强引用强引用关联对象的主要特点是不回收。 在Java程序中，最常见的引用类型是强引用（普通系统99%以上都是强引用)，也就是我们最常见的普通对象引用，也是默认的引用类型。 当在Java语言中使用new操作符创建一个新的对象，并将其赋值给一个变量的时候，这个变量就成为指向该对象的一个强引用。 强引用的对象是可触及的（可达的），垃圾收集器永远不会回收强引用的对象。 对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为null，就是可以当做垃圾被收集了，当然具体回收时机还是要看垃圾收集策略。 相对的，软引用、弱引用和虚引用的对象是软可触及、弱可触及和虚可触及的，在一定条件下，都是可以被回收的。所以，强引用是造成Java内存泄漏的主要原因之一。 看下面的例子： 1234567891011121314151617public class StrongReferenceTest { public static void main(String[] args) { StringBuffer str = new StringBuffer (\"Hello\"); StringBuffer str1 = str; str = null;//取消str对“Hello”的引用 System.gc(); try {//暂停一段时间，保证GC会被触发 Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } //“Hello”对象不会被回收，因此可以打印出内容 System.out.println(str1); //\"Hello\" }} 上述程序执行时，主动触发GC机制，正常来讲，GC会将str关联的“Hello”对象回收，但“Hello”被str1强引用关联着，因此实际上“Hello”对象不会被回收。 本例中的两个引用，都是强引用，强引用具备以下特点： 强引用可以直接访问目标对象。 强引用所指向的对象在任何时候都不会被系统回收，虚拟机宁可抛出OOM异常，也不会回收强引用所指向对象。 强引用可能导致内存泄漏。 2、软引用软引用关联对象的主要特点是内存不足即回收， 内存足够时不会回收软引用关联的对象。 软引用是用来描述一些还有用，但非必需的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收（第一次回收是指回收不可达对象），如果这次回收还没有足够的内存，才会抛出内存溢出异常。 这时出现OOM异常，并不是软引用对象导致的，因为软引用对象二次回收已经被回收掉了。 软引用通常用来实现内存敏感的缓存。比如高速缓存，如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 垃圾回收器在某个时刻决定回收软可达的对象的时候，会清理软引用，并可选地把引用存放到一个引用队列(Reference Queue) 。 类似弱引用，区别是Java虚拟机会尽量让软引用的存活时间长一些，迫不得已才清理。 案例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class SoftReferenceTest { public static class User { public User(int id, String name) { this.id = id; this.name = name; } public int id; public String name; @Override public String toString() { return \"[id=\" + id + \", name=\" + name + \"] \"; } } public static void main(String[] args) { //创建对象，建立软引用 SoftReference&lt;User&gt; userSoftRef = new SoftReference&lt;User&gt;(new User(1, \"John\")); /*上面的一行代码，等价于如下的三行代码 User u1 = new User(1,\"songhk\");//先建立一个强引用 //将创建软引用，指向强引用关联的对象 SoftReference&lt;User&gt; userSoftRef = new SoftReference&lt;User&gt;(u1); u1 = null;//取消强引用，只保留软引用对对象的关联 */ //从软引用中获得对象 System.out.println(userSoftRef.get());//[id=1, name=John] System.gc(); System.out.println(\"After GC:\"); //由于堆空间内存足够，不会回收软引用的可达对象。 System.out.println(userSoftRef.get()); try {//模拟堆内存不足的情况，-Xms10m,-Xmx10m //会发生OOM的情况 byte[] b = new byte[1024 * 1024 * 7]; } catch (Throwable e) { e.printStackTrace(); } finally { //再次从软引用中获取数据 //OOM之前，垃圾回收器会回收软引用的可达对象。输出null System.out.println(userSoftRef.get());//null } }} 执行以上程序，发现当内存足够时，软引用关联的对象并没有被回收，接下来试图创建大对象，导致堆空间内存不足，触发GC，这时会将软引用关联的对象回收掉。最后的结果输出为null，说明软引用对象确实被回收掉了。 并不是要发生OOM时才会回收软引用关联的对象，只要堆内存不能存储软引用关联的对象时，就会将软引用关联的对象回收。 3、弱引用弱引用关联对象的主要特点是发现即回收。 弱引用也是用来描述那些非必需对象，只被弱引用关联的对象只能生存到下一次垃圾收集发生为止。在系统GC时，只要发现弱引用，不管系统堆空间使用是否充足，都会回收掉只被弱引用关联的对象。 但是，由于垃圾回收器的线程通常优先级很低，因此，并不一定能很快地发现持有弱引用的对象。在这种情况下，弱引用对象可以存在较长的时间。 弱引用和软引用一样，在构造弱引用时，也可以指定一个引用队列，当弱引用对象被回收时，就会加入指定的引用队列，通过这个队列可以跟踪对象的回收情况。 软引用、弱引用都非常适合来保存那些可有可无的缓存数据。如果这么做，当系统内存不足时，这些缓存数据会被回收，不会导致内存溢出。而当内存资源充足时，这些缓存数据又可以存在相当长的时间，从而起到加速系统的作用。 弱引用的案例： 123456789101112131415public class WeakReferenceTest { public static void main(String[] args) { //构造了弱引用 WeakReference&lt;User&gt; userWeakRef = new WeakReference&lt;User&gt;(new User(1, \"John\")); //从弱引用中获取对象 System.out.println(userWeakRef.get()); //[id=1, name=John] System.gc(); //不管当前内存空间足够与否，都会回收它的内存 System.out.println(\"After GC:\"); //重新尝试从弱引用中获取对象 System.out.println(userWeakRef.get()); //null }} 执行上述代码，最后一行输出结果为null，说明弱引用关联的对象被回收了。只要GC回收执行，弱引用关联的对象就会被回收。 4、虚引用虚引用关联对象的主要特点是对象回收跟踪。 虚引用也称为“幽灵引用”或者“幻影引用”，是所有引用类型中最弱的一个。 一个对象是否有虚引用的存在，完全不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它和没有引用几乎是一样的，随时都可能被垃圾回收器回收。 它不能单独使用，也无法通过虚引用来获取被引用的对象。当试图通过虚引用的get()方法取得对象时，总是nu11。 为一个对象设置虚引用关联的唯一目的在于跟踪垃圾回收过程。比如:能在这个对象被收集器回收时收到一个系统通知。 虚引用必须和引用队列一起使用。虚引用在创建时必须提供一个引用队列作为参数。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象后，将这个虚引用加入引用队列，以通知应用程序对象的回收情况。 由于虚引用可以跟踪对象的回收时间，因此，也可以将一些资源释放操作放置在虚引用中执行和记录。 案例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class PhantomReferenceTest { public static PhantomReferenceTest obj;//当前类对象的声明 static ReferenceQueue&lt;PhantomReferenceTest&gt; phantomQueue = null;//引用队列 //创建线程，一直检测引用队列，如果虚引用对象被回收了，引用队列不为空，打印回收记录 public static class CheckRefQueue extends Thread { @Override public void run() { while (true) { if (phantomQueue != null) { PhantomReference&lt;PhantomReferenceTest&gt; objt = null; try { objt = (PhantomReference&lt;PhantomReferenceTest&gt;) phantomQueue.remove(); } catch (InterruptedException e) {e.printStackTrace();} if (objt != null) { System.out.println(\"追踪垃圾回收过程：PhantomReferenceTest实例被GC了\"); } } } } } public static void main(String[] args) { Thread t = new CheckRefQueue(); t.setDaemon(true);//设置为守护线程：当程序中没有非守护线程时，守护线程也就执行结束。 t.start(); phantomQueue = new ReferenceQueue&lt;PhantomReferenceTest&gt;(); obj = new PhantomReferenceTest(); //构造了 PhantomReferenceTest 对象的虚引用，并指定了引用队列 PhantomReference&lt;PhantomReferenceTest&gt; phantomRef = new PhantomReference&lt;PhantomReferenceTest&gt;(obj, phantomQueue); try { //无法通过虚引用获取其关联的对象 System.out.println(phantomRef.get()); //null //将强引用去除 obj = null; System.out.println(\"调用GC\"); System.gc(); //一旦将obj对象回收，就会将此虚引用存放到引用队列中。 Thread.sleep(1000); if (obj == null) { System.out.println(\"obj 是 null\"); } else { System.out.println(\"obj 可用\"); } } catch (InterruptedException e) { e.printStackTrace(); } }}/*执行结果null调用GC追踪垃圾回收过程：PhantomReferenceTest实例被GC了obj 是 null*/ 5、终结器引用终结器引用（Final Reference）用以实现对象的finalize ()方法。无需手动编码，其内部配合引用队列使用。 在GC时，终结器引用入队。由Finalizer线程通过终结器引用找到被引用对象并调用它的finalize ()方法，第二次GC时才能回收被引用对象。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://kangshitao.github.io/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://kangshitao.github.io/tags/JVM/"}]},{"title":"深入理解String的intern()方法","slug":"understanding-string-intern","date":"2021-05-10T11:40:39.000Z","updated":"2022-05-22T13:30:54.806Z","comments":true,"path":"2021/05/10/understanding-string-intern/","link":"","permalink":"http://kangshitao.github.io/2021/05/10/understanding-string-intern/","excerpt":"从JVM的角度理解字符串的创建和拼接过程，理解intern()方法","text":"一、String基本特征 Java中的字符串String，使用\"\"引起来表示。两种实例化方式： String s1 = “hello”; String s2 = new String(\"hello\"); String声明为final的，不可被继承 String类实现了Serializable接口、Comparable接口。 String类重写了equals()方法，代码如下： 12345678910111213//JDK 15public boolean equals(Object anObject) { if (this == anObject) { return true; } if (anObject instanceof String) { String aString = (String)anObject; if (!COMPACT_STRINGS || this.coder == aString.coder) { return StringLatin1.equals(value, aString.value); } } return false;} JDK8之前，String使用char型数组存放数据，JDK9改为byte型数组。修改原因，官方描述如下，参考： We propose to change the internal representation of the String class from a UTF-16 char array to a byte array plus an encoding-flag field. The new String class will store characters encoded either as ISO-8859-1/Latin-1 (one byte per character), or as UTF-16 (two bytes per character), based upon the contents of the string. The encoding flag will indicate which encoding is used. String-related classes such as AbstractStringBuilder, StringBuilder, and StringBuffer will be updated to use the same representation, as will the HotSpot VM’s intrinsic string operations. This is purely an implementation change, with no changes to existing public interfaces. There are no plans to add any new public APIs or other interfaces. The prototyping work done to date confirms the expected reduction in memory footprint, substantial reductions of GC activity, and minor performance regressions in some corner cases. String代表不可变的字符序列，详细使用可以参考Java学习笔记09(1)-常用类之String。 通过字面量定义的字符串存储在字符串常量池(String Pool)（JDK7将字符串常量池移到了堆中）中，目的是共享；通过new创建对象的方式构建的字符串存储在堆（堆中字符串常量池以外的空间）中。 字符串常量池中是不会存储相同内容的字符串： String Pool 是一个固定大小的Hashtable（底层采用数组和链表实现，Hashtable无法扩容，这一点不同于HashMap）。如果放进String Pool的String非常多， 就会造成严重的哈希冲突，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用String.intern()时性能会大幅下降。 使用- XX:StringTableSize可设置StringTable的长度 在JDK 6中StringTable的值默认大小为1009，所以如果常量池中的字符串过多就会导致效率下降很快。对于StringTableSize的设置没有要求。 在JDK 7中，StringTable的长度默认值是60013。StringTableSize的设置没有要求。 从JDK 8开始，StringTable长度可设置的最小值要求为1009。 二、String的内存分配Java中，8中基本数据类型的常量池都是系统协调的，String类型的常量池比较特殊，它的主要使用方法有两种： 直接使用\"\"号，即字面量的方式，声明出来的字符串对象会直接存储在常量池中。 比如：String s = \"hello\"; 如果不是使用\"\"的方式（使用new方式，或者和变量拼接等方式）声明的String对象是放在堆中的。可以使用String类提供的intern()方法，intern()方法会从字符串常量池中查询当前字符串是否存在，如果存在，直接返回字符串，若不存在就会将当前字符串放入常量池中并返回。 JDK 6及以前，字符串常量池存放在永久代。 JDK 7中，字符串常量池被移到了堆中（原因：permSize默认空间比较小；永久代垃圾回收频率低）： 所有的字符串都保存在Heap中，和其他普通对象一样，调优时仅需调整堆大小即可。 这次改动让我们重新考虑在JDK 7中使用String.intern();。因为调整以后，常量池中不需要必须存储一份对象了，可以直接存储堆中的引用。也就是说，调用此方法时，如果堆中已经存在相等的String对象，会直接保存对象的引用，而不会重新创建对象。这一点的体现可以参考下文的例题。 JDK 8中，字符串常量池依然是在堆中。 三、String的基本操作 情况一：Java语言规范（链接）里要求，完全相同的字符串字面量，应该包含同样的unicode字符序列，并且必须是指向同一个String类实例。 123456789101112public class StringTest4 { public static void main(String[] args) { System.out.println();//3142个已加载字符串常量 System.out.println(\"1\");//3143 System.out.println(\"2\");//3144 System.out.println(\"3\");;//3145 //如下的字符串\"1\" 到 \"3\"不会再次加载 System.out.println(\"1\");//3145 System.out.println(\"2\");//3145 System.out.println(\"3\");//3145 }} 情况二： 12345678910111213class Memory { public static void main(String[] args) {//line 1 int i = 1;//line 2 Object obj = new Object();//line 3 Memory mem = new Memory();//line 4 mem.foo(obj);//line 5 }//line 9 private void foo(Object param) {//line 6 String str = param.toString();//line 7 System.out.println(str); }//line 8} 上述程序的内存结构如下： 四、字符串拼接操作1、字符串拼接的特征字符串拼接有以下特征： 常量与常量的拼接，结果在常量池，原理是编译期优化，生成字节码文件的时候，已经生成了常量的拼接结果。 123456789101112131415161718192021public class StringTest { @Test public void test1(){ String s1 = \"a\" + \"b\" + \"c\";//编译期优化：等同于\"abc\" String s2 = \"abc\"; //\"abc\"一定是放在字符串常量池中，将此地址赋给s2 System.out.println(s1 == s2); //true System.out.println(s1.equals(s2)); //true }}/*在前端编译生成的字节码文件中，已经将s1优化为“abc”如下为部分字节码文件内容： 0 ldc #7 &lt;abc&gt; 可见，s1的值已经优化为\"abc\" 2 astore_1 3 ldc #7 &lt;abc&gt; 5 astore_2 6 getstatic #9 &lt;java/lang/System.out&gt; 9 aload_110 aload_2...*/ 常量池中不会存在相同内容的常量。 如果拼接的字符串里有变量，结果在堆中（堆中字符串常量池以外的堆空间），相当于new了新对象。拼接的原理是StringBuilder。 12345678910111213141516171819public class StringTest{ public void test3(){ String s1 = \"a\"; String s2 = \"b\"; String s3 = \"ab\"; String s4 = s1 + s2; System.out.println(s3 == s4);//false }}/*上述的s1 + s2 的具体执行细节：(变量s是为了容易理解定义的，实际上是匿名的）① StringBuilder s = new StringBuilder();② s.append(\"a\");③ s.append(\"b\");④ s.toString(); --&gt; 约等于 new String(\"ab\")补充：在jdk5.0之后使用的是StringBuilder,在jdk5.0之前使用的是StringBuffers3在堆中的字符串常量池中，而s4在堆中字符串常量池以外的位置，因此二者地址不相等*/ 上述程序的字节码文件如下： 1234567891011121314151617181920212223240 ldc #47 &lt;a&gt;2 astore_13 ldc #49 &lt;b&gt;5 astore_26 ldc #51 &lt;ab&gt;8 astore_39 new #33 &lt;java/lang/StringBuilder&gt; 12 dup13 invokespecial #35 &lt;java/lang/StringBuilder.&lt;init&gt;&gt;16 aload_117 invokevirtual #36 &lt;java/lang/StringBuilder.append&gt; 20 aload_221 invokevirtual #36 &lt;java/lang/StringBuilder.append&gt; 24 invokevirtual #40 &lt;java/lang/StringBuilder.toString&gt; 27 astore 429 getstatic #9 &lt;java/lang/System.out&gt;32 aload_333 aload 435 if_acmpne 42 (+7)38 iconst_139 goto 43 (+4)42 iconst_043 invokevirtual #15 &lt;java/io/PrintStream.println&gt;46 return 通过变量拼接字符串的过程，可以总结如下，当遇到有变量的字符串拼接时： 首先使用new方式创建StringBuilder对象（JDK 5.0之前是StringBuffer） 然后调用append()方法，将要拼接的字符串内容添加到StringBuilder对象中 最后调用StringBuilder对象的toString()方法，将其转换为String类型，赋给指定的变量。 此外，还需要注意的是，如果字符串拼接是变量，但是是用final修饰的，此时这种变量就是常量，同样在编译期优化，结果存放到字符串常量池中： 123456789public class StringTest{ public void test4(){ final String s1 = \"a\"; //常量 final String s2 = \"b\"; String s3 = \"ab\"; String s4 = s1 + s2; //此时的s4等价于\"a\"+\"b\" System.out.println(s3 == s4);//true }} 建议：针对于final修饰类、方法、基本数据类型、引用数据类型的量的结构时，能用final时尽量使用。这样前端编译期就能赋值，提高运行效率。 如果拼接的结果调用intern()方法，则主动将常量池中没有的字符串对象放入池中，并返回此对象的地址（引用，reference），具体参加下一节内容。 2、‘+’号和append方法对比对于字符串拼接，可以使用+号直接拼接字符串，也可以在StringBuffer/StringBuilder对象中使用append()方法，二者的效率对比如下： 123456789101112131415161718192021222324public class StringTest{ public void test6(){ long start = System.currentTimeMillis(); method1(100000);//3989ms //method2(100000);//7ms long end = System.currentTimeMillis(); System.out.println(\"花费的时间为：\" + (end - start)); } public void method1(int highLevel){ String src = \"\"; for(int i = 0;i &lt; highLevel;i++){ src = src + \"a\";//每次循环都会创建一个StringBuilder、String } } public void method2(int highLevel){ //只需要创建一个StringBuilder StringBuilder src = new StringBuilder(); for (int i = 0; i &lt; highLevel; i++) { src.append(\"a\"); } }} 以上结果表明，使用StringBuffer/StringBuilder对象中的append()方法进行字符串拼接，效率要远高于+号拼接String的方式。 使用+号拼接时，每次都需要创建一个StringBuffer/StringBuilder对象，然后调用append()方法添加内容，最后调用toString()方法生成String对象并重新赋值。 使用append()方式，只创建了一个StringBuffer/StringBuilder对象，因此效率要高很多。 此外，用String的字符串拼接方式，内存中由于创建了较多的StringBuilder和String的对象，内存占用更大，如果进行GC，需要花费额外的时间。 因此，实际开发中，如果需要大量的字符串操作，尽量使用StringBulider。 如果确定字符串长度不高于某个值的情况下，建议使用带参的构造器实例化StringBuilder，底层会一次性申请指定长度的数组，这样可以避免频繁扩容带来的效率降低。 五、intern()的使用1、intern（）方法JDK源码中intern()方法的定义和描述： 12345678910111213141516171819/*Returns a canonical representation for the string object.A pool of strings, initially empty, is maintained privately by the class String.When the intern method is invoked, if the pool already contains a string equal tothis String object as determined by the equals(Object) method, then the string fromthe pool is returned. Otherwise, this String object is added to the pool and areference to this String object is returned.It follows that for any two strings s and t, s.intern() == t.intern() is true if andonly if s.equals(t) is true.All literal strings and string-valued constant expressions are interned. Stringliterals are defined in section 3.10.5 of the The Java Language Specification.Returns:a string that has the same contents as this string, but is guaranteed to be from apool of unique strings.*/public native String intern(); 根据描述可知，当str调用str.intern()时，如果字符串常量池中已经有和str相等的字符串（使用equals()方法判断），则返回当前字符串（或者说字符串对象的引用）；如果没有str字符串的话，会在常量池中生成，然后再返回此字符串。 s.intern() == t.intern()等价于s.equals(t) 为 true 如果不是用\"\"声明的String对象，可以使用String提供的intern()方法，intern()方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中，比如： 12//返回的结果是字符串常量池中的引用，即myInfo指向了字符串常量池中的“hello\"String myInfo = new String(\"hello\").intern(); 也就是说，如果在任意字符串上调用intern()方法，那么其返回结果所指向的那个类实例，必须和直接以常量形式出现的字符串实例完全相同。因此，下列表达式的值必定是true： 1(\"a\" + \"b\" + \"c\").intern() == \"abc\"; //结果为true 通俗点讲，Interned String确保字符串在字符串常量池里只有一份拷贝，这样可以节约内存空间，加快字符串操作任务的执行速度。 进一步来说，例如，想要保证变量s指向的是字符串常量池中的数据，比如”hello”这个字符串，有两种方式： 直接使用字面量定义的方式，String s = \"hello\"; 调用String类的intern()方法，比如String s = new String(\"hello\").intern(); 无论字符串是怎样方式定义或生成的，只要调用intern()方法，返回的一定是此字符串在字符串常量池中的引用 2、关于new String()问题引申一：如果使用new String(\"ab\")方式创建字符串对象，会创建几个对象呢？答案是两个 通过字节码可以看出： 12345678910111213public class StringNewTest { public static void main(String[] args) { String str = new String(\"ab\"); }}//以上代码的字节码文件如下： 0 new #7 &lt;java/lang/String&gt; //1.创建String对象 3 dup 4 ldc #9 &lt;ab&gt; //2.字符串常量池中的对象（数组） 6 invokespecial #11 &lt;java/lang/String.&lt;init&gt;&gt; 9 astore_110 return//根据字节码文件可知，底层创建了String对象和字符串常量池中的对象\"ab\" 字符串常量池中创建了”ab”字符串对象。 问题引申二：如果使用new String(\"a\")+new String(\"b\")方式创建字符串对象，会创建几个对象呢？答案是6个 12345678910111213141516171819202122public class StringNewTest { public static void main(String[] args) { String str = new String(\"a\") + new String(\"b\"); }}//以上程序字节码文件为： 0 new #7 &lt;java/lang/StringBuilder&gt; //对象1 3 dup 4 invokespecial #9 &lt;java/lang/StringBuilder.&lt;init&gt;&gt; 7 new #10 &lt;java/lang/String&gt; //对象210 dup11 ldc #12 &lt;a&gt; //对象313 invokespecial #14 &lt;java/lang/String.&lt;init&gt;&gt;16 invokevirtual #17 &lt;java/lang/StringBuilder.append&gt;19 new #10 &lt;java/lang/String&gt; //对象422 dup23 ldc #21 &lt;b&gt; //对象525 invokespecial #14 &lt;java/lang/String.&lt;init&gt;&gt;28 invokevirtual #17 &lt;java/lang/StringBuilder.append&gt;31 invokevirtual #23 &lt;java/lang/StringBuilder.toString&gt; //对象634 astore_135 return 通过字节码文件可知，一共创建了6个对象，分别为： new StringBuilder()，字节码第0行 new String(\"a\")，字节码第7行 常量池的”a”，字节码第11行 new String(\"b\")，字节码第19行 常量池的“b“，字节码第23行 toString()方法创建的String对象，字节码第31行 这里的StringBuilder的toString()方法创建了一个String对象： 1234567//StringBuilder中toString()方法的源码。JDK15public String toString() { // Create a copy, don't share the array return isLatin1() ? StringLatin1.newString(value, 0, count) : StringUTF16.newString(value, 0, count);}//参数中的value是一个数组 值得注意的是，这里toString()方法只创建了一个String对象，没有在字符串常量池中创建”ab”字符串对象，因为其直接使用数组创建字符串，而不是使用字面量的方式，所以字符串常量池中没有”ab”这个字符串。 3、通过实例进一步理解例一，参考深入解析String#intern： 1234567891011public static void main(String[] args) { String s = new String(\"1\"); s.intern(); String s2 = \"1\"; System.out.println(s == s2); //JDK6 false; JDK7 false String s3 = new String(\"1\") + new String(\"1\"); s3.intern(); String s4 = \"11\"; System.out.println(s3 == s4); //JDK6 false; JDK7 true} 可以看到，在JDK6中结果都是false，而在JDK7及以后的版本中结果为false和true。这是为什么呢？ 在JDK6及以前的版本中，常量池放在永久区（Perm区），永久区和Heap区是完全分开的。前面说过，使用\"\"号声明的字符串直接在字符串常量池中生成，而new出来的String对象放在堆中。因此s和s3都是指向堆中对象的一个引用地址，s2和s4是方法区字符串常量池中对象地址，无论如何都不相等。 对于JDK7及以后的版本： 先看 s 和 s2 对象。 String s = new String(\"1\"); 第一句代码，生成了2个对象，即常量池中的“1” 和堆中的String对象。其中s是指向堆中的String对象的引用。s.intern(); 这一句是 s 对象去字符串常量池中寻找后发现 “1” 已经在常量池里了。因此String s2 = \"1\"; 这句代码生成一个 s2的引用指向字符串常量池中的“1”对象。 结果就是 s 和 s2 的引用地址明显不同。 对于 s3和s4。String s3 = new String(\"1\") + new String(\"1\");这句代码生成了字符串常量池中的“1” ，此时s3引用对象内容是”11”，存放在堆中。但此时常量池中是没有 “11”对象的。接下来s3.intern();将 s3中的“11”字符串放入 String 常量池中，因为此时常量池中不存在“11”字符串，常规做法是跟 jdk6 那样，在常量池中生成一个 “11” 的对象，关键点是jdk7 常量池中可以直接存储堆中的引用。因此常量池中存放的是引用，这份引用指向 s3 引用的对象。 也就是说引用地址是相同的。最后String s4 = \"11\"; 这句代码中”11”是显式声明的，因此会直接去常量池中创建，创建的时候发现已经有这个对象了，此时也就是指向 s3 引用对象的一个引用，所以 s4 引用就指向和 s3 一样了，最后比较 s3 == s4 是 true。 例二，将例一中的intern()语句下调一行： 1234567891011public static void main(String[] args) { String s = new String(\"1\"); String s2 = \"1\"; s.intern(); System.out.println(s == s2); //JDK6 false; JDK7 false String s3 = new String(\"1\") + new String(\"1\"); String s4 = \"11\"; //在字符串常量池中生成了“11” s3.intern(); System.out.println(s3 == s4); //JDK6 false; JDK7 false} 此时不同版本的结果都是false： 对于s 和 s2 ，s.intern();，这一句往后放不会有什么影响，因为对象池中在执行第一句代码String s = new String(\"1\");的时候已经生成“1”对象了。下边的s2声明都是直接从常量池中取地址引用的。 s 和 s2 的引用地址是不会相等的。 对于s3和s4，首先执行String s4 = \"11\";声明 s4 的时候常量池中是不存在“11”对象的，执行完毕后，“11“对象是 s4 声明产生的新对象，方法返回字符串常量池中“11”的引用赋给s4。然后再执行s3.intern();时，常量池中“11”对象已经存在了，因此 s3 和 s4 的引用是不同的。s3是指向堆中对象的引用，而s4是字符串常量池中的引用，所以结果是false 4、总结String中intern()的作用： 在JDK 6中，intern()尝试将字符串对象放入字符串常量池。 如果常量池中有，则不会放入，返回已有的对象地址 如果没有，会把此对象复制一份，放入常量池，并返回常量池中对象地址。 在JDK7及以后，intern()尝试将字符串对象放入字符串常量池。 如果常量池中有，则不会放入，返回已有的对象地址 如果没有，会把此对象的引用地址复制一份，放入常量池，并返回常量池中对象引用地址。 5、练习练习1： 12345678910111213141516public class StringExer1 { public static void main(String[] args) { String s = new String(\"a\") + new String(\"b\");//new String(\"ab\") //在上一行代码执行完以后，字符串常量池中并没有\"ab\" /* jdk6中：在串池中创建一个字符串\"ab\" jdk7中：串池中没有创建字符串\"ab\", 而是创建一个引用，指向new String(\"ab\")，将此引用返回 */ String s2 = s.intern(); System.out.println(s2 == \"ab\");//jdk6:true jdk7:true System.out.println(s == \"ab\");//jdk6:false jdk7:true //\"ab\"与String s3 = \"ab\"写法结果相同 }} 练习2： 123456789public class StringExer2 { public static void main(String[] args) { //执行完以后，不会在字符串常量池中会生成\"ab\" String s1 = new String(\"a\") + new String(\"b\"); s1.intern(); String s2 = \"ab\"; System.out.println(s1 == s2); //jdk6 false; jdk7 true }} 练习3： 123456789public class StringExer3 { public static void main(String[] args) { //执行完以后，会在字符串常量池中会生成\"ab\" String s1 = new String(\"ab\"); s1.intern(); String s2 = \"ab\"; System.out.println(s1 == s2); //jdk6 false; jdk7 false }} 6、intern（）的使用实际开发中，如果程序中存在大量重复字符串，使用intern()会节省大量空间，与JDK版本无关。 12345678910111213141516public class StringIntern2 { static final int MAX_COUNT = 1000 * 10000; static final String[] arr = new String[MAX_COUNT]; public static void main(String[] args) { Integer[] data = new Integer[]{1,2,3,4,5,6,7,8,9,10}; long start = System.currentTimeMillis(); for (int i = 0; i &lt; MAX_COUNT; i++) { //两种创建字符串的方式，分别为不使用intern和使用intern //arr[i] = new String(String.valueOf(data[i % data.length])); arr[i] = new String(String.valueOf(data[i % data.length])).intern(); } long end = System.currentTimeMillis(); System.out.println(\"花费的时间为：\" + (end - start)); }} 通过运行程序可知，使用intern()方法时，占用的空间大小相较于不使用intern()时要小很多，主要原因是因为： 不使用intern()创建字符串对象，会在堆中生成大量的String对象，且不能回收，导致空间占用很大。 使用intern()方法创建对象，如果字符串常量池中已经存在要创建的对象，则数组元素直接指向字符串常量池中的字符串对象，无需在堆中维护过多的String对象（或者说创建之后可以被回收销毁），因此空间占用小。 注意，两种方式在字符串常量池中创建的字符串个数是相等的，区别只是堆中字符串对象的数量不同 实际应用：在大的网站平台，需要内存中存储大量字符串，这时候如果字符串都调用intern()方法，会明显降低内存大小。 关于intern()方法错误的使用，也可以参考深入解析String#intern 六、G1中的String去重操作Garbage First收集器对String的去重操作，参考官方说明JEP 192: String Deduplication in G1 背景： 对许多Java应用（有大的也有小的）做的测试得出以下结果: 堆存活数据集合里面string对象占了25% 堆存活数据集合里面重复的string对象有13.5% string对象的平均长度是45 许多大规模的Java应用的瓶颈在于内存，测试表明，在这些类型的应用里面，Java堆中存活的数据集合差不多25%是string对象。更进一步，这里面差不多一半string对象是重复的，即string1.equals(string2 )=true。堆上存在重复的string对象必然是一种内存的浪费。在G1垃圾收集器中实现自动持续对重复的strfing对象进行去重，这样就能避免浪费内存。 实现： 当垃圾收集器工作的时候，会访问堆上存活的对象。对每一个访问的对象都会检查是否是候选的要去重的string对象。 如果是，把这个对象的一个引用插入到队列中等待后续的处理。一个去重的线程在后台运行，处理这个队列。处理队列的一个元素意味着从队列删除这个元素，然后尝试去引用和它一样的string对象。 使用一个hashtable来记录所有的被string对象使用的不重复的char数组。当去重的时候，会查这个hashtable，来看堆上是否已经存在一个一模一样的char数组。 如果存在，string对象会被调整为引用那个数组，释放对原来的数组的引用，最终会被垃圾收集器回收掉。 如果查找失败，char数组会被插入到hashtable，这样以后的时候就可以共享这个数组。 命令行选项： UseStringDeduplication (bool) ：开启String 去重，默认是不开启的 PrintStringDeduplicationStatistics (bool) ：打印详细的去重统计信息 StringDeduplicationAgeThreshold (uintx) ：达到这个年龄的String对象被认为是去重的候选对象。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://kangshitao.github.io/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"http://kangshitao.github.io/tags/JVM/"}]},{"title":"JVM-不同JDK版本中方法区的演变","slug":"method-area-evolution","date":"2021-05-09T03:27:46.000Z","updated":"2022-05-22T13:30:54.798Z","comments":true,"path":"2021/05/09/method-area-evolution/","link":"","permalink":"http://kangshitao.github.io/2021/05/09/method-area-evolution/","excerpt":"JDK6，JDK7，JDK8及以后的方法区的变化","text":"1、方法区的演变方法区（Method Area）存放的内容为：类型信息、常量、静态变量、即时编译器编译后的代码缓存、域信息、方法信息等。 HotSpot虚拟机中，方法区(Method Area)在JDK8中经历了重要的变化。 JDK 8之前，HotSpot虚拟机中，使用永久代实现方法区，永久代与方法区的概念并不等价，永久代只是方法区的实现而已。 方法区只是逻辑上的分区概念，真正实现方式是永久代或元空间。 从JDK6版本有了移除永久代的计划，直到JDK 8版本，永久代被彻底移除，取而代之的是元空间（Meta-space），具体演变过程如下（参考《深入理解Java虚拟机 第三版》P46；JVM教程）： JDK 6版本及之前，使用永久代实现方法区，此时的永久代，或者说方法区，使用的是JVM内存。 JDK 7版本，把原本在永久代的字符串常量池、静态变量等移出到了堆中，永久代仍然使用JVM内存。 静态变量仅是指的引用名（变量本身），只是引用名的位置发生了改变，new出来的对象实体，一直是保存在堆中。参考《深入理解Java虚拟机》P152的案例。 JDK 8版本，将永久代中剩余的内容，包括类型信息、字段、方法、常量等，移出到了元空间中。彻底废弃了永久代的概念。元空间使用的是本地内存（Native Memory）。注意，JDK8中仍然有方法区的概念，不过是实现方法变成了本地内存的元空间。 如图： 2、为什么要废弃永久代关于为什么要废弃永久代，使用本地内存的元空间代替，官方解释原因参考(来源)： Motivation This is part of the JRockit and Hotspot convergence effort. JRockit customers do not need to configure the permanent generation (since JRockit does not have a permanent generation) and are accustomed to not configuring the permanent generation. 上述内容简单来说，是因为Oracle官方想要将JRockit虚拟机的优秀功能移植到HotSpot虚拟机中，而JRockit虚拟机不存在永久代的概念，为了保持一致，将HotSpot虚拟机中的永久代移除。 这种说法并未从深层次解释原因，关于为什么不使用永久代的原因，需要从永久代本身的一些特点来解释： 为永久代设置空间大小是很难确定的。某些场景下，如果动态加载类过多，容易产生永久代(Perm)的OOM问题。因为永久代有-XX:MaxPermSize参数，限制了永久代的上限空间，32位系统默认大小是4GB。而JRockit虚拟机没有这种限制，只要不超过线程可用本地内存上限，就不会有问题。元空间不在虚拟机中，而是使用本地内存，默认情况下只受本地内存大小限制。 HotSpot虚拟机中的永久代，设计初衷是将收集器的分代机制扩展至方法区，即使用永久代实现方法区，方便垃圾收集器能够像管理Java堆一样管理这部分内存，省去专门为方法区编写内存管理代码的工作。现在回头看来，这种做法并不是好主意。 对永久代的调优很困难。对方法区的垃圾回收，涉及到常量池回收和类型的卸载（类的回收）等，类型回收的条件相当苛刻，比较消耗时间。 3、为什么要移动字符串常量池JDK 7中将String Table（字符串常量池）放到了堆空间中。因为永久代的回收效率很低，在full GC时才会回收永久代。而full GC在老年代空间不足、永久代空间不足时才会触发，这就导致StringTable的回收效率并不高。开发中会有大量的字符串被创建，如果回收效率低，会导致永久代内存不足。放到堆里面，能及时回收内存。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://kangshitao.github.io/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://kangshitao.github.io/tags/JVM/"},{"name":"java","slug":"java","permalink":"http://kangshitao.github.io/tags/java/"}]},{"title":"JDBC与Druid数据库连接池","slug":"jdbc-datasource","date":"2021-04-30T07:58:59.000Z","updated":"2022-05-22T13:30:54.796Z","comments":true,"path":"2021/04/30/jdbc-datasource/","link":"","permalink":"http://kangshitao.github.io/2021/04/30/jdbc-datasource/","excerpt":"JDBC简介，Druid数据库连接池、Apache-DBUtils工具类的用法","text":"一、传统数据库连接1、JDBC简介JDBC(Java Database Connectivity)是独立于特定数据库管理系统、通用的SQL数据库存取和操作的公共接口（一组API），定义了用来访问数据库的标准Java类库（java.sql,javax.sql），使用这些类库可以以一种标准的方法、方便地访问数据库资源。 开发人员只需要面向JDBC的接口编程即可，不同数据库厂商各自需要实现JDBC接口，即为不同的数据库驱动。 使用JDBC连接并操作数据库的步骤： 导入java.sql和所使用的数据库的驱动，即.jar包 加载并注册驱动程序 创建Connection对象，建立连接 创建Statement或PreparedStatement对象 执行SQL语句，实现CRUD操作，如果是查询操作，会返回结果集ResultSet并需要处理。 关闭Statement/PreparedStatement对象和Connection连接，如果有ResultSet，也需要关闭。 2、数据库连接java.sql.Driver接口是所有JDBC驱动程序需要实现的接口，数据库厂商需要实现此接口。程序中使用驱动程序管理器类(java.sql.DriverManager)调用这些Driver实现（即注册驱动）。 创建连接的步骤： 加载并读取配置相关信息，如数据库用户名，密码，驱动的类名，驱动URL 加载驱动，即实例化Driver，一般不主动实例化，而是使用反射的方式，根据加载的JDBC驱动的类名，加载驱动。如Class.forName(“com.mysql.jdbc.Driver”); 注册驱动: 方式一，使用DriverManager.registerDriver(com.mysql.jdbc.Driver)注册驱动. 方式二，通常不手动注册，因为 Driver接口的驱动程序类都包含了静态代码块，在这个静态代码块中，会调用 DriverManager.registerDriver()方法来注册自身的一个实例。比如MySQL的Driver实现类的源码如下 1234567static { try { java.sql.DriverManager.registerDriver(new Driver()); } catch (SQLException E) { throw new RuntimeException(\"Can't register driver!\"); }} 获取连接。调用DriverManager 类的静态 getConnection() 方法建立到数据库的连接。 url用于标识一个被注册的驱动程序，驱动程序管理器通过这个 URL 选择正确的驱动程序，从而建立到数据库的连接。JDBC URL由三部分组成，即jdbc:子协议:子名称，子名称用于定位具体的数据库，包含主机名、端口号、数据库名。比如对于MySQL来说，其URL编写格式为：jdbc:mysql://[主机名称:mysql的服务端口号]/数据库名称[?参数=值&amp;参数=值]，例如test数据库，可以写为：jdbc:mysql://localhost:3306/test?characterEncoding=utf-8，如果有编码问题，可以设置连接时的参数。 使用DriverManager 获取数据库连接举例： 123456789101112131415161718192021222324public void testConnection() throws Exception { //1.加载配置文件 InputStream is = ConnectionTest.class.getClassLoader(). getResourceAsStream(\"jdbc.properties\"); roperties pros = new Properties(); pros.load(is); //2.读取配置信息 String user = pros.getProperty(\"user\"); String password = pros.getProperty(\"password\"); String url = pros.getProperty(\"url\"); String driverClass = pros.getProperty(\"driverClass\"); //3.加载驱动(包含了实例化Driver和注册驱动两步) Class.forName(driverClass); /* 上述步骤通过反射获取Driver实现类的Class实例，目的是在此过程中调用 对应实现类的静态代码块，代码块中实例化Driver，并注册了驱动 */ //4.获取连接 Connection conn = DriverManager.getConnection(url,user,password); System.out.println(conn);} 其中jdbc.properties配置文件需要在src目录下，内容如下： 1234user=root password=abc123url=jdbc:mysql://localhost:3306/test?characterEncoding=utf-8driverClass=com.mysql.jdbc.Driver 这里操作符两边不能用空格。 二、使用PreparedStatement实现CRUD操作在java.sql 包中有 3 个接口分别定义了对数据库的调用的不同方式： Statement：用于执行静态 SQL 语句并返回它所生成结果的对象。 PrepatedStatement：SQL 语句被预编译并存储在此对象中，可以使用此对象多次高效地执行该语句。 CallableStatement：用于执行 SQL 存储过程 1、PreparedStatement介绍 可以通过调用 Connection 对象的 preparedStatement(String sql) 方法获取 PreparedStatement 对象 PreparedStatement 接口是 Statement 的子接口，它表示一条预编译过的 SQL 语句 PreparedStatement 对象所代表的 SQL 语句中的参数用?来表示，调用 PreparedStatement 对象的 setXxx() 方法来设置这些参数，setXxx() 方法有两个参数，第一个参数是要设置的 SQL 语句中的参数的索引(从1开始)，第二个是设置的 SQL 语句中的参数的值。 2、PreparedStatement的使用PreparedStatement 和 Statement对比： PreparedStatement是Statement的子类，二者都能实现对数据库的CRUD操作 Statement使用字符串拼接操作，繁琐。而使用PreparedStatement的代码可读性和可维护性强。 PreparedStatement 对SQL语句预编译，能最大可能提高性能： DBServer会对预编译语句提供性能优化。因为预编译语句有可能被重复调用，所以语句在被DBServer的编译器编译后的执行代码被缓存下来，那么下次调用时只要是相同的预编译语句就不需要编译，只要将参数直接传入编译过的语句执行代码中就会得到执行。 statement语句中，即使是相同操作，但因为数据内容不一样导致整个语句本身不能匹配，没有缓存语句的意义。事实是没有数据库会对普通语句编译后的执行代码缓存。这样每执行一次都要对传入的语句编译一次，效率降低。 Statement存在SQL注入问题，PreparedStatement 使用预编译和?占位符传值，可以防止此问题 。 此外，PreparedStatement还能够实现对Blob数据的操作，并且对于批量插入比较高效。 举例1：使用PreparedStatement实现增、删、改操作 1234567891011121314151617181920212223242526272829303132/*我们将上述提到的数据库连接操作，以及资源关闭操作，封装到JDBCUtils工具类中，即以下的几个静态方法：public static Connection getConnection()：返回一个Connection实例public static void closeResource(Connection c,Statement ps)：关闭资源public static void closeResource(Connection c,Statement ps,ResultSet rs)：关闭资源*/public class PreparedStatementTest{ //适用于不同的表的增、删、改操作 public void update(String sql,Object ... args){ Connection conn = null; PreparedStatement ps = null; try { //1.获取数据库的连接 conn = JDBCUtils.getConnection(); //2.获取PreparedStatement的实例 (或：预编译sql语句) ps = conn.prepareStatement(sql); //3.填充占位符 for(int i = 0;i &lt; args.length;i++){ ps.setObject(i + 1, args[i]); } //4.执行sql语句 ps.execute(); } catch (Exception e) { e.printStackTrace(); }finally{ //5.关闭资源 JDBCUtils.closeResource(conn, ps); } }} 举例2：使用PreparedStatement实现查询操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class prepareStatementTest{ // 通用的针对于不同表的查询:返回一个对象 public &lt;T&gt; T getInstance(Class&lt;T&gt; clazz, String sql, Object... args) { Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { // 1.获取数据库连接 conn = JDBCUtils.getConnection(); // 2.预编译sql语句，得到PreparedStatement对象 ps = conn.prepareStatement(sql); // 3.填充占位符 for (int i = 0; i &lt; args.length; i++) { ps.setObject(i + 1, args[i]); } // 4.执行executeQuery(),得到结果集：ResultSet rs = ps.executeQuery(); // 5.得到结果集的元数据：ResultSetMetaData ResultSetMetaData rsmd = rs.getMetaData(); // 6.1通过ResultSetMetaData得到columnCount,columnLabel；通过ResultSet得到列值 int columnCount = rsmd.getColumnCount(); if (rs.next()) { T t = clazz.newInstance(); for (int i = 0; i &lt; columnCount; i++) {// 遍历每一个列 // 获取列值 Object columnVal = rs.getObject(i + 1); // 获取列的别名:列的别名必须和类的属性相同 String columnLabel = rsmd.getColumnLabel(i + 1); // 6.2使用反射，给对象的相应属性赋值 Field field = clazz.getDeclaredField(columnLabel); field.setAccessible(true); field.set(t, columnVal); } return t; } } catch (Exception e) { e.printStackTrace(); } finally {// 7.关闭资源 JDBCUtils.closeResource(conn, ps, rs); } return null; }} 如果考虑事务操作，则不应该在方法中获取和关闭连接，需要在调用之前传入Connection对象，对于事务的操作可以简化为以下步骤： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public void testJDBCTransaction() { Connection conn = null; try { // 1.获取数据库连接 conn = JDBCUtils.getConnection(); // 2.开启事务,关闭自动提交 conn.setAutoCommit(false); // 3.进行数据库操作，这里的两个SQL操作组成一个事务 String sql1 = \"update user_table set balance = balance - 100 where user = ?\"; update(conn, sql1, \"AA\"); //执行事务 // 模拟网络异常。如果有异常，事务会回滚 //System.out.println(10 / 0); String sql2 = \"update user_table set balance = balance + 100 where user = ?\"; update(conn, sql2, \"BB\"); // 4.若没有异常，则提交事务 conn.commit(); } catch (Exception e) { e.printStackTrace(); // 5.若有异常，则回滚事务 try { conn.rollback(); } catch (SQLException e1) { e1.printStackTrace(); } } finally { try { //6.恢复自动提交 conn.setAutoCommit(true); } catch (SQLException e) { e.printStackTrace(); } //7.关闭连接 JDBCUtils.closeResource(conn, null, null); } }//使用事务以后的方法需要改写，将连接对象作为参数传入，其余内容不变//对于查询操作的方法同样如此。public void update(Connection conn,String sql, Object... args) { PreparedStatement ps = null; try { ps = conn.prepareStatement(sql); for (int i = 0; i &lt; args.length; i++) { ps.setObject(i + 1, args[i]); } ps.execute(); } catch (Exception e) { e.printStackTrace(); } finally { JDBCUtils.closeResource(null, ps); }} Connection的对象也可以调用setTransactionIsolation()方法设置事务的隔离级别 3、资源释放执行完操作后，必须要释放资源： 释放ResultSet， Statement，Connection。 数据库连接（Connection）是非常稀有的资源，用完后必须马上释放，如果Connection不能及时正确的关闭将导致系统宕机。Connection的使用原则是尽量晚创建，早释放。 可以在finally中关闭，保证及时其他代码出现异常，资源也一定能被关闭。 4、总结JDBC涉及到的两种思想和两种技术： 两种思想 面向接口编程的思想 ORM思想(object relational mapping) 一个数据表对应一个java类 表中的一条记录对应java类的一个对象 表中的一个字段对应java类的一个属性 SQL查询的结果集中列的别名，必须要和类的属性名相同。 两种技术 JDBC结果集的元数据：ResultSetMetaData，作用为 获取结果集列数：getColumnCount() 获取列的别名：getColumnLabed() 通过反射，创建指定类的对象，获取指定的属性并赋值。 三、DAO的使用DAO（Data Access Object）：访问数据信息的类和接口，只包括了对数据的CRUD（Create、Retrival、Update、Delete）操作，而不包含任何业务相关的信息。有时也称作：BaseDAO 作用：为了实现功能的模块化，更有利于代码的维护和升级。 使用DAO主要包括三部分： 将DAO定义为一个抽象类，包含了CRUD基本操作，适用于所有表。 对每个表，定义一个接口，接口规范了当前表的不同功能。 每个表对应一个实现类，此类继承DAO抽象类，并实现了此表对应的接口。 最后，我们只需要调用实现类的方法，满足不同的需求。 比如，对于Customer类，数据库中对应customers表，使用DAO及其相关实现类如下 DAO.java文件类，定义抽象类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133/* * DAO: data(base) access object * 封装了针对于数据表的通用的操作 */public abstract class BaseDAO&lt;T&gt; { private Class&lt;T&gt; clazz = null; //需要获取BaseDAO子类的带泛型父类的泛型，根据此泛型得知要操作的类。 //可以在代码块或者构造器中获取。 public BaseDAO(){ //带泛型的父类，即BaseDAO&lt;Customer&gt; Type genericSuperclass = this.getClass().getGenericSuperclass(); ParameterizedType paramType = (ParameterizedType) genericSuperclass; //获取父类的泛型，即Customer Type[] actualTypeArguments = paramType.getActualTypeArguments(); clazz = (Class&lt;T&gt;) actualTypeArguments[0];//数组的第一个值就是Customer } // 通用的增删改操作 public int update(Connection conn, String sql, Object... args) { PreparedStatement ps = null; try { // 1.预编译sql语句，返回PreparedStatement的实例 ps = conn.prepareStatement(sql); // 2.填充占位符 for (int i = 0; i &lt; args.length; i++) { ps.setObject(i + 1, args[i]);// 小心参数声明错误！！ } // 3.执行 return ps.executeUpdate(); } catch (Exception e) { e.printStackTrace(); } finally {// 4.资源的关闭 JDBCUtils.closeResource(null, ps); } return 0; } // 通用的查询操作，用于返回数据表中的一条记录 public T getInstance(Connection conn, String sql, Object... args) { PreparedStatement ps = null; ResultSet rs = null; try { ps = conn.prepareStatement(sql); for (int i = 0; i &lt; args.length; i++) { ps.setObject(i + 1, args[i]); } rs = ps.executeQuery(); // 获取结果集的元数据 :ResultSetMetaData ResultSetMetaData rsmd = rs.getMetaData(); // 通过ResultSetMetaData获取结果集中的列数 int columnCount = rsmd.getColumnCount(); if (rs.next()) { T t = clazz.getConstructor().newInstance(); // 处理结果集一行数据中的每一个列 for (int i = 0; i &lt; columnCount; i++) { // 获取列值 Object columValue = rs.getObject(i + 1); // 获取每个列的列名 String columnLabel = rsmd.getColumnLabel(i + 1); // 给t对象指定的columnName属性，赋值为columValue：通过反射 Field field = clazz.getDeclaredField(columnLabel); field.setAccessible(true); field.set(t, columValue); } return t; } } catch (Exception e) { e.printStackTrace(); } finally { JDBCUtils.closeResource(null, ps, rs); } return null; } // 通用的查询操作，用于返回数据表中的多条记录构成的集合 public List&lt;T&gt; getForList(Connection conn, String sql, Object... args) { PreparedStatement ps = null; ResultSet rs = null; try { ps = conn.prepareStatement(sql); for (int i = 0; i &lt; args.length; i++) { ps.setObject(i + 1, args[i]); } rs = ps.executeQuery(); // 获取结果集的元数据 :ResultSetMetaData ResultSetMetaData rsmd = rs.getMetaData(); // 通过ResultSetMetaData获取结果集中的列数 int columnCount = rsmd.getColumnCount(); // 创建集合对象 ArrayList&lt;T&gt; list = new ArrayList&lt;T&gt;(); while (rs.next()) { T t = clazz.newInstance(); // 处理结果集一行数据中的每一个列:给t对象指定的属性赋值 for (int i = 0; i &lt; columnCount; i++) { // 获取列值 Object columValue = rs.getObject(i + 1); // 获取每个列的列名 String columnLabel = rsmd.getColumnLabel(i + 1); // 给t对象指定的columnName属性，赋值为columValue：通过反射 Field field = clazz.getDeclaredField(columnLabel); field.setAccessible(true); field.set(t, columValue); } list.add(t); } return list; } catch (Exception e) {e.printStackTrace();} finally {JDBCUtils.closeResource(null, ps, rs);} return null; } //用于查询特殊值的通用的方法 //由于不同列的类型不同，使用泛型方法 public &lt;E&gt; E getValue(Connection conn,String sql,Object...args){ PreparedStatement ps = null; ResultSet rs = null; try { ps = conn.prepareStatement(sql); for(int i = 0;i &lt; args.length;i++){ ps.setObject(i + 1, args[i]); } rs = ps.executeQuery(); if(rs.next()){ return (E) rs.getObject(1); } } catch (SQLException e) { e.printStackTrace(); }finally{ JDBCUtils.closeResource(null, ps, rs); } return null; }} CustomerDAO.java文件，定义接口： 1234567891011121314151617181920212223242526/* * 此接口用于规范针对于customers表的常用操作 */public interface CustomerDAO { //将cust对象添加到数据库中 void insert(Connection conn,Customer cust); //针对指定的id，删除表中的一条记录 void deleteById(Connection conn,int id); //去修改数据表中指定的记录 void update(Connection conn,Customer cust); //针对指定的id查询得到对应的Customer对象 Customer getCustomerById(Connection conn,int id); //查询表中的所有记录构成的集合 List&lt;Customer&gt; getAll(Connection conn); //返回数据表中的数据的条目数 Long getCount(Connection conn); //返回数据表中最大的生日 Date getMaxBirth(Connection conn);}//可以根据需求，定义不同功能的方法 CustmoerDAOImpl.java文件，实现接口，继承抽象类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/*对于customer表，定义一个实现类，实现接口中的所有方法。实现接口方法时，调用的是DAO抽象类中的方法。*/public class CustomerDAOImpl extends BaseDAO&lt;Customer&gt; implements CustomerDAO{ @Override public void insert(Connection conn, Customer cust) { String sql = \"insert into customers(name,email,birth)values(?,?,?)\"; update(conn, sql,cust.getName(),cust.getEmail(),cust.getBirth()); } @Override public void deleteById(Connection conn, int id) { String sql = \"delete from customers where id = ?\"; update(conn, sql, id); } @Override public void update(Connection conn, Customer cust) { String sql = \"update customers set name=?,email=?,birth=? where id=?\"; update(conn,sql,cust.getName(),cust.getEmail(),cust.getBirth(),cust.getId()); } @Override public Customer getCustomerById(Connection conn, int id) { String sql = \"select id,name,email,birth from customers where id = ?\"; Customer customer = getInstance(conn,sql,id); return customer; } @Override public List&lt;Customer&gt; getAll(Connection conn) { String sql = \"select id,name,email,birth from customers\"; List&lt;Customer&gt; list = getForList(conn,sql); return list; } @Override public Long getCount(Connection conn) { String sql = \"select count(*) from customers\"; return getValue(conn, sql); } @Override public Date getMaxBirth(Connection conn) { String sql = \"select max(birth) from customers\"; return getValue(conn, sql); }} 四、数据库连接池1、连接池简介传统的数据库连接存在的问题： 普通的JDBC数据库连接使用 DriverManager 来获取，每次向数据库建立连接的时候都要将 Connection 加载到内存中，再验证用户名和密码。需要数据库连接的时候，就向数据库要求一个，执行完成后再断开连接。这样的方式将会消耗大量的资源和时间。数据库的连接资源并没有得到很好的重复利用。若同时有几百人甚至几千人在线，频繁的进行数据库连接操作将占用很多的系统资源，严重的甚至会造成服务器的崩溃。 对于每一次数据库连接，使用完后都得断开。否则，如果程序出现异常而未能关闭，将会导致数据库系统中的内存泄漏，最终将导致重启数据库。 这种开发不能控制被创建的连接对象数，系统资源会被毫无顾及的分配出去，如连接过多，也可能导致内存泄漏，服务器崩溃。 为了解决以上的问题，可以采用数据库连接池技术： 数据库连接池的基本思想：就是为数据库连接建立一个“缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完毕之后再放回去。 数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是重新建立一个。 数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中，这些数据库连接的数量是由最小数据库连接数来设定的。无论这些数据库连接是否被使用，连接池都将一直保证至少拥有这么多的连接数量。连接池的最大数据库连接数量限定了这个连接池能占有的最大连接数，当应用程序向连接池请求的连接数超过最大连接数量时，这些请求将被加入到等待队列中。 数据库连接池的优点： 资源重用。由于数据库连接得以重用，避免了频繁创建和释放连接引起的大量性能开销。在减少系统消耗的基础上，另一方面也增加了系统运行环境的平稳性。 更快的系统反应速度。数据库连接池在初始化过程中，往往已经创建了若干数据库连接置于连接池中备用。此时连接的初始化工作均已完成。对于业务请求处理而言，直接利用现有可用连接，避免了数据库连接初始化和释放过程的时间开销，从而减少了系统的响应时间 新的资源分配手段，控制每个应用的最大连接数。对于多应用共享同一数据库的系统而言，可在应用层通过数据库连接池的配置，实现某一应用最大可用数据库连接数的限制，避免某一应用独占所有的数据库资源 统一的连接管理，避免数据库连接泄漏。在较为完善的数据库连接池实现中，可根据预先的占用超时设定，强制回收被占用连接，从而避免了常规数据库连接操作中可能出现的资源泄露 JDBC 的数据库连接池使用javax.sql.DataSource 来表示，DataSource 只是一个接口，该接口通常由服务器(Weblogic, WebSphere, Tomcat)提供实现，也有一些开源组织提供实现： DBCP 是Apache提供的数据库连接池。tomcat 服务器自带dbcp数据库连接池。速度相对c3p0较快，但因自身存在BUG，Hibernate3已不再提供支持。 C3P0 是一个开源组织提供的一个数据库连接池，速度相对较慢，稳定性还可以。hibernate官方推荐使用 Proxool 是sourceforge下的一个开源项目数据库连接池，有监控连接池状态的功能，稳定性较c3p0差一点 BoneCP 是一个开源组织提供的数据库连接池，速度快 Druid 是阿里提供的数据库连接池，据说是集DBCP 、C3P0 、Proxool 优点于一身的数据库连接池，但是速度不确定是否有BoneCP快 DataSource 通常被称为数据源，它包含连接池和连接池管理两个部分，习惯上也经常把DataSource 称为连接池。 DataSource用来取代DriverManager来获取Connection，获取速度快，同时可以大幅度提高数据库访问速度。 整个应用只需要创建一个数据源（连接池）即可。 当数据库访问结束后，程序还是像以前一样关闭数据库连接：conn.close();但conn.close()操作并没有关闭数据库的物理连接，它仅仅把数据库连接释放，归还给了数据库连接池（由busy状态变为free状态）。 2、Druid数据库连接池Druid是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、Proxool等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池，是目前最好的连接池之一。 连接池的一些配置参数： 配置 缺省 说明 name 如果存在多个数据源，监控的时候可以通过名字来区分开来。如果没有配置，将会生成一个名字，格式是：”DataSource-” + System.identityHashCode(this) url 连接数据库的url，不同数据库不一样。例如：mysql : jdbc:mysql://10.20.153.104:3306/druid2 username 连接数据库的用户名 password 连接数据库的密码。 driverClassName 根据url自动识别 这一项可配可不配，如果不配置druid会根据url自动识别dbType，然后选择相应的driverClassName(建议配置) initialSize 0 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时 maxActive 8 同时维持的最大连接数 maxIdle 8 最大的空闲连接数。已废弃。类似于JVM中的Xmx minIdle 0 最小的空闲连接数。类似于JVM中的Xmn minEvictableIdleTimeMillis 1800000L 池中的空闲连接在一段时间内一直空闲，被逐出连接池的时间 maxWait -1 获取连接时最大等待时间，单位毫秒。-1表示无限等待。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置useUnfairLock属性为true使用非公平锁。 poolPreparedStatements false 是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。 maxOpenPreparedStatements -1 开启池的prepared后的同时最大连接数。要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100 testOnBorrow true 申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。 testOnReturn false 归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能 testWhileIdle false 建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。 timeBetweenEvictionRunsMillis 有两个含义： 1)Destroy线程会检测连接的间隔时间2)testWhileIdle的判断依据，详 connectionInitSqls 物理连接初始化的时候执行的sql Druid数据库连接池使用案例： 1234567891011121314151617//只需要创建一个连接池，因此写在静态代码块中private static DataSource source;static{ try { Properties pros = new Properties(); FileInputStream is = new FileInputStream(\"src/druid.properties\"); pros.load(is); //创建一个druid连接池 source = DruidDataSourceFactory.createDataSource(pros); } catch (Exception e) { e.printStackTrace(); }}public static Connection getConnection3() throws SQLException { Connection conn = source.getConnection(); return conn;} 其中druid.properties配置文件内容如下： 123456url=jdbc:mysql:///test?characterEncoding=utf8username=rootpassword=abc123driverClassName=com.mysql.jdbc.DriverinitialSize=10maxActive=10 五、Apache-DBUtils工具类commons-dbutils是 Apache 组织提供的一个开源 JDBC工具类库，它是对JDBC的简单封装，学习成本极低，并且使用dbutils能极大简化jdbc编码的工作量，同时也不会影响程序的性能。 API介绍： org.apache.commons.dbutils.QueryRunner该类简单化了SQL查询，与ResultSetHandler搭配使用，可以完成大部分数据库操作。QueryRunner的主要方法有： update：执行插入、更新、删除操作 insert：只支持insert语句 query：查询操作 org.apache.commons.dbutils.ResultSetHandler该接口用于处理ResultSet，将数据按要求转换为另一种形式。并且提供了一个单独的方法：Object handle (java.sql.ResultSet.rs)。该接口的主要实现类有： ArrayHandler：把结果集中的第一行数据转成对象数组。 ArrayListHandler：把结果集中的每一行数据都转成一个数组，再存放到List中。 BeanHandler：将结果集中的第一行数据封装到一个对应的JavaBean实例中。 BeanListHandler：将结果集中的每一行数据都封装到一个对应的JavaBean实例中，存放到List里。 ColumnListHandler：将结果集中某一列的数据存放到List中。 KeyedHandler(name)：将结果集中的每一行数据都封装到一个Map里，再把这些map再存到一个map里，其key为指定的key。 MapHandler：将结果集中的第一行数据封装到一个Map里，key是列名，value就是对应的值。 MapListHandler：将结果集中的每一行数据都封装到一个Map里，然后再存放到List ScalarHandler：查询单个值对象 工具类org.apache.commons.dbutils.DbUtils用于关闭连接、装载JDBC驱动程序等操作。里面的所有方法都是静态的。比如以下方法： public static void close(xxx) throws java.sql.SQLException，关闭指定的资源。 public static void closeQuietly(xxx): 这一类方法不仅能在Connection、Statement和ResultSet为NULL情况下避免关闭，还能隐藏一些在程序中抛出的SQLEeception。 public static void commitAndClose(Connection conn)throws SQLException： 用来提交连接的事务，然后关闭连接 public static void commitAndCloseQuietly(Connection conn)： 用来提交连接，然后关闭连接，并且在关闭连接时不抛出SQL异常。 public static void rollback(Connection conn)throws SQLException：允许conn为null，因为方法内部做了判断 public static void rollbackAndClose(Connection conn)throws SQLException rollbackAndCloseQuietly(Connection) public static boolean loadDriver(java.lang.String driverClassName)：这一方装载并注册JDBC驱动程序，如果成功就返回true。使用该方法，不需要捕捉这个异常ClassNotFoundException DBUtils的使用案例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class dbutilsTest{ /* BeanHandler：是ResultSetHandler接口的实现类，用于封装表中的一条记录 */ @Test public void testQuery1(){ Connection conn = null; try{ conn = JDBCUtils.getConnection(); QueryRunner runner = new QueryRunner(); String sql = \"select id,name,email,birth from customers where id=?\"; BeanHandler&lt;Customer&gt; handler = new BeanHandler&lt;&gt;(Customer.class); Customer query = runner.query(conn, sql, handler, 22); System.out.println(query); }catch (SQLException e){ e.printStackTrace(); }finally { JDBCUtils.closeResource(conn,null); } } /* MapHandler：是ResultSetHandler接口的实现类，对应表中的一条记录 将字段及字段的值作为map中的key和value */ @Test public void testQuery3(){ Connection conn = null; try{ conn = JDBCUtils.getConnection(); QueryRunner runner = new QueryRunner(); String sql = \"select id,name,email,birth from customers where id=?\"; MapHandler handler = new MapHandler(); Map&lt;String, Object&gt; query = runner.query(conn, sql, handler, 22); System.out.println(query); }catch (SQLException e){ e.printStackTrace(); }finally { JDBCUtils.closeResource(conn,null); } } /* ScalarHandler用于查询特殊值 */ @Test public void testQuery5(){ Connection conn = null; try{ conn = JDBCUtils.getConnection(); QueryRunner runner = new QueryRunner(); String sql = \"select Max(birth) from customers\"; ScalarHandler scalarHandler = new ScalarHandler(); //返回sql.date类型，转为util.date型 Date date = (Date)runner.query(conn, sql, scalarHandler); System.out.println(date); }catch (SQLException e){ e.printStackTrace(); }finally { JDBCUtils.closeResource(conn,null); } } /* 自定义ResultSetHandler实现类 */ @Test public void testQuery7(){ Connection conn = null; try{ conn = JDBCUtils.getConnection3(); QueryRunner runner = new QueryRunner(); String sql = \"select id,name,email,birth from customers where id=?\"; ResultSetHandler&lt;Customer&gt; handler = new ResultSetHandler&lt;Customer&gt;() { @Override public Customer handle(ResultSet rs) throws SQLException { return \"自定义结果\"; } }; Customer query = runner.query(conn, sql, handler, 23);//返回sql.date类型，转为util.date型 System.out.println(query); }catch (SQLException e){ e.printStackTrace(); }finally { JDBCUtils.closeResource(conn,null); } }} 六、总结1、JDBC总结至此，回顾使用JDBC编程的几个主要步骤，主要总结为三步：创建连接、CRUD操作、关闭资源。 可以发现，我们使用数据库连接池代替了传统的连接方式，使用DBUtils工具类代替了手动创建Statement对象实现CRUD的操作，和关闭资源的操作。 JDBC的流程可以总结为下（考虑事务）： 123456789101112131415161718192021222324252627public void testUpdateWithTx() { Connection conn = null; try { /*1.获取连接的操作 方式一：手写的连接：JDBCUtils.getConnection(); 方式二：使用数据库连接池：C3P0;DBCP;Druid */ /*2.对数据表进行CRUD操作 方式一：使用PreparedStatement对象 public void update(Connection conn,String sql,Object ... args){} public T getInstance(Connection conn,String sql,Object ... args){} 方式二：使用dbutils提供的jar包中提供的QueryRunner类 */ //提交数据 conn.commit(); } catch (Exception e) { e.printStackTrace(); try {//回滚数据 conn.rollback(); } catch (SQLException e1) {e1.printStackTrace();} }finally{ /*3.关闭连接等操作 方式一：JDBCUtils.closeResource(); 方式二：使用dbutils中的DbUtils工具类提供的关闭资源的方法 */ }} 2、常见问题总结问题1：数据库连接池工作原理和实现方案? 工作原理：JAVA EE服务器启动时会建立一定数量的池连接，并一直维持不少于此数目的池连接(minIdle)。客户端程序需要连接时，池驱动程序会返回一个未使用的池连接，并将其标记为busy状态。如果当前没有空闲连接，池驱动程序就新建一定数量的连接，新建连接的数量有配置参数决定。当使用的池连接调用完成后，池驱动程序将此连接标记为free，其他调用就可以使用这个连接。 实现方案：连接池使用集合来进行装载，返回的Connection是原始Connection的代理，代理Connection的close方法，当调用close方法时，不是真正关闭物理连接，而是把它代理的Connection对象放回到连接池中，等待下一次重复利用。 问题2：JDBC是如何实现Java程序和JDBC驱动的松耦合的？ 通过制定接口，数据库厂商来实现。我们只要通过接口调用即可，所有的操作都是通过JDBC接口完成的，而驱动只有在通过Class.forName反射机制来加载的时候才会出现。——面向接口编程 问题3：PreparedStatement有什么缺点，如何解决 缺点：不能直接用它来执行in条件语句。 解决方案： 分别进行单条查询——性能很差，不推荐。 使用存储过程——这取决于数据库的实现，不是所有数据库都支持。 动态生成PreparedStatement——不能享受PreparedStatement的缓存带来的好处。 在PreparedStatement查询中使用NULL值——如果知道输入变量的最大个数的话，这是个不错的办法，扩展一下还可以支持无限参数。 问题4：JDBC的ResultSet是什么 在查询数据库后会返回一个ResultSet，它像是查询结果集的一张数据表。 ResultSet对象维护了一个游标，指向当前的数据行。开始的时候这个游标指向的是第一行。如果调用了ResultSet的next()方法游标会下移一行，如果没有更多的数据了，next()方法会返回false。可以在for循环中用它来遍历数据集。 默认的ResultSet是不能更新的，游标也只能往下移。也就是说只能从第一行到最后一行遍历一遍。不过也可以创建可以回滚或者可更新的ResultSet。 当生成ResultSet的Statement对象要关闭或者重新执行或是获取下一个ResultSet的时候，ResultSet对象也会自动关闭。 可以通过ResultSet的get方法，传入列名或者从1开始的序号来获取列数据。 问题5：JDBC的DataSource是什么，有什么好处 DataSource即数据源，它是定义在javax.sql中的一个接口，跟DriverManager相比，它的功能要更强大。DataSource也被称为数据库连接池。除了提供连接外，它还能够管理连接对象，提供如下功能： 缓存PreparedStatement以便更快的执行 可以设置连接超时时间 提供日志记录的功能 ResultSet大小的最大阈值设置 通过JNDI的支持，可以为servlet容器提供连接池的功能 问题6：JDBC中存在哪些不同类型的锁 从广义上讲，有两种锁机制来防止多个用户同时操作引起的数据损坏。 乐观锁：只有当更新数据的时候才会锁定记录。 悲观锁：从查询到更新和提交整个过程都会对数据记录进行加锁。 更多问题总结参考：JDBC面试题都在这里","categories":[{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"},{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://kangshitao.github.io/tags/MySQL/"},{"name":"SQL","slug":"SQL","permalink":"http://kangshitao.github.io/tags/SQL/"}]},{"title":"MySQL数据库基础篇","slug":"mysql-basis","date":"2021-04-26T13:14:17.000Z","updated":"2022-05-22T13:30:54.800Z","comments":true,"path":"2021/04/26/mysql-basis/","link":"","permalink":"http://kangshitao.github.io/2021/04/26/mysql-basis/","excerpt":"MySQL的使用，常用SQL语句，DDL、DML、DQL，事务，视图，存储结构，函数","text":"一、数据库概述1、使用数据库的优势使用数据库有两个优势： 持久化数据到本地。 可以实现结构化查询，方便管理。 2、数据库相关概念DB(Database)：数据库，保存一组有组织的数据的容器。 DBMS(Database Management System)：数据库管理系统，又称为数据库软件（产品），用于管理DB中的数据。 SQL(Structured Query Language)：结构化查询语言，用于和DBMS通信的语言，包括数据插入、查询、更新、删除，数据库模式创建和修改，以及数据访问控制。 3、SQL的语言分类DDL(Data Definition Language)：数据定义语言。允许用户定义数据，包括创建（create）、删除（drop）、修改（alter）这些操作。通常，DDL由数据库管理员执行。 DML(Data Manipulation Language)：数据操作语言。DML为用户提供添加（insert）、删除（delete）、更新数据（update）的能力，这些是应用程序对数据库的日常操作。 DQL(Data Query Language)：数据查询语言，执行查询（select）操作。TCL(Transaction Control Language)：事务控制语言，执行commit、rollback等操作。 二、关系数据库1、什么是关系型数据库RDBMS(Relational Database Management System)：关系型数据库管理系统，即基于关系模型的数据库。 关系模型把数据看作是一个二维表格，任何数据都可以通过行号和列号来唯一确定，它的数据模型看起来就是一个Excel表。 2、RDBMS存储数据的特点RDBMS存储数据的特点： 数据以表格的形式出现，每个表都有唯一的名字，用于标识自己。 若干的表格组成数据库。 表本身具有一些特性，这些特性定义了数据在表中如何存储，类似java中 “类”的设计。 表中的列也称为字段（Column）。列类似于java 中的”属性”。 表中的行称为记录（Record），每一行是一组相关的数据。行类似于java中的“对象”。 3、常见的关系型数据库 商用数据库，例如：Oracle，SQL Server，DB2等； 开源数据库，例如：MySQL，PostgreSQL等； 桌面数据库，以微软Access为代表，适合桌面应用程序使用； 嵌入式数据库，以Sqlite为代表，适合手机应用和桌面程序。 4、NoSQLNoSQL数据库，也就是非SQL的数据库，包括MongoDB、Cassandra、Dynamo等等，它们都不是关系数据库。SQL数据库从始至终从未被取代过，NoSQL的发展历程： 1970: NoSQL = We have no SQL 1980: NoSQL = Know SQL 2000: NoSQL = No SQL! 2005: NoSQL = Not only SQL 2013: NoSQL = No, SQL! 今天，SQL数据库仍然承担了各种应用程序的核心数据存储，而NoSQL数据库作为SQL数据库的补充，两者不再是二选一的问题，而是主从关系。 三、MySQL1、MySQL介绍MySQL是目前应用最广泛的开源关系数据库。MySQL最早是由瑞典的MySQL AB公司开发，该公司在2008年被SUN公司收购，SUN公司在2009年被Oracle公司收购，所以MySQL最终就变成了Oracle旗下的产品。 MySQL优势： 开源、免费、成本低 性能高、移植性好 体积小，便于安装 2、MySQL安装MySQL属于c/s架构的软件，一般来讲只安装服务端。以下案例以 MySQL5.7 为例 下载链接 3、MySQL服务的启动和停止Windows下，MySQL启动和停止有两种方式： 计算机—右击管理—服务，启动MySQL服务 通过管理员身份运行cmd： net start 服务名（启动服务），例net start mysql57 net stop 服务名（停止服务），例net stop mysql57 4、MySQL服务的登录和退出​ 方式一：通过mysql自带的客户端（MySQL Line Client），只限于root用户 ​ 方式二：通过windows的命令提示符，以管理员身份打开 登录：mysql [-h 主机名 -P 端口号] -u 用户名 -p密码，[]里的内容表示可以省略 其中p参数和密码直接不能有空格，其他参数和值之间空格可有可无，比如-uroot，表示root用户。 密码可以不添加值，直接回车，然后输入密码，不会显示出明文。 如果是本机，并且端口是3306，可以省略-h和-P参数，直接输入用户名和密码即可。 退出：exit 如下图： 5、MySQL的常见命令查看当前所有的数据库: 1show databases; 打开指定的库: 1use 库名; 查看当前库的所有表: 1show tables; 查看其它库的所有表： 1show tables from 库名; 查看表结构： 1desc 表名; 查看表的列属性： 1show columns from 表名; 查看表的索引： 1show index from 表名; 查看xx状态： 12345678# 查看指定表的状态信息show table status from 表名/数据库;# 查看主从复制中的主机状态show master status;# 查看主从复制中从机状态show slave status; 查看服务器的版本： 123456# 方式一，在mysql服务端查看：select version();# 方式二，在cmd窗口查看：mysql --version或mysql --V 用户管理指令： 添加用户的两种方式 1、使用insert指令，在mysql.user表中添加用户： 1234567891011121314# 比如想添加用户：user，密码：123456，并授予select权限# 只需要在user表的指定列添加内容即可。insert into mysql.user(host,user,password，select_priv) values('localhost','user',password('123456'),'Y');flush privileges;/* 其中host列表示限制登陆的主机，localhost表示只能当前主机登陆，可以指定ip，使用%表示任意主机。MySQL5.7以后，password改名为authentication_string。密码需要使用password()函数进行加密，MySQL8.0.11移除了这个函数，可以使用MD5()代替。可以根据需求授予其他权限，只需要相应列赋值为'Y'即可。添加完后，使用flush privileges语句刷新授权表，使之立即生效，否则需要重启MySQL服务才生效。*/ 2、使用grant命令 12345# 比如给指定数据库比如student库，添加用户user，密码123,授予select权限grant select # 指定授予的权限on student.* # 指定数据库和表，*表示所有，这里表示student库所有表to 'user'@'localhost' # 指定用户名和登陆主机，localhost根据需求填写indentified by '123'; # 指定登录密码。 grant指令更多内容，参考GRANT Statement 6、MySQL的语法规范MySQL中的命令有以下规范： 不区分大小写，建议关键字大写，表名和列名小写 每条命令以;或\\g结尾 每条命令根据需要，可以进行缩进或换行。关键字不能缩写或分行。 注释 单行注释：#注释文字 单行注释：-- 注释文字,(注意--后面有空格) 多行注释：/* 注释文字 */ 字符（建议加，有时必须加）和日期型要加引号，数值不需要加。表的别名不需要加引号 四、MySQL数据类型MySQL支持所有标准SQL数值数据类型（SQL数据类型参考链接）。作为SQL标准的扩展，MySQL也支持整数类型TINYINT、MEDIUMINT和BIGINT。详细参考MySQL数据类型 MySQL中的TRUE和FALSE，也可以分别用1和0表示。 MySQL中的数据类型包括数值型、字符型、日期型等。 数值型 类型 字节 说明 整型 Tinyint 1 有符号：-128~127 无符号：0~255 Smallint 2 有符号：-32768~32767 无符号：0~65535 Mediumint 3 有符号：-8,388,608~8,388,607 无符号：0~16,777,215 Int/Integer 4 有符号：-2,147,483,648~2,147,483,647 无符号：0~4,294,967,296 Bigint 8 有符号：-2^63~2^63-1 无符号：0~2^64 浮点型小数 float(M,D) 4 ±1.75494351E-38 ~ ±3.402823466E+38 double(M,D) 8 ±2.2250738585072014E-308 ~ ±1.7976931348623157E+308 定点型小数 DEC(M,D) DECIMAL(M,D) M+2 最大取值范围与double相同， 给定decimal的有效取值范围由M和D决定 说明： 如果不设置无符号还是有符号，默认是有符号，如果想设置无符号，需要在类型后面添加unsigned关键字 如果插入的数值超出了整型的范围,会报out of range异常，并且插入临界值 如果不设置长度，会有默认的长度。长度不决定范围，长度代表了显示的最大宽度。可以选择在长度不够时，用0在左边填充，需要在类型后面添加zerofill。zerofill只支持正数（无符号） 定点型的精确度较高，如果要求插入数值的精度较高如货币运算等则考虑使用 M表示整数部位个数+小数部位个数的总长度。D表示小数部位长度。如果插入的数值超过范围，会报out of range异常，并插入临界值。 M和D都可以省略。如果是decimal，则M默认为10，D默认为0。 float和double，会根据插入的数值的精度来决定精度。 字符型 类型 最多字符数 描述 char(M) M M为0~255之间的整数，固定长度的字符，比较耗费空间，效率高 varchar(M) M M为0~65535之间的整数，可变长度的字符，比较节省空间，效率低 M表示最大的字符个数，而不是存储空间。 M 其他字符型类型： binary和varbinary用于保存较短的二进制 enum用于保存枚举类型，要求插入的值必须属于列表中指定的值之一。如果列表成员为1~255，则需要1个字节存储。如果列表成员为255~65535，则需要2个字节存储，最多为65535个成员。 set用于保存集合。里面可以保存0~64个成员。一次可以选取多个成员。根据成员个数不同，存储所占的字节从1-8变化。 text用于存放较长的文本 blob用于存放较大的二进制 日期型 日期和时间类型 字节 最小值 最大值 date 4 1000-01-01 9999-12-31 datetime 8 1000-01-01 00:00:00 9999-12-31 23:59:59 timestamp 4 1970-01-01 00:00:00 2038-1-19某一时刻 time 3 -838:59:59 838:59:59 year 1 1901 2155 其中字符型和日期型的常量值必须要用''或\"\"包起来。数值型不需要。 datetime和timestamp的对比 二者都是保存日期和时间。 datetime占用8字节，范围是1000-9999，不受时区的影响。 timestamp占用4字节，范围为1970-2038，受时区的影响，其值会根据时区的变化而变化。即插入数据以后，如果修改时区，表中的时间戳也会改变为对应时区的值。 五、DQL语言DQL为数据查询语言，执行查询（select）操作。 DQL的完整查询语句结构： 123456789select 字段,... # 7from 表1 [别名] # 1[连接类型 join 表2]... # 2[on 连接条件] # 3[where 筛选条件] # 4[group by 分组字段] # 5[having 分组后的筛选条件] # 6[order by 排序的字段或表达式] # 8[limit 偏移量(起始条目索引),条数]; # 9 以上各部分的执行顺序：from→join→on→where→group by(开始使用select中的别名，后面的语句都可以使用)- →AVG/SUM/MAX/MIN等分组函数→having→select→distinct→order by→limit 以下案例使用的数据库：myemployees，其中有departments、employees、job_grades、jobs、locations共五张表。各自的包含的字段如下： departments表： employees表： job_grades表： jobs表： locations表： 1、基础查询语法： 12SELECT 查询内容 [FROM 表名]; 类似于Java中的System.out.println(要打印的东西); 查询的结果是一个虚拟的表，不会改变原来的表格。 特点：①通过select查询出的结果 ，是一个虚拟的表格，不是真实存在 ②查询内容可以是常量值、表达式、字段、函数 示例： 12345678910111213141516171819202122232425262728293031323334#1.查询单个字段SELECT last_name FROM employees;#2.查询多个字段SELECT last_name,salary,email FROM employees;#3.查询所有字段SELECT `employee_id`, `first_name`, `last_name`, `phone_number`, `last_name`, `job_id`, `phone_number`, `job_id`, `salary`, `commission_pct`, `manager_id`, `department_id`, `hiredate` FROM employees ;#方式二，*号表示所有字段： SELECT * FROM employees;#4.查询常量SELECT 100;#5.查询函数SELECT VERSION();#6.查询表达式SELECT 100%98; 别名：如果要查询的字段有重名的情况，可以使用别名区分；同样，表也可以起别名。 定义别名有两种方式： 使用as: 123456789SELECT 100%98 AS 结果;/*运行结果为：+------+| 结果 |+------+| 2 |+------+*/SELECT last_name AS 姓,first_name AS 名 FROM employees; 使用空格，将as替换为空格即可： 1SELECT last_name 姓,first_name 名 FROM employees; 去重：使用distinct对结果去重 12#案例：查询员工表中涉及到的所有的部门编号SELECT DISTINCT department_id FROM employees; +号在MySQL中的作用： MySQL中的+号只有运算符的作用，其运算规则如下： 如果两个操作值都是数值型，做加法运算 如果一方为字符型，则尝试进行转换，转换成功就做加法运算，如果转换失败，则将字符值当作0 任何数和null做加法运算，结果都是null 1234select 100+90; # 结果为190select '123'+90; # 结果为213select 'john'+90; # 结果为90select null+10; # 结果为null 2、条件查询语法： 123select 要查询的字段|表达式|常量值|函数from 表where 筛选条件; # where后面加筛选条件 根据筛选条件的不同，可以分为以下几种： ① 条件表达式 使用以下条件运算符： 操作符 含义 = 等于，也可以作为赋值符号，为了便于区分，变量赋值尽量用:=符号。不能用于判断null值 &gt; 大于 &gt;= 大于等于 &lt; 小于 &lt;= 小于等于 &lt;&gt;或!= 不等于，两种写法均可，不能用于判断null值 案例： 123456789#案例1：查询工资&gt;12000的员工信息SELECT * FROM employees WHERE salary&gt;12000;#案例2：查询部门编号不等于90号的员工名和部门编号SELECT last_name, department_idFROM employeesWHERE department_id&lt;&gt;90; ②逻辑表达式 使用以下逻辑运算符： 操作符 含义 and或&amp;&amp; 与 or或 || 或 not或! 非 案例： 1234567891011#案例1：查询工资z在10000到20000之间的员工名、工资以及奖金SELECT last_name, salary, commission_pctFROM employeesWHERE salary&gt;=10000 AND salary&lt;=20000;#案例2：查询部门编号不是在90到110之间，或者工资高于15000的员工信息SELECT * FROM employeesWHERE NOT(department_id&gt;=90 AND department_id&lt;=110) OR salary&gt;15000; ③其他 包括以下几种： 操作符 含义 like 模糊查询，%用于匹配任意个字符，包括0个，_用于匹配任意一个字符 between ... and ... 判断是否在范围之间，相当于&gt;=和&lt;= in 使用=号判断 is null，is not null 用于判断是否为null like 一般用于字符型数据，也可以查询数值型数据。使用通配符查询，默认\\为转义字符，也可以使用escape自定义转移字符。 案例： 1234567#查询员工名中包含字符a的员工信息SELECT * FROM employeesWHERE last_name LIKE '%a%';#查询员工名中第二个字符为_的员工名SELECT last_name FROM employeesWHERE last_name LIKE '_#_%' ESCAPE '#'; # 自定义#作为转义字符 between and语句包含两个临界值，且要求是合法的范围： 123456#查询员工编号在100到120之间的员工信息SELECT * FROM employeesWHERE employee_id BETWEEN 100 AND 120;#等价于：SELECT * FROM employeesWHERE employee_id &gt;= 100 AND employee_id&lt;=120; in用于判断某字段的值是否属于in列表中的某一项，使用=号判断 in列表的值类型必须一致或兼容 in列表中不支持通配符 案例： 123456#查询工种编号是IT_PROG、AD_VP、AD_PRES中其中一个的所有员工的姓名和工种编号SELECT last_name, job_id FROM employeesWHERE job_id IN( 'IT_PROT' ,'AD_VP','AD_PRES');#等价于SELECT last_name, job_id FROM employeesWHERE job_id = 'IT_PROT' OR job_id = 'AD_VP' OR JOB_ID ='AD_PRES'; is null和is not null用于判断字段是否为null，且只能用于判断是否为null，不能用于判断是否等于某个数值： 1234#查询没有奖金的员工名和奖金率SELECT last_name,commission_pct FROM employeesWHERE commission_pct IS NULL; &lt;=&gt;既可以判断是否等于某个数值，也能用于判断是否为null： 123456789#案例1：查询没有奖金的员工名和奖金率SELECT last_name, commission_pctFROM employeesWHERE commission_pct &lt;=&gt;NULL;#案例2：查询工资为12000的员工名和工资SELECT last_name, salaryFROM employeesWHERE salary &lt;=&gt; 12000; 3、排序查询语法： 1234select 查询列表from 表名[where 筛选条件]order by 排序的字段|表达式|函数|别名 [asc|desc]; # 使用order by排序 默认asc，表示升序。也可以使用desc指定为降序 order by的位置一般放在最后面（除limit外) 案例： 1234567891011121314151617181920212223242526272829#1、按单个字段排序SELECT * FROM employees ORDER BY salary DESC;#2、添加筛选条件再排序#查询部门编号&gt;=90的员工信息，并按员工编号降序SELECT * FROM employees WHERE department_id&gt;=90ORDER BY employee_id DESC;#3、按表达式排序#查询员工信息 按年薪降序SELECT *,salary*12*(1+IFNULL(commission_pct,0)) FROM employeesORDER BY salary*12*(1+IFNULL(commission_pct,0)) DESC;#4、按别名排序#查询员工信息 按年薪升序SELECT *,salary*12*(1+IFNULL(commission_pct,0)) 年薪FROM employeesORDER BY 年薪 ASC;#5、按函数排序#查询员工名，并且按名字的长度降序SELECT LENGTH(last_name),last_name FROM employeesORDER BY LENGTH(last_name) DESC;#6、按多个字段排序#案例：查询员工信息，要求先按工资降序，再按employee_id升序SELECT * FROM employeesORDER BY salary DESC,employee_id ASC; 4、常见函数MySQL中的函数类似于java中的方法，将一组逻辑语句封装在方法体中，对外暴露方法名。 优势：提高代码重用性，隐藏了实现细节。 调用函数的语法： 1select 函数名(实参列表) [from 表名...] 函数根据作用对象的个数不同，可以分为单行函数和分组函数。 单行函数 字符函数 length：求参数的字节个数，比如一个汉字三个字节 concat：字符拼接，只要有一个为null，则结果为null substr：截取子串。sql中的索引是从1开始的 instr：返回子串第一次出现的索引 trim：去除首尾指定的空格和字符 upper：转换成大写 lower：转换成小写 lpad：左填充 rpad：右填充 replace(str,a,b)：将str中的a替换成b 案例： 12345#截取从指定索引处指定字符长度的字符(不是字节长度)SELECT SUBSTR('你好，MySQL',1,2) out_put; # 你好SELECT LENGTH(TRIM(' 张 翠 山 ')) AS out_put; # 11# trim只能去除首尾的空格，length求得是字节的个数 数学函数 round：四舍五入 rand：返回一个[0,1)之间的随机数 ceil：向上取整，返回&gt;=该参数的最小整数 floor：向下取整，返回&lt;=该参数的最大整数 truncate：截断（直接截断，不会四舍五入），保留小数点后的n位 mod：取余 案例： 1234SELECT ROUND(-1.55); #-2SELECT CEIL(-1.02); #-1SELECT FLOOR(-9.99); #-10SELECT TRUNCATE(1.69999,1); # 1.6 日期函数 now：返回当前系统日期+时间 curdate：返回当前系统日期，不包含时间 curtime：返回当前时间，不包含日期 year：获取指定日期的年份 month：获取指定日期的月份 monthname：获取指定日期月份的英文 day：获取指定日期的日 hour：获取指定日期的小时 minute：获取指定日期的分钟 second：获取指定日期的秒 str_to_date：将字符通过指定的格式转换成日期 date_format：将日期转换成字符 datediff：返回两个日期相差的天数 案例： 12SELECT YEAR('1998-1-1') 年; # 1998SELECT DATE_FORMAT(NOW(),'%y年%m月%d日') AS out_put; # 21年04月25日 流程控制函数，包括if和case函数。这里作为函数，可以用在任何地方，包括begin end里面和外面，注意和后面的if结构和case结构区分。 if函数：if(条件，值1，值2)，如果条件成立，返回值1，否则返回值2 case函数：作为函数，其有两种用法，格式如下： 123456789101112131415#用法1：case 要判断的字段或表达式when 常量1 then 值1when 常量2 then 值2...else 值nendl; #用法2：case when 条件1 then 值1when 条件2 then 值2...else 值nend; if/case结构作为函数时，可以应用在begin end结构中或外面，其返回结果必须是值；语句中不用加分号，最后结束才加分号。 if/case作为流程控制结构时，只能用于begin end结构中，其返回的是执行语句，中间需要加分号，且end后面要加if/case。作为流程控制结构的语法参考最后一章流程控制。 案例： 12345678910111213141516171819202122232425262728293031# if# 例一SELECT IF(10&lt;5,'大','小');# 例2SELECT last_name, commission_pct, IF(commission_pct IS NULL,'没奖金','有奖金') 备注FROM employees;# case# 例1SELECT salary 原始工资,department_id,CASE department_idWHEN 30 THEN salary*1.1WHEN 40 THEN salary*1.2WHEN 50 THEN salary*1.3ELSE salaryEND AS 新工资FROM employees;# 例2SELECT salary,CASE WHEN salary&gt;20000 THEN 'A'WHEN salary&gt;15000 THEN 'B'WHEN salary&gt;10000 THEN 'C'ELSE 'D'END AS 工资级别FROM employees; 其他 version：获取MySQL当前版本 database：获取当前数据库 user：获取当前用户 if null(参数,指定值)：如果参数值为null，则返回指定值，否则返回参数的值 is null(参数)：判断字段或表达式是否为null，如果是，返回1，否则返回0 password(\"str\")：返回str的密码形式 md5(\"str\")：返回str的MD5形式 案例： 123SELECT VERSION();SELECT DATABASE();SELECT USER(); 分组函数 sum：求和。一般用于处理数值 max ：最大值 min： 最小值 avg：平均值。一般用于处理数值 count：计数。参数可以是字段、*、常量值（一般用1），*表示所有字段同时考虑，一般用来统计行数。常量值也能用来统计行数。 1.、以上五个分组函数都忽略null值，除了count(*)，因为主键一定不为空2、max、min、count可以处理任何数据类型。3、都可以搭配distinct使用，用于统计去重后的结果 4、MYISAM存储引擎下 ，COUNT(*)的效率高；INNODB存储引擎下，COUNT(*)和COUNT(1)的效率差不多，比COUNT(字段)要高一些。 和分组函数同时查询的字段，必须是group by后的字段，不然会出现错误结果。 案例： 12345678SELECT SUM(salary) FROM employees;SELECT AVG(salary) FROM employees;# 与distinct搭配使用SELECT COUNT(DISTINCT salary),COUNT(salary) FROM employees; # 57,107# 和分组函数一同查询的字段有限制# 下面这种，employee_id是无意义的，只有group by后的字段才能和分组函数一起查询SELECT AVG(salary),employee_id FROM employees; 5、分组查询语法： 12345select 查询列表from 表[where 筛选条件]group by 分组的字段 # 使用group by进行分组[having 条件语句]; 说明： 1、和分组函数一同查询的字段必须是group by后出现的字段，确保意义正确 2、筛选分为两类：分组前筛选(where)和分组后(having)筛选。having后面一般跟的分组函数，表示对初步筛选后的结果再进行筛选。 3、分组可以按单个字段也可以按多个字段。 4、可以搭配排序使用。 5、having 和group by后，mysql支持别名，Oracle不支持。一般也不使用。 6、having后面的条件一般是分组函数，如果是一般的字段，必须是select中的字段（自己实验得出）。规范来说，having必须是在使用group by语句之后才能使用，如果不是在group by后面，having的作用和where的作用相同，但是不建议这么做，最好按照规范来做。 123456789101112131415/*MySQL 5.7版本，出现以下结果*/SELECT salary FROM employees WHERE salary&gt;15000; # 输出正确结果SELECT last_name FROM employeesWHERE salary&gt;15000; # 输出正确结果#－－－－－－－－－－－－－－－－－－SELECT salary FROM employees HAVING salary&gt;15000; # 输出正确结果#如果having后的字段，没在select中，会报错SELECT last_name FROM employees HAVING salary&gt;15000; # 显示语法错误，原因是‘having clause’中没有salary列 where和having的区别： where是分组前进行筛选，是对原始表筛选；having是在分组后筛选，是对分组后的结果再进行筛选，一般的筛选条件是分组函数。可以根据代码执行顺序进行推断。 在语句格式上，where写在group by 前面，having写在group by后面。 案例： 1234567891011121314151617181920212223242526272829303132#案例1：查询每个工种的员工平均工资SELECT AVG(salary),job_id #和分组函数同时查询的字段，是用于分组的字段FROM employeesGROUP BY job_id;#案例2：查询邮箱中包含a字符的每个部门的最高工资SELECT MAX(salary),department_idFROM employeesWHERE email LIKE '%a%'GROUP BY department_id;#案例3：查询哪个部门的员工个数&gt;5SELECT COUNT(*),department_idFROM employeesGROUP BY department_id # 先查询每个部门员工个数HAVING COUNT(*)&gt;5; # 然后选出个数&gt;5的#案例4：查询每个工种有奖金的员工的最高工资&gt;6000的工种编号和最高工资,按最高工资升序SELECT job_id,MAX(salary) mFROM employeesWHERE commission_pct IS NOT NULLGROUP BY job_idHAVING m&gt;6000ORDER BY m;#按多个字段分组#案例5：查询每个查询每个工种每个部门的平均工资SELECT department_id, job_id,AVG(salary) FROM employeesGROUP BY department_id,job_id; # 顺序可以颠倒# 这两种写法等价，每个A，每个B和每个B，每个A结果相同。SELECT department_id, job_id,AVG(salary) FROM employeesGROUP BY job_id,department_id; 6、多表连接查询当查询的字段来自多个表时，就需要使用连接查询。 如果不使用连接条件，或者连接条件无效，则多个表会按照笛卡儿乘积的形式连接，即查询的结果为m*n的表。 解决这种现象就需要添加有效的连接条件。 连接方式按照功能分类： 内连接 等值连接 非等值连接 自连接 外连接。 左外连接，left join左边是主表 右外连接，right join右边是主表 全外连接 交叉连接 其中，SQL 92标准仅支持内连接，ORACLE和SQL Server支持一部分外连接（mysql不支持），SQL 99标准支持内连接+外连接+交叉连接(mysql不支持全外连接)。 下面以两个表连接为例，说明连接查询的语法格式。 内连接 等值连接 等值内连接的结果是多表的交集。n表连接，至少需要n-1个连接条件。 1234567891011121314# SQL 92语法select 查询列表from 表1 别名，表2 别名where 表1.字段= 表2.字段 # 连接条件 [and 筛选条件]其他结构...# SQL 99语法select 查询列表from 表1 别名[inner] join 表2 别名on 连接条件其他结构...# SQL 99语法将筛选条件和连接条件分离，便于阅读 非等值连接 12345678910111213# SQL 92select 查询列表from 表1 别名，表2, 别名...where 非等值连接条件[and 筛选条件]其他结构...# SQL 99select 查询列表from 表1 别名[inner] join 表2 别名on 非等值连接条件其他结构... 自连接 123456789101112131415# 自连接是指同一张表自己和自己连接。#将同一张表看作两个表，起两个别名。# SQL 92select 查询列表from 表 别名1,表 别名2where 连接条件[and 筛选条件]其他结构...# SQL 99语法select 查询列表from 表 别名1[inner] join 表 别名2on 连接条件其他结构... 总结：对于内连接，SQL 92和SQL 99标准只有在连接表的方式和连接条件的位置不同，其余用法相同。SQL 99语法将连接条件写在on语句后面，与筛选条件分离，提高了易读性。 内连接案例： 123456789101112131415161718192021222324252627282930313233343536373839#案例1：查询有奖金的每个部门的部门名、部门的领导编号，以及该部门的最低工资# SQL 92，等值连接SELECT department_name,d.`manager_id`,MIN(salary)FROM departments d,employees eWHERE d.`department_id`=e.`department_id`AND commission_pct IS NOT NULLGROUP BY department_name,d.`manager_id`;# SQL 99，等值连接SELECT d.department_name,d.manager_id,MIN(salary)FROM employees e JOIN departments dON e.`department_id` = d.`department_id`WHERE e.`commission_pct` IS NOT NULLGROUP BY e.`department_id`;#案例2：查询员工的工资和工资级别# SQL 92，非等值连接SELECT salary,grade_levelFROM employees e,job_grades gWHERE salary BETWEEN g.`lowest_sal` AND g.`highest_sal`;# SQL 99，非等值连接SELECT salary,grade_levelFROM employees eJOIN job_grades g ON e.`salary` BETWEEN g.`lowest_sal` AND g.`highest_sal`;#案例3：查询员工名和上级的名称# SQL 92，自连接SELECT e.last_name,m.last_nameFROM employees e,employees mWHERE e.`manager_id`=m.`employee_id`;# SQL 99，自连接SELECT e.last_name,m.last_nameFROM employees eJOIN employees mON e.`manager_id`= m.`employee_id`; 外连接 外连接的查询结果为主表中的所有记录，如果从表中有和它匹配的，则显示匹配的值，如果从表中没有和它匹配的，则从表的结果显示null。外连接查询结果=内连接结果+主表中有，从表没有的记录。 外连接的特性决定了其应用场景为一般用于查询两个表交集以外的部分。即用于查询一个表中有，另一个表没有的记录。 左外连接和右外连接交换两个表的顺序，可以实现同样的效果 。 全外连接=内连接的结果+表1有，表2没有+表2有，表1没有。 交叉连接可以省略连接条件，其结果是笛卡尔积。 MySQL中只有SQL 99支持外连接（但不支持全外连接），只介绍SQL 99，语法如下： 12345678# 语法：select 查询内容from 表1left [outer]|right [outer]|full [outer]|cross join 表2 on 连接条件其他结构...;#outer可以省略 外连接案例： 1234567891011121314#案例1：查询哪个部门没有员工#左外SELECT d.*,e.employee_idFROM departments dLEFT OUTER JOIN employees eON d.`department_id` = e.`department_id`WHERE e.`employee_id` IS NULL; #右外,调换两个表的顺序后使用右外连接，和上面写法等价 SELECT d.*,e.employee_idFROM employees eRIGHT OUTER JOIN departments dON d.`department_id` = e.`department_id`WHERE e.`employee_id` IS NULL; 总结 以集合关系来理解内连接和外连接： 7、子查询嵌套在其他语句内部的select语句称为子查询或内查询。外面的语句可以是insert、update、delete、select等，一般为select语句较多。 如果外面的语句是select语句，则称其为主查询或外查询。 子查询根据位置的不同和结果集的不同可以有以下分类。 按子查询出现的位置分类： select后面：仅支持标量子查询 from后面：表子查询 where或having后面(常用)：标量子查询、列子查询、行子查询 exists后面（相关子查询）：均可。exists返回结果0或1，可以用in代替 按结果集的行列数不同分类： 标量子查询（结果集只有一行一列） 列子查询（结果集只有一列多行） 行子查询（结果集一行多列） 表子查询（又称嵌套子查询。结果集一般为多行多列,一或多都可） 特点： 子查询放在小括号内。 子查询一般放在条件的右侧。 子查询的执行优先于主查询执行，主查询的条件用到了子查询的结果。 标量、单行子查询，一般搭配着单行操作符使用：&lt;，&gt;，=，&lt;=，&gt;=，&lt;&gt; 多行子查询，一般搭配着多行操作符使用：in/not in、any|some、all in/not in表示等于/不等于列表中的任意一个，例：xxx in (); any|some表示和子查询返回的某一个值进行比较（只要有一个满足即可），例：xxx &gt;any();。大于any|some等价于大于最小值，小于any|some等价于小于最大值。any|some一般很少使用。 all表示和子查询返回的所有值进行比较。 相关子查询和嵌套子查询对比 嵌套子查询的执行不依赖于外部的查询。其执行过程为： 执行子查询，其结果不被显示，而是传递给外部查询，作为外部查询的条件使用。 执行外部查询，并显示整个结果。 相关子查询的执行依赖于外部查询。多数情况下是子查询的WHERE子句中引用了外部查询的表。其执行过程为： 从外层查询中取出一个元组，将元组相关列的值传给内层查询。 执行内层查询，得到子查询操作的值。 外查询根据子查询返回的结果或结果集得到满足条件的行。 然后外层查询取出下一个元组重复做步骤1-3，直到外层的元组全部处理完毕。 比如下面的例子： 123456789101112131415161718192021222324252627282930313233# 嵌套子查询# 查询工资大于平均工资的员工信息/*平均工资是子查询，其不依赖于外查询*/SELECT * FROM employeesWHERE salary&gt;( SELECT AVG(salary) FROM employees);# 相关子查询# 查询每个部门的员工数量和部门信息/*可以使用子查询的方式，也可以使用外连接+分组查询的方式。查询员工数量时，需要将子查询和父查询根据部门id关联起来，先统计一个部门的数量，然后继续统计下一个部门数量,子查询和父查询二者交替执行*/SELECT d.*,( SELECT COUNT(*) FROM employees e WHERE e.`department_id`=d.`department_id` ) AS 'NUMBER'FROM departments d;# exist也是相关子查询。能用exist的，也能使用in代替# 查询有员工的部门名SELECT department_nameFROM departments dWHERE EXISTS( SELECT * FROM employees e WHERE d.`department_id`=e.`department_id`); 子查询案例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788# -------------用在where和having后使用子查询------------#案例1：查询最低工资大于50号部门最低工资的 部门id 和 其最低工资/*思路：1.先查出50号部门的最低工资2.然后查出每个部门的最低工资，3.根据前两步的结果筛选出最低工资大于50号部门最低工资的部门信息*/SELECT MIN(salary),department_idFROM employeesGROUP BY department_idHAVING MIN(salary)&gt;( SELECT MIN(salary) FROM employees WHERE department_id = 50);#案例2：查询其它工种中，比‘IT_PROG’工种任一工资低的员工的 员工号、工种和薪资/*思路：1.查询‘IT_PROG’部门的任一工资2.查询员工信息，salary&lt;1的结果*/SELECT employee_id,job_id,salaryFROM employeesWHERE salary&lt;ANY( SELECT DISTINCT salary FROM employees WHERE job_id = 'IT_PROG') AND job_id&lt;&gt;'IT_PROG';# 小于any，只要比最大值小就可以，因此可以不用anySELECT employee_id,job_id,salaryFROM employeesWHERE salary&lt;( SELECT MAX(salary) FROM employees WHERE job_id = 'IT_PROG') AND job_id&lt;&gt;'IT_PROG';# -------------用在select后使用子查询------------#案例：查询每个部门的员工个数和部门信息SELECT d.*,( SELECT COUNT(*) FROM employees e WHERE e.department_id = d.`department_id` ) 个数 FROM departments d; # -------------用在from后使用子查询------------# from后面的子查询结果作为一张表，必须起别名# 案例：查询每个部门的平均工资的工资等级/*思路：1.使用子查询，查询每个部门的平均工资2.根据平均工资查找工资等级*/SELECT ag_dep.*,g.`grade_level`FROM ( SELECT AVG(salary) ag,department_id FROM employees GROUP BY department_id) ag_depINNER JOIN job_grades gON ag_dep.ag BETWEEN lowest_sal AND highest_sal;# -------------用在exists后使用子查询------------# 查询有员工的部门名# 使用 inSELECT department_nameFROM departments dWHERE d.`department_id` IN( SELECT department_id FROM employees);# 使用外连接SELECT DISTINCT department_nameFROM departments dINNER JOIN employees eON d.`department_id`=e.`department_id`WHERE e.`employee_id` IS NOT NULL;# 使用existsSELECT department_nameFROM departments dWHERE EXISTS( SELECT * FROM employees e WHERE d.`department_id`=e.`department_id`); 8、分页查询如果想要显示查询结果中的一部分，就需要使用分页查询，使用limit限制返回的结果开始位置和条数。 分页查询通常用于实际web项目中，根据用户需求提交对应页数的查询结果。 语法： 1234567select 查询内容from 表[where 条件][group by 分组字段][having 条件][order by 排序字段]limit [偏移量,] 条目数; # 使用limit语句进行分页 说明： 偏移量从0开始，可以省略，默认为0，理解为索引-1。偏移量为0表示从第一条开始 limit子句放在查询语句的最后。 如果每页显示条目数为sizePage，当前页数为page，则查询语句为： 12select * from 表limit (page-1)*sizePage,sizePage; 案例： 12345678#案例1：查询第11条到第25条信息SELECT * FROM employees LIMIT 10,15;#案例2：查询有奖金的员工中，工资较高的前10名员工信息SELECT * FROM employees WHERE commission_pct IS NOT NULL ORDER BY salary DESC LIMIT 10; 子查询经典案例，使用排序和分页组合求最值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 1.查询工资最低的员工姓名和工资SELECT last_name,salaryFROM employeesWHERE salary = ( # 先使用子查询查找最低工资 SELECT MIN(salary) FROM employees);# 2.查询平均工资最低的部门信息/*思路：1.先查询每个部门的平均工资2.筛选出平均工资中最低的部门3.根据上一步的结果，查询出部门信息*/# 方式一：SELECT * FROM departments d # d.根据id，查询部门信息WHERE d.`department_id` = ( SELECT department_id # c.找出平均工资为最低平均工资的部门id FROM employees GROUP BY department_id HAVING AVG(salary)= ( SELECT MIN(ag.a_s) # b.找出最低的平均工资 FROM( # a.查询出每个部门的平均工资和id SELECT AVG(salary) a_s,department_id FROM employees GROUP BY department_id ) AS ag ));# 方式二，使用limit，求出平均工资以后进行排序，就可以直接选出部门idSELECT * FROM departments dWHERE d.`department_id`= ( SELECT department_id FROM employees GROUP BY department_id ORDER BY AVG(salary) LIMIT 1 # 递增排序中的第一条就是要查询的部门);# 3.各个部门中 最高工资最低的部门的最低工资是多少SELECT MIN(salary) FROM employeesWHERE department_id = ( # 子查询将排序和分页组合找出最值 SELECT department_id FROM employees GROUP BY department_id ORDER BY MAX(salary) LIMIT 1);# 4.查询平均工资最高的部门的manager信息SELECT last_name,department_id,email,salaryFROM employeesWHERE employee_id=( # b,根据部门id找出管理者id SELECT manager_id FROM departments WHERE department_id = ( # a,找出平均工资最高的部门id SELECT department_id FROM employees GROUP BY department_id ORDER BY AVG(salary) DESC LIMIT 1 )); 9、联合查询如果要查询的结果来自于多个表，且多个表没有直接的连接关系，但查询的信息一致时，可以使用联合查询。联合查询使用union将多次的查询结果合并成一个结果。 语法： 1234567# 使用union将多个查询语句合并select xxxunion [all]select xxxunion [all].....select xxx 说明： 要求多条查询语句的查询的列数必须一致 多条查询语句的查询的列的类型和含义尽量相同 union默认去重，union all代表不去重 join和union的区别 join用于外连接，是根据一定的连接条件将两张表连接，并生成连接后的结果表，连接条件是on后面的条件。连接包括左外连接、右外连接、全连接和交叉连接。 union表示联合查询，是将两个查询结果合并在一起，不需要进行表的连接。union连接的查询语句查询的字段个数必须一致。union默认去重，可以使用all保留全部结果。 六、DML语言DML指数据操作语言。 主要是对表格的添加（insert）、删除（delete）、修改（update）操作。 1、insert向表格中插入数据有两种方式： 方式一： 1insert into 表名(字段1,字段2,...) values(值1,值2,...); 要求： 字段类型和值类型必须一致或兼容，字段和值的顺序可以和表中不一致，但是字段和值必须一一对应。 可以为空的字段，如果要插入null值，有两种方式：①字段和值都省略，此时值默认为null；②字段和值都写，值为null。 不可以为空的字段，必须插入值。 字段个数和值的个数必须一致。 字段可以省略，但默认所有字段，并且顺序和表中的存储顺序一致。 方式二： 12insert into 表名set 列名1=值,列名2=值,...; 两种方式的对比： 方式一支持插入多行，方式二不支持： 1234INSERT INTO employees(employee_id,last_name,salary)values(123,'john','15000'),values(124,'jerry','12000'),values(125,'mickey','11000'); 方式一支持子查询，方式二不支持： 12345678# 查询标量INSERT INTO employees(employee_id,last_name,salary)SELECT 123,'john','15000';# 从表2中查询到的结果插入表1INSERT INTO employees(employee_id,last_name,salary)SELECT id,name,salaryFROM employees WHERE id&lt;3; 2、update修改单表的记录： 12345678update 表名 set 字段=新值,字段=新值...[where 条件];# 案例# 将90号部门的员工工资修改为15000update employeesset salary=15000where department_id90; 修改多表记录： 123456789101112# SQL 92语法update 表1 别名1,表2 别名2set 字段=新值，字段=新值...where 连接条件[and 筛选条件];# SQL 99语法，唯一不同的就是连接表的方式不同。其余相同update 表1 别名[inner]|left [outer]|right [outer] join 表2 别名on 连接条件set 列=值,...[where 筛选条件]; 3、deletedelete表示删除表中的一条或多条记录（一行或多行），有两种方式 方式1，使用delete 单表的删除： 123delete from 表名 [where 筛选条件][limit 条目数] 一般会使用where筛选特定的记录删除，如果没有筛选条件，会删除所有的记录。 可以使用limit限定删除的条数，只能用一个参数，表示删除查询结果的前几条。 多表的删除（级联删除）： 123456# 同样地，也分为两种标准的语句，仅仅是连接表的时候不同，其余语句完全相同。# 以SQL 92为例delete 别名1，别名2from 表1 别名1，表2 别名2where 连接条件[and 筛选条件]; 方式2，使用truncate： 1truncate table 表名; delete和truncate两种方式删除记录的区别（详细对比可以参考下文）： truncate不能加where条件，而delete可以加where条件，意味着truncate会删除表中的所有记录。 truncate的效率稍高。 truncate 删除带自增长的列的表后，如果再插入数据，数据从1开始，delete 删除带自增长列的表后，如果再插入数据，数据从上一次的断点处开始 truncate删除没有返回值，delete删除有返回值 truncate属于DDL语言，删除不能回滚，delete是DML语言，支持事务，可以回滚 七、DDL语句DDL为数据定义语言。允许用户定义数据，包括创建（create）、删除（drop）、修改（alter）表和数据库，操作对象是表和数据库。通常，DDL由数据库管理员执行。 1、create创建数据库： 1create database [if not exists] 库名; 创建表： 12345678910111213141516# 语法：create table [if not exists] 表名( 列名 列的类型[(长度) 约束], 列名 列的类型[(长度) 约束], 列名 列的类型[(长度) 约束], ... 列名 列的类型[(长度) 约束]);# 例：创建名为stuinfo的表，包含的列和类型如下：CREATE TABLE IF NOT EXISTS stuinfo( stuId INT, stuName VARCHAR(20), # varchar类型必须有长度 gender CHAR, bornDate DATETIME); 创建库/表的时候，可以使用if not exists进行判断，如果要创建的库/表不存在，则创建，否则不会创建。不能创建名字相同的两个库/表。 表的复制 将create和select语句结合，可以实现表的复制： 12345678910# 仅复制表的结构create table 新表名 like 旧表# 复制表的字段和数据create table 新表名select 字段列表 from 旧表 [where 筛选条件];#仅仅复制某些字段create table 新表名select 字段列表 from 旧表 where false; 2、alter修改库/表使用alter语句 修改数据库，一般很少对现有数据库进行修改： 1234#已废弃.现在需要去文件路径中重命名RENAME DATABASE books TO 新库名; # 更数据库字符集ALTER DATABASE books CHARACTER SET gbk; 修改表： 修改表中的字段： 123456789101112# 添加新的列，必须指定类型# 新列默认在表中的位置为最后，可以使用first或after参数指定位置alter table 表名 add column 列名 类型 [约束] [first|after 列名];# 删除某列（无法使用if exist进行判断）alter table 表名 drop column 列名;# 修改列名alter table 表名 change column 旧列名 新列名 类型;# 修改列的类型或约束alter table 表名 modify column 列名 类型 [约束]; 修改表名： 1234# 格式：alter table 表名 rename [to] 新表名;# 案例：ALTER TABLE author RENAME TO book_author; 3、drop删除数据库： 1drop database [if exists] 库名; 删除表： 1drop table [if exists] 表名; 同样地，删除数据库/表的时候，可以使用if exists判断是否存在，避免报错。 八、约束和标识列1、约束约束指的是一种限制，用于限制表中的数据，为了保证表中的数据的准确和可靠性。 主要有以下六大约束： NOT NULL：非空，用于保证该字段的值不能为空。比如姓名、学号等 DEFAULT：默认，用于保证该字段有默认值。比如性别 CHECK：检查约束[mysql中不支持]。比如年龄、性别，检查年龄是否在某个区间内、性别是否是男或女。 PRIMARY KEY：主键，用于保证该字段的值具有唯一性，并且非空。比如学号、员工编号等 UNIQUE：唯一，用于保证该字段的值具有唯一性，可以为空（unique key可以插入多个null值，空值并不受唯一性约束）。比如座位号。 FOREIGN KEY：外键，用于限制两个表的关系，用于保证该字段的值必须来自于主表的关联列的值在从表添加外键约束，用于引用主表中某列的值。比如学生表的专业编号（学生表为从表，专业表为主表），员工表的部门编号，员工表的工种编号。 其中主键、外键、唯一键都是key，会默认生成索引。 关于key MySQL文档：key是索引的近义词，可以将key理解为索引。 参考1：key是表中的字段，它们参与RDBMS系统中的以下活动a.表与表中数据之间的依赖关系由key建立b.标识数据的唯一性。c.使表的约束有效果, 进而能够保证数据都是有效的。d.有可能会提升数据库表的查询效率。 key 包含两层意义和作用：一是约束（偏重于约束和规范数据库的结构完整性）；二是索引（辅助查询用）包括primary key (主键)、unique key(唯一键)、foreign key(外键) 等 约束可以在创建表和修改表(添加数据前)时添加。 添加约束有两类： 列级约束：六大约束语法上都支持，但外键约束没有效果。不可以起约束名。 表级约束：除了非空、默认，其他的都支持。可以起约束名（约束名对于主键没有效果，一直是primary） 主键和唯一键对比： 主键的值是唯一的，非空，一个表中最多只能有一个主键，允许多个字段组合在一起作为主键，但不推荐。 唯一键的值是唯一的，但是允许值为空，一个表中可以有多个唯一键，同样允许多个字段组合在一起作为唯一键，但不推荐。 外键： 要求在从表设置外键关系 从表的外键列的类型和主表的关联列的类型要求一致或兼容，名称无要求 主表的关联列必须是一个key（一般是主键或唯一） 插入数据时，先插入主表，再插入从表。删除数据时，先删除从表，再删除主表： 12345678910111213#方式一：级联删除，删除主表数据时，将从表中相关的记录(整行)也删除#添加外键时，在最后添加 on delete cascade。例如：ALTER TABLE stuinfo ADD CONSTRAINT fk_stuinfo_major FOREIGN KEY(majorid) REFERENCES major(id) ON DELETE CASCADE; # 方式二：级联置空，删除主表数据时，将从表中相关的记录中对应的字段置为null#添加外键时，在最后添加 on delete set null。例如：ALTER TABLE stuinfo ADD CONSTRAINT fk_stuinfo_major FOREIGN KEY(majorid) REFERENCES major(id) ON DELETE SET NULL; 添加约束 列级约束，直接在类型后添加约束名 12345678# 例如。create table 表名( 字段名 字段类型 not null, # 非空 字段名 字段类型 primary key, # 主键 字段名 字段类型 unique, # 唯一键 字段名 字段类型 default, # 默认 ...); 表级约束，在字段都定义完后，再为指定的列添加约束 12345678910111213141516# 语法：[constraint 约束别名] 约束(字段名);# 例如：CREATE TABLE stuinfo( id INT, stuname VARCHAR(20), gender CHAR(1), seat INT, age INT, majorid INT, CONSTRAINT pk PRIMARY KEY(id),#主键 CONSTRAINT uq UNIQUE(seat),#唯一键 CONSTRAINT ck CHECK(gender ='男' OR gender = '女'),#检查（MySQL不支持） CONSTRAINT fk_stuinfo_major FOREIGN KEY(majorid) REFERENCES major(id)#外键); 如果多个字段组合作为主键或唯一键，将这几个字段都写在表级约束的括号中，逗号隔开。 表级约束和列级约束可以一起使用，定义外键时使用表级约束，其他约束使用列级约束即可。 查看表中的所有索引（主键、外键、唯一键）： 1SHOW INDEX FROM 表名; 除了在定义表时添加约束，也可以在修改表的时候添加约束： 12345#1、添加列级约束alter table 表名 modify column 字段名 字段类型 新约束;#2、添加表级约束alter table 表名 add [constraint 约束名] 约束类型(字段名) [外键相关]; 删除约束 在修改表的语句中，也可以删除约束，一般的约束在类型后面不加约束就代表删除，对于key，则需要使用drop显式删除，具体如下： 123456789101112131415#1.删除非空约束ALTER TABLE stuinfo MODIFY COLUMN stuname VARCHAR(20) NULL;#2.删除默认约束ALTER TABLE stuinfo MODIFY COLUMN age INT;#3.删除主键ALTER TABLE stuinfo DROP PRIMARY KEY;#4.删除唯一键，使用删除索引的语法ALTER TABLE stuinfo DROP INDEX seat;#5.删除外键，需要先将对应的索引删除ALTER TABLE stuinfo DROP INDEX fk_stuinfo_major;ALTER TABLE stuinfo DROP FOREIGN KEY fk_stuinfo_major; MySQL中直接删除外键以后，外键依然存在，需要先将同名索引删除，然后再删除外键，这样查询时就不会显示外键了。 删除外键的时候，同名索引如果没被删，MYSQL认为外键仍然存在，MYSQL会在show keys命令里继续显示外键，当drop table时，MYSQL会提示Can’t DROP ‘xxx’; check that column/key exists”如果再次想删除外键的时候，会报1091错误，提示外键名错误，因为实际上外键已经不存在了。因此MySQL中需要先将对应的索引删除，再删除外键。 2、标识列标识列又称为自增长列，可以不用手动的插入值，系统提供默认的序列值，默认从1开始。 格式：在key的约束后面加上auto_increment即可。 用法：添加数据时，标识列可以填null，或者不赋值，系统都会自动在已有的基础上+1。也可以手动指定值。 特点： 标识列不是必须和主键搭配，但要求是一个key。 一个表最多只能有一个标识列。 标识列的类型只能是数值型，一般是int型。如果是非int型，自动赋值时是整数，可以手动插入小数。 可以通过SHOW VARIABLES LIKE '%auto_increment%'; 查看标识列的步长和默认起始值. 标识列可以通过SET auto_increment_increment=n设置步长。mysql不支持设置起始值，但可以通过手动插入值，设置起始值。 使用： 12345678910111213# 创建表时设置标识列CREATE TABLE tab_identity( id INT, NAME FLOAT UNIQUE AUTO_INCREMENT, seat INT );# 修改表时设置标识列ALTER TABLE tab_identity MODIFY COLUMN id INT PRIMARY KEY AUTO_INCREMENT;#三、修改表时删除标识列ALTER TABLE tab_identity MODIFY COLUMN id INT; 九、数据库事务TCL（Transaction Control Language）： 事务控制语言 1、事务概述事务：一个或一组SQL语句（一般是DML语句）组成的一个执行单元，这个执行单元要么全部执行，要么全部不执行。 DDL语句不支持事务，可以认为DDL语句执行完自动提交，因此也无法回滚。 事务的四大特性（ACID）： 原子性（Atomic）：组成事务的SQL语句要么都执行，要么都不执行（回滚）。 一致性（Consistent）：事务完成前后，所有数据的状态都是一致的。比如A账户只要减去了100，B账户则必定加上了100。 隔离性（Isolation）：多个事务同时操作相同数据库的同一个数据时，即多个事务并发执行，每个事务作出的修改必须与其他事务隔离。 持久性（Duration）：事务一旦提交，对数据库数据的修改被持久化到本地存储。 事务分类： 隐式事务：没有明显的开启和结束的标记，本身就是一个事务。对于单条SQL语句，数据库系统自动将其作为一个事务执行，这种事务被称为隐式事务。隐式事务系统会自动提交。 显式事务：具有明显的开启和结束的标记，即手动开启事务。显式事务必须保证系统的自动提交功能被禁用，实际上，MySQL中显示开启事务时，自动提交是无效的，不需要手动设置。 2、事务的开启一个完整的事务包括以下执行流程：开启事务→执行事务语句→提交或回滚。 事务的执行结果要么是提交，要么是回滚。 步骤一：开启事务 开启事务有两种方式，一种是关闭自动提交模式，隐式开启事务；另一种是显式开启事务，有两种显式开启事务的语法，具体如下： 方式一：关闭自动提交模式，之后遇到需要开启事务的sql时，会自动开启事务，相当于隐式开启事务: 12set autocommit=0; # 将自动提交模式关闭执行语句 方式二：显式开启事务 12345# 方式一：start transaction;#方式二：begin; 步骤二：执行语句 在这一步，可以编写执行语句，包括insert、update、delete等语句。 DDL语言（create、drop、truncate等）是非事务的，可以理解为事务中的DDL语言执行完后会自动提交（禁用自动提交也没用），无法回滚，影响事务其他DML操作。 如果事务中掺杂了DDL语句，执行完DDL语句后会自动提交，导致之前的执行语句被提交，无法回滚，因此为了安全起见，尽量将DDL和DML完全分开，便于回滚。 步骤三：结束事务 事务的结束有两种情况： commit [work]：提交，表示事务的执行单元都执行了。 rollback [work] ：回滚，表示事务的执行单元都没执行。 事务相关的其他关键字： savepoint identifier：设置一个名为identifier的保存点 release savepoint identifier：删除一个事务的名为identifier的保存点，当没有指定的保存点时，执行该语句会抛出一个异常； rollback to identifier ：把事务回滚到保存点。不算真正地结束事务，仍可以使用rollback将整个事务的修改撤销，因此执行了此语句后，也需要显式运行commit或rollback命令结束事务。 事务的使用案例： 123456789101112#开启事务，三种均可#SET autocommit=0;#START TRANSACTION;begin;#事务执行语句UPDATE employees SET salary = 17200 WHERE username='K_ing';UPDATE employees SET salary = 10000 WHERE username='Marry';#结束事务，要么提交，要么回滚ROLLBACK;#commit; drop、delete、truncate三者的区别： drop用于删除整个表。 delete可以使用筛选条件，删除表中的一行或多行记录。并且同时将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作。 truncate table则一次性地从表中删除所有的数据，即所有行，不能使用筛选条件。并不把单独的删除操作记录记入日志保存，操作不能恢复。 delete是DML语言，支持事务，delete操作可以会滚；而truncate和drop是ddl语言，不支持事务，因此无法回滚。 truncate和delete只删除数据，drop则删除整个表，包括结构和数据。 delete可以激活触发器。truncate不能激活触发器。 当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，并且标识列也从1重新开始计数；delete操作不会减少表或索引所占用的空间，标识列还是从断点处计数。drop语句将表所占用的空间全释放掉。 速度上：drop&gt;truncate&gt;delete 3、事务的隔离级别当多个事务同时操作同一个数据库的相同数据时，容易导致并发问题，包括以下问题： 脏写（丢失修改）：一个事务修改了其他事务还没有提交的数据，如果其他事务回滚，导致当前事务的修改丢失。事务B去修改了事务A修改过的值，但是此时事务A还没提交，所以事务A随时会回滚，导致事务B修改的值也没了。脏读：一个事务读取到了其他事务未提交（一般指数据修改）的数据。事务B去查询了事务A修改过的数据，但是此时事务A还没提交，所以事务A随时会回滚，导致事务B再次查询就读不到刚才事务A修改的数据了。 脏读和脏写都是因为一个事务去更新或者查询了另外一个还没提交的事务更新过的数据。因为另外一个事务还没提交，所以它随时可能会回滚，那么必然导致你更新的数据就没了，或者你之前查询到的数据就没了，这就是脏写和脏读两种场景。 不可重复读：同一个事务中，多次读取到的数据不一致，即中间有其他事务提交了修改（一般指数据修改）。事务A读取一个字段后，事务B更新了该字段并提交了，导致A再次读取的时候和之前不一致了，即无法重复读取到相同的某个值。 幻读：一个事务多次读取数据时，中间有其他事务提交了更新操作（一般指插入或删除）的数据。比如同样的查询语句，第一次查询出n条，然后别的事务进行了插入或删除，第二次查询出m条，同样的查询语句得到的结果不一样，就像出现了幻觉。 可以通过设置隔离级别避免事务的并发问题，主要有以下四种隔离级别： 隔离级别 脏读 不可重复读 幻读 说明 read uncommitted 未解决 未解决 未解决 允许事务读取未被其他事务提交的更改 read committed 解决 未解决 未解决 只允许事务读取已经被其它事务提交的更改。Oracle的默认隔离级别 repeatable read 解决 解决 未解决 确保事务可以多次从一个字段中读取相同的值，事务持续期间，禁止其他事务对这个字段更新。MySQL的默认隔离级别 serializable 解决 解决 解决 确保事务可以多次从一个表中读取相同的行，事务持续期间，禁止其他事务对该表执行插入、更新和删除操作。可以避免所有并发问题，性能最差。 上述四种隔离级别，MySQL全部支持，Oracle只支持read committed和serializable。 4、设置隔离级别事务的隔离级别包括全局级别和会话级别： 全局级别：对后续新的所有会话连接有效，对已经存在的会话连接无效。 会话级别：对数据库会话连接的后续新发起或当前未提交的事务有效。如果没有session关键字的话，只对当前数据库会话连接的后续新发起的事务有效，当前未提交的事务，还是继续使用之前的事务隔离级别。 设置隔离级别的语法： 12345# 设置全局隔离级别set global transaction isolation level 隔离级别名;# 设置当前会话连接的隔离级别set [session] transaction isolation level 隔离级别名; 查看隔离级别： 1234#查看当前会话隔离级别select @@tx_isolation;#查看全局隔离级别select @@global.tx_isolation; 5、MyISAM引擎和InnoDB引擎对比InnoDB引擎是MySQL5.5开始引入的。InnoDB和MyISAM引擎的对比： 是否支持行级锁。MyISAM只支持表锁，而InnoDB支持表锁和行锁，且默认为行锁。 是否支持事务。MyISAM不支持事务，InnoDB支持事务，具有提交和回滚事务的能力。 是否支持外键。MyISAM不支持外键，InnoDB支持外键。 是否支持数据库异常崩溃后的安全恢复。MyISAM不支持，InnoDB支持。InnoDB引擎能够保证，在数据库异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态，恢复的过程依赖于redo log 扩展：InnoDB是如何保证ACID特性的？ 1、InnoDB引擎使用redo log(重做日志)保证事务的持久性 2、InnoDB引擎使用undo log(回滚日志)保证事务的原子性 3、InnoDB引擎使用锁机制、MVCC等手段保证事务的隔离性 4、保证了上述三个特性后，一致性才得以保障。 十、视图1、概述视图是MySQL 5.1的新特性。视图是一张虚拟的表，它的数据来自于表，通过执行时动态生成。视图的用法和表相同。视图只保存了SQL逻辑，没有保存查询结果，因此其几乎不占用物理空间，视图一般仅用于查询，仅仅少数情况下才能修改数据。 视图的优势： 提高SQL语句的重用性，简化了复杂的SQL操作，提高了效率 和表实现了分离，提高了安全性 2、创建视图创建视图： 12create [or replace] view 视图名 as 查询语句;# 使用or replace还可以用于视图的修改 使用案例： 12345678910111213# 使用视图，查询各部门的平均工资级别# 1.创建视图查看每个部门的平均工资CREATE VIEW myview ASSELECT AVG(salary) ag,department_idFROM employeesGROUP BY department_id;# 2.使用创建的视图查询SELECT myview.`ag`,g.grade_levelFROM myviewJOIN job_grades gON myview.`ag` BETWEEN g.`lowest_sal` AND g.`highest_sal`; 3、删除视图删除视图： 1234drop view 视图名,视图名,...; # 可以一次删除多个视图#案例：删除myv1，myv2，myv3三个视图DROP VIEW myv1,myv2,myv3; 4、查看视图查看视图有两种方式： 12345#方式一：DESC 视图名;#方式二：SHOW CREATE VIEW 视图名; 5、更新视图和修改表相似，更新视图包括修改视图本身，和修改视图中的内容两部分。 修改视图本身： 1234567#方式一：可用于修改和创建视图create or replace view 视图名as 查询语句;# 方式二：alter view 视图名as 查询语句; 修改视图的内容 一般的视图只用来查询，对视图进行插入、删除、修改数据，如果能操作成功，则会对源表中的数据也会进行修改。但是绝大多数情况下无法对视图进行修改，而且也不建议对视图进行修改。 以下情况的视图无法更新： SQL语句包含分组函数、distinct、group by、having、union或者union all的视图 常量视图 select中包含子查询的视图 包含join的视图 from一个不能更新的视图 where子句的子查询引用了from子句中的表 十一、变量变量包括： 系统变量 全局变量 会话变量 自定义变量 用户变量 局部变量 1、系统变量系统变量：变量由系统定义，不是用户定义，属于服务器层面。必须拥有super权限才能修改系统变量。 系统变量分为全局变量和会话变量。全局变量需要添加global关键字，会话变量需要添加session关键字，如果不写，默认为会话级别。 全局变量 作用域：服务器每次启动将为所有的全局变量赋初始值，针对于所有会话（连接）有效，但不能跨重启。 查看全局变量： 12345678# 查看所有全局变量SHOW GLOBAL VARIABLES;# 查看满足条件的部分系统变量SHOW GLOBAL VARIABLES LIKE 'xxx';# 查看指定的系统变量的值，SELECT @@global.变量名 设置全局变量： 12345# 以autocommit为例# 方式一：SET @@global.变量名=值;# 方式二：SET GLOBAL 变量名=值; 会话变量 作用域：针对于当前会话（连接）有效 查看会话变量： 123456789101112# 查看所有会话变量SHOW [SESSION] VARIABLES;# 查看满足条件的部分会话变量SHOW [SESSION] VARIABLES LIKE 'xxx';# 查看指定的会话变量的值#SELECT @@[session.]变量名;# 例：SELECT @@autocommit;# 或写成SELECT @@session.autocommit; 设置会话变量： 12SET @@session.变量名=值;SET [SESSION] 变量名=值; 2、自定义变量自定义变量是由用户自定义，而不是系统提供的。其分为用户变量和局部变量。 自定义变量的使用一般都有声明、赋值、使用（查看、比较、运算等）三个步骤。 用户变量 作用域：和会话变量的作用域相同，对于当前会话（连接）有效。在begin end里面和外面都可以使用。 声明用户变量，要求声明时必须初始化值。有两种赋值操作符：=和:= 12345678#方式一SET @变量名=值;#方式二SET @变量名:=值;#方式三SELECT @变量名:=值; 为用户变量赋值： 1234567# 方式一，和初始化时相同：SET @变量名=值;SET @变量名:=值;SELECT @变量名:=值;# 方式二：SELECT 字段 INTO @变量名 FROM 表; 查看用户变量： 1SELECT @变量名; 局部变量 作用域：仅在定义它的begin end块中有效。 声明局部变量必须在begin end块中的最前面部分。 局部变量一般不用加@符号，但是声明时需要指定类型，用户变量不需要指定类型。 声明局部变量： 1DECLARE 变量名 类型 [DEFAULT 值]; 为局部变量赋值： 1234567#方式一，同样是三种：SET 局部变量名=值;SET 局部变量名:=值;SELECT @局部变量名:=值;#方式二：SELECT 字段 INTO 局部变量名 FROM 表; 查看局部变量的值： 1SELECT 局部变量名; 十二、存储过程和函数存储过程和函数都是事先经过编译 并存储在数据库中的一段SQL语句的集合。 优势： 提高了sql语句的重用性，减少了开发人员的压力 提高了数据处理的效率 减少数据在数据库和应用服务器之间的传输次数 1、存储过程创建存储过程 语法： 1234create procedure 存储过程名(参数模式 参数名 参数类型,...)begin 存储过程体(一条或多条合法的SQL语句);end 结束符 参数可以有0个（比如只有插入语句）或多个。参数模式包括三种： IN：表示该参数可以作为输入，即该参数需要调用方传入值 OUT：表示该参数可以作为输出，即该参数可以作为返回值 INOUT：表示该参数既可以作为输入又可以作为输出，即该参数既需要传入值，又可以返回值 存储过程体如果只有一个SQL语句，可以省略begin和end，如果有多个SQL语句，每条SQL语句必须需要使用;结尾。 MySQL默认将;作为结束符，所以如果存储过程中有多个语句，但又希望将多个语句都执行，因此创建存储过程之前需要将修改默认的结束符。使用 delimiter重新设置结束符，保证过程体中的;被直接传递到服务器，而不会被客户端解释。例如，将//设置结束符的语句为：delimiter // SQLyog 10.0，定义存储过程前必须要设置结束符，生成的存储过程会自动将结束符设置为$$$$，如果没有手动将结束符改为;，系统会自动添加delimiter ;语句，因此每次创建存储过程都要重新设置结束符。 手写存储过程，建议在开头设置结束符，在末尾将结束符重新设置为; 调用存储过程 123call 存储结构名(实参);# 如果是in模式的参数，可以直接传入值# 如果是out或inout模式的参数，必须预先定义变量，然后作为参数传入。 删除存储过程 存储过程不能修改，一般做法是将原来的删除，然后新建。 12# 每次只能删除一个，不能删除多个DROP PROCEDURE [IF EXISTS] 存储过程名; 查看存储过程 1SHOW CREATE PROCEDURE 存储过程名; 例：创建存储过程，输入员工id，输出其管理者的id和名字 123456789101112131415161718192021222324/* 声明存储结构*/DELIMITER @@ # 设置结束符为@@# 确保存储过程能正确创建，如果已经存在，删除原有的DROP PROCEDURE IF EXISTS `myp`@@CREATE PROCEDURE myp(IN id INT, OUT managerId INT, OUT managerName VARCHAR(20))BEGIN # 将查询的结果值赋给输出变量，这里参数为局部变量 SELECT m.`employee_id`,m.`last_name` INTO managerId,managerName FROM employees m INNER JOIN employees e ON m.`employee_id`=e.`manager_id` WHERE e.`employee_id`=id;END @@ # end后面要加设置的结束符DELIMITER ; # 将结束符改回分号/*调用存储结构in模式参数直接传入值，out模式的参数要先声明，或者传入的时候指定名字*/CALL myp (110,@mid,@mname); # 调用存储结构，传入参数SELECT @mid,@mname; # 查看结果值 2、函数函数和存储过程相似，唯一的区别是，存储过程可以有0个返回值，也可以有多个返回，适合做批量插入、批量更新；而函数有且仅有1个返回值，适合做处理数据后返回一个结果的情况。 创建函数 12345CREATE FUNCTION 函数名(参数名 参数类型,...) RETURNS 返回类型BEGIN 函数体; RETURN xx; #必须有返回值END 结束符 和存储过程相同，函数的参数也可是是0个或多个；结束符和存储过程的用法也相同；如果函数体只有一句，同样可以省略begin end语句。 调用函数 1SELECT 函数名(参数列表); # 存储过程用的是CALL 删除函数 12# 同样每次只能删除一个DROP FUNCTION [IF EXISTS] 函数名; 查看函数 1SHOW CREATE FUNCTION 函数名; 函数使用案例：根据部门名，返回该部门的平均工资 12345678910111213141516171819/*创建函数*/DELIMITER @@ # 先将分隔符设置为@@DROP FUNCTION IF EXISTS `myf`@@CREATE FUNCTION myf(deptName VARCHAR(20)) RETURNS DOUBLEBEGIN #声明一个局部变量，用于接收查询结果，并返回 DECLARE sal DOUBLE ; SELECT AVG(salary) INTO sal FROM employees e JOIN departments d ON e.department_id = d.department_id WHERE d.department_name=deptName; RETURN sal; # 返回结果值END @@DELIMITER ; # 将分隔符重新设置为分号/*调用函数*/SELECT myf('IT'); 十三、流程控制结构流程控制结构包括以下三种： 顺序结构：程序从上到下依次执行 分支结构：程序从两条或多条路径中选择一条去执行，比如if、case结构 循环结构：程序在满足一定条件的基础上，重复执行一段代码，比如while、loop、repeat 1、分支结构分支结构包括if结构和case结构，只能用于begin end中，要和if函数、case函数区分开，流程控制函数既可以用在begin end里面，也可以用在外面。if函数适用于简单双分支，而if结构适用于区间判断的多分支，case适用于等值判断。 if结构 语法： 12345if 条件1 then 语句1;elseif 条件1 then 语句2;...else 语句n;end if; case结构 语法： 123456789101112131415# 方式一：类似于switchcase 表达式when 值1 then 语句1;when 值2 then 语句2;...else 语句n;end case;# 方式二：类似于多重ifcase when 条件1 then 语句1;when 条件2 then 语句2;...else 语句n;end case; 分支结构使用案例 创建函数，实现传入成绩返回等级的功能。如果成绩&gt;90，返回A，如果成绩&gt;80，返回B，如果成绩&gt;60，返回C，否则返回D。 123456789101112131415161718192021222324252627282930313233343536# 方式一：使用if结构DELIMITER @@ # 先将分隔符设置为@@DROP FUNCTION IF EXISTS `myf_if`@@CREATE FUNCTION myf_if(score FLOAT) RETURNS CHARBEGIN # 设置局部变量保存结果 DECLARE ch CHAR DEFAULT 'A'; IF score&gt;90 THEN SET ch='A'; ELSEIF score&gt;80 THEN SET ch='B'; ELSEIF score&gt;60 THEN SET ch='C'; ELSE ch='D'; END IF; RETURN ch;END @@DELIMITER ;#调用函数SELECT myf_if(87);# 方式二：使用case结构DELIMITER @@ # 先将分隔符设置为@@DROP FUNCTION IF EXISTS `myf_case`@@CREATE FUNCTION myf_case(score FLOAT) RETURNS CHARBEGIN #设置局部变量保存结果 DECLARE ch CHAR DEFAULT 'A'; CASE WHEN score&gt;90 THEN SET ch='A'; WHEN score&gt;80 THEN SET ch='B'; WHEN score&gt;60 THEN SET ch='C'; ELSE SET ch='D'; END CASE; RETURN ch;END @@DELIMITER ;#调用函数SELECT myf_case(56); 2、循环结构循环结构包括while，loop，repeat三种。 同样，循环结构只能在begin end中使用。 循环结构中，包括两个循环控制语句： iterate：类似于java中的continue，结束本次循环，进入下一次循环。 leave：类似于java中的breek，跳出当前循环体。 循环控制语句后面必须有循环结构的标签名，也就是说，如果循环结构中使用了循环控制语句，此循环结构必须添加标签。 while结构 123[标签:] WHILE 循环条件 DO 循环体END WHILE [标签]; loop结构 loop结构没有循环条件，想要结束循环必须使用leave语句，loop结构可以用于模拟简单的死循环。 123[标签:] loop 循环体;end loop [标签]; repeat结构 1234[标签:] repeat 循环体;until 结束循环条件end repeat [标签]; 使用循环结构的案例： 123456789101112131415161718# 使用存储结构和循环结构，实现批量插入，要求只插入偶数次的记录DELIMITER @@ # 先将分隔符设置为@@DROP PROCEDURE IF EXISTS test_while@@CREATE PROCEDURE test_while(IN insertCount INT)BEGIN DECLARE i INT DEFAULT 0; a: WHILE i&lt;=insertCount DO SET i=i+1; IF MOD(i,2)!=0 THEN ITERATE a; END IF; INSERT INTO admin(username,`password`) VALUES(CONCAT('xiaohua',i),'0000'); END WHILE a;END @@DELIMITER ;# 传入100，只会插入偶数时的记录CALL test_while1(100);","categories":[{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"http://kangshitao.github.io/tags/MySQL/"},{"name":"SQL","slug":"SQL","permalink":"http://kangshitao.github.io/tags/SQL/"}]},{"title":"Java学习笔记17-Java9&10&11新特征","slug":"java-note-1701","date":"2021-04-19T08:56:30.000Z","updated":"2022-05-22T13:30:54.796Z","comments":true,"path":"2021/04/19/java-note-1701/","link":"","permalink":"http://kangshitao.github.io/2021/04/19/java-note-1701/","excerpt":"Java9、10、11新特性，模块化，jShell命令，接口私有方法，var","text":"一、Java 9新特性Java 9的新特性官方文档 从Java 9发布开始，Java的计划发布周期变为6个月。 总的来说，Java 9的新特性主要有： 模块化系统 jShell命令 多版本兼容jar包 接口的私有方法 钻石操作符的使用升级 语法改进：try语句 String存储结构变更 便利的集合特性：of() 增强的StreamAPI 全新的HTTP客户端API Deprecated的相关API javadoc的HTML5支持 Javascript引擎升级：Nashorn java的动态编译器 1、JDK和JRE目录结构改变Java 9开始，JDK的目录结构发生改变。 Java 9之前的JDK目录： Java 9及以后的JDK目录结构： 2、模块化系统Java 9之前的项目，存在的缺陷： Java运行环境的膨胀和臃肿。每次JVM启动的时候，至少会有30～60MB的内存加载，主要原因是JVM需要加载rt.jar，不管其中的类是否被classloader加载，第一步整个jar都会被JVM加载到内存当中去（而模块化可以根据模块的需要加载程序运行需要的class） 当代码库越来越大，创建复杂，代码交错的几率呈指数级的增长。不同版本的类库交叉依赖导致让人头疼的问题，这些都阻碍了Java开发和运行效率的提升。 很难真正地对代码进行封装，而系统并没有对不同部分（也就是JAR文件）之间的依赖关系有个明确的概念。每一个公共类都可以被类路径之下任何其它的公共类所访问到，这样就会导致无意中使用了并不想被公开访问的API。 Java 9提出Jigsaw(积木，拼图)项目的概念，之后的版本改名为Modularity，表示模块化项目。 本质上来说，模块(module)的概念其实就是package外再裹一层，就是用模块来管理各个package，通过声明某个package暴露，不声明默认就是隐藏。因此，模块化使得代码组织上更安全，因为它可以指定哪些部分可以暴露，哪些部分隐藏。模块化的实现目标： 模块化的主要目的在于减少内存的开销 只须必要模块，而非全部jdk模块，可简化各种类库和大型应用的开发和维护 改进Java SE平台，使其可以适应不同大小的计算设备 改进其安全性，可维护性，提高性能 模块化的使用 模块将由通常的类和新的模块声明文件（module-info.java）组成。该文件位于java代码结构的顶层，描述符明确地定义了模块需要什么依赖关系，以及哪些模块被外部使用。在exports子句中未提及的所有包默认情况下将封装在模块中，不能在外部使用。 如图： 要想在java9demo模块中调用java9test模块下包中的结构，需要在java9test的module-info.java中声明： 12345module java9test{ //将想要对外暴露的包，使用exports导出。 //没有使用exports语句导出的包，默认被封装到模块里面 exports com.atguigu.bean;} 对应地，需要在java9demo模块的src下，创建module-info.java文件，声明下面语句： 1234module java9demo{ //requires指明对其他模块的依赖 requires java9test;} 3、jShell命令交互式编程环境REPL(read-evaluate-print-loop)指的是以交互式的方式对语句和表达式求值。 jShell是Java语言在Java 9新增的REPL工具，让Java像脚本语言一样运行。无需创建Java文件就可以运行程序。 jShell也可以从文件中加载语句或者将语句保存到文件中。 jShell也可以使用tab键进行自动补全和自动添加分号。 使用方法 启动：在命令提示符窗口中输入jshell（Windows的DOS命令不区分大小写）即可打开jShell 使用： /help intro：获取帮助 /list：控制正在执行的操作 /help：获取有关命令的列表 /exit：退出jShell jShell环境下，语句末尾的;可以省略，为了提高代码可读性，建议不要省略。 jShell中没有受检异常(编译时异常) 4、语法改进：接口的私有方法Java 8中对于接口添加了静态方法和默认方法，Java 9中加入了私有方法。接口更像一个抽象类了。 5、语法改进：钻石操作符使用升级钻石操作符（diamond operator)：&lt;&gt; Java 9中钻石操作符可以和匿名实现类共同使用： 12345678//匿名操作类后面可以使用&lt;&gt;操作符Comparator&lt;Object&gt; com = new Comparator&lt;&gt;(){ @Override public int compare(Object o1, Object o2){ return 0; }}//Java 9以前这样写会报编译异常：Cannot use“&lt;&gt;”with anonymous inner classes 6、语法改进：try语句Java 8中，可以实现资源的自动关闭，但是要求执行后必须关闭的所有资源必须在try子句中初始化，否则编译不通过： 12345try(InputStreamReader reader = new InputStreamReader(System.in)){ //读取数据细节省略}catch(IOException e){ e.printStackTrace();} Java9中，用资源语句编写try将更容易，可以在try子句中使用已经初始化过的资源，但是此时的资源是final的，无法再被修改： 123456789InputStreamReader reader = new InputStreamReader(System.in);OutputStreamWriter writer = new OutputStreamWriter(System.out);try(reader; writer){ //reader是final的，不可再被赋值 //reader = null; //会报错 //具体读写操作省略}catch(IOException e) { e.printStackTrace();} 7、String存储结构改变Java 9开始，String（包括StringBuffer、StringBuilder）的底层存储结构不再是char型数组，而是用byte数组加编码标记，节省空间。 8、集合工厂方法Java 9之前，如果想创建一个只读、不可改变的集合，需要好几步： 123456789List&lt;String&gt; namesList =newArrayList &lt;&gt;(); //创建集合namesList.add(\"Joe\"); //添加元素namesList.add(\"Bob\");namesList.add(\"Bill\");namesList = Collections.unmodifiableList(namesList); //更改为不可变集合System.out.println(namesList);//下面这种方法得到的也是只读集合List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5); Java 9为集合类添加了静态方法of()，用于构建只读集合。包括List、Set、Map。只读集合如果添加元素，会导致UnsupportedOperationException异常。 List中的of()方法 Map中的of()方法 9、InputStream加强InputStream添加transferTo方法，可以用来将数据直接传输到OutputStream，这是在处理原始数据流时非常常见的一种用法: 1234567ClassLoader cl =this.getClass().getClassLoader();try(InputStream is = cl.getResourceAsStream(\"hello.txt\"); OutputStream os = new FileOutputStream(\"src\\\\hello1.txt\")) { is.transferTo(os);//把输入流中的所有数据直接自动地复制到输出流中}catch(IOException e) { e.printStackTrace();} 10、增强的Stream APIJava 9中，Stream接口中添加了4个新的方法： default Stream&lt;T&gt; takeWhile(Predicate&lt;? super T&gt; predicate)：返回从开头开始，按照指定规则的尽量多的元素（一旦遇到不符合条件的数据，就停止）。 default Stream&lt;T&gt; dropWhile(Predicate&lt;? super T&gt; predicate)：返回符合条件的前n个元素之后的元素，与takeWhile互补。 public static&lt;T&gt; Stream&lt;T&gt; ofNullable(T t)：创建一个单元素的Stream实例，t可以为空（Java 8中的of()方法不能为单个null） public static&lt;T&gt; Stream&lt;T&gt; iterate(T seed, Predicate&lt;? super T&gt; hasNext, UnaryOperator&lt;T&gt; next)：iterate的重载方法，可以提供一个Predicate (判断条件)来指定什么时候结束迭代。 11、Optional创建Stream对象除了对Stream本身的扩展，Optional和Stream之间的结合也得到了改进。 现在可以通过Optional的新方法stream()将一个Optional对象转换为一个(可能是空的) Stream对象。 比如： 12345678910public class Test{ public void test(){ List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(\"Tom\"); list.add(\"Jerry\"); Optional&lt;List&lt;String&gt;&gt; optional = Optional.ofNullable(list); Stream&lt;List&lt;String&gt;&gt; stream = optional.stream(); stream.flatMap(x -&gt; x.stream()).forEach(System.out::println); }} 12、JavaScript引擎升级Nashorn项目在Java 9中得到改进。 二、Java 10新特性Java 10共定义了109个新特性，其中包含12个JEP(JDK Enhancement Proposal)，还有新API和JVM规范以及Java语言规范上的改动。 12个JEP： 286:Local-Variable Type Inference：局部变量类型推断 296:Consolidate the JDK Forest into a Single Repository：JDK库的合并 304:Garbage-Collector Interface：统一的垃圾回收接口 307:Parallel Full GC for G1：为G1提供并行的Full GC 310:Application Class-Data Sharing：应用程序类数据（AppCDS）共享 312:Thread-Local Handshakes ThreadLocal：握手交互 313:Remove the Native-Header Generation Tool (javah)：移除JDK中附带的javah工具 314:Additional Unicode Language-Tag Extensions：使用附加的Unicode语言标记扩展 316:Heap Allocation on Alternative Memory Devices：能将堆内存占用分配给用户指定的备用内存设备 317:Experimental Java-Based JIT Compiler：使用基于Java的JIT编译器 319:Root Certificates：根证书 322:Time-Based Release Versioning：基于时间的发布版本 其中值得关注的是：Local-Variable Type Inference，局部变量类型推断。 1、局部变量类型推断使用var代替局部变量的显示类型声明，适用于编译器可以推断出类型的地方，包括以下三种情况： 局部变量的初始化 增强for循环中的索引 传统for循环中的索引 代码实现： 12345678910111213public class Test{ public void test1() { //1.声明变量时，根据所附的值，推断变量的类型 var num = 10; var list = new ArrayList&lt;Integer&gt;(); list.add(123); //2.遍历操作 for (var i : list) {System.out.println(i);} //3.普通的遍历操作 for (var i = 0; i &lt; 10; i++) {System.out.println(i);} }} var不适用于以下情况： 没有初始化的局部变量声明 方法的返回类型 方法的参数类型 构造器的参数类型 属性 catch块 原理：在处理var时，编译器先是查看表达式右边部分，并根据右边变量值的类型进行推断，作为左边变量的类型，然后将该类型写入字节码当中。正确使用var生成的字节码文件和不使用var时生成的字节码文件内容是相同的。 注意： var不是一个关键字。因此可以作为方法名或变量名，但是不能用它作为类名。除了不能用作类名以外，别的都可以。 var并不会改变Java是一门静态类型语言的事实。这一特征只发生在编译阶段，对运行时性能不会产生任何影响。编译器在编译阶段自动推断出类型，然后写入字节码文件。反编译出的字节码文件仍是传统带类型的代码。 2、集合新增创建不可变集合的方法Java 9 为集合（List,Set,Map）添加了of()方法用于创建不可变集合，Java 10 则添加了copyOf()方法，同样用于创建不可变集合，二者的区别如下： 123456789101112131415public class Test{ public void test5(){ //示例1： var list1 = List.of(\"Java\", \"Python\", \"C\"); var copy1 = List.copyOf(list1); //list1是不可变集合，直接返回list1 System.out.println(list1 == copy1); // true //示例2： var list2 = new ArrayList&lt;String&gt;(); list2.add(\"aaa\"); //list2是可变集合，底层会调用of方法新建一个只读集合并返回 var copy2 = List.copyOf(list2); System.out.println(list2 == copy2); // false //结果不同。 }} 上面两种结果不同，是因为copyOf()会先判断参数集合是不是AbstractImmutableList（不可变）类型的，如果是，则直接返回，否则会调用of方法创建一个只读集合并返回。 三、Java 11新特性1、概述Java 11是一个长期支持版本，包括ZGC、Http Client等重要更新，以及17个值得关注的JEP。 2、新增字符串处理方法Java 11新增了一系列字符串处理的方法： 方法 描述 boolean isBlank() 判断字符串是否为空白 String strip() 去除首尾空白 String stripTrailing() 去除尾部空格 String stripLeading() 去除首部空格 String repeat(int n) 复制字符串n次 Stream&lt;String&gt; lines() 统计行数 strip和trim的区别是：trim无法消除Unicode空白字符\\u2000，而strip可以。 3、Optional加强Optional增加了几个方法，Java 9-11新增的方法： 新增方法 描述 新增的版本 booleanisEmpty() 判断value是否为空 JDK 11 ifPresentOrElse(Consumer&lt;superT&gt; action, Runnable emptyAction) value非空，执行参数1功能；如果value为空，执行参数2功能 JDK 9 Optional&lt;T&gt; or (Supplier&lt;?extends Optional&lt;?extendsT&gt;&gt;supplier) value非空，返回对应的Optional；value为空，返回形参封装的Optional JDK 9 Stream&lt;T&gt;stream() value非空，返回仅包含此value的Stream；否则，返回一个空的Stream JDK 9 TorElseThrow() value非空，返回value；否则抛异常NoSuchElementException JDK 10 4、局部变量类型推断升级新增了在var上添加注解的语法格式： 12Consumer&lt;String&gt; con = (@Deprecated var t) -&gt; System.out.println(t.toUpperCase()); 5、全新的HTTP客户端APIJava9开始引入的处理HTTP请求的HTTPClient API，该API支持同步和异步，在Java11中已经为正式可用状态，可以在java.net包中找到这个API。 它将替代仅适用于blocking模式的HttpURLConnection（HttpURLConnection是在HTTP1.0的时代创建的，并使用了协议无关的方法），并提供对WebSocket和HTTP/2的支持。 代码实现： 12345678910111213141516171819202122232425262728293031323334353637public class Test{ //HttpClient替换原有的HttpURLConnection。 @Test public void test4(){ try { HttpClient client = HttpClient.newHttpClient(); HttpRequest request = HttpRequest.newBuilder( URI.create(\"http://127.0.0.1:8080/test/\")).build(); HttpResponse.BodyHandler&lt;String&gt; responseBodyHandler = HttpResponse.BodyHandlers.ofString(); HttpResponse&lt;String&gt; response = client.send( request, responseBodyHandler); String body = response.body(); System.out.println(body); } catch (IOException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } } @Test public void test5(){ HttpClient client = HttpClient.newHttpClient(); HttpRequest request = HttpRequest.newBuilder( URI.create(\"http://127.0.0.1:8080/test/\")).build(); HttpResponse.BodyHandler&lt;String&gt; responseBodyHandler = HttpResponse.BodyHandlers.ofString(); CompletableFuture&lt;HttpResponse&lt;String&gt;&gt; sendAsync = client.sendAsync(request, responseBodyHandler); sendAsync.thenApply(t -&gt; t.body()). thenAccept(System.out::println); //HttpResponse&lt;String&gt; response = sendAsync.get(); //String body = response.body(); //System.out.println(body); }} 6、更简化的编译运行程序传统的编译运行过程： ①编译：javac hello.java，生成字节码文件hello.class ②运行：java hello，运行字节码文件 Java 11中简化了编译运行过程，以上两步可以使用java hello.java一步代替。 使用简化命令的要求： 执行源文件的第一个类，第一个类必须包含主方法。 不可以使用其他源文件中的自定义类，可以使用本文件中的自定义类。 7、废弃Nashorn引擎Java 11废弃了Nashorn引擎，可以考虑使用GraalVM 8、ZGCGC是Java的主要优势之一。GC停顿太长，会影响应用的响应时间，消除或者减少GC停顿时长，java将对更广泛的应用场景是一个更有吸引力的平台。随着现代系统可用内存不断增长，用户希望JVM能够以高效的方式利用这些内存，并且无需长时间的GC暂停时间。 ZGC（A ScalableLow-Latency Garbage Collector(Experimental) ），是JDK11最为瞩目的特性。 ZGC是一个并发，基于region，压缩型的垃圾收集器，只有root扫描阶段会STW(stop the world)，因此GC停顿时间不会随着堆的增长和存活对象的增长而变长。 ZGC优势： GC暂停时间不会超过10ms。 既能处理几百兆的小堆,也能处理几个T的大堆(OMG)。 和G1相比,应用吞吐能力不会下降超过15%。 为未来的GC功能和利用colord指针以及Load barriers优化奠定基础。 初始只支持64位系统。 ZGC的设计目标是：支持TB级内存容量，暂停时间低（&lt;10ms），对整个程序吞吐量的影响小于15%。将来还可以扩展实现机制，以支持不少令人兴奋的功能，例如多层堆（即热对象置于DRAM和冷对象置于NVMe闪存），或压缩堆。 9、其他新特性Java 11的其他新特征： Unicode10 Deprecate the Pack200 Tools and API 新的Epsilon垃圾收集器 完全支持Linux容器（包括Docker） 支持G1上的并行完全垃圾收集 最新的HTTPS安全协议TLS1.3 Java Flight Recorder 四、总结展望1、标准化和轻量级的JSON API一个标准化和轻量级的JSON API被许多Java开发人员所青睐。但是由于资金问题无法在Java当前版本中见到，但并不会削减掉。Java平台首席架构师Mark Reinhold在JDK9邮件列中说：“这个JEP将是平台上的一个有用的补充，但是在计划中，它并不像Oracle资助的其他功能那么重要，可能会重新考虑JDK10或更高版本中实现。” 2、新的货币API对许多应用而言货币价值都是一个关键的特性，但JDK对此却几乎没有任何支持。严格来讲，现有的java.util.Currency类只是代表了当前ISO4217货币的一个数据结构，但并没有关联的值或者自定义货币。 JDK对货币的运算及转换也没有内建的支持，更别说有一个能够代表货币值的标准类型了。 如果用Maven的话，可以做如下的添加，即可使用相关的API处理货币： 12345&lt;dependency&gt; &lt;groupId&gt;org.javamoney&lt;/groupId&gt; &lt;artifactId&gt;moneta&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt; 3、展望 随着云计算和AI等技术浪潮，当前的计算模式和场景正在发生翻天覆地的变化，不仅对Java的发展速度提出了更高要求，也深刻影响着Java技术的发展方向。传统的大型企业或互联网应用，正在被云端、容器化应用、模块化的微服务甚至是函数(FaaS，Function-as-a-Service)所替代。 Java虽然标榜面向对象编程，却毫不顾忌的加入面向接口编程思想，又扯出匿名对象之概念，每增加一个新的东西，对Java的根本所在的面向对象思想的一次冲击。反观Python，抓住面向对象的本质，又能在函数编程思想方面游刃有余。Java对标C/C++，以抛掉内存管理为卖点，却又陷入了JVM优化的噩梦。选择比努力更重要，选择Java的人更需要对它有更清晰的认识。 Java需要在新的计算场景下，改进开发效率。这话说的有点笼统，我谈一些自己的体会，Java代码虽然进行了一些类型推断等改进，更易用的集合API等，但仍然给开发者留下了过于刻板、形式主义的印象，这是一个长期的改进方向。 五、ReferenceJava笔记系列，参考自尚硅谷Java核心教程，衷心感谢。","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记16-Java8的其它新特征","slug":"java-note-1601","date":"2021-04-18T15:00:45.000Z","updated":"2022-05-22T13:30:54.796Z","comments":true,"path":"2021/04/18/java-note-1601/","link":"","permalink":"http://kangshitao.github.io/2021/04/18/java-note-1601/","excerpt":"Lambda表达式，函数式接口，方法引用和构造器引用，Stream API，Optional类","text":"Java 8 简介Java 8的特征： 速度更快 代码更少，因为新加入了Lambda表达式 强大的Stream API 便于并行 最大化减少空指针异常：Optional Nashorn引擎，允许在JVM上运行JS应用。 Java 8主要更新内容参考官方说明 What’s New in JDK 8 新特性总结： 并行流与串行流并行流就是把一个内容分成多个数据块，并用不同的线程分别处理每个数据块的流。相比较串行的流，并行的流可以很大程度上提高程序的执行效率。 Java 8中将并行进行了优化，可以很容易的对数据进行并行操作。Stream API可以使用parallel()与sequential()方法在并行流与顺序流之间进行切换。 一、Lambda表达式Lambda表达式是JDK 8中新的语法，操作符为-&gt;，一个Lambda表达式由3部分构成： 左侧-&gt;右侧 其中操作符左侧指定Lambda表达式需要的参数列表，右侧指定了Lambda体，是抽象方法的实现逻辑，即Lambda表达式要执行的功能。 Lambda表达式的本质是函数式接口的实例，其作为接口的实例出现。 具体使用方式： 1234567891011121314151617181920//情况1:无参，无返回值Runnable r = ()-&gt;{System.out.println(\"hello\");};//情况2，一个参数，无返回值Consumer&lt;String&gt; con = (String str) -&gt;{System.out.println(str);};//情况3，数据类型可以省略，编译器可以推断，即类型推断Consumer&lt;String&gt; con = (str) -&gt;{System.out.println(str);};//情况4，如果只有一个参数，参数的小括号可以省略Consumer&lt;String&gt; con = str -&gt;{System.out.println(str);};//情况5，可以有两个及以上的参数，多条执行语句，有返回值Comparator&lt;Integer&gt; com = (x,y)-&gt;{ System.out.println(\"hello\"); return Integer.compare(x,y);};//情况6，只有一条语句时，{}和return可以省略Comparator&lt;Integer&gt; com = (x,y)-&gt;Integer.compare(x,y); 总结： 左边：lambda形参列表的参数类型可以省略(类型推断)；如果lambda形参列表只有一个参数，其一对()也可以省略。 右边：lambda体应该使用一对{}包裹；如果lambda体只有一条执行语句（可能是return语句），省略{}和return。如果有返回值，则return和{}必须都有。因此{}和return要么都有，要么都没有。 二、函数式(Functional)接口函数式接口指的是只包含一个抽象方法的接口。可以用注解@FunctionalInterface检查。 可以通过Lambda表达式创建函数式接口的对象，执行体就是实现抽象方法的代码。如果Lambda表达式抛出非运行时异常，该异常需要在目标接口的抽象方法上声明。 Lambda表达式是一个函数式接口的实例，只要一个对象是函数式接口的实例对象，就可以用Lambda表达式来表达。所以说实现函数式接口的匿名实现类的表示方式都可以改成Lambda表达式的形式。 java.util.function包下定义了Java8的丰富的函数式接口，其中有四种核心的函数式接口： 函数式接口 参数类型 返回类型 用途 消费型接口Consumer&lt;T&gt; T void 对类型为T的对象应用操作，包含方法void accept(T t)，相当于消费者 供给型接口Supplier&lt;T&gt; 无 T 返回类型为T的对象，包含方法：T get()，相当于供给者，用户获取对象 函数型接口Function&lt;T, R&gt; T R 对类型为T的对象应用操作，并返回结果是R类型的对象。包含方法：R apply(T t)，用于类型转换 断定型接口Predicate&lt;T&gt; T boolean 确定类型为T的对象是否满足某约束，并返回boolean值。包含方法：boolean test(T t)，用于判断 其他函数式接口： 函数式接口 参数类型 返回类型 用途 BiFunction&lt;T,U,R&gt; T, U R 对类型为T,U参数应用操作，返回R类型的结果。包含方法为：R apply(T t, U u); UnaryOperator&lt;T&gt;(Function子接口) T T 对类型为T的对象进行一元运算，并返回T类型的结果。包含方法为：T apply(T t); BinaryOperator&lt;T&gt;(BiFunction子接口) T,T T 对类型为T的对象进行二元运算，并返回T类型的结果。包含方法为：T apply(Tt 1,Tt 2); BiConsumer&lt;T,U&gt; T, U void 对类型为T,U参数应用操作。包含方法为：void accept(T t,U u); BiPredicate&lt;T,U&gt; T, U boolean 包含方法为：boolean test(T t,U u); ToIntFunction&lt;T&gt;ToLongFunction&lt;T&gt;ToDoubleFunction&lt;T&gt; T intlongdouble 分别计算int、long、double值的函数 IntFunction&lt;R&gt;LongFunction&lt;R&gt;DoubleFunction&lt;R&gt; intlongdouble R 参数分别为int、long、double类型的函数 使用实例： 12345678910111213141516171819public class LambdaTest { @Test public void test1(){ //方法一，使用匿名实现类，重写accept方法。 happyTime(500, new Consumer&lt;Double&gt;() { @Override public void accept(Double m) { System.out.println(\"价格为：\" + m); } }); System.out.println(\"********************\"); //方法二，使用Lambda表达式，执行体就是相当于重写accept方法。 happyTime(400,money -&gt; System.out.println(\"价格为：\" + money)); } //happyTime方法第二个参数是消费型接口类型的实例 public void happyTime(double money, Consumer&lt;Double&gt; con){ con.accept(money); }} 三、方法引用与构造器引用1、方法引用当要传给Lambda体的操作，已经有实现的方法了，可以使用方法引用。 方法引用，本质上是Lambda表达式，可以认为是Lambda表达式的一个语法糖。所以方法引用也是函数式接口的实例。方法引用的操作符为:: 方法引用有三种方式： 对象::实例方法名 类::静态方法名 类::实例方法名 对于前两种方式，要求接口中的抽象方法的形参列表和返回值类型必须和方法引用的方法的形参列表和返回值类型相同。 使用举例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113/*自定义Employee类。包含空参构造器和带参构造器。其中getName()方法定义如下public String getName() {return name;}*/public class MethodRefTest { // 情况一：对象 :: 实例方法 /*例1： Consumer中的void accept(T t) PrintStream中的void println(T t)，二者都是返回某个类型的对象。 */ @Test public void test1() { //Lambda表达式写法 Consumer&lt;String&gt; con1 = str -&gt; System.out.println(str); con1.accept(\"北京\"); //方法引用写法 PrintStream ps = System.out; Consumer&lt;String&gt; con2 = ps::println; //Consumer&lt;String&gt; con2 = System.out::println; //和上面相同 con2.accept(\"beijing\"); } /* 例2， Supplier中的T get() Employee类中的String getName()，二者都是返回某个类型的对象。 */ @Test public void test2() { Employee emp = new Employee(1001,\"Tom\",23,5600); //Lambda表达式写法 Supplier&lt;String&gt; sup1 = () -&gt; emp.getName(); System.out.println(sup1.get()); //方法引用写法 Supplier&lt;String&gt; sup2 = emp::getName; System.out.println(sup2.get()); } // 情况二：类 :: 静态方法 /*例1： Comparator中的int compare(T t1,T t2) Integer中的int compare(T t1,T t2)，二者实现方法相同 */ @Test public void test3() { //Lambda表达式写法 Comparator&lt;Integer&gt; com1 = (t1,t2) -&gt; Integer.compare(t1,t2); System.out.println(com1.compare(12,21)); //方法引用写法 Comparator&lt;Integer&gt; com2 = Integer::compare; System.out.println(com2.compare(12,3)); } /*例2： Function中的R apply(T t) Math中的Long round(Double d) */ @Test public void test4() { //匿名实现类写法 Function&lt;Double,Long&gt; func = new Function&lt;Double, Long&gt;() { @Override public Long apply(Double d) {return Math.round(d);} }; //Lambda表达式写法 Function&lt;Double,Long&gt; func1 = d -&gt; Math.round(d); System.out.println(func1.apply(12.3)); //方法引用写法 Function&lt;Double,Long&gt; func2 = Math::round; System.out.println(func2.apply(12.6)); } // 情况三：类 :: 实例方法 /*例1： Comparator中的int comapre(T t1,T t2) String中的int t1.compareTo(t2) */ @Test public void test5() { //Lambda表达式写法 Comparator&lt;String&gt; com1 = (s1,s2) -&gt; s1.compareTo(s2); System.out.println(com1.compare(\"abc\",\"abd\")); //方法引用写法 Comparator&lt;String&gt; com2 = String :: compareTo; System.out.println(com2.compare(\"abd\",\"abm\")); } /*例2： BiPredicate中的boolean test(T t1, T t2); String中的boolean t1.equals(t2) */ @Test public void test6() { //Lambda表达式写法 BiPredicate&lt;String,String&gt; pre1 = (s1,s2) -&gt; s1.equals(s2); System.out.println(pre1.test(\"abc\",\"abc\")); //方法引用写法 BiPredicate&lt;String,String&gt; pre2 = String :: equals; System.out.println(pre2.test(\"abc\",\"abd\")); } /*例3： Function中的R apply(T t) Employee中的String getName(); */ @Test public void test7() { Employee employee = new Employee(1001, \"Jerry\", 23, 6000); //Lambda表达式写法 Function&lt;Employee,String&gt; func1 = e -&gt; e.getName(); System.out.println(func1.apply(employee)); //方法引用写法 Function&lt;Employee,String&gt; func2 = Employee::getName; System.out.println(func2.apply(employee)); }} 2、构造器引用格式：ClassName::new 和方法引用类似，要求函数式接口的抽象方法的形参列表和构造器的形参列表一致。 抽象方法的返回值类型即为构造器所属的类的类型。 代码实现： 1234567891011121314151617181920212223242526272829303132333435public class ConstructorRefTest { //构造器引用 /*例1： Supplier中的T get() Employee的空参构造器：Employee() */ @Test public void test1(){ //匿名实现类写法 Supplier&lt;Employee&gt; sup = new Supplier&lt;Employee&gt;() { @Override public Employee get() {return new Employee();} }; //Lambda表达式写法 Supplier&lt;Employee&gt; sup1 = () -&gt; new Employee(); System.out.println(sup1.get()); //构造器引用写法 Supplier&lt;Employee&gt; sup2 = Employee :: new; System.out.println(sup2.get()); } /*例2： BiFunction中的R apply(T t,U u) Employee的带参构造器：Employee(int id, String name) */ @Test public void test3(){ //Lambda表达式写法 BiFunction&lt;Integer,String,Employee&gt; func1 = (id,name) -&gt; new Employee(id,name); System.out.println(func1.apply(1001,\"Tom\")); //构造器引用写法 BiFunction&lt;Integer,String,Employee&gt; func2 = Employee :: new; System.out.println(func2.apply(1002,\"Tom\")); }} 3、数组引用格式：type[]::new，其中type表示数组类型。 可以将数组看成一个特殊的类，写法与构造器引用一致。 代码实现： 123456789101112131415public class ArrayRefTest { //数组引用 //Function中的R apply(T t) @Test public void test4(){ //Lambda表达式写法 Function&lt;Integer,String[]&gt; func1 = length -&gt; new String[length]; String[] arr1 = func1.apply(5); System.out.println(Arrays.toString(arr1)); //数组引用写法 Function&lt;Integer,String[]&gt; func2 = String[] :: new; String[] arr2 = func2.apply(10); System.out.println(Arrays.toString(arr2)); }} 四、强大的Stream API1、Stream简介Stream API ( java.util.stream)把真正的函数式编程风格引入到Java中。这是目前为止对Java类库最好的补充，Stream API可以极大提高Java程序员的生产力。 Stream是数据渠道，用于操作数据源(集合、数组等)所生成的元素序列。 Stream API可以对集合进行操作，可以执行非常复杂的查找、过滤和映射数据等操作，类似于使用SQL执行的数据库查询。也可以使用Stream API来并行执行操作。简言之，Stream API提供了一种高效且易于使用的处理数据的方式。 Stream和Collection集合的区别： Collection是一种静态的内存数据结构。主要面向内存，存储在内存中。 Stream是有关计算的。主要是面向CPU，通过CPU实现计算。 Stream的特点： Stream 自己不会存储元素。 Stream 不会改变源对象，会返回一个持有结果的新Stream，类似于视图(Collections工具类会对集合本身进行修改，比如排序操作)。 Stream 操作是延迟执行的，即会等到需要结果的时候才执行，执行终止操作的时候才执行中间操作。 2、使用Stream想要使用Stream，需要执行以下三个步骤： 实例化Stream类(java.util.stream.Stream)，得到Stream类对象stream。 中间操作。中间操作链，对数据源的数据进行处理，比如排序，筛选，映射等。 终止操作。执行终止操作时才会执行中间操作，并产生结果。终止操作后，stream不能再被使用。 3、Stream实例化Stream类有四种实例化方法： 通过集合。Java 8的Collection接口被扩展，提供了两个获取Stream实例的方法： default Stream&lt;E&gt; stream()：返回一个顺序流 default Stream&lt;E&gt; parallelStream():返回一个并行流 通过数组。Arrays工具类提供了stream()方法，用于获取数组流，对于不同的数据类型，提供了其重载方法，返回的类型也不同： public static &lt;T&gt; Stream&lt;T&gt; stream(T[] array)：返回Stream实例。 public static IntStream stream(int[] array)：对于int型数组，返回IntStream实例。 public static LongStream stream(long[] array)：对于long型数组，返回LongStream实例。 public static DoubleStream stream(double[] array)：对于double型数组，返回DoubleStream实例。 通过Stream类的of()方法。 public static&lt;T&gt; Stream&lt;T&gt; of(T...values)：参数可以是单个数据，或者多个数据。如果直接将数组或者是集合作为参数，默认当作一个参数。参数不能为单个null，但是可以是多个null 通过Stream类静态方法创建无限流。创建无限流有两种方式： public static&lt;T&gt; Stream&lt;T&gt; iterate(final T seed, final UnaryOperator&lt;T&gt; f)：迭代 public static&lt;T&gt; Stream&lt;T&gt; generate(Supplier&lt;T&gt; s)：生成 代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class StreamAPITest { //创建 Stream方式一：通过集合 @Test public void test1(){ List&lt;Employee&gt; employees = EmployeeData.getEmployees(); //返回一个顺序流 Stream&lt;Employee&gt; stream = employees.stream(); //返回一个并行流 Stream&lt;Employee&gt; parallelStream = employees.parallelStream(); } //创建 Stream方式二：通过数组 @Test public void test2(){ //对于int、long、double类型数组，返回特定的stream int[] arr = new int[]{1,2,3,4,5,6}; IntStream stream = Arrays.stream(arr); //传入对象数组 Employee e1 = new Employee(1001,\"Tom\"); Employee e2 = new Employee(1002,\"Jerry\"); Employee[] arr1 = new Employee[]{e1,e2}; Stream&lt;Employee&gt; stream1 = Arrays.stream(arr1); } //创建 Stream方式三：通过Stream的of() @Test public void test3(){ //注意传入的参数个数 List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); Stream&lt;List&lt;Integer&gt;&gt; list1 = Stream.of(list); Stream&lt;Object&gt; objectStream = Stream.of(list.toArray()); //直接传入集合或数组，当成一个参数 int[] array = new int[3]; Stream&lt;int[]&gt; array1 = Stream.of(array); Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3, 4, 5, 6); } //方式四：创建无限流 @Test public void test4(){ //迭代 //遍历前10个偶数 Stream.iterate(0, t -&gt; t + 2).limit(10).forEach(System.out::println); //生成 Stream.generate(Math::random).limit(10).forEach(System.out::println); }} 4、Stream中间操作有了Stream类的对象以后，可以执行中间操作。中间操作可以链式操作，只有遇到终止操作的时候，中间操作才会一次性执行，称为“惰性求值”。 中间操作分成以下3种： ①筛选与切片 方法 描述 filter(Predicate p) 接收Lambda表达式，从流中排除某些元素 distinct() 筛选，通过流所生成元素的hashCode()和equals()去除重复元素 limit(long maxSize) 截断流，使其元素不超过给定数量 skip(long n) 跳过元素，返回一个跳过前n个元素的流。若流中元素不足n个，则返回一个空流。与limit(n)操作互补 ②映射 方法 描述 map(Functionf) 接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素。 mapToDouble(ToDoubleFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的DoubleStream。 mapToInt(ToIntFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的IntStream。 mapToLong(ToLongFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的LongStream。 flatMap(Function f) 接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流 ③排序 方法 描述 sorted() 产生一个新流，按自然顺序排序 sorted(Comparator com) 产生一个新流，按比较器顺序排序 5、Stream终止操作终止操作会从流的流水线生成结果。其结果可以是任何不是流的值，例如：List、Integer，甚至是void。 流进行了终止操作后，不能再次被使用。 终止操作有以下几种： 方法 描述 count() 返回流中元素总数 max(Comparator c) 返流中最大值 min(Comparator) 返回流中最小值 forEach(Consumer c) 内部迭代(使用Collection接口需要用户去做迭代，称为外部迭代) reduce(T iden,BinaryOperator b)， 规约 可以将流中元素反复结合起来，得到一个值。返回T reduce(BinaryOperator b)， 规约 可以将流中元素反复结合起来，得到一个值。返回Optional collect(Collector c)，收集 将流转换为其他形式。接收一个Collector接口的实现，用于给Stream中元素做汇总的方法 map和reduce的连接通常称为map-reduce模式。 Collector接口（收集器）中方法的实现决定了如何对流执行收集的操作(如收集到List、Set、Map)。另外，Collectors类提供了很多静态方法，可以方便地创建Collector实例，具体方法如下表： 方法 返回类型 作用 toList List&lt;T&gt; 把流中元素收集到List toSet Set&lt;T&gt; 把流中元素收集到Set toCollection Collection&lt;T&gt; 把流中元素收集到创建的集合 counting Long 计算流中元素的个数 summingInt Integer 对流中元素的整数属性求和 averagingInt Double 计算流中元素Integer属性的平均值 summarizingInt IntSummaryStatistics 收集流中Integer属性的统计值。如：平均值 joining String 连接流中每个字符串 maxBy Optional&lt;T&gt; 根据比较器选择最大值 minBy Optional&lt;T&gt; 根据比较器选择最小值 reducing 归约产生的类型 从一个作为累加器的初始值开始，利用BinaryOperator与流中元素逐个结合，从而归约成单个值 collectingAndThen 转换函数返回的类型 包裹另一个收集器，对其结果转换函数 groupingBy Map&lt;K, List&lt;T&gt;&gt; 根据某属性值对流分组，属性为K结果为V partitioningBy Map&lt;Boolean,List&lt;T&gt;&gt; 根据true或false进行分区 代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104/*Employee的带参构造器声明：public Employee(int id, String name, int age, double salary)*/class EmployeeData { public static List&lt;Employee&gt; getEmployees(){ List&lt;Employee&gt; list = new ArrayList&lt;&gt;(); list.add(new Employee(1001, \"马化腾\", 34, 6000.38)); list.add(new Employee(1002, \"马云\", 12, 9876.12)); list.add(new Employee(1003, \"刘强东\", 33, 3000.82)); list.add(new Employee(1004, \"雷军\", 26, 7657.37)); list.add(new Employee(1005, \"李彦宏\", 65, 5555.32)); list.add(new Employee(1006, \"比尔盖茨\", 42, 9500.43)); list.add(new Employee(1007, \"任正非\", 26, 4333.32)); list.add(new Employee(1008, \"扎克伯格\", 35, 2500.32)); return list; }}public class StreamAPITest2 { //1-匹配与查找 @Test public void test1(){ List&lt;Employee&gt; employees = EmployeeData.getEmployees(); //练习：判断是否所有的员工的年龄都大于18 boolean allMatch = employees.stream().allMatch(e -&gt; e.getAge() &gt; 18); System.out.println(allMatch); //练习：判断是否存在员工姓“雷” boolean noneMatch = employees.stream(). noneMatch(e -&gt; e.getName().startsWith(\"雷\")); System.out.println(noneMatch); //返回第一个元素 Optional&lt;Employee&gt; employee = employees.stream().findFirst(); System.out.println(employee); //返回当前流中的任意元素 Optional&lt;Employee&gt; employee1 = employees.parallelStream().findAny(); System.out.println(employee1); } @Test public void test2(){ List&lt;Employee&gt; employees = EmployeeData.getEmployees(); // 返回流中元素的总个数 long count = employees.stream().f ilter(e -&gt; e.getSalary() &gt; 5000). count(); System.out.println(count); //返回流中最大值 //练习：返回最高的工资 Stream&lt;Double&gt; salaryStream = employees.stream().map(e -&gt; e.getSalary()); Optional&lt;Double&gt; maxSalary = salaryStream.max(Double::compare); System.out.println(maxSalary); //返回流中最小值 //练习：返回最低工资的员工 Optional&lt;Employee&gt; employee = employees.stream(). min((e1, e2) -&gt; Double.compare(e1.getSalary(), e2.getSalary())); System.out.println(employee); //内部迭代 employees.stream().forEach(System.out::println); //使用集合的遍历操作 employees.forEach(System.out::println); } //2-归约 @Test public void test3(){ //练习1：计算1-10的自然数的和 List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7,8,9,10); Integer sum = list.stream().reduce(0, Integer::sum); System.out.println(sum); //练习2：计算公司所有员工工资的总和 List&lt;Employee&gt; employees = EmployeeData.getEmployees(); Stream&lt;Double&gt; salaryStream = employees.stream().map(Employee::getSalary); Optional&lt;Double&gt; sumMoney = salaryStream.reduce((d1,d2) -&gt; d1 + d2); System.out.println(sumMoney.get()); } //3-收集 @Test public void test4(){ //练习1：查找工资大于6000的员工，结果返回为一个List或Set List&lt;Employee&gt; employees = EmployeeData.getEmployees(); //返回List List&lt;Employee&gt; employeeList = employees.stream(). filter(e -&gt; e.getSalary() &gt; 6000). collect(Collectors.toList()); employeeList.forEach(System.out::println); //返回Set Set&lt;Employee&gt; employeeSet = employees.stream(). filter(e -&gt; e.getSalary() &gt; 6000). collect(Collectors.toSet()); employeeSet.forEach(System.out::println); }} 五、Optional类Optional&lt;T&gt;类(java.util.Optional)是一个容器类，它可以保存类型T的值，代表这个值存在。或者仅仅保存null，表示这个值不存在。是为了避免出现空指针异常而创建的。 Optional容器类，存放的是对象 原来用null表示一个值不存在，现在Optional可以更好的表达这个概念。并且可以避免空指针异常。 Optional类提供了如下方法，利用这些方法，可以不用显式进行空值检测：创建Optional类对象的方法： Optional.of(T t)：创建一个Optional实例，t必须非空； Optional.empty()：创建一个空的Optional实例 Optional.ofNullable(T t)：t可以为null 判断Optional容器中是否包含对象： boolean isPresent()：判断是否包含对象 void ifPresent(Consumer&lt;? super T&gt; consumer)：如果有值，就执行Consumer接口的实现代码，并且该值会作为参数传给它。 获取Optional容器的对象： T get():如果调用对象包含值，返回该值，否则抛异常 T orElse(T other)：如果有值则将其返回，否则返回指定的other对象。 T orElseGet(Supplier&lt;? extends T&gt; other)：如果有值则将其返回，否则返回由Supplier接口实现类提供的对象。 T orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier)：如果有值则将其返回，否则抛出由Supplier接口实现类提供的异常。 应用举例： 1234567891011121314151617class Girl{ private String name; public Girl() {} public Girl(String name) {this.name = name;}}public class OptionalTest{ public static void main(String[] args) { Girl girl = new Girl(\"Jack\"); //如果值为空，则返回指定的对象 //值非空，返回非空值： Girl{name='Jack'} System.out.println(Optional.ofNullable(girl). orElse(new Girl(\"Jessica\"))); //值为空，返回指定值：Girl{name='Tom'} System.out.println(Optional.ofNullable(null). orElse(new Girl(\"Tom\"))); }}","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记15-反射","slug":"java-note-1501","date":"2021-04-18T10:22:07.000Z","updated":"2022-05-22T13:30:54.795Z","comments":true,"path":"2021/04/18/java-note-1501/","link":"","permalink":"http://kangshitao.github.io/2021/04/18/java-note-1501/","excerpt":"反射机制，Class类，运行时类，类的加载，利用反射机制获取运行时类的结构，动态代理","text":"一、Java反射机制概述Reflection(反射)是被视为动态语言的关键，反射机制允许程序在执行期间借助于Reflection API取得任何类的内部信息，并能直接操作任意对象的内部属性及方法。 类加载完之后，在堆内存的方法区中产生了一个Class类型的对象（一个类只有一个Class对象），这个对象包含了完整的类的结构信息。可以通过这个对象看到类的结构。 反射就是通过实例化对象反向得到其所属类的全部信息：实例化对象—&gt;getClass()方法—&gt;得到完整的“包类”名称。 动态语言与静态语言 动态语言是运行时可以改变结构的语言，例如新的函数、对象等，主要有：C#、JavaScript、PHP、Python、Erlang等。 静态语言是运行时结构不可变的语言，比如Java、C、C++ Java虽然不是动态语言，但是可以使用反射机制、字节码操作获得类似动态语言的特性。 二、理解Class类并获取Class实例1、Class类在Object类中定义了如下方法，此方法被所有子类继承： public final Class getClass() 返回值是Class类型，Class类是用来描述类的类，此类是Java反射的源头，也就是说可以通过反射求出类的名称。 程序经过javac.exe命令以后，会生成一个或多个字节码文件(.class结尾)。使用java.exe命令对某个字节码文件进行解释运行。相当于将某个字节码文件加载到内存中。此过程就称为类的加载。加载到内存中的类，称为运行时类，此运行时类，就作为Class的一个实例。 加载到内存中的运行时类，会缓存一定的时间。在此时间之内，可以通过不同的方式来获取此运行时类。 对于每个类而言，JRE都为其保留一个不变的Class类型的对象。一个Class对象包含了特定某个结构(class/interface/enum/annotation/primitive type/void/[])的有关信息。 Class本身也是一个类。 Class对象只能由系统建立对象。 一个加载的类在JVM中只会有一个Class实例，Class的实例就对应着一个运行时类。 一个Class对象对应的是一个加载到JVM中的一个.class文件。 每个类的实例都会记得自己是由哪个Class实例所生成。 通过Class可以完整地得到一个类中的所有被加载的结构。 Class类是Reflection的根源，任何想动态加载、运行的类，必须先获得相应的Class对象。 2、获取Class类实例Class对象只能由系统创建，我们四种方式获取此实例，以String类为例： 通过类的class属性获取，前提是已知具体的类。此方法最安全可靠，程序性能最高： Class clazz = String.class; 调用实例的getClass()方法，前提是已知当前类的实例： Class clazz = \"hello\".getClass(); 使用Class类的静态方法forName()获取，前提是已知一个类的全类名。可能抛出ClassNotFoundException异常： Class clazz = Class.forName(\"java.lang.String\"); 其他方式： ClassLoader cl = this.getClass().getClassLoader(); Class clazz = cl.loadClass(\"java.lang.String\"); 哪些类可以有Class对象？ class：类，外部类，成员类（成员内部类、静态内部类），局部内部类，匿名内部类。 interface：接口 []：数组 enum：枚举类 annotation：注解@interface primitive type：基本数据类型 void 三、类的加载与ClassLoader的理解1、类的加载过程程序使用某个类时，如果该类没有加载到内存中，会通过以下三个主要步骤对类初始化： 加载：将class文件字节码内容加载到内存中，并将这些静态数据转换成方法区的运行时数据结构，然后生成一个代表这个类的java.lang.Class对象，作为方法区中类数据的访问入口（即引用地址）。所有需要访问和使用类数据只能通过这个Class对象。这个加载的过程需要类加载器参与。 链接：将Java类的二进制代码合并到JVM的运行状态之中的过程。包括三个阶段： 验证：确保加载的类信息符合JVM规范，例如：以cafe开头，没有安全方面的问题 准备：正式为类变量（static）分配内存并设置类变量默认初始值的阶段，这些内存都将在方法区中进行分配。 解析：虚拟机常量池内的符号引用（常量名）替换为直接引用（地址）的过程。 初始化：执行行类构造器&lt;clinit&gt;()方法的过程。类构造器&lt;clinit&gt;()方法是由编译期自动收集类中所有类变量的赋值动作和静态代码块中的语句合并产生的（类构造器是构造类信息的，不是构造该类对象的构造器）。当初始化一个类的时候，如果发现其父类还没有进行初始化，则需要先触发其父类的初始化。虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确加锁和同步。 什么时候会发生类初始化? 详细可参考《深入理解Java虚拟机 第3版》第7章 虚拟机类加载机制。 类的主动引用（一定会发生类的初始化）: 当虚拟机启动，先初始化main方法所在的类 new一个类的对象 调用类的静态成员（除了final常量）和静态方法 使用java.lang.reflect包的方法对类进行反射调用 当初始化一个类，如果其父类没有被初始化，则先会初始化它的父类 类的被动引用（不会发生类的初始化）： 当访问一个静态域时，只有真正声明这个域的类才会被初始化 当通过子类引用父类的静态变量，不会导致子类初始化 通过数组定义某个类的引用，不会触发此类的初始化 引用常量不会触发此类的初始化（常量在链接阶段就存入调用类的常量池中了） 2、类加载器类加载器的作用：在加载阶段，类加载器将class文件字节码内容加载到内存中，并将这些静态数据转换成方法区的运行时数据结构然后在堆中生成一个代表这个类的java.lang.Class对象，作为方法区中类数据的访问入口。类缓存：标准的JavaSE类加载器可以按要求查找类，但一旦某个类被加载到类加载器中，它将维持加载（缓存）一段时间。不过JVM垃圾回收机制可以回收这些Class对象。 JVM规范定义了如下类型的类加载器： 引导类加载器用来装载核心类库，无法直接获取。 代码实现： 123456789101112131415161718192021public class ClassLoaderTest { @Test public void test1(){ //对于自定义类，使用系统类加载器进行加载 ClassLoader classLoader = ClassLoaderTest.class.getClassLoader(); System.out.println(classLoader); //jdk.internal.loader.ClassLoaders$AppClassLoader@2f0e140b //调用系统类加载器的getParent()：获取扩展类加载器 ClassLoader classLoader1 = classLoader.getParent(); System.out.println(classLoader1); //jdk.internal.loader.ClassLoaders$PlatformClassLoader@2aaf7cc2 //调用扩展类加载器的getParent()：无法获取引导类加载器 //引导类加载器主要负责加载java的核心类库，无法加载自定义类。 ClassLoader classLoader2 = classLoader1.getParent(); System.out.println(classLoader2); //null ClassLoader classLoader3 = String.class.getClassLoader(); System.out.println(classLoader3); //null。核心类 }} 类加载器的getResourceAsStream(String str)方法可以用来获取类路径下指定文件的输入流，可以用来加载properties配置文件： 123456789101112131415161718192021public class ClassLoaderTest { @Test public void test2() throws Exception { Properties pros = new Properties(); //此时的文件默认在当前的module下。 //读取配置文件的方式一： //FileInputStream fis = new FileInputStream(\"jdbc.properties\"); //FileInputStream fis = new FileInputStream(\"src\\\\jdbc1.properties\"); //pros.load(fis); //读取配置文件的方式二：使用ClassLoader //配置文件默认识别为：当前module的src下 ClassLoader classLoader = ClassLoaderTest.class.getClassLoader(); InputStream is = classLoader.getResourceAsStream(\"jdbc1.properties\"); pros.load(is); String user = pros.getProperty(\"user\"); String password = pros.getProperty(\"password\"); System.out.println(\"user = \" + user + \",password = \" + password); }} 四、创建运行时类的对象获得了Class对象以后，可以创建运行时类的对象。 有两种方法创建运行时类对象： 调用Class对象的newInstance()方法。使用此方法有两个要求： 要求运行时类必须有一个无参数的构造器。 要求运行时类的构造器的访问权限需要足够，一般为public 调用Class对象的getDeclaredConstructor(Class&lt;?&gt;... parameterTypes)，参数就是运行时类对应构造器的参数，返回Constructor类对象，Constructor类中也有newInstance()方法，可以构造运行时类对象。这种方法不要求运行时类必须有无参构造器。 代码实例，通过反射，创建运行时类对象： 123456789101112131415161718192021222324252627282930313233public class NewInstanceTest { //反射的动态性 @Test public void test(){ for(int i = 0;i &lt; 10;i++){ int num = new Random().nextInt(2);//0,1 String classPath = \"\"; //只有在运行时才知道具体的类 switch(num){ case 0: classPath = \"java.util.Date\"; break; case 1: classPath = \"java.lang.Object\"; break; } try { Object obj = getInstance(classPath); System.out.println(obj); } catch (Exception e) {e.printStackTrace();} } } /* 创建一个指定类的对象。 classPath:指定类的全类名 */ public Object getInstance(String classPath) throws Exception { Class clazz = Class.forName(classPath); return clazz.newInstance();//方式一 //方式二 //return clazz.getDeclaredConstructor().newInstance(); }} 上述代码，体现了反射的动态性，运行时动态创建指定类的对象，这是反射机制应用最多的地方。 五、获取运行时类的完整结构通过反射不仅可以创建运行时类的对象，还可以获取运行时类的完整结构，包括以下所有结构，这些操作都是基于Class类，使用Class类对象调用Class类的相关方法： 运行时类实现的全部接口 所继承的父类 全部的构造器 全部的方法 全部的Field 1、获取运行时类实现的接口调用public Class&lt;?&gt;[]getInterfaces()方法获取运行时类实现的所有接口。 2、获取运行时类继承的父类调用public Class&lt;? Super T&gt;getSuperclass()返回此Class所表示的实体（类、接口、基本类型）的父类的Class。 3、获取运行时类的构造器获取运行时类的构造器： public Constructor&lt;T&gt;[] getConstructors()：返回此Class对象所表示的类的所有public构造方法。 public Constructor&lt;T&gt;[] getDeclaredConstructors()：返回此Class对象表示的类声明的所有构造方法。 返回的Constructor类，有以下方法： public int getModifiers()：取得修饰符: public StringgetName()：取得方法名称: public Class&lt;?&gt;[] getParameterTypes()：取得参数的类型 public T newInstance(Object ... initargs)：构建运行时类的实例 4、获取运行时类的方法获取运行时类的方法： public Method[] getDeclaredMethods()：返回此Class对象所表示的类或接口的全部方法 public Method[] getMethods()：返回此Class对象所表示的类或接口的public的方法 返回的Method类中有以下方法： public Class&lt;?&gt; getReturnType()：取得全部的返回值 public Class&lt;?&gt;[] getParameterTypes()：取得全部的参数 public int getModifiers()：取得修饰符 public Class&lt;?&gt;[] getExceptionTypes()：取得异常信息 5、获取运行时类的Field获取Field： public Field[] getFields()：返回此Class对象所表示的类或接口的public的Field。 public Field[] getDeclaredFields()：返回此Class对象所表示的类或接口的全部Field。 返回的Field类中有以下方法： public int getModifiers()：以整数形式返回此Field的修饰符 public Class&lt;?&gt; getType()：得到Field的属性类型 public String getName()：返回Field的名称。 6、获取运行时类其他结构获取注解相关内容 public &lt;A extends Annotation&gt; A getAnnotation(Class&lt;T&gt; annotationClass) public &lt;A extends Annotation&gt; A getDeclaredAnnotation(Class&lt;A&gt; annotationClass) 泛型相关 public Type getGenericSuperclass()：获取父类泛型类型 ParameterizedType：泛型类型，继承了Type接口。ParameterizedTypeImpl类实现了此接口。 getActualTypeArguments()：ParameterizedType中定义的Type[]类型数组，用于获取实际的泛型类型参数数组 类所在的包 public Package getPackage() 六、调用运行时类的指定结构使用反射获取不仅可以一次获取所有的结构，也可以获取指定的某个结构，然后调用此结构。 1、调用指定方法可以使用反射获取指定的方法，并调用此方法。步骤如下： getMethod(Stringname,Class…parameterTypes)方法取得指定的Method对象，并设置此方法操作时所需要的参数类型。 使用Object invoke(Objectobj, Object[]args)进行调用，并向方法中传递要设置的obj对象的参数信息。 invoke方法的说明： Object对应原方法的返回值，若原方法无返回值，此时返回null 若原方法若为静态方法，此时形参Object obj可为null 若原方法形参列表为空，则Object[] args为null 若原方法声明为private,则需要在调用此invoke()方法前，显式调用方法对象的setAccessible(true)方法，设置可见性，然后即可访问private的方法。 代码实例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class ReflectionTest{ /* Person类中有非静态方法show，和静态方法showDesc() private static void showDesc() */ public void testMethod() throws Exception { Class clazz = Person.class; //创建运行时类的对象 Person p = (Person) clazz.newInstance(); /* 1.获取指定的某个方法 getDeclaredMethod(): 参数1：指明获取的方法的名称 参数2：指明获取的方法的形参列表 */ //获取Person类中的show方法 Method show = clazz.getDeclaredMethod(\"show\", String.class); //2.保证当前方法是可访问的 show.setAccessible(true); /* 3. 调用方法的invoke()方法: 参数1：方法的调用者，指明是哪个对象的方法 参数2：给方法形参赋值的实参 invoke()的返回值即为对应类中调用的方法的返回值。 */ //类似于String nation = p.show(\"CHN\"); Object returnValue = show.invoke(p,\"CHN\"); System.out.println(returnValue); /* 调用静态方法 */ //调用showDesc方法 Method showDesc = clazz.getDeclaredMethod(\"showDesc\"); showDesc.setAccessible(true); //如果调用的运行时类中的方法没有返回值，则此invoke()返回null Object returnVal = showDesc.invoke(Person.class); //这两种写法都可以，参数为空即可，不需要指明对象， //因为静态方法不需要通过对象调用，类中的静态方法是已知的。 //Object returnVal2 = showDesc.invoke(clazz); //Object returnVal3 = showDesc.invoke(null); System.out.println(returnVal);//null }} 2、调用指定属性同样，反射机制可以调用指定的某个属性，并且可以直接通过Field类操作类中的属性，通过Field类提供的set()和get()方法就可以完成设置和取得属性内容的操作。 获取指定属性 ： public Field getField(String name)：返回此Class对象表示的类或接口的指定的public的Field。 public Field getDeclaredField(String name)：返回此Class对象表示的类或接口的指定的Field。 Field中的方法： public Object get(Object obj)：取得指定对象obj上此Field的属性内容 public void set(Object obj,Object value)：设置指定对象obj上此Field的属性内容 代码实例： 12345678910111213141516public class ReflectionTes{ @Test public void testField1() throws Exception { //创建Class类实例 Class clazz = Person.class; //创建运行时类的对象 Person p = (Person) clazz.newInstance(); //1. 获取运行时类中指定变量名的属性，获取Person中的name属性 Field name = clazz.getDeclaredField(\"name\"); //2.保证当前属性是可访问的 name.setAccessible(true); //3.获取、设置对象p的name属性值为“Tom” name.set(p,\"Tom\"); System.out.println(name.get(p)); // Tom }} 3、调用指定构造器通过反射获取指定的构造器，也可以创建运行时类的对象。 获取指定构造器： public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes)：获取public的参数类型为指定类型的构造器。 public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes)：获取运行时类声明的参数类型为指定参数的构造器， 代码实例： 123456789101112131415161718public class ReflectionTest{ //Person类中有以下构造器 //private Person(String name) @Test public void testConstructor() throws Exception { Class clazz = Person.class; /* 1.获取指定的构造器 getDeclaredConstructor():参数：指明构造器的参数列表 */ Constructor constructor = clazz.getDeclaredConstructor(String.class); //2.保证此构造器是可访问的 constructor.setAccessible(true); //3.调用此构造器创建运行时类的对象 Person per = (Person) constructor.newInstance(\"Tom\"); System.out.println(per); }} 关于setAccessible方法的说明 Method和Field、Constructor对象都有setAccessible()方法。 setAccessible用于启动和禁用访问安全检查的开关： 参数值为true指示反射的对象在使用时应该取消Java语言访问检查。有以下作用： 提高反射的效率。如果代码中必须用反射，而该句代码需要频繁的被调用，需要设置为true。 使得原本无法访问的私有成员也可以访问。 参数值为false指示反射的对象应该实施Java语言访问检查。 七、反射的应用：动态代理1、动态代理概述代理模式：使用一个代理将对象包装起来,然后用该代理对象取代原始对象。任何对原始对象的调用都要通过代理。代理对象决定是否以及何时将方法调用转到原始对象上。代理类和被代理类要实现同一个接口。 静态代理：代理类和目标对象的类都是在编译期间确定下来，不利于程序的扩展。每一个代理类只能为一个接口服务，这样程序开发中必然产生过多的代理。 动态代理：通过一个代理类完成全部的代理功能。在程序运行时根据需要动态创建目标类的代理对象。 动态代理使用场合： 调试 远程方法调用 动态代理相比于静态代理的优点：抽象角色中（接口）声明的所有方法都被转移到调用处理器一个集中的方法中处理，这样，可以更加灵活和统一的处理众多的方法。 一种静态代理实现举例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.atguigu.java;/*静态代理举例特点：代理类和被代理类在编译期间，就确定了。 *///共同接口interface ClothFactory{ void produceCloth();}//代理类class ProxyClothFactory implements ClothFactory{ private ClothFactory factory;//用被代理类对象进行实例化 public ProxyClothFactory(ClothFactory factory){ this.factory = factory; } @Override public void produceCloth() { System.out.println(\"代理工厂做一些准备工作\"); factory.produceCloth(); System.out.println(\"代理工厂做一些后续的收尾工作\"); }}//被代理类class NikeClothFactory implements ClothFactory{ @Override public void produceCloth() { System.out.println(\"Nike工厂生产一批运动服\"); }}public class StaticProxyTest { public static void main(String[] args) { //创建被代理类的对象 ClothFactory nike = new NikeClothFactory(); //创建代理类的对象 ClothFactory proxyClothFactory = new ProxyClothFactory(nike); //调用代理类的方法 proxyClothFactory.produceCloth(); }}/*输出结果代理工厂做一些准备工作Nike工厂生产一批运动服代理工厂做一些后续的收尾工作*/ 2、动态代理实现Java中提供了Proxy类，专门用于完成代理操作。其是所有动态代理类的父类。通过此类为一个或多个接口动态地生成实现类。 Proxy类提供用于创建动态代理类和动态代理对象的静态方法: static Class&lt;?&gt; getProxyClass(ClassLoader loader, Class&lt;?&gt;...interfaces)：创建一个动态代理类所对应的Class对象 static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces InvocationHandler h)：直接创建一个动态代理对象。第一个参数是类加载器，第二个参数是被代理类实现的全部接口，第三个参数是InvocationHandler接口的实现类实例。 动态代理实现步骤： 创建一个实现接口InvocationHandler的类，它必须实现invoke方法，以完成代理的具体操作。 创建被代理的类以及接口。 通过Proxy的静态方法new ProxyInstance(ClassLoader loader, Class[] interfaces, InvocationHandler h)创建一个Subject接口代理。 通过Subject代理调用RealSubject实现类的方法。 以上步骤很难体现出动态代理的优势，下面的例子是更实用的动态代理机制的代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293package com.atguigu.java;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;/* 动态代理的举例 *///步骤2.创建实现的共同接口和被代理类interface Human{ String getBelief(); void eat(String food);}//被代理类class SuperMan implements Human{ @Override public String getBelief() { return \"I believe I can fly!\"; } @Override public void eat(String food) { System.out.println(\"我喜欢吃\" + food); }}class HumanUtil{ public void method1(){ System.out.println(\"*****通用方法一*****\"); } public void method2(){ System.out.println(\"*****通用方法二*****\"); }}/*要想实现动态代理，需要解决的问题？问题一：如何根据加载到内存中的被代理类，动态的创建一个代理类及其对象。问题二：当通过代理类的对象调用方法a时，如何动态的去调用被代理类中的同名方法a。 *///步骤3.创建Subject接口代理。class ProxyFactory{ //调用此方法，返回一个代理类的对象。解决问题一 public static Object getProxyInstance(Object obj){//obj:被代理类的对象 MyInvocationHandler handler = new MyInvocationHandler(); handler.bind(obj); return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), handler);}}//步骤1.创建实现InvocationHandler接口的类class MyInvocationHandler implements InvocationHandler{ private Object obj;//需要使用被代理类的对象进行赋值 public void bind(Object obj){ this.obj = obj; } //当我们通过代理类的对象，调用方法a时，就会自动的调用如下的方法：invoke() //将被代理类要执行的方法a的功能就声明在invoke()中 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { HumanUtil util = new HumanUtil(); util.method1(); //method:即为代理类对象调用的方法，此方法也就作为了被代理类对象要调用的方法 //obj:被代理类的对象 Object returnValue = method.invoke(obj,args); util.method2(); //上述方法的返回值就作为当前类中的invoke()的返回值。 return returnValue; }}public class ProxyTest { public static void main(String[] args) { SuperMan superMan = new SuperMan(); //proxyInstance:代理类的对象。通过指定的被代理类，创建代理类对象 Human proxyInstance = (Human) ProxyFactory.getProxyInstance(superMan); //当通过代理类对象调用方法时，会自动的调用被代理类中同名的方法 String belief = proxyInstance.getBelief(); System.out.println(belief); proxyInstance.eat(\"火锅\"); }}/*输出结果*****通用方法一**********通用方法二*****I believe I can fly!*****通用方法一*****我喜欢吃火锅*****通用方法二******/ 3、动态代理与AOPAOP（Aspect Orient Programming），面向切片编程。 使用Proxy生成一个动态代理时，往往并不会凭空产生一个动态代理，这样没有太大的意义。通常都是为指定的目标对象生成动态代理。 这种动态代理在AOP中被称为AOP代理，AOP代理可代替目标对象，AOP代理包含了目标对象的全部方法。但AOP代理中的方法与目标对象的方法存在差异：AOP代理里的方法可以在执行目标方法之前、之后插入一些通用处理。","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记14-网络编程","slug":"java-note-1401","date":"2021-04-17T15:00:21.000Z","updated":"2022-05-22T13:30:54.795Z","comments":true,"path":"2021/04/17/java-note-1401/","link":"","permalink":"http://kangshitao.github.io/2021/04/17/java-note-1401/","excerpt":"网络编程概述，IP和端口号，网络协议，TCP/UDP网络编程，URL编程","text":"一、网络编程概述Java提供了网络类库，可以轻松实现网络连接，底层细节隐藏在Java的本机安装系统里，由JVM控制。Java实现了一个跨平台的网络库，程序员面对的是一个统一的网络编程环境。 网络编程的目的：直接或间接地通过网络协议与其它计算机实现数据交换，进行通讯。 实现网络编程面对的两个问题： 如何准确定位某台主机，如何定位主机上的特定应用。 解决方法：使用IP地址定位主机，端口号定位特定应用 找到主机后如何可靠高效地进行数据传输。 解决方法：提供网络通信协议。 二、网络通信两个要素想要实现网络中的主机互相通信，需要满足两个条件： 已知通信双方的地址，包括IP和端口号。 一定的规则，即网络通信协议。有OSI和TCP/IP两个参考模型 ，OSI参考模型过于理想化，主要是使用TCP/IP参考模型（TCP/IP协议）。 OSI参考模型 TCP/IP参考模型 TCP/IP参考模型各层对应协议 应用层 应用层 HTTP、FTP、Telnet、DNS... 表示层 会话层 传输层 传输层 TCP、UDP... 网络层 网络层 IP、ICMP、ARP... 数据链路层 物理+数据链路层 以太网、无线LAN... 物理层 1、IP和端口号IP地址 IP：唯一的标识Internet上的计算机（通信实体），Java中使用InetAddress类代表IP。 Internet上的主机有两种方式表示地址： 域名(hostName，主机名)：比如 www.baidu.com。其中本地主机名用localhost表示 IP地址(hostAddress)：比如 182.61.200.7。本地地址用127.0.0.1表示 InetAddress没有公共的构造器，提供了两个静态方法用于实例化： public static InetAddress getLocalHost()：返回localhost地址的InetAddress对象 public static InetAddress getByName(String host)：返回指定主机地址的InetAddress对象，host参数可以是域名或者ip地址。 InetAddress常用的方法： public String getHostName()：返回当前主机的域名(主机名) public String getHostAddress()：返回当前主机的ip地址 public boolean isReachable(int timeout)：测试指定时间内是否可以到达当前地址 应用实例： 123456789101112131415public class InetAddressTest { @Test public void test() throws IOException { InetAddress inet1 = InetAddress.getByName(\"www.baidu.com\"); System.out.println(inet1.getHostAddress()); // 182.61.200.7 System.out.println(inet1.getHostName()); // www.baidu.com InetAddress inet2 = InetAddress.getByName(\"182.61.200.7\"); System.out.println(inet2.getHostAddress()); // 182.61.200.7 System.out.println(inet2.getHostName()); // 182.61.200.7 System.out.println(inet1.isReachable(500)); //true System.out.println(inet2.isReachable(500)); //true }} 端口号 端口号用来标识正在计算机上运行的程序（进程）。不同的进程有不同的端口号，端口号用一个16位的整数表示，范围是0-65535 端口分类： 公认端口：0-1023。被预先定义的服务通信占用，如HTTP占用端口80，FTP占用端口21，Telnet占用端口23等。 注册端口：1024-49151，分配给用户进程或应用程序。比如Tomcat占用端口8080，MySQL占用端口3306，Oracle占用端口1521等。 动态/私有端口：49152-65535，即1100 0000 0000 0000-1111 1111 1111 1111 端口号和IP地址的组合，得到网络套接字：Socket。 2、网络通信协议网络通信协议对速率、传输代码、代码结构、传输控制步骤、出错控制等制定标准。 以TCP/IP协议为例。TCP/IP协议将网络协议分成了物理链路层、网络层、传输层和应用层四层，其中传输层有两个非常重要的协议： TCP(Transmission Control Protocol)：传输控制协议。 使用TCP协议前，须先建立TCP连接，形成传输数据通道。 传输前，采用“三次握手”方式，点对点通信，是可靠的。 TCP协议进行通信的两个应用进程：客户端、服务端。 在连接中可进行大数据量的传输。 传输完毕，需释放已建立的连接，效率低。 UDP(User Datagram Protocol)：用户数据报协议。 将数据、源、目的封装成数据包，不需要建立连接。 每个数据报的大小限制在64K内。 发送不管对方是否准备好，接收方收到也不确认，是不可靠的。 可以广播发送。 发送数据结束时无需释放资源，开销小，速度快。 TCP的三次握手和四次挥手： Socket 网络上具有唯一标识的IP地址和端口号组合在一起，构成唯一能识别的标识符套接字(Socket)。 通信的两端都要有Socket，是两台机器间通信的端点。 网络通信其实就是Socket间的通信。 Socket允许程序把网络连接当成一个流，数据在两个Socket间通过IO传输。 一般主动发起通信的应用程序属客户端，等待通信请求的为服务端。 Socket分类： 流套接字（stream socket）：使用TCP提供可依赖的字节流服务。 数据报套接字（datagram socket）：使用UDP提供“尽力而为”的数据报服务。 Socket类的常用构造器： public Socket(InetAddress address, int port)：创建一个流套接字并将其连接到指定IP地址的指定端口号。 public Socket(String host, int port)：创建一个流套接字并将其连接到指定主机上的指定端口号。 Socket类的常用方法： public InputStream getInputStream()：返回此套接字的输入流。可以用于接收网络消息 public OutputStream getOutputStream()：返回此套接字的输出流。可以用于发送网络消息 public InetAddress getInetAddress()：此套接字连接到的远程IP地址；如果套接字是未连接的，则返回null。 public InetAddress getLocalAddress()：获取套接字绑定的本地地址。即本端的IP地址 public int getPort()：此套接字连接到的远程端口号；如果尚未连接套接字，则返回0。 public int getLocalPort()：返回此套接字绑定到的本地端口。如果尚未绑定套接字，则返回-1。即本端的端口号。 public void close()：关闭此套接字。套接字被关闭后，便不可在以后的网络连接中使用（即无法重新连接或重新绑定）。需要创建新的套接字对象。关闭此套接字也将会关闭该套接字的InputStream和OutputStream。 public void shutdownInput()：如果在套接字上调用shutdownInput()后从套接字输入流读取内容，则流将返回EOF（文件结束符）。即不能在从此套接字的输入流中接收任何数据。 public void shutdownOutput()：禁用此套接字的输出流。对于TCP套接字，任何以前写入的数据都将被发送，并且后跟TCP的正常连接终止序列。如果在套接字上调用shutdownOutput()后写入套接字输出流，则该流将抛出IOException。即不能通过此套接字的输出流发送任何数据。 三、TCP网络编程1、TCP通信流程TCP连接的套接字函数： 基于Socket的TCP编程，基本步骤： 客户端： 创建Socket：根据指定服务端的IP地址或端口号构造Socket类对象（使用Socket类的两个构造器方法）。若服务器端响应，则建立客户端到服务器的通信线路。若连接失败，会出现异常。 打开连接到Socket的输入/输出流：用getInputStream()方法获得输入流，使用getOutputStream()方法获得输出流，进行数据传输。 按照一定的协议对Socket进行读/写操作：通过输入流读取服务器放入线路的信息（但不能读取自己放入线路的信息），通过输出流将信息写入线程。 关闭Socket：断开客户端到服务器的连接，释放线路。 客户端建立socketAtClient对象的过程就是向服务器发出套接字连接请求。 客户端可以自定义，可以是浏览器 服务器： 调用ServerSocket（int port）：创建一个服务端套接字，并绑定到指定端口上，用于监听客户端的请求。 调用accept（）：监听连接请求，如果客户端请求连接，则接受连接。此方法返回通信套接字对象。 调用返回的Socket类对象的getOutputStream()和getInputStream()：获取输出流和输入流，开始网络数据的发送和接收。 关闭ServerSocket和Socket对象：客户端访问结束，关闭通信套接字。 ServerSocket对象负责等待客户端请求建立套接字连接。服务器必须实现建立一个等待客户请求建立socket连接的ServerSocket对象。 accept接收客户的socket请求，并返回一个socket对象。 服务端可以自定义，可以是Tomcat服务器 2、TCP网络编程案例应用举例1，客户端发送文件给服务端， 服务端保存到本地，并返回“接收成功”给客户端： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class TCPTest3 { @Test public void client() throws IOException { //1.创建Socket，指定要连接的主机地址和端口号 Socket socket = new Socket(InetAddress.getByName(\"127.0.0.1\"),9090); //2.打开连接到socket的输出流 OutputStream os = socket.getOutputStream(); //3.建立文件流 FileInputStream fis = new FileInputStream(new File(\"beauty.jpg\")); //4.写数据 byte[] buffer = new byte[1024]; int len; while((len = fis.read(buffer)) != -1){ os.write(buffer,0,len); } //写完数据以后要关闭数据输出流，不然会一直处于阻塞状态 socket.shutdownOutput(); //5.接收来自于服务器端的数据，并显示到控制台上 InputStream is = socket.getInputStream(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] bufferr = new byte[20]; int len1; while((len1 = is.read(buffer)) != -1){ baos.write(buffer,0,len1); } System.out.println(baos.toString()); //6.关闭流 fis.close(); os.close(); socket.close(); is.close(); baos.close(); } @Test public void server() throws IOException { //1.创建ServerSocket对象，设置端口为9090 ServerSocket ss = new ServerSocket(9090); //2.调用accept监听连接请求，连接成功后才会执行下面的代码 Socket socket = ss.accept(); //3.获取输入流 InputStream is = socket.getInputStream(); //4.构建节点流 FileOutputStream fos = new FileOutputStream(new File(\"beauty2.jpg\")); //5.将输入流内容写到文件中 byte[] buffer = new byte[1024]; int len; while((len = is.read(buffer)) != -1){ fos.write(buffer,0,len); } System.out.println(\"文件传输完成\"); //6.服务器端给予客户端反馈 OutputStream os = socket.getOutputStream(); os.write(\"我是服务器，文件已收到\".getBytes()); //7.关闭连接。这里需要使用try-catch捕获异常。 fos.close(); is.close(); socket.close(); ss.close(); os.close(); }} 应用举例2，客户端向服务器发送信息，服务器返回接受成功，直到输入“exit”断开连接： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129/*Client.java文件*/package com.atguigu.Exer;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.InetAddress;import java.net.Socket;import java.nio.charset.StandardCharsets;import java.util.Scanner;public class Client { public static void main(String[] args) { new Client().start(); } public void start() { Socket socket = null; OutputStream os = null; Scanner sc = null; ByteArrayOutputStream baos = null; while (true) { try { //1. socket = new Socket(InetAddress.getByName(\"127.0.0.1\"), 9999); //2. os = socket.getOutputStream(); //3. System.out.println(\"Input message：\"); sc = new Scanner(System.in); String message = sc.next(); os.write(message.getBytes(StandardCharsets.UTF_8)); socket.shutdownOutput();//写完数据以后要关闭数据输出流 //接收来自服务器的消息 InputStream is = socket.getInputStream(); baos = new ByteArrayOutputStream(); int len = 0; while ((len = is.read()) != -1) { baos.write(len); } System.out.println(baos.toString()); if (\"exit\".equals(message)) break; } catch (IOException e) { e.printStackTrace(); } finally { if (os != null) { try { os.close(); } catch (IOException e) { e.printStackTrace(); } } if (socket != null) { try { socket.close(); } catch (IOException e) { e.printStackTrace(); } } } } }}/*Server.java文件*/package com.atguigu.Exer;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.io.InputStream;import java.net.ServerSocket;import java.net.Socket;public class Server { public static void main(String[] args) { new Server().start(); } public void start() { ServerSocket ss = null; Socket socket = null; InputStream is = null; ByteArrayOutputStream baos = null; try { ss = new ServerSocket(9999); while (true) { socket = ss.accept(); is = socket.getInputStream(); int len = 0; baos = new ByteArrayOutputStream(); while ((len = is.read()) != -1) { baos.write(len); } String message = baos.toString(); System.out.print(\"From \" + socket.getInetAddress().getHostName() + \": \"); System.out.println(message); socket.getOutputStream().write( \"-----Message received-----\".getBytes()); socket.shutdownOutput();//写完数据以后要关闭数据输出流 if (\"exit\".equals(message)) break; } } catch (IOException e) { e.printStackTrace(); } finally { if (ss != null) { try { ss.close(); } catch (IOException e) { e.printStackTrace(); } } if (socket != null) { try { socket.close(); } catch (IOException e) { e.printStackTrace(); } } if (is != null) { try { is.close(); } catch (IOException e) { e.printStackTrace(); } } if (baos != null) { try { baos.close(); } catch (IOException e) { e.printStackTrace(); } } } }} 四、UDP网络编程1、UDP通信流程UDP连接的套接字函数： 类DatagramSocket和DatagramPacket实现了基于UDP协议网络程序。 DatagramSocket，数据报套接字，负责发送和接收UDP数据报(数据包)，系统不保证UDP数据报一定能够安全送到目的地，也不能确定什么时候可以抵达。 DatagramPacket对象封装了UDP数据报(数据包)，在数据报中包含了发送端的IP地址和端口号以及接收端的IP地址和端口号。 UDP协议中每个数据报都给出了完整的地址信息，因此无须建立发送方和接收方的连接。如同发快递包裹一样。 DatagramSocket类的常用方法： public DatagramSocket(int port)：创建数据报套接字并将其绑定到本地主机上的指定端口。套接字将被绑定到通配符地址，IP地址由内核来选择。 public DatagramSocket(int port,InetAddress laddr)：创建数据报套接字，将其绑定到指定的本地地址。本地端口必须在0到65535之间（包括两者）。如果IP地址为0.0.0.0，套接字将被绑定到通配符地址，IP地址由内核选择。 public void close()：关闭此数据报套接字。 public void send(DatagramPacket p)：从此套接字发送数据报包。DatagramPacket包含的信息指示：将要发送的数据、其长度、远程主机的IP地址和远程主机的端口号。 public void receive(DatagramPacket p)：从此套接字接收数据报包。当此方法返回时，DatagramPacket的缓冲区填充了接收的数据。数据报包也包含发送方的IP地址和发送方机器上的端口号。此方法在接收到数据报前一直阻塞。数据报包对象的length字段包含所接收信息的长度。如果信息比包的长度长，该信息将被截短。 public InetAddress getLocalAddress()：获取套接字绑定的本地地址。 public int getLocalPort()：返回此套接字绑定的本地主机上的端口号。 public InetAddress getInetAddress()：返回此套接字连接的地址。如果套接字未连接，则返回null。 public int getPort()：返回此套接字的端口。如果套接字未连接，则返回-1。 DatagramPacket类的常用方法： public DatagramPacket(byte[] buf,int length)：构造DatagramPacket，用来接收长度为length的数据包。length参数必须小于等于buf.length。 public DatagramPacket(byte[] buf,int length,InetAddress address,int port)：构造数据报包，用来将长度为length的包发送到指定主机上的指定端口号。length参数必须小于等于buf.length。 public InetAddress getAddress()：返回某台机器的IP地址，此数据报将要发往该机器或者是从该机器接收到的。 public int getPort()：返回某台远程主机的端口号，此数据报将要发往该主机或者是从该主机接收到的。 public byte[] getData()：返回数据缓冲区。接收到的或将要发送的数据从缓冲区中的偏移量offset处开始，持续length长度。 public int getLength()：返回将要发送或接收到的数据的长度。 UDP网络通信步骤： 由于UDP通信不需要建立连接，因此客户端和服务端步骤相同。 使用DatagramSocket创建socket。 使用DatagramPacket建立数据包，将要发送/接收的数据、IP地址、端口号封装到数据包中。 调用socket的发送、接收方法。 关闭socket。 2、UDP网络编程案例应用实例，发送端向接收端发送信息： 1234567891011121314151617181920212223242526272829public class UDPTest { //发送端 @Test //为了看着简洁，使用throws处理异常。正确方式是try-catch public void sender() throws IOException { //1.创建数据包套接字对象 DatagramSocket socket = new DatagramSocket(); String str = \"我是UDP发送端\"; byte[] data = str.getBytes(); InetAddress inet = InetAddress.getLocalHost(); //2.将要发送的数据以及IP和端口号封装到数据包中 DatagramPacket packet = new DatagramPacket(data,0,data.length,inet,9090); //3.发送数据 socket.send(packet); //4.关闭socket，这里同样应该使用try-catch处理异常。 socket.close(); } //接收端 @Test public void receiver() throws IOException { DatagramSocket socket = new DatagramSocket(9090); byte[] buffer = new byte[100]; DatagramPacket packet = new DatagramPacket(buffer,0,buffer.length); //将接收的数据存入数据包 socket.receive(packet); System.out.println(new String(packet.getData(),0,packet.getLength())); socket.close(); }} 五、URL编程1、URL介绍URL（Uniform Resource Locator）：统一资源定位符，表示Internet上某一资源的地址。 通过url可以访问Internet上的各种网络资源，浏览器通过解析给定的url，在网络上查找相应的文件或其他资源。 URL基本结构有5部分：&lt;传输协议&gt;://&lt;主机名&gt;:&lt;端口号&gt;/&lt;文件名&gt;#片段名?参数列表。 例如：http://127.0.0.1:8080/helloworld/index.jsp#a?username=admin&amp;password=123 #片段名：即锚点，例如小说定位到章节。 参数列表格式：参数名=参数值&amp;参数名=参数值… 2、URL类java.net.URL类用于表示URL，其有四种构造器： public URL (String spec)：通过一个表示URL地址的字符串可以构造一个URL对象。 例如：URL url= new URL (\"http://www.baidu.com/\"); public URL(URL context, String spec)：通过基URL和相对URL构造一个URL对象。 例如：URL downloadUrl= new URL(url, “download.html\"); public URL(String protocol, String host, String file) 例如：newURL(\"http\",\"www.baidu.com\",“download.html\"); public URL(String protocol, String host,intport, String file); 例如:URL gamelan = newURL(\"http\",\"www.baidu.com\", 80,“download.html\"); URL类的构造器都声明抛出非运行时异常，必须对这种异常进行处理，通常使用try-catch语句捕获。 URL类的常用方法： public String getProtocol()：获取该URL的协议名 public String getHost()：获取该URL的主机名 public String getPort()：获取该URL的端口号 public String getPath()：获取该URL的文件路径 public String getFile()：获取该URL的文件名 publicString getQuery()：获取该URL的查询名 3、URL编程URL的方法openStream()能从网络上读取数据。 若希望输出数据，例如向服务器端的CGI（公共网关接口-Common GatewayInterface-的简称，是用户浏览器和服务器端的应用程序进行连接的接口）程序发送一些数据，则必须先与URL建立连接，然后才能对其进行读写，此时需要使用URLConnection类。 URLConnection是抽象类，HttpURLConnection抽象类继承了URLConnection，HttpsURLConnectionImpl继承了HttpURLConnection抽象类。 URLConnection表示到URL所引用的远程对象的连接。当与一个URL建立连接时，首先要在一个URL对象上通过方法openConnection()生成对应的URLConnection对象。如果连接过程失败，将产生IOException. URL url = new URL (\"http://www.baidu.com/index.html\"); URLConnectonn u = url.openConnection( ); 通过URLConnection对象获取的输入流和输出流，可以与现有的CGI程序进行交互。 public Object getContent() throws IOException public int getContentLength( ) public String getContentType( ) public long getDate( ) public long getLastModified( ) public InputStream getInputStream( ) throws IOException public OutputSteram getOutputStream( ) throws IOException 应用实例，使用URL编程下载网络资源文件： 1234567891011121314151617181920212223242526272829303132333435363738394041public class URLTest1 { public static void main(String[] args) { HttpURLConnection urlConnection = null; InputStream is = null; FileOutputStream fos = null; try { //1.构造URL对象 URL url = new URL(\"https://www.baidu.com/img/ PCtm_d9c8750bed0b3c7d089fa7d55720d6cf.png\"); //2.生成URLConnection对象，其实是HttpsURLConnectionImpl对象 urlConnection = (HttpURLConnection) url.openConnection(); //3.建立连接 urlConnection.connect(); //4.获取并下载资源 is = urlConnection.getInputStream(); fos = new FileOutputStream(\"D:\\\\BaiduLogo.jpg\"); byte[] buffer = new byte[1024]; int len; while((len = is.read(buffer)) != -1){ fos.write(buffer,0,len); } System.out.println(\"下载完成\"); } catch (IOException e) { e.printStackTrace(); } finally { //5.关闭资源 if(is != null){ try {is.close();} catch (IOException e) {e.printStackTrace();} } if(fos != null){ try {fos.close();} catch (IOException e) {e.printStackTrace();} } if(urlConnection != null){urlConnection.disconnect();} } }} 4、URI、URL和URN的区别URI(uniform resource identifier)，统一资源标识符，用来唯一的标识一个资源。 URL(uniform resource locator)，统一资源定位符，它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源。 URN(uniform resource name)，统一资源命名，通过名字来标识资源，比如mailto:java-net@java.sun.com。 也就是说，URI是以一种抽象的，高层次概念定义统一资源标识，而URL和URN则是具体的资源标识的方式，URL和URN都是一种URI。 在Java的URI中，一个URI实例可以代表绝对的，也可以是相对的，只要符合URI语法规则即可。而URL类不仅符合语义，还包含了定位该资源的信息，因此它不能是相对的。","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记13-IO流","slug":"java-note-1301","date":"2021-04-16T12:51:33.000Z","updated":"2022-05-22T13:30:54.795Z","comments":true,"path":"2021/04/16/java-note-1301/","link":"","permalink":"http://kangshitao.github.io/2021/04/16/java-note-1301/","excerpt":"IO流,节点流,缓冲流,转换流,字符集,字符编码,打印流,数据流,序列化,反序列化","text":"一、File类1、File类的使用java.io.File类的一个对象，表示一个文件或一个文件目录，与平台无关。 File能新建、删除、重命名文件和目录，但不能访问文件内容本身，访问文件内容需要使用输入输出流。 Java中表示一个真实存在的文件或目录，必须有一个File对象，但Java程序的一个File对象可能没有一个真实存在的文件或目录。 File对象可以作为参数传递给流的构造器。 2、构造File类对象File类的构造器有四种： public File(String pathname)：以pathname为路径创建File对象，可以是绝对路径和相对路径。 public File(String parent,String child)：以parent为父路径，child为子路径创建File对象。 public File(File parentFile,String childPath)：根据父File对象和子文件路径创建File对象。 public File(URI uri)：根据给定的url创建File对象。 IDEA中，main方法中默认的相对路径是当前project下，Test方法则是默认当前module。 路径中每级目录之间用路径分隔符隔开，Windows和Dos系统默认采用\\表示，UNIX和URL使用/表示分隔符。 为了支持跨平台，File类提供了常量public static final String separator，它能根据不同系统动态提供分隔符。 代码示例： 123456789101112131415161718public class FileTest { @Test public void test1(){ //构造器1 File file1 = new File(\"hello.txt\"); File file2 = new File(\"D:Java\\\\JavaSenior\\\\day08\\\\hello.txt\"); System.out.println(file1); // hello.txt System.out.println(file2); // D:Java\\JavaSenior\\day08\\hello.txt //构造器2： File file3 = new File(\"D:Java\",\"JavaSenior\"); System.out.println(file3); // D:Java\\JavaSenior //构造器3： File file4 = new File(file3,\"hi.txt\"); System.out.println(file4); // D:Java\\JavaSenior\\hi.txt }} 3、File类中的方法File类中的常用方法： File类的获取功能： public String getAbsolutePath()：获取绝对路径 public String getPath()：获取路径 public String getName()：获取名称 public String getParent()：获取上层文件目录路径。若无，返回null public long length()：获取文件长度（即：字节数）。不能获取目录的长度。 public long lastModified()：获取最后一次的修改时间，毫秒值 public String[] list()：获取指定目录下的所有文件或者文件目录的名称数组 public File[] listFiles()：获取指定目录下的所有文件或者文件目录的File数组 FIle类的重命名功能： public boolean renameTo(File dest)：把当前文件重命名为指定的文件路径，要求当前文件必须存在的且目标dest不存在。 File类的判断功能： public boolean isDirectory()：判断是否是文件目录 public boolean isFile()：判断是否是文件 public boolean exists()：判断是否存在 public boolean canRead()：判断是否可读 public boolean canWrite()：判断是否可写 public boolean isHidden()：判断是否隐藏 File类的创建功能： public boolean createNewFile()：创建文件。若文件存在，则不创建，返回false public boolean mkdir()：创建文件目录。如果此文件目录存在，就不创建。如果此文件目录的上层目录不存在，也不创建。 public boolean mkdirs()：创建文件目录。如果此文件目录存在，就不创建。如果上层文件目录不存在，一并创建。 File类的删除功能： public boolean delete()：删除文件或者文件目录 Java中的删除不经过回收站。 如果要删除的文件目录不为空，则删除失败。 二、IO流的原理及分类1、IO流概述Java中，对于数据的输入/输出操作以流(stream)的方式进行。 流的分类： 根据操作的数据单位不同，分为：字节流（8 bit），字符流（16 bit） 根据流的流向不同，分为：输入流、输出流 根据流的角色不同，分为：节点流、处理流 IO流的四个基类，其他类都是继承自这四个抽象类： （抽象基类） 字节流 字符流 输入流 InputStream Reader 输出流 OutputStream Writer IO流的类层次图： 节点流：直接从数据源或目的地读写数据。 上图中的FileInputStream/FileOutputStream/FileReader/FileWrider都是节点流。 处理流：不直接连接到数据源或目的地，而是“连接”在已存在的流（节点流或处理流）之上，通过对数据的处理为程序提供更强大的读写功能。比如缓冲流、打印流等。 2、IO流基类InputStream和Reader是所有输入流的基类，分别用于字节流和字符流。二者的典型实现类分别为FileInputStream和FileReader，使用FileInputStream和FileReader从文件系统中的某个文件中获得输入字节/字符。 InputStream中的方法： int read()：从输入流中读取数据的下一个字节。返回0-255内的int字节值，如果到达流末尾，返回-1 int read(byte[] b)：从输入流中最多将b.length个字节的数据读入byte数组中。如果到达流末尾，返回-1，否则以整数形式返回实际读取的字节数。 int read(byte[] b, int off, int len)：读取最多len个字节数据，存放到数组b中off以后的位置。如果到达流末尾，返回-1 public void close() throws IOException：关闭此输入流，并释放与该流关联的所有系统资源。 Reader中的方法： int read()：读取单个字符，作为整数读取的字符，范围在0-65535之间（0x00-0xff，2个字节的Unicode码），如果到达流末尾，返回-1 int read(char[] c) int read(char[] c, int off, int len) public void close() throws IOException OutputStream和Writer是所有输出流的基类，其典型实现类分别是FileOutputStream和Writer，用于写出数据。 OutputStream中的方法： void write(int b)：将单个字节b写入指定的输出文件 void write(byte[] b)：将字节数组b中的数据写出到文件 void write(byte[] b,int off, int len)：将数组中从off开始的长度为len的所有字节写出到文件 void flush()：刷新 void close()：关闭 Writer中的方法： void write(int c)：将单个字符c写入指定的输出文件 void write(char[] c)：将字符数组c中的数据写出到文件 void write(char[] c,int off, int len)：将数组中从off开始的长度为len的所有字符写出到文件 void flush()：刷新 void close()：关闭 IO流部署于内存里的资源，GC无法回收该资源，操作结束后，必须要显式关闭文件IO资源。 三、节点流（文件流）FileInputStream/FileOutputStream/FileReader/FileWrider都是节点流，用于读入/读出数据。 节点流的构造器，以FileInputStream为例，其余都相似： public FileInputStream(File file)：根据File对象file创建输入节点流 public FileInputStream(String name)：根据name创建输入节点流，其实底层还是根据字符串创建了File对象，再使用第一个构造器。 读入/读出数据的大体步骤： 创建File类对象，指明要操作的文件 提供具体的节点流 调用read/write方法读入/写出数据 关闭流 应用实例，将文件1的内容读取到控制台，然后复制到文件2： 1234567891011121314151617181920212223242526272829303132public class FileInputOutputStreamTest{ FileInputStream fis = null; FileOutputStream fos = null; try{ //1&amp;2. 创建File对象，创建文件流 fis = new FileInputStream(new File(\"hello1.txt\")); fos = new FileOutputStream(new File(\"hello2.txt\")); //3.进行读写操作 byte[] buffer = new byte[1024]; int len; while((len = fis.read(buffer)) != -1){ fos.write(buffer,0,len); //这里必须是长度为len，读多少写多少 } }catch(IOException e){ e.printStackTrace(); }finally{ //4.关闭操作。为保证关闭操作一定会执行，写在finally中 if(fos != null){ try{ fos.close(); }catch (IOException e){ e.printStackTrace(); } } if(fis != null){ try{ fis.close(); }catch (IOException e){ e.printStackTrace(); } } }} 字符流只能处理字符，操作普通文本文件(.txt,.java,.c,.cpp等)，.doc不是文本文件。 字节流可以操作普通文本文件，也可以操作.mp3,.avi,.rmvb,.mp4,.jpg,.doc,.ppt等。 使用read()读取文件时，必须保证文件存在。 FileWriter/FileOutputStream有两个构造器，一个参数的构造器，默认对原有文件进行覆盖。两个参数的构造器，第二个参数是append，用于判断是进行追加还是覆盖。如果文件不存在，则自动创建。 字符流底层也是用字节流实现的。 四、缓冲流缓冲流是为了提高读写速度，在使用时创建内部缓冲区（默认缓冲区大小为8192字节，8KB）的一种处理流。缓冲流要“套接”在节点流之上才能使用。 根据数据操作单位不同，有两种输入输出缓冲流： BufferedInputStream/BufferedOutputStream BufferedReader/BufferedWriter 下面以 BufferedInputStream/BufferedOutputStream为例，说明缓冲流的原理及使用方法。 BufferedInputStream读取数据时，先一次性读取8KB数据存入缓冲区，然后读操作从缓冲区中获取数据。 BufferedOutputStream写入数据时，先写到缓冲区中，将缓冲区写满，然后write操作从缓冲区中写到文件中。使用flush()可以强制将缓冲区的内容全部写入输出流。 关闭流时，只需要关闭最外层即可，最外层关闭时会自动将节点流关闭。 缓冲流关闭时会自动执行flush操作。 使用缓冲流读入/读出数据的大体步骤： 创建File类对象，指明要操作的文件 提供具体的节点流 创建缓冲流 调用read/write方法读入/写出数据 关闭缓冲流 代码实例，使用缓冲流复制视频： 12345678910111213141516171819202122232425262728293031323334353637383940public class FileInputOutputStreamTest{ BufferedInputStream bis = null; BufferedOutputStream bos = null; try{ //1&amp;2. 创建File对象，创建文件流 FileInputStream fis = new FileInputStream(new File(\"视频1.mp4\")); FileOutputStream fos = new FileOutputStream(new File(\"视频2.mp4\")); //3.创建缓冲流 //默认缓冲区大小是8192Byte，可以指定大小 bis = new BufferedInputStream(fis); bos = new BufferedOutputStream(fos); //4.进行读写操作 byte[] buffer = new byte[1024]; int len; /* 读取的时候，先一次性将缓冲区存满，然后每次read操作从缓冲区读取1024字节到数组buffer中。 写入的时候，先将缓冲区写满，然后再根据字节数组，每次将1024字节写入文件。 */ while((len = bis.read(buffer)) != -1){ bos.write(buffer,0,len); } }catch(IOException e){ e.printStackTrace(); }finally{ //5.关闭操作。只需要关闭最外层即可，且会自动调用flush方法。 if(bos != null){ try{ bos.close(); }catch (IOException e){ e.printStackTrace(); } } if(bis != null){ try{ bis.close(); }catch (IOException e){ e.printStackTrace(); } } }} 五、转换流1、转换流概述转换流用于字节流和字符流之间的转换，Java中有两个转换流： InputStreamReader：将InputStream转换为Reader，字节、字节数组→字符数组、字符串，相当于解码。有以下常用构造器： public InputStreamReader(InputStream in)：使用默认字符集对in进行解码 public InputStreamReader(InputStream in, String charsetName)：使用指定字符集解码 OutputStreamWriter：将Writer转换为OutputStream，字符数组、字符串→字节、字节数组，相当于编码。有构造器： public OutputStreamWriter(OutputStream out)：使用默认字符集（字符编码）对out进行编码 public OutputStreamWriter(OutputStream out, String charsetName)：使用指定字符集（字符编码）编码 字符流底层操作是基于字节流，使用转换流进行转换。过程为：文本1—&gt;字节流—&gt;InputStreamReader—&gt;字符流—&gt;程序—&gt;字符流—&gt;OutputStreamWriter—&gt;字节流—&gt;文本2 对于字符数据，使用字符流操作更高效。 转换流通常用于处理文件乱码问题，实现编码和解码操作。 未解决疑问：JDK源码中将UTF-8描述为字符集(charset)，好像没有区分字符集和字符编码的概念？Java中字符编码器是什么东西？ 具体用法： 123456//输入FileInputStream fis = new FileInputStream(\"dbcp1.txt\");InputStreamReader isr = new InputStreamReader(fis,\"UTF-8\");//输出FileOutputStream fos = new FileOutputStream(\"dbcp2.txt\");OutputStreamWriter osw = new OutputStreamWriter(fos,\"gbk\"); 2、字符编码 字符集（Charset）：字符集指的是一个系统支持的所有抽象字符的集合。字符集中的每个字符的位置叫做码位（Code Point），码位上的值为码位值（Code point value）。字符集就是把抽象字符映射为码位值。常见的字符集有GB2312、GBK、GB18030、Big5、Unicode、ASCII等字符集。 字符编码（Character Encoding）：字符编码是一种映射规则，根据这个映射规则可以将某个字符映射成其他形式的数据（比如比特模式、自然数序列、8位组、电脉冲等），以便在计算机中存储和传输。简而言之就是字符编码是字符集和实际存储数值之间的转换关系。 总结：字符集建立起数字和字符之间的索引关系。某个字符在计算机中怎么表示，具体占用几个字符等，这就需要编码规则来解决，即字符编码，它规定了字符如何编码成二进制，存储在计算机中。 直接使用字符集中的码位值存储，会造成空间浪费，比如本来ASCII字符只需要一个字节，如果直接使用字符集编码，需要三个字节，因此出现了UTF-8等变长编码，其对于ASCII字符仍然使用一个字节存储。 Unicode出现之前，几乎所有的字符集和其编码方式都是绑定的，可以说字符集就是编码方式。 Unicode字符集有多种编码方式，即UTF-8、UTF-16、UTF-32等。 问题一，关于ASCII码、ANSI和ISO8859-XXX： ASCII码是最早出现的字符集，包括128个字符，字符集表如下： ANSI是一种字符代码，表示扩展的ASCII编码。对于0x00~0x7F的128个字符，与ASCII码一致，超过此范围的使用0x80~0xFFFF来编码。这种使用多个字节来代表一个字符的各种汉字延伸编码的方式，称为ANSI编码，比如GB2312、GBK、GB18030、Big5、Shift_JIS等。 在英文的Windows操作系统中，ANSI编码表示ISO-8859-1编码(Latin-1，西欧常用字符，包括德法两国的字母)。 在简体中文的Windows操作系统中，ANSI编码表示GBK编码。 在繁体中文的Windows操作系统中，ANSI编码表示Big5编码。 在日文的Windows操作系统中，ANSI编码表示Shift_JIS编码 欧洲国家对ASCII码进行扩充，只扩充128-255这一段，0-127与ASCII码相同，形成了在欧洲国家的一些子标准，比如ISO8859-1字符集、ISO8859-2字符集等，具体可以参考链接。 问题二，关于GBxxxx编码： GB2312（或GB2312-80）是最早出现的汉字编码，收录6763个汉字，由于其不能处理一些罕见字，出现了GBK编码，兼容GB2312，并且包括了BIG5的所有汉字。 2000年发布了GB18030字符集，采用单字节、双字节、四字节三种编码方式，完全兼容ASCII码和GBK码。2005年又进行了修订与扩展，推出了GB18030-2005，共收录70244个汉字。 问题三，Unicode和UTF-8的关系： 结论：UTF-8是Unicode的实现方式之一。 Unicode是字符集，为每个字符规定了唯一的编号。实现它的方式有多种，比如UTF-8、UTF-16、UTF-32等字符编码都是Unicode的实现方式，Unicode字符集具体存储成什么样的字节流，取决于字符编码方案。 UTF-8是一种变长的编码方式，每次8个位传输数据，使用1-4个字节表示一个符号，根据不同的符号而变化字节长度 。UTF-16是每次16个位传输数据，具体可参考链接1和链接2。 UTF-8的编码方式，参考链接： 六、标准输入输出流标准输入输入流，分别代表系统标准的输入和输出设备，默认输入设备是键盘，默认输出设备是显示器： System.in：标准的输入流，默认从键盘输入，类型是InputStream，其源码为：public static final InputStream in. System.out：标准的输出流，默认从控制台输出，类型是PrintStream，其源码为：public static final PrintStream out. System类的set方法可以重新指定输入和输出的流： public static void setIn(InputStream in) public static void setOut(PrintStream out) 例题，使用标准输入输出流，从键盘输入字符，将读取到的整行字符串转出大写输出，并继续输出，直到输入“exit”时退出程序： 1234567891011121314151617181920212223242526272829303132public class SystemStreamTest { /* 方法一：使用Scanner实现，调用next()返回一个字符串 方法二：使用System.in实现。 System.in ---&gt; 转换流 ---&gt; BufferedReader的readLine() */ public static void main(String[] args) { BufferedReader br = null; try { //System.in是InputStream类型 InputStreamReader isr = new InputStreamReader(System.in); br = new BufferedReader(isr); while (true) { System.out.println(\"请输入字符串：\"); String data = br.readLine(); if (\"exit\".equalsIgnoreCase(data)) { System.out.println(\"程序结束\"); break; } String upperCase = data.toUpperCase(); System.out.println(upperCase); } } catch (IOException e) { e.printStackTrace(); } finally { if (br != null) { try { br.close();} catch (IOException e) {e.printStackTrace();} } } }} 七、打印流打印流PrintStream和PrintWriter提供了一系列重载的print()和println()方法，用于多种数据类型的输出。 PrintStream和PrintWriter的输出不会抛出异常。 PrintStream和PrintWriter有自动flush功能。 PrintStream打印的所有字符使用平台默认的字符编码转换为字节，在需要写入字符的情况下，应该使用PrintWriter类。 System.out返回的是PrintStream的实例。 代码实例，输出ASCII字符： 123456789101112131415161718192021public class PrintStreamTest{ public void test2() { PrintStream ps = null; try { FileOutputStream fos = new FileOutputStream(new File(\"D:\\\\IO\\\\text.txt\")); // 创建打印输出流,设置为自动刷新模式(写入换行符或字节 '\\n' 时都会刷新输出缓冲区) ps = new PrintStream(fos, true); if (ps != null) {// 把标准输出流(控制台输出)改成文件 System.setOut(ps); } for (int i = 0; i &lt;= 255; i++) { // 输出ASCII字符 System.out.print((char) i); // 每50个数据一行 if (i % 50 == 0) System.out.println(); } } catch (FileNotFoundException e) {e.printStackTrace();} finally {if (ps != null) {ps.close();}} }} 八、数据流数据流用于方便地操作Java语言的基本数据类型和String类型。 数据流有两个类： DataInputStream：套接在InputStream子类的流上。其包含的方法如下 boolean readBoolean() char readChar() double readDouble() long readLong() String readUTF() byte readByte() float readFloat() short readShort() int readInt() void readFully(byte[] b) DataOutputStream：套接在OutputStream子类的流上。其中的方法与DataInputStream中一致，只需要将read改为write即可。 应用实例： 1234567891011121314151617181920212223242526272829303132333435363738394041public class OtherStreamTest { /* 将内存中的字符串、基本数据类型的变量写出到文件中 这里处理异常应该使用try-catch-finally. */ @Test public void test3() throws IOException { //1. DataOutputStream dos = new DataOutputStream(new FileOutputStream(\"data.txt\")); //2. dos.writeUTF(\"数据结构\"); dos.flush(); //刷新操作，将内存中的数据写入文件，每次写完都要刷新 dos.writeInt(23); dos.flush(); dos.writeBoolean(true); dos.flush(); //3. dos.close(); } /* 将文件中存储的基本数据类型变量和字符串读取到内存中，保存在变量中。 注意点：读取不同类型的数据的顺序要与当初写入文件时，保存的数据的顺序一致！ */ @Test public void test4() throws IOException { //1. DataInputStream dis = new DataInputStream(new FileInputStream(\"data.txt\")); //2. String name = dis.readUTF(); int age = dis.readInt(); boolean isMale = dis.readBoolean(); System.out.println(\"name = \" + name); System.out.println(\"age = \" + age); System.out.println(\"isMale = \" + isMale); //3. dis.close(); }} 九、对象流1、对象流概述对象流ObjectInputStream和ObjectOutputStream，用于存储和读取基本类型数据或对象的处理流。可以把Java中的对象写入到数据中（序列化），或者把对象从数据源中还原回来（反序列化）。 序列化：用ObjectOutputStream类保存基本数据类型或对象的机制。 反序列化：用ObjectInputStream类读取基本数据类型或对象的机制。 2、序列化和反序列化transient关键字 transient意为短暂的、临时的。用transient关键字修饰的变量无法被序列化。 同样，用static关键字修饰的变量也无法被序列化。 对象序列化机制 对象序列化机制允许把内存中的Java对象转换成平台无关的二进制流，从而允许把这种二进制流持久地保存在磁盘上，或通过网络将这种二进制流传输到另一个网络节点。当其它程序获取了这种二进制流，就可以恢复成原来的Java对象。 序列化就是将内存中的java对象保存到磁盘中或通过网络传输出去。而反序列化就是将磁盘中的对象还原成内存中的一个java对象。 序列化的好处在于可将任何实现了Serializable接口的对象转化为字节数据，使其在保存和传输时可被还原。 序列化是RMI（Remote Method Invoke–远程方法调用）过程的参数和返回值都必须实现的机制，RMI是JavaEE的基础，因此序列化机制是JavaEE平台的基础。 如果需要让某个对象支持序列化机制，则必须让对象所属的类及其属性是可序列化的，为了让某个类是可序列化的，该类必须实现如下两个接口之一。否则，会抛出NotSerializableException异常 Serializable Externalizable 实现Serializable接口的类，都有一个表示序列化版本标识符的静态变量： private static final long serialVersionUID 其用来表明类的不同版本之间的兼容性。目的是以序列化对象进行版本控制，有关各版本反序列化时是否兼容。 如果实现类没有显式定义此变量，它的值是Java运行时环境根据类的内部细节自动生成的。若类的实例变量做了修改，serialVersionUID可能发生变化，导致无法反序列化。建议显式声明此常量。 反序列化时，JVM会把传来的字节流的serialVersionUID与本地相应实体类的serialVersionUID进行比较，如果相同就认为是一致的，可以进行反序列化，否则会出现异常InvalidCastException 3、使用对象流序列化对象序列化步骤： 创建ObjectOutputStream对象，记为oos 调用oos的writeObject(对象)方法，输出可序列化对象 每写出一次，就需要flush一次。 反序列化步骤： 创建ObjectInputStream对象，记为ois 调用ois的readObject()方法，读取流中的对象 可序列化的类中的属性，如果是引用类型，其必须也是可序列化的。String类型是可序列化的。 实现代码： 1234567891011121314//序列化，将对象变为二进制流ObjectOutputStream oos = new ObjectOutputStream( new FileOutputStream(\"data.txt\"));Personp = newPerson(\"韩梅梅\", 18, \"中华大街\", newPet());oos.writeObject(p);oos.flush();oos.close();//反序列化，将磁盘中数据读出并还原为对象ObjectInputStream ois = new ObjectInputStream( new FileInputStream(\"data.txt\"));Personp1 = (Person)ois.readObject();System.out.println(p1.toString());ois.close(); 关于java.io.Serializable接口的理解 Serializable接口是空方法接口，这样的接口称为标志接口。实现了Serializable接口的对象，可将它们转换成一系列字节，并可在以后完全恢复回原来的样子。这一过程亦可通过网络进行。这意味着序列化机制能自动补偿操作系统间的差异。换句话说，可以先在Windows机器上创建一个对象，对其序列化，然后通过网络发给一台Unix机器，然后在那里准确无误地重新“装配”。不必关心数据在不同机器上如何表示，也不必关心字节的顺序或者其他任何细节。 由于大部分作为参数的类如String、Integer等都实现了java.io.Serializable的接口，也可以利用多态的性质，作为参数使接口更灵活。 十、随机存取文件流RandomAccessFile实现了DataInput和DataOutput这两个接口，意味着这个类既可以读也可以写。 RandomAccessFile包含一个记录指针，用来标识当前读写所处的位置，也就是说，类支持“随机访问”的方式，可以从文件的任意地方读、写文件。这个指针可以自由移动： long getFilePointer()：获取文件记录指针的当前位置 void seek(long pos)：将文件记录指针定位到pos位置 RandomAccessFile的构造器： public RandomAccessFile(File file,String mode)：mode参数用于指定访问模式 public RandomAccessFile(String name, String mode) mode有四种值： r：以只读方式打开。如果文件不存在，则报异常。 rw：以读写方式打开，可读可写。如果文件不存在，会自动创建文件。 rwd：可读可写，并且同步文件内容的更新 rws：可读可写，同步文件内容和元数据的更新 RandomAccessFile对象写数据，是以对目标文件覆盖的形式写入，默认指针从头开始，将内容逐个覆盖。可以通过指针实现文件内容插入的操作。 实现内容插入效果： 12345678910111213141516171819202122232425public class RandomAccessFileTest { /* 使用RandomAccessFile实现数据的插入效果,从第3个位置插入数据 */ @Test public void test3() throws IOException { RandomAccessFile raf1 = new RandomAccessFile(\"hello.txt\",\"rw\"); raf1.seek(3);//将指针调到角标为3的位置 //保存指针3后面的所有数据到StringBuilder中 //也可以将StringBuilder替换为ByteArrayOutputStream StringBuilder builder = new StringBuilder( (int) new File(\"hello.txt\").length()); byte[] buffer = new byte[20]; int len; while((len = raf1.read(buffer)) != -1){ builder.append(new String(buffer,0,len)) ; } //调回指针，写入“xyz” raf1.seek(3); raf1.write(\"xyz\".getBytes()); //将StringBuilder中的数据写入到文件中 raf1.write(builder.toString().getBytes()); raf1.close(); }} 十一、NIO.2中Path/Paths/Files类的使用JDK1.4版本提出NIO（New IO，Non-Blocking IO），以更高效的方式进行文件的读写操作。 JDK1.7对NIO进行了扩展，称之为NIO.2。早期的File类功能有限，大部分方法出错时仅返回失败，不会提供异常信息。NIO.2引入了Path接口，并提供了Files、Paths工具类，都声明在java.nio.file包下。 Path接口可以看成File类的升级版本，表示一个文件或目录，文件或目录可以不存在。 使用Path接口创建对象：Path path = Paths.get(\"hello.txt\"); Paths工具类，提供静态的get()方法用来获取Path对象： static Pathget(String first, String … more)：用于将多个字符串串连成路径 static Path get(URI uri)：返回指定uri对应的Path路径 Path接口常用方法 String toString()：返回调用Path对象的字符串表示形式 boolean startsWith(String path):判断是否以path路径开始 boolean endsWith(String path):判断是否以path路径结束 boolean isAbsolute():判断是否是绝对路径 Path getParent()：返回Path对象包含整个路径，不包含Path对象指定的文件路径 Path getRoot()：返回调用Path对象的根路径 Path getFileName():返回与调用Path对象关联的文件名 int getNameCount() :返回Path根目录后面元素的数量 Path getName(int idx):返回指定索引位置idx的路径名称 Path toAbsolutePath():作为绝对路径返回调用Path对象 Path resolve(Path p):合并两个路径，返回合并后的路径对应的Path对象 File toFile():将Path转化为File类的对象 Files工具类常用方法 Path copy(Path src, Path dest, CopyOption … how):文件的复制 Path createDirectory(Path path, FileAttribute&lt;?&gt; … attr) :创建一个目录 Path createFile(Path path, FileAttribute&lt;?&gt; … arr):创建一个文件 void delete(Path path) :删除一个文件/目录，如果不存在，执行报错 void deleteIfExists(Path path): Path对应的文件/目录如果存在，执行删除 Path move(Path src, Path dest, CopyOption…how):将src移动到dest位置 long size(Path path) :返回path指定文件的大小 用于判断： boolean exists(Path path, LinkOption … opts) :判断文件是否存在 boolean isDirectory(Path path, LinkOption … opts):判断是否是目录 boolean isRegularFile(Path path, LinkOption … opts) :判断是否是文件 boolean isHidden(Path path):判断是否是隐藏文件 boolean isReadable(Path path):判断文件是否可读 boolean isWritable(Path path) :判断文件是否可写 boolean notExists(Path path, LinkOption … opts):判断文件是否不存在 用于操作内容： SeekableByteChannel newByteChannel(Path path, OpenOption…how):获取与指定文件的连接，how指定打开方式。 DirectoryStream&lt;Path&gt; newDirectoryStream(Path path) :打开path指定的目录 InputStream newInputStream(Path path, OpenOption…how):获取InputStream对象 OutputStream newOutputStream(Path path, OpenOption…how):获取OutputStream对象","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记12-泛型","slug":"java-note-1201","date":"2021-04-11T04:30:29.000Z","updated":"2022-05-22T13:30:54.794Z","comments":true,"path":"2021/04/11/java-note-1201/","link":"","permalink":"http://kangshitao.github.io/2021/04/11/java-note-1201/","excerpt":"泛型的使用，自定义泛型，泛型通配符","text":"一、泛型的引入JDK 5.0引入了泛型(Genetic)。JDK 5.0之前的集合容器类在声明阶段无法确定容器内存的什么类型数据，JDK 5.0中将元素类型设计为一个参数，这个类型参数就是泛型。例如Collection&lt;E&gt;、List&lt;E&gt;、ArrayList&lt;E&gt;中的&lt;E&gt;就是类型参数，即泛型。 定义：泛型就是允许在定义类、接口时通过一个标识表示类中某个属性的类型或者是某个方法的返回值及参数类型。这个类型参数将在使用时（例如继承或实现这个接口、用这个类型声明变量、创建对象时）确定（即传入实际的类型参数，也称为类型实参）。 如果没有泛型，任何类型都可以添加到集合中，类型不安全，且读取出来的对象需要强制转换，可能会有ClassCastException异常。使用泛型可以在编译时就检查，只有指定类型才可以添加到集合中。 二、在集合中使用泛型集合接口或集合类在jdk5.0时都修改为带泛型的结构。 在实例化集合类时，可以指明具体的泛型类型。指明完以后，在集合类或接口中凡是定义类或接口时，内部结构（比如：方法、构造器、属性等）使用到类的泛型的位置，都指定为实例化的泛型类型。比如：add(E e)，实例化以后：add(Integer e) 注意点： 泛型的类型必须是类，不能是基本数据类型。需要用到基本数据类型的位置，用包装类替换。 如果实例化时没有指明泛型的类型，默认类型为java.lang.Object类型。 以List为例，List实际上表示持有任何Object类型的原生List，而List&lt;?&gt;表示具有某种特定类型的非原生List，只是我们不知道哪种类型是什么 集合中使用泛型的例子： 1234567891011121314151617181920212223public class GenericTest { //在集合中使用泛型,以ArrayList为例 @Test public void test2(){ //指定泛型类型，只能添加Integer类型 ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); //也可以写成以下形式，JDK 7.0新增的类型推断功能 //ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(78); list.add(87); //编译时，就会进行类型检查，保证数据的安全 //添加的类型不是Integer时，编译时就会报错 //list.add(\"Tom\"); //迭代器中使用泛型 Interator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext()){ //不需要判断类型，一定是Integer int num = iterator.next(); System.out.println(num); } }} 泛型的嵌套使用： 12345678910111213141516171819202122public class GenericTest { //在集合中使用泛型的情况：以HashMap为例 @Test public void test3(){ //Map&lt;String,Integer&gt; map = new HashMap&lt;String,Integer&gt;(); //类型推断 Map&lt;String,Integer&gt; map = new HashMap&lt;&gt;(); map.put(\"Tom\",87); map.put(\"Jerry\",87); map.put(\"Jack\",67); //泛型的嵌套 Set&lt;Map.Entry&lt;String,Integer&gt;&gt; entry = map.entrySet(); Iterator&lt;Map.Entry&lt;String, Integer&gt;&gt; iterator = entry.iterator(); while(iterator.hasNext()){ Map.Entry&lt;String, Integer&gt; e = iterator.next(); String key = e.getKey(); Integer value = e.getValue(); System.out.println(key + \"=\" + value); } }} 三、自定义泛型结构可以在类、接口以及方法上使用泛型，分别为泛型类、泛型接口、泛型方法。 1、泛型类与泛型接口 泛型类可以有多个参数，此时应将多个参数一起放在尖括号内，比如class Test&lt;E1,E2,E3&gt;。 泛型类的构造器不能有尖括号结构，和一般类的构造器一样。 类实例化以后，操作原来泛型位置的结构必须与指定的泛型类型一致。 泛型不同的引用不能相互赋值，比如List&lt;Object&gt; list = new ArrayList&lt;String&gt;();是错误的，提示无法类型转换。 泛型如果不指定，将被擦除，泛型对应的类型均按照Object处理，但不等价于Object。建议如果使用泛型就一直使用泛型，如果不使用就都不使用。泛型擦除后，编译不会进行类型检查。 12345678910111213public class Test { public static void main(String[] args) { //使用时：类似于Object，但不等同于Object ArrayList list = new ArrayList(); list.add(33); test(list); //泛型擦除，编译不会类型检查 //一旦指定Object，编译会类型检查，必须按照Object处理 ArrayList&lt;Object&gt; list2 = new ArrayList&lt;Object&gt;(); //test(list2); //会报错，类型必须相同 } public static void test(ArrayList&lt;Integer&gt; list) { }} 如果泛型结构是接口或抽象类，则不可创建泛型类的对象。 在类/接口上声明的泛型，在本类或本接口中即代表某种类型，可以作为非静态属性的类型、非静态方法的参数类型、非静态方法的返回值类型。但在静态方法中不能使用类的泛型，因为类的泛型是在实例化时指定的，静态方法不需要通过对象调用。 异常类不能是泛型的，try-catch中不能用泛型。 不能实例化泛型，即不能new E[]，可以先声明Object类型的数组，然后强制转换：E[] elements = (E[])new Object[capacity];参考ArrayList源码中的声明Object[] elementData;，而非泛型参数类型数组。 123456public class Order&lt;T&gt; { public Order(){ T[] arr = new T[10]; //错误，编译不通过 T[] arr = (T[]) new Object[10]; //正确，编译通过 }} 父类有泛型，子类可以选择指定泛型类型或者保留泛型： 子类不保留父类的泛型：按需实现 如果没有类型，则进行擦除 指定具体类型 子类保留父类的泛型：泛型子类。泛型子类在实例化时可以指定泛型类型 全部保留 部分保留 结论：子类必须在保留或者指定二者之间做出选择。此外，子类除了指定或保留父类的泛型，还可以额外增加自己的泛型。 比如下面的例子： 12345678910class Father&lt;T1,T2&gt;{}//子类不保留父类泛型class Son1 extends Father{} //1.没有类型，擦除//2.指定类具体类型。这时的Son2类不是泛型子类，只是个普通的类。class Son2 extends Father&lt;Integer,String&gt;{} //子类保留父类泛型//Son3和Son4都是泛型子类，因为它们都有泛型class Son3&lt;T&gt; extends Father&lt;T1,T2&gt;{} //1.全部保留。子类可以有自己的泛型class Son4 extends Father&lt;Integer,T2&gt;{} //2.部分保留 2、泛型方法方法中也可以使用泛型，泛型方法中可以定义泛型参数，此时参数的类型就是传入数据的类型。 泛型方法的泛型与类的泛型无关，即泛型方法所在的类是不是泛型类没有关系。 只使用类的泛型的方法不是泛型方法。 泛型方法可以是静态的，因为静态方法在调用的时候会指定泛型方法的类型参数。 泛型方法的格式： 权限符 &lt;泛型&gt; 返回类型 方法名（泛型 参数1，...） 比如： 1234567891011121314public class Test { //返回值前面的&lt;E&gt;泛型必须要有。参数传入的泛型类型就是E的类型 public static &lt;E&gt; List&lt;E&gt; copyFromArrayToList(E[] arr){ //泛型方法 //传入的String类型，此时方法中用到泛型的地方都是String类型 ArrayList&lt;E&gt; list = new ArrayList&lt;&gt;(Arrays.asList(arr)); System.out.println(list); return list; } @Test public void test(){ String[] a = new String[]{\"AA\",\"BB\",\"CC\"}; copyFromArrayToList(a); //传入的String类型 }} 四、泛型在继承上的体现如果类A是类B的父类，那么class &lt;A&gt; 和class &lt;B&gt;二者不具备子父类关系，二者是并列关系。 比如ArrayList&lt;Object&gt; list1和ArrayList&lt;String&gt; list2，那么list1 = list2是错误的。 如果A是类B的父类，A&lt;E&gt;是 B&lt;E&gt;的父类。 举例： 12345678910111213141516171819202122232425public class GenericTest { @Test public void test1(){ Object obj = null; String str = null; obj = str; //正确，String是Object的子类 List&lt;Object&gt; list1 = null; List&lt;String&gt; list2 = new ArrayList&lt;String&gt;(); //此时的list1和list2的类型不具有子父类关系 list1 = list2; //错误，编译不通过 /*反证法： 假设list1 = list2正确 那么list1.add(123)会导致混入非String的数据，出错。 */ } @Test public void test2(){ List&lt;String&gt; list1 = null; ArrayList&lt;String&gt; list2 = null; //ArrayList是List的实现类，可以赋值，但是必须保证泛型参数相同 list1 = list2; }} 五、通配符通配符?代表具体的类型参数，例如List&lt;?&gt;是List&lt;String&gt;、List&lt;Object&gt;等各种泛型List的父类。 假设现在有List&lt;?&gt;的一个对象list，那么可以安全读取list中的元素，因为一定是Object类型的。不可以向list中写入元素，因为不知道list中元素的类型，但是可以写入null，其他都都不可以。 代码举例： 1234567891011121314151617181920public class Test{ @Test public void test3(){ List&lt;Object&gt; list1 = null; List&lt;String&gt; list2 = null; List&lt;?&gt; list = new ArrayList&lt;&gt;(); //list是list1和list2的父类 list = list1;//正确 list = list2;//正确 //添加(写入)：对于List&lt;?&gt;不能向其内部添加数据。 //除了添加null之外。 list.add(\"DD\"); //错误 list.add(null); //正确 //获取(读取)：允许读取数据，读取的数据类型为Object。 Object o = list.get(0); //可以读取数据，类型是Object System.out.println(o); }} 注意点： public static &lt;?&gt; void test(ArrayList&lt;?&gt; list){}编译错误，不能用在泛型方法声明上，返回值类型前面&lt;&gt;不能使用?通配符。返回值必须是确定的类型。 class GenericTypeClass&lt;?&gt;{}编译错误，?不能用在泛型类的声明上。 ArrayList&lt;?&gt; list2 = new ArrayList&lt;?&gt;();编译错误，?不能用在创建对象上，右边属于创建集合对象，必须是确定的类型。 有限制的通配符 ? extends A：理解为&lt;=A类，类型限定了只能是A类或者是A类的子类。 class&lt;? extends A&gt;可以作为class&lt;A&gt;和class&lt;B&gt;的父类，其中B是A的子类 ? super A：理解为&gt;=A类，类型限定了只能是A类或者是A类的父类。 class&lt;? super A&gt;可以作为class&lt;A&gt;和class&lt;B&gt;的父类，其中B是A的父类 对于接口，&lt;? extends Comparable&gt;表示只允许泛型为实现Comparable接口的实现类的引用调用。 使用举例： 123456789101112131415161718192021222324252627282930313233343536373839public class GenericTest { @Test public void test4(){ List&lt;? extends Person&gt; list1 = null; //只能是Person或Person的子类 List&lt;? super Person&gt; list2 = null; //只能是Person或Person的父类 List&lt;Student&gt; list3 = new ArrayList&lt;Student&gt;(); List&lt;Person&gt; list4 = new ArrayList&lt;Person&gt;(); //Person是Student的父类 List&lt;Object&gt; list5 = new ArrayList&lt;Object&gt;(); list1 = list3; //正确 list1 = list4; //正确 list1 = list5; //错误 list2 = list3; //错误 list2 = list4; //正确 list2 = list5; //正确 //读取数据： list1 = list3; Person p = list1.get(0); //要用最大类型接收 //编译不通过，因为如果是Person类型，不能赋给Student引用 //Student s = list1.get(0); list2 = list4; Object obj = list2.get(0); //用Object类型接收 //编译不通过，因为如果是Person的父类，不能赋给Person引用 //Person obj = list2.get(0); //写入数据： //编译不通过，extends不能写 //list1.add(new Student()); //编译通过 //super可以写 list2.add(new Person()); list2.add(new Student()); }} 总结： 使用extends通配符只能读，不能写(只能写null)，类似于?通配符。因为有上限，返回的任意类型都能够向上转型到确定的类型，但是不允许使用set方法传入引用(null除外)。 使用super通配符可以写，也可以读。写的时候可以安全地向上转型，读的时候，只能使用Object类型接收，因为Object是所有类的根父类，可以向上转型为Object。","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记11-Java集合","slug":"java-note-1101","date":"2021-04-09T14:11:30.000Z","updated":"2022-05-22T13:30:54.794Z","comments":true,"path":"2021/04/09/java-note-1101/","link":"","permalink":"http://kangshitao.github.io/2021/04/09/java-note-1101/","excerpt":"Java集合框架，Collection，List，Set，Iterator，Map，Collections工具类","text":"一、Java集合框架概述1、概述Java集合像一种容器，可以动态地把多个对象的引用放入容器中。 数组在存储方面的特点： 数组初始化以后长度确定。 声明的类型决定了元素初始化时的类型。 数组存储数据的缺点： 初始化以后长度就不可变，不便于扩展。 提供的属性和方法少，不便于添加删除、插入等操作，效率不高，无法直接获取元素个数。 数据有序、可以重复，存储数据的特点单一。 Java集合类可以用户存储数量不等的多个对象，还可用于保存具有映射关系的关联数组。 2、集合框架Java 集合框架图： Java集合框架主要有两个接口，Collection接口和Map接口： Collection接口：单列集合，其包括以下几个接口 List接口：存储有序(指存储位置有序)、可重复的数据 常用实现类为ArrayList、LinkedList、Vector Set接口：存储无序、不可重复的数据 常用实现类有HashSet、LinkedHashSet、TreeSet Queue接口：先进先出 常用实现类有LinkedList、PriorityQueue Map接口：双列集合，用来存储成对的(key-value)数据 常用实现类有HashMap、LinkedHashMap、TreeMap、Hashtable、Properties 无序性指的是存储的数据在底层数组中并非按照数组索引的顺序添加，而是根据数据的哈希值决定的。 二、Collection接口方法向Collection接口的实现类对象中添加数据时，要求此数据所在的类要重写equals()方法。 Collection接口定义了能够用于List/Set/Queue的方法。包括以下方法： 1、添加元素：add(Object obj)、addAll(Collection coll)2、获取有效元素的个数：int size()3、清空集合：void clear()4、是否是空集合：boolean isEmpty()5、是否包含某个元素： boolean contains(Object obj)：是通过元素的equals方法来判断是否是同一个对象 boolean containsAll(Collection c)：也是调用元素的equals方法来比较。拿两个集合的元素挨个比较。 6、删除： boolean remove(Object obj)：通过元素的equals方法判断是否是要删除的那个元素。只会删除找到的第一个元素。 boolean removeAll(Collection coll)：取当前集合的差集。 7、取两个集合的交集：boolean retainAll(Collection c)：把交集的结果存在当前集合中，不影响c本身 8、集合是否相等：boolean equals(Object obj) 9、转成对象数组：Object[] toArray() 数组转换为集合，调用数组的asList()方法： 12345List arr1 = Arrays.asList(new int[]{123, 456});System.out.println(arr1.size());//1，此时添加的是int[]数组对象引用，长度是1List&lt;Integer&gt; arr2 = Arrays.asList(new Integer[]{123, 456});System.out.println(arr2.size());//2，添加的是Integer数组，有两个元素 10、获取对象哈希值：hashCode() 11、遍历：iterator()，返回迭代器对象，用于集合遍历 三、Iterator迭代器接口Collection接口继承了Iterator&lt;E&gt;接口，该接口有iterator()方法，因此Collection的实现类都有这个方法，调用此方法返回一个实现了Iterator接口的对象，可以用于遍历： 123456789Collection coll = new ArrayList(); //以ArrayList为例Iterator iterator = coll.iterator(); //返回一个迭代器对象// Iterator&lt;Integer&gt; iterator = coll.iterator(); //Iterator是泛型类while(iterator.hasNext()){ Object obj = iterator.next(); if(obj.equals(\"xxx\")){ iter.remove(); }} Iterator接口的三个方法： boolean hasNext()：判断是否有下一个值 E next()：指针下移，并返回下移以后指向的值，E是泛型 void remove()：移除当前指向的值。执行remove操作后，需要执行next才能进行下一步操作 迭代器指针初始第一个元素之前，需要next()操作才指向第一个值。 集合对象每次调用iterator()方法都得到一个全新的迭代器对象，默认游标都在集合的第一个元素之前。 JDK 5.0新增了foreach循环，用于遍历集合、数组，foreach内部仍然使用了迭代器： 123456789101112131415/*for (元素类型 局部变量：集合或数组对象){ //方法体}*///遍历集合ArrayList&lt;Integer&gt; a = new ArrayList&lt;&gt;();for(Integer i : a){ System.out.println(i);}//遍历数组int[] array = new int[]{1,2,3};for(int i:array){ System.out.println(i);} 四、Collection子接口一：List1、List接口方法除了从Collection接口继承的方法以外，List接口还新增了一些根据索引操作集合元素的方法： void add(int index, Object ele):在index位置插入ele元素 boolean addAll(int index, Collection eles):从index位置开始将eles中的所有元素添加进来 Object get(int index):获取指定index位置的元素 int indexOf(Object obj):返回obj在集合中首次出现的位置 int lastIndexOf(Object obj):返回obj在当前集合中末次出现的位置 Object remove(int index):移除指定index位置的元素，并返回此元素 List接口继承了Collection中的方法，包括remove(Object obj)方法。remove(2)默认认为是索引2，remove(new Integer(2))才认为删除的是对象。 Object set(int index, Object ele):设置指定index位置的元素为ele List subList(int fromIndex, int toIndex):返回从fromIndex到toIndex位置的子集合 2、实现类List存储有序的、可重复的数据，常用实现类，三者的对比： ArrayList：List接口主要实现类，适合频繁查找；线程不安全，效率高；底层使用数组实现：Object[] elementData；扩容时默认为原来的1.5倍 LinkedList：适合频繁插入、删除操作；线程不安全；底层使用双向链表存储； Vector：List接口的早期实现类，与ArrayList几乎相同；线程安全，因此效率低；底层同样使用数组实现；与ArrayList另一点不同是扩容时扩大为原来的2倍 (JDK15中，Vector和ArrayList扩容机制相同)。此外，Vector还有一个子类Stack。 3、ArrayListArrayList对象在JDK 7.0和JDK 8.0中的创建过程不同，JDK 7.0中创建ArrayList对象类似于单例模式的饿汉式，8.0中类似于单例模式的懒汉式，延迟了数组的创建，节省内存。 JDK 7.0中，创建ArrayList对象的过程： ArrayList list = new ArrayList(); 初始化时底层创建长度是10的Object[]数组elementDatalist.add(123); 底层执行elementData[0] = new Integer(123);操作…list.add(11); 如果此次的添加导致底层elementData数组容量不够，则扩容。默认情况下，扩容为原来的容量的1.5倍，同时需要将原有数组中的数据复制到新的数组中。 结论：建议开发中使用带参的构造器：ArrayList list = new ArrayList(int capacity)，防止频繁扩容降低效率 JDK 8.0中，创建ArrayList对象过程： ArrayList list = new ArrayList(); 底层Object[] elementData初始化为{}，并没有创建长度为10的数组 list.add(123); 第一次调用add()时，底层才创建了长度10的数组，并将数据123添加到elementData[0]…后续的添加和扩容操作与JDK 7 无异。 4、LinkedListLinkedList类新增了其特有的方法，方便对双向链表操作： void addFirst(Object obj) void addLast(Object obj) Object getFirst() Object getLast() Object removeFirst() Object removeLast() LinkedList创建对象的过程： LinkedList list = new LinkedList(); 内部声明了Node类型的first和last属性，默认值为nulllist.add(123); 将123封装到Node中，创建了Node对象(创建链表节点，add方法用尾插法插入节点)。 其中，LinkedList的双向链表中的节点用Node表示，实现如下： 1234567891011121314public class LinkedList&lt;E&gt;...{ ... private static class Node&lt;E&gt; { //内部类：Node，构造每个链表节点 E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) { //构造器 this.item = element; this.next = next; this.prev = prev; } } ...} 五、Collection子接口二：Set1、Set概述Set接口是Collection的子接口，Set接口没有提供额外的方法。 Set存储无序、不可重复的数据。添加相同的元素会添加失败。 Set根据equals判断两个对象是否相同。 Set接口的常用实现类有： HashSet：是Set接口的主要实现类；线程不安全；可以存储null值 LinkedHashSet：HashSet的子类；遍历其内部数据时按照添加的顺序遍历，对于频繁的遍历操作效率高于HashSet TreeSet：按照添加对象的制定属性进行排序。 向Set(主要指：HashSet、LinkedHashSet)中添加的数据，其所在的类一定要重写hashCode()和equals()。因为添加数据时要用到两个方法进行判断。 重写的hashCode()和equals()尽可能保持一致性：相等(equals返回true)的对象必须具有相等的散列码，不相等的对象尽量有不同的散列码。 对象中用作 equals() 方法比较的 Field，都应该用来计算 hashCode 值。 重写hashCode方法中，用到31这个数字的原因： 选择系数的时候要选择尽量大的系数。因为如果计算出来的hash地址越大，哈希冲突出现的次数越少，查找起来效率也会提高。（减少哈希冲突） 并且31只占用5bits,相乘造成数据溢出的概率较小。 31可以由i*31== (i&lt;&lt;5)-1来表示,现在很多虚拟机里面都有做相关优化。（提高算法效率） 31是一个素数，素数作用就是如果我用一个数字来乘以这个素数，那么最终出来的结果只能被素数本身和被乘数还有1来整除！(减少冲突) 哈希冲突指不同的哈希值(不同的数据)通过哈希函数得到的哈希值(索引位置)是相同的。解决哈希冲突的方法有：开放地址法、链式地址法(HashMap采用的方法)、建立公共溢出区、再哈希法。 2、HashSetHashSet底层采用HashMap实现，Set就是HashMap中的Key，Value是统一定义的空对象，源代码中的Value：private static final Object PRESENT = new Object(); 其底层原理和HashMap相同，使用了数组和链表（JDK8中加入了红黑树），具体见HashMap解析。 HashSet添加元素的过程，与HashMap相同，实现原理参考下文的HashMap。 3、TreeSetTreeSet中添加的数据要求是相同类的对象，其可以根据自然排序和定制排序两种方式排序。 TreeSet中比较两个对象是否相同的标准是compareTo()/compare()返回0。 TreeSet用TreeMap实现，底层使用红黑树结构存储数据。 红黑树： 红黑树是一种自平衡的二叉查找树。红黑树牺牲部分平衡性，换取插入/删除操作时少量的旋转次数，但是搜索效率下降，总体性能优于AVL树（平衡二叉搜索树）。 红黑树定义： 结点是红色或黑色。 根节点是黑色。 所有叶子节点都是黑色(叶子节点是NIL节点，即空对象) 每个红色节点的两个子节点都是黑色。（从每个叶子到根的所有路径上不能有两个连续的红色结点） 从任意一个节点到其每个叶子节点的所有路径，包含相同数量的黑色节点。（保证了从根到叶子节点的最长路径不超过最短路径的两倍长，最多是两倍 ） 六、Map接口1、概述Map与Collection并列存在，用于保存具有映射关系的双列数据：key-value对。 Map结构的理解： key：使用Set存放key，无序，不可重复，key所在类必须重写hashCode()和equals()方法，因为添加数据时要用到，而Object类中的hashCode()没有方法体。 value：用Collection存放，无序，可重复，value所在的类要重写equals()方法。 entry：一个key-value构成一个entry，entry构成的集合是Set，是无序，不可重复的。 两个key相同需要保证：equals方法返回true并且hashCode得到的值相等： 如果a和b相等，那么a.equals(b)一定为true，则a.hashCode()必须等于b.hashCode()； 如果a和b不相等，那么a.equals(b)一定为false，则a.hashCode()和b.hashCode()尽量不要相等。 Map接口几个实现类的对比： HashMap：Map的主要实现类；线程不安全，效率高；允许存储null的key和value LinkedHashMap：HashMap子类，在原有的HashMap基础上添加了一对指针，指向前一个元素和后一个元素，因此可以按照添加的顺序遍历。对于频繁遍历操作，效率高于HashMap。 TreeMap：保证按照添加的key-value对进行排序，实现排序遍历；根据key进行自然排序或定制排序；底层使用红黑树 Hashtable：原始的Map实现类；线程安全，效率低；不能存储null的key和value Properties：Hashtable的子类，常用来处理配置文件，其key和value都是String类型。 2、Map接口方法Map接口中定义的方法如下： 添加、删除、修改操作： V put(K key,V value)：将指定key-value添加到(或修改)当前map对象中，并返回value的值 void putAll(Map m):将m中的所有key-value对存放到当前map中 V remove(Object key)：移除指定key的key-value对，并返回value boolean remove(Object key, Object value)：移除指定key和value的key-value对，并返回boolean类型 void clear()：清空当前map中的所有数据 元素查询的操作： V get(Object key)：获取指定key对应的value V getOrDefault(Object key, V defaultValue)：如果指定的key值不存在，返回defaultValue boolean containsKey(Object key)：是否包含指定的key boolean containsValue(Object value)：是否包含指定的value int size()：返回map中key-value对的个数 boolean isEmpty()：判断当前map是否为空 boolean equals(Object obj)：判断当前map和参数对象obj是否相等 元视图操作的方法： Set&lt;K&gt; keySet()：返回所有key构成的Set集合 Collection&lt;V&gt; values()：返回所有value构成的Collection集合 Set&lt;Entry&lt;K,V&gt;&gt; entrySet()：返回所有key-value对构成的Set集合 3、HashMapHashMap是Map接口最常用的实现类。在JDK 7.0版本和JDK 8.0版本中，HashMap的底层实现原理不同。 HashMap中的Entry数组，这个数组中可以存储元素的位置称为“桶(bucket)”，每个bucket都有指定的索引，系统可以根据索引快速访问该bucket里存储的元素。 JDK 7.0中创建HashMap对象的过程： HashMap map = new HashMap(); 实例化，底层创建了长度是16的一维数组Entry[] table。map.put(key1,value1);执行put操作，首先，调用key1所在类的hashCode()和HashMap中的扰动方法hash()计算key1哈希值，此哈希值经过某种算法(int index = (n - 1) &amp; hash;)计算以后，得到在Entry数组中的存放位置。 如果此位置上的数据为空，此时的key1-value1添加成功。 ——&gt;情况1 如果此位置上的数据不为空(哈希冲突/碰撞。此位置上的存在一个或多个数据以链表形式存在),比较key1和已经存在的一个或多个数据的哈希值（这里比较的是经过hash()方法计算得出的哈希值）： 如果key1的哈希值与已经存在的数据的哈希值都不相同，此时key1-value1添加成功。——&gt;情况2 如果key1的哈希值和已经存在的某一个数据(key2-value2)的哈希值相同，继续比较：调用key1所在类的equals(key2)方法： 如果equals()返回false：此时key1-value1添加成功。——&gt;情况3 如果equals()返回true：使用value1替换value2（如果在HashSet中，这种情况会添加失败，但是在Map中则是进行value覆盖）。 对于添加成功的情况2和情况3而言：元素a 与已经存在指定索引位置上数据以链表的方式存储。 关于HashMap的说明 hashCode()得到原始的哈希值，Java中又使用了hash()方法进行扰动，得到哈希值以后没有直接作为索引(直接将哈希值作为索引，数值太大)，而是使用与操作计算在数组中的索引，JDK7和8中的计算索引方法相同：int index = (table.length - 1) &amp; hash; 扰动函数hash()的作用（源码注释：JDK7中为了防止低效的哈希函数，JDK8中是为了解决JDK7中只考虑低位的缺陷），JDK8中，改变了hash()的实现，将哈希值的高位和低位混合，加大低位的随机性，从而在获得数组索引时减少冲突（这种冲突是由于计算索引值引起的），因为只算低位的话，就算哈希值不同，也可能得到相同的索引值引起冲突。如果是hashCode()计算出不同数据的哈希值相同（哈希冲突），hash()方法是解决不了的。hash()的具体解析可以参考链接。 12345678910111213141516171819//JDK 7中的hash方法 final int hash(Object k) { int h = 0; if (useAltHashing) { if (k instanceof String) { return sun.misc.Hashing.stringHash32((String) k); } h = hashSeed; } h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); }}//JDK 8中的hash方法 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); }//将原始哈希值的高位和其本身异或，减少计算索引时出现的冲突。 哈希冲突指的是不同的数据映射到了相同的位置（不同数据的哈希值相同），在HashMap中出现冲突有两个原因，一个是hashCode()计算的哈希值相同引起的哈希冲突，另一个是不同哈希值但是经过索引计算映射到了同一个位置。JDK8中hashCode()得到的哈希值相同，则hash()得到的也相同，hashCode()得到的哈希值不同，那么hash()得到的值肯定也不同。 所以在添加数据时，如果此位置上已有数据（出现哈希冲突），需要判断哈希值（hash()返回值）是否相同，如果哈希值不同却出现在了同一个位置（情况2），是由于Java中计算索引的方法导致的，可以直接添加；如果哈希值相同（hashCode()计算出的哈希值相同引起哈希冲突），这时只能通过equals()方法比较是不是相同的数据，如果是相同的数据，则进行覆盖，否则就添加。 JDK 8.0创建HashMap对象与JDK 7.0其他的不同： new HashMap()初始化时，底层没有创建一个长度为16的数组，首次调用put()方法时才创建，这一点类比于ArrayList在两个版本的区别。 JDK 8.0底层数组是Node[]，而非Entry[]，实际上内部类Node实现了内部接口Entry： 1234567891011121314151617181920212223242526public class HashMap&lt;K,V&gt;...{ //内部类Node static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; V value; Node&lt;K,V&gt; next; //Node[]数组中每个位置存储一个Node对象，每个对象的next引用指向下一个元素 //在JDK 7中，同样，每个Entry[]数组的每个位置存储一个Entry对象，有next指针 Node(int hash, K key, V value, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } ... //内部类中的其他方法，比如实现的getKey()、getValue()等 } //内部接口 Entry interface Entry&lt;K, V&gt; { K getKey(); V getValue(); ... } ...//HashMap中的其他方法} JDK 7.0底层结构是数组+链表，JDK 8.0底层结构是数组+链表+红黑树，因此添加到已有元素的位置上时，需要判断是链表节点还是树节点。 JDK 8.0中，当某个bucket的链表长度&gt;8，并且数组长度（容量,capacity,table的长度）&gt;64时，才将链表改为红黑树。如果仅是长度&gt;8，数组容量不到64，会进行扩容。 如果映射关系被移除，下次resize方法时判断树的节点个数&lt;6，会将树转为链表。这里为了避免树和链表频繁转换带来的效率损失，才使用6，而没有直接选择8。 形成链表时，和ArrayList相同（七上八下）。JDK 7.0中，冲突时使用头插法将新节点插入到链表，由于是线程不安全的，可能导致出现环形链表(链表死循环)。JDK 8.0使用尾插法解决了这一问题。 HashMap的重要常量： DEFAULT_INITIAL_CAPACITY：HashMap的默认容量，16 DEFAULT_LOAD_FACTOR：HashMap的默认加载因子：0.75 threshold：扩容的临界值 = 容量 x 填充因子，比如16*0.75=12 TREEIFY_THRESHOLD：Bucket中链表长度大于改值时，就转化为红黑树：8 MIN_TREEIFY_CAPACITY：桶中的Node被树化时最小的hash表容量：64 MAXIMUM_CAPACITY：HashMap最大支持容量： 2^{30} table：存储元素的数组，总是2的n次幂 entrySet：存储所有entry元素的集合（Set） size：存储的键值对的数量 modCount：HashMap扩容和结构改变的次数。 链表长度大于8并且容量大于64时，才变为红黑树，为什么是8？为什么容量要大于64？ 答：阈值为8是出于时间和空间两方面权衡。哈希值离散性理想情况下，链表长度达到8的几率很小，bin中的节点分布频率服从泊松分布，链表长度大于8的几率小于千万分之一，此情况下如果仍达到了8个节点，说明节点数以后很可能还会继续增加，需要使用红黑树优化查找效率。另一方面，树节点占用空间是普通节点的2倍，如果阈值太小，频繁使用树结构会造成空间浪费。 关于容量大于64，源码中解释： 123456/*The smallest table capacity for which bins may be treeified.(Otherwise the table is resized if too many nodes in a bin.)Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts between resizing and treeification thresholds.*/ 也就是说，为了避免扩容和树化阈值之间的冲突，至少需要4x8=32个bin，如果长度太小，树化以后，如果扩容可能还需要树化，降低了效率。底层数组容量一直是2的n次幂，要想保证32个位置有元素，考虑0.75负载因子，至少需要64的长度。 HashMap的扩容机制： 添加数据时，当当前存放的值（size）超出临界值（threshold）且要存放的位置非空时会扩容，默认的扩容方式是扩容为原来容量的2倍，然后重新计算旧数组中节点的存储位置并复制过去。由于是扩容为2倍，索引计算方式为哈希值和数组长度-1进行与操作，得到的新数组索引要么是原下标位置，要么是原下标+原数组大小。 JDK 7采用头插法将每个bucket上的链表依次取出并放到新数组指定的位置，结果是链表顺序会变反。并且在多线程的情况下，容易导致链表循环。想要线程安全，可以使用ConcurrentHashMap JDK 8采用尾插法，解决了链表循环的问题。 Java的HashMap解决哈希冲突的方法： 使用链地址法，链接相同位置上的数据。 使用2次扰动函数（源码中的hash()函数），将hashCode()得到的哈希值的高位和低位混合，加大低位的随机性，使哈希值映射到数组索引更平均。 JDK 8.0中又引入红黑树，进一步降低遍历的时间复杂度，使遍历更快 LinkedHashMap LinkedHashMap是HashMap的子类，其在HashMap的存储基础上，使用双向链表记录添加元素的顺序。 与LinkedHashSet类似，LinkedHashMap可以维护Map的迭代顺序，迭代顺序与Key-value对插入顺序一致。 LinkedHashMap中的存储结构： 1234567891011121314public class LinkedHashMap&lt;K,V&gt; extends HashMap&lt;K,V&gt; implements Map&lt;K,V&gt;{ ... static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; { //Entry有两个额外的指针，分别指向上一个和下一个节点 Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) { super(hash, key, value, next); } } ...} JDK 8中HashMap添加数据的过程源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class HashMap&lt;K,V&gt;...{ ... final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果table为空，扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果目标位置为空，创建新节点并添加 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //如果目标位置有值，进一步判断 else { Node&lt;K,V&gt; e; K k; //如果目标位置的值，hash值和数据都相同，进行覆盖 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果目标位置的值和要添加的值不同，则添加。 //判断是链表节点还是树节点，如果是树节点，调用putTreeVal else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //如果是链表节点，需要依次往下遍历 else { //遍历当前链表 for (int binCount = 0; ; ++binCount) { //如果到达链表尾部，则新建链表节点，并不马上插入节点 //需要判断当前已有节点个数，是否需要树化 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); //如果此时链表已经有了8个节点，调用treeifyBin树化 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //此方法会额外判断table数组长度是否大于64， //如果大于64才构造红黑树，否则执行扩容操作 treeifyBin(tab, hash); break; } //如果找到和待添加的值相同的数据，则break if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; //如果既没有到达末尾，也没有找到相同数据，则将e赋给p，继续向后找 p = e; } } //进行value覆盖 if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size &gt; threshold) resize(); //判断添加数据以后是否需要扩容 afterNodeInsertion(evict); return null; } ...} 关于HashMap的常见问题，可以参考HashMap数据结构相关知识总结 4、TreeMap保证按照添加的key-value对进行排序，实现排序遍历。只考虑key的自然排序或定制排序。使用自然排序或定制排序的方法比较key的大小，而不是equals()方法。 底层使用红黑树结构。 5、HashtableHashMap 和 Hashtable 的区别 HashMap 是线程不安全的，Hashtable 是线程安全的； 由于线程安全，所以 Hashtable 的效率比不上 HashMap； HashMap最多只允许一条记录的键为null，允许多条记录的值为null，而 Hashtable 不允许key和value的值为null； HashMap 默认初始化数组的大小为16，Hashtable 为 11，前者扩容时，扩大两倍，后者扩大两倍+1； HashMap 在hashCode基础上需要重新计算 hash 值，而 Hashtable 直接使用对象的 hashCode。 Properties Properties是Hashtable的子类，用于处理属性文件。 由于属性文件里的key、value都是字符串类型，所以Properties里的key和value都是字符串类型 存取数据时，建议使用setProperty(String key,String value)方法和getProperty(String key)方法： 1234Properties pros = new Properties();pros.load(new FileInputStream(\"jdbc.properties\"));String user = pros.getProperty(\"user\");System.out.println(user); 七、Collections工具类和操作数组的工具类Arrays类似，Collections是操作Set、List、Map等集合的工具类。 Collections提供了一系列静态方法，用于对集合元素的排序、查询和修改等操作： reverse(List)：反转 List 中元素的顺序 shuffle(List)：对 List 集合元素进行随机排序 sort(List)：根据元素的自然顺序对指定 List 集合元素按升序排序 sort(List，Comparator)：根据指定的 Comparator 产生的顺序对 List 集合元素进行排序 swap(List，int i， int j)：将指定 list 集合中的 i 处元素和 j 处元素进行交换 Object max(Collection)：根据元素的自然顺序，返回给定集合中的最大元素 Object max(Collection，Comparator)：根据 Comparator 指定的顺序，返回给定集合中的最大元素 Object min(Collection) Object min(Collection，Comparator) int frequency(Collection，Object)：返回指定集合中指定元素的出现次数 void copy(List dest,List src)：将src中的内容复制到dest中 boolean replaceAll(List list，Object oldVal，Object newVal)：使用新值替换 List 对象的所有旧值 此外，Collections类还提供了多个synchronizedXxx() 方法，该方法可使将指定集合包装成线程同步的集合，从而可以解决多线程并发访问集合时的线程安全问题： static &lt;T&gt; Collection&lt;T&gt; synchronizedCollection(Collection&lt;T&gt; c) static &lt;T&gt; Set&lt;T&gt; synchronizedSet(Set&lt;T&gt; s) static &lt;T&gt; List&lt;T&gt; synchronizedList(List&lt;T&gt; list) static &lt;K,V&gt; Map&lt;K,V&gt; synchronizedMap(Map&lt;K,V&gt; m) static &lt;K,V&gt; NavigableMap&lt;K,V&gt; synchronizedNavigableMap(NavigableMap&lt;K,V&gt; m) static &lt;T&gt; NavigableSet&lt;T&gt; synchronizedNavigableSet(NavigableSet&lt;T&gt; s) static &lt;K,V&gt; SortedMap&lt;K,V&gt; synchronizedSortedMap(SortedMap&lt;K,V&gt; m) static &lt;T&gt; SortedSet&lt;T&gt; synchronizedSortedSet(SortedSet&lt;T&gt; s)","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记10-枚举类与注解","slug":"java-note-1001","date":"2021-04-05T08:50:08.000Z","updated":"2022-05-22T13:30:54.794Z","comments":true,"path":"2021/04/05/java-note-1001/","link":"","permalink":"http://kangshitao.github.io/2021/04/05/java-note-1001/","excerpt":"自定义枚举类、enum、注解(Annotation)","text":"一、枚举类1、什么是枚举类类的对象只有有限个，确定的，称此类为枚举类。比如星期、性别、季节、xx状态等。 当需要定义一组常量时，强烈建议使用枚举类。 如果枚举类中只有一个对象，则可以作为单例模式的实现方式。 属性： 枚举类对象的属性不应允许被改动，所以应该使用private final修饰。 枚举类中使用private final修饰的属性应该在构造器中为其赋值。 若枚举类显式地定义了带参数的构造器，则在列出枚举值时也应该对应地传入参数。 2、自定义枚举类JDK 5.0之前，没有enum关键字，只能自定义枚举类，步骤为： 私有化类的构造器，保证不能在类的外部创建其对象。 在类的内部创建枚举类的实例，声明为：public static final 对象如果有实例变量，应该声明为private final，并在构造器中初始化。 举例说明： 12345678910111213141516171819202122232425262728293031323334public class SeasonTest { public static void main(String[] args) { Season spring = Season.SPRING; System.out.println(spring); }}class Season{ //1.声明对象属性为private final private final String seasonName; //季节名字 private final String seasonDec; //季节描述 //2.构造器应该是private的 private Season(String seasonName,String seasonDec){ this.seasonName = seasonName; this.seasonDec = seasonDec; //{seasonName='春天', seasonDec='春暖花开'} } //3.创建确定个数的实例public static final public static final Season SPRING = new Season(\"春天\",\"春暖花开\"); public static final Season SUMMER = new Season(\"夏天\",\"夏日炎炎\"); public static final Season AUTUMN = new Season(\"秋天\",\"秋高气爽\"); public static final Season WINTER = new Season(\"冬天\",\"冰天雪地\"); //4.根据需求，可以选择性地创建其他函数 public String getSeasonName() { return seasonName;} public String getSeasonDec() { return seasonDec;} @Override public String toString() { return \"{\" + \"seasonName='\" + seasonName + '\\'' + \", seasonDec='\" + seasonDec + '\\'' + '}'; }} 3、使用enum定义枚举类JDK 5.0新增了enum定义枚举类的方式，使用enum定义的枚举类默认继承了java.lang.Enum类，因此不能再继承其他类。 使用说明： 枚举类的构造器只能使用private权限修饰符。 枚举类的所有实例必须在枚举类中显式列出（以,分隔，以;结尾）。列出的实例，系统会自动添加public static final修饰。 必须在枚举类的第一行声明枚举类对象。 JDK 5.0中，switch表达式中可以使用枚举类对象，case子句可以直接使用枚举值的名字，无需添加枚举类作为限定。 使用enum定义枚举类： 12345678910111213141516171819202122232425enum Season{ //1.提供当前枚举类的对象，多个对象之间用\",\"隔开，末尾对象\";\"结束 SPRING(\"春天\",\"春暖花开\"), SUMMER(\"夏天\",\"夏日炎炎\"), AUTUMN(\"秋天\",\"秋高气爽\"), WINTER(\"冬天\",\"冰天雪地\"); //2.声明Season对象的属性:private final修饰 private final String seasonName; private final String seasonDesc; //3.构造器应该是private的，enum里面可以省略private关键字 Season(String seasonName,String seasonDesc){ this.seasonName = seasonName; this.seasonDesc = seasonDesc; } //可以根据需要声明其他方法 public String getSeasonName() { return seasonName; } public String getSeasonDesc() { return seasonDesc; }} 4、Enum类Enum类有以下几个常用方法： values()：静态方法，枚举类调用此方法返回包含此枚举类中所有枚举对象的枚举类型的对象数组。这个方法是Java编译器在编译枚举类的时候自动添加的方法。 valueOf(String str)：把一个字符串str转为对应的枚举类对象。要求str‘必须是枚举类对象的“名字”。如不是，会有运行时异常IllegalArgumentException。 toString：可以被重写 public final boolean equals：枚举类中可以直接使用==比较两个枚举常量是否相等，Enum类中的equals方法也是直接使用==实现的，此方法是为了在Set、List和Map中使用。 public final int hashCode getDeclaringClass：得到枚举常量所属枚举类型的Class对象，可以用来判断两个枚举常量是否属于同一个枚举类型 name：得到当前枚举常量的名字。 ordinal：得到当前枚举常量的次序。 compareTo：枚举类型实现了Comparable接口，比较两个枚举常量的大小(按照声明的顺序排列) protected final Object clone：枚举类型不能被Clone，为了防止子类实现克隆方法，Enum实现了一个仅抛出CloneNotSupportedException异常的final方法clone()。 代码举例： 123456789101112131415161718192021222324252627282930313233343536373839404142public class SeasonTest2 { public static void main(String[] args) { //toString方法： System.out.println(Season2=.SPRING); //SPRING //父类是Enum类 System.out.println(Season2.class.getSuperclass()); //class java.lang.Enum //values方法 Season[] values = Season.values(); for(Season i: values){ System.out.println(i); } /*输出： SPRING SUMMER AUTUMN WINTER */ //valueOf(String str)方法,返回枚举类中，对象名是str的枚举类对象 Season winter = Season.valueOf(\"WINTER\"); System.out.println(winter.toString()); //WINTER //等同于Systou.out.println(winter) //枚举类在switch中的应用 Season season = Season.SPRING; switch (season){ case SPRING: System.out.println(\"春天\"); //输出：春天 break; case SUMMER: System.out.println(\"夏天\"); break; case AUTUMN: System.out.println(\"秋天\"); break; case WINTER: System.out.println(\"冬天\"); break; } }} 5、枚举类实现接口和普通Java类一样，枚举类可以实现一个或多个接口： 若每个枚举值在调用实现的接口方法呈现相同的行为方式，则只要统一实现该方法即可。 若需要每个枚举值在调用实现的接口方法呈现出不同的行为方式,则可以让每个枚举值分别来实现该方法。 比如下面的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class SeasonTest2 { public static void main(String[] args) { //values方法 Season2[] values = Season2.values(); for(Season2 i: values){ System.out.println(i); i.info(); } }}enum Season2 implements Info{ //每个枚举变量单独实现Info接口中的方法 SPRING (\"春天\",\"春暖花开\"){ public void info(){ System.out.println(\"spring\"); } }, SUMMER (\"夏天\",\"夏日炎炎\"){ public void info(){ System.out.println(\"summer\"); } }, AUTUMN (\"秋天\",\"秋高气爽\"){ public void info(){ System.out.println(\"autumn\"); } }, WINTER(\"冬天\",\"冰天雪地\"){ public void info(){ System.out.println(\"winter\"); } }; private final String seasonName; private final String seasonDec; Season2(String seasonName,String seasonDec){ this.seasonName = seasonName; this.seasonDec = seasonDec; }}interface Info{ void info();}/*输出结果为：SPRINGspringSUMMERsummerAUTUMNautumnWINTERwinter*/ 二、注解1、概述JDK 5.0开始支持注解（Annotation），注解是代码里的特殊标记，可以在编译、类加载、运行时被读取，并执行相应的处理。通过使用注解，可以在不改变原有逻辑的情况下，在源文件中嵌入一些补充信息。代码分析工具、开发工具和部署工具可以通过这些补充信息进行验证或者部署。 Annotation可以像修饰符一样被使用,可用于修饰包,类,构造器,方法,成员变量,参数,局部变量的声明，这些信息被保存在Annotation的“name=value”对中。 在JavaSE中，注解的使用目的比较简单，例如标记过时的功能，忽略警告等。在JavaEE/Android中注解占据了更重要的角色，例如用来配置应用程序的任何切面，代替JavaEE旧版中所遗留的繁冗代码和XML配置等。 框架 = 注解 + 反射 + 设计模式 2、常见注解常见的注解主要用三种用处： 1、生成文档相关的注解。 @author标明开发该类模块的作者，多个作者之间使用,分割 @version标明该类模块的版本@see参考转向，也就是相关主题 @since表示从哪个版本开始增加的 @param对方法中某参数的说明，如果没有参数就不能写 @return对方法返回值的说明，如果方法的返回值类型是void就不能写 @exception对方法可能抛出的异常进行说明，如果方法没有用throws显式抛出的异常就不能写 其中 @param@return和@exception这三个标记都是只用于方法的。 @param的格式要求：@param形参名形参类型形参说明 @return的格式要求：@return返回值类型返回值说明 @exception的格式要求：@exception异常类型异常说明 @param和@exception可以并列多个 例如： 12345/***@author xxx*@version 1.0*@see Math.java*/ 2、编译时进行格式检查（JDK内置的三个基本注解） @Override：限定重写父类方法，该注解只能用于方法。 @Deprecated：用于表示所修饰的元素(类、方法等)已过时。通常是因为所修饰的结构危险或存在更好的选择 @SuppressWarnings：抑制编译器警告。 3、跟踪代码依赖性，实现替代配置文件的功能。例如Serverlet3.0中注解使得不再需要在web.xml文件中进行Servlet部署： 3、自定义注解自定义注解使用@interface关键字，并且自动继承了java.lang.annotation.Annotation接口。 注解的成员变量在Annotation定义中以无参数方法的形式来声明。其方法名和返回值定义了该成员的名字和类型，称之为配置参数。类型只能是八种基本数据类型、String类型、Class类型、enum类型、Annotation类型以及以上类型的数组。 定义注解成员变量时如果指定初始值，可以使用default关键字。 如果只有一个参数成员，建议使用参数名为value 如果定义的注解含有配置参数，那么使用时必须指定参数值，除非它有默认值。格式是参数名=参数值，如果只有一个参数成员，且名称为value，可以省略value= 没有成员定义的Annotation称为标记；包含成员变量的Annotation称为元数据Annotation。 自定义注解必须配上注解的信息处理流程才有意义。 自定义注解举例： 12345678910111213141516171819202122public class Hello { //使用是指定配置参数 @Report(type = 3,level = \"level\",value = \"string\") public int n; //指定部分参数 @Report(level = \"level\",value = \"string\") public int p; @Report(value = \"string\") // 只对value赋值，等同于@Report(\"string\") public int x; @Report //对所有参数使用默认值 public int y;}//以下是自定义的一个注解，如果是public修饰的，必须单独放在一个java文件中//三个配置参数都有默认值，因此使用的时候可以指定，也可以不指定public @interface Report { int type() default 0; //类型为int，配置参数名为type，默认值是0 String level() default \"info\"; String value() default \"\";} 4、元注解用于修饰其他注解的注解，就是元注解(meta-annotation)。 JDK 5.0提供了4个标准的元注解： @Retention：指定被修饰的注解的生命周期。 @Target：指定被修饰的注解能够用于修饰哪些程序元素。 @Documented：表示所修饰的注解在被javadoc解析时保留下来。 @Inherited：被修饰的注解将具有继承性。 1、@Retention @Retentio元注解用于定义Annotation的生命周期，其包含一个RetentionPolicy类型的成员变量，使用@Retention元注解时，必须为该成员变量指定值，有以下三种值(枚举变量)： RetentionPolicy.SOURCE：在源文件中有效（即源文件中保留），编译器直接丢弃这种策略的注释 RetentionPolicy.CLASS：在class文件中有效（即class保留），运行Java程序时，JVM不会保留这种注解。这是默认值。 RetentionPolicy.RUNTIME：在运行时有效（即运行时保留），运行Java程序时，JVM会保留注释。程序可以通过反射获取该注释。 如下图： 使用举例： 123456@Retention(RetentionPolicy.RUNTIME)public @interface MyAnnotation { int type() default 0; String level() default \"info\"; String value() default \"\";} 2、@Target @Target用于指定被修饰的Annotation能用于修饰哪些元素，@Target包含一个名为value的数组成员变量，可以取以下的值： 取值 含义 ElementType.CONSTRUCTOR 用于描述构造器 ElementType.PACKAGE 用于描述包 ElementType.FIELD 用于描述域(包括枚举常量) ElementType.TYPE 用于描述类、接口(包括注解类型)或enum声明 ElementType.METHOD 用于描述方法 ElementType.LOCAL_VARIABLE 用于描述局部变量 ElementType.PARAMETER 用于描述参数 3、@Documented @Documented用于指定被改元注解修饰的注解类将被javadoc工具提取成文档。默认情况下，javadoc不包括注解。 定义为Documented的注解必须设置Retention的值为RUNTIME。 4、@Inherited @Inherited修饰的注解具有继承性，其子类自动具有该注解，即该注解类的子类可以继承父类级别的注解。 5、反射获取注解信息JDK 5.0在java.lang.reflect包下新增了AnnotatedElement接口,该接口代表程序中可以接受注解的程序元素。 当一个Annotation类型被定义为运行时Annotation后,该注解才是运行时可见,当class文件被载入时保存在class文件中的Annotation才会被虚拟机读取。 程序可以调用AnnotatedElement对象的如下方法来访问Annotation信息： getAnnotation(Class&lt;T&gt; annotatoinClass) getAnnotations() getDeclaredAnnotations() isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass) 6、JDK 8中注解新特征JDK 8.0新增了可重复注解和类型注解。 1、可重复注解 a. 在MyAnnotation上声明@Repeatable，成员值为MyAnnotations.class，此时的MyAnnotations为容器注解。 b. 要求MyAnnotation的@Target和@Retention等元注解与MyAnnotations相同。 使用示例： 123456789101112131415161718192021//注意：这三个类都是public的，需要分别写在三个文件中@Inherited@Retention(RetentionPolicy.RUNTIME) @Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE})public @interface MyAnnotations { MyAnnotation[] value();}@Inherited@Repeatable(MyAnnotations.class) //Repeatable的参数是容器注解的类型@Retention(RetentionPolicy.RUNTIME)@Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE, TYPE_PARAMETER,TYPE_USE})public @interface MyAnnotation { String value() default \"hello\";}//此时MyAnnotation注解可以重复使用@MyAnnotation(value=\"hi\") @MyAnnotation(value=\"abc\")public class Person{} 2、类型注解 JDK 8.0之后，元注解@Target的参数类型ElementType枚举值多了两个：TYPE_PARAMETER和TYPE_USE。在JDK 8.0之前，注解只能是在声明的地方所使用，Java8开始，注解可以应用在任何地方。 ElementType.TYPE_PARAMETER：表示该注解能写在类型变量的声明语句中（如：泛型声明）。 ElementType.TYPE_USE：表示该注解能写在使用类型的任何语句中。 比如，同样使用上面的@MyAnnotation，其元注解@Target的参数包括了TYPE_PARAMETER和TYPE_USE，表明该注解可以写在类型变量的声明语句中，也能写在使用类型的任何语句中： 123456class Test&lt;@MyAnnotation T&gt;{ //写在声明语句中 public void show() throws @MyAnnotation RuntimeException{ ArrayList&lt;@MyAnnotation String&gt; list = new ArrayList&lt;&gt;(); int num = (@MyAnnotation int) 10L; //写在任何语句中 }}","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记09(3)-常用类之Java比较器和其他常用类","slug":"java-note-0903","date":"2021-04-05T07:05:13.000Z","updated":"2022-05-22T13:30:54.793Z","comments":true,"path":"2021/04/05/java-note-0903/","link":"","permalink":"http://kangshitao.github.io/2021/04/05/java-note-0903/","excerpt":"Comparable与Comparator接口、System类、Math类、BigInteger与BigDecimal","text":"一、Java比较器Java实现对象排序有两种方式： 自然排序：java.lang.Comparable 定制排序：java.util.Comparator 1、ComparableComparable接口强行对实现它的每个类的对象进行整体排序，这种排序称为类的自然排序。 实现Comparable的类，必须实现compareTo(Object obj)方法，从小到大的排序规则如下： 如果当前对象this大于obj，返回正整数。 如果当前对象this小于obj，返回负整数。 如果当前对象this等于obj，返回0。 以上规则是从小到大排列，如果想从大到小排列，则正负和上面相反。 String类、包装类等类实现了Comparable接口，并实现了compareTo()方法，进行了从小到大的排列。 实现Comparable接口的对象列表可以通过Collections.sort或Arrays.sort进行自动排序，比如String数组就可以自动比较大小，自动排序： 12345678910public class CompareTest { @Test public void test(){ String[] str = new String[]{\"DD\",\"BB\",\"AA\",\"CC\"}; //String实现了Comparable接口，String对象可以比较大小 Arrays.sort(str); //借助Arrays.sort进行排序 System.out.println(Arrays.toString(str)); //输出结果为：[AA, BB, CC, DD] }} 2、Comparator当元素的类型没有实现java.lang.Comparable接口而又不方便修改代码，或者实现了java.lang.Comparable接口的排序规则不适合当前的操作，那么可以考虑使用Comparator的对象来排序，强行对多个对象进行整体排序的比较。 实现Comparator接口需要实现其compare(Obj o1, Obj o2)方法，规则和compareTo(Object obj)相同。 同样地，可以将Comparator传递给sort方法（如Collections.sort或Arrays.sort），控制排序规则。还可以使用Comparator来控制某些数据结构（如有序set或有序映射）的顺序，或者为那些没有自然顺序的对象collection提供排序。 举例： 123456789101112131415161718192021public class CompareTest { @Test public void test3(){ String[] str = new String[]{\"DD\",\"BB\",\"AA\",\"CC\"}; //实现Comparator接口，自定义排序规则。需要重写compare方法 //Arrays.sort方法的第二个参数，需要比较器对象，这里使用匿名实现类对象 Arrays.sort(str, new Comparator() { @Override public int compare(Object o1, Object o2) { //如果使用泛型，这里可以不用强制转型 if(o1 instanceof String &amp;&amp; o2 instanceof String){ String s1 = (String) o1; String s2 = (String) o2; return -s1.compareTo(s2); }else{ throw new RuntimeException(\"类型错误\");} } }); System.out.println(Arrays.toString(str)); //临时改变了排序规则，此时输出为[DD, CC, BB, AA] }} Comparable接口的方式一旦指定，保证Comparable接口实现类的对象在任何位置都可以比较大小。Comparator接口属于临时性的比较。 二、System类java.lang.System类代表系统，系统级的很多属性和控制方法都放置在该类的内部。 System类的构造器是private的，因此无法创建该类的对象，其内的成员变量和成员方法都是static的，可以方便调用。 成员变量： in：标准输入流 out：标准输出流 err：标准错误输出流 成员方法： native long currentTimeMillis()：返回当前的计算机时间，时间的表达格式为当前计算机时间和GMT时间(格林威治时间)1970年1月1号0时0分0秒所差的毫秒数。 void exit(int status)：退出程序。其中status的值为0代表正常退出，非零代表异常退出。使用该方法可以在图形界面编程中实现程序的退出功能等。 void gc()：请求系统进行垃圾回收。至于系统是否立刻回收，则取决于系统中垃圾回收算法的实现以及系统执行时的情况。 String getProperty(String key)：获得系统中属性名为key的属性对应的值。系统中常见的属性名以及属性的作用如下： java.version：Java运行时环境版本 java.home：Java安装目录 os.name：操作系统的名称 os.version：操作系统的版本 user.name：用户名称 user.home：用户的主目录 user.dir：用户的当前目录 代码举例： 123456789101112131415161718192021public class OtherClass { @Test public void test1() { System.out.println(\"java的version:\" + System.getProperty(\"java.version\")); System.out.println(\"java的home:\" + System.getProperty(\"java.home\")); System.out.println(\"os的name:\" + System.getProperty(\"os.name\")); System.out.println(\"os的version:\" + System.getProperty(\"os.version\")); System.out.println(\"user的name:\" + System.getProperty(\"user.name\")); System.out.println(\"user的home:\" + System.getProperty(\"user.home\")); System.out.println(\"user的dir:\" + System.getProperty(\"user.dir\")); }}/*以上代码输出结果为：java的version:15.0.1java的home:D:\\JDK15os的name:Windows 10os的version:10.0user的name:xxxuser的home:C:\\Users\\xxxuser的dir:D:\\IntelliJ IDEA\\Project\\Java_shangguigu\\JavaSenior\\day04*/ 三、Math类java.lang.Math类提供了一系列静态方法用于科学计算，其方法的参数和返回值类型一般为double型： abs：绝对值 acos/asin/atan/cos/sin/tan：三角函数 sqrt：平方根 pow(double a, double b)：求a的b次幂 log：自然对数 exp：e为底数 max(double a, double b)：求a、b之间的最大值 min(double a, double b)：求a、b之间的最小值 random()：返回0.0到1.0之间的随机数 long round(double a)：double型数据a转换为long型（四舍五入） toDegrees(double angrad)：弧度—&gt;角度 toRadians(double angdeg)：角度—&gt;弧度 四、BigInteger与BigDecimal1、BigIntegerLong是long的包装类，最大值为 2^{63}-1 ，如果是再大的数，就需要使用BigInteger类。java.math.BigInteger表示不可变的任意精度的整数。BigInteger类用int[]来模拟非常大的整数，BigInteger类对象进行计算的时候只能使用实例方法。 构造器： BigInteger(String val)：根据字符串构建BigInteger对象 常用方法： public BigInteger abs()：返回此BigInteger的绝对值的BigInteger。 BigInteger add(BigInteger val)：返回其值为(this + val)的BigInteger BigInteger subtract(BigInteger val)：返回其值为(this-val)的BigInteger BigInteger multiply(BigInteger val)：返回其值为(this * val)的BigInteger BigInteger divide(BigInteger val)：返回其值为(this / val)的BigInteger。整数相除只保留整数部分。 BigInteger remainder(BigInteger val)：返回其值为(this % val)的BigInteger。 BigInteger[] divideAndRemainder(BigInteger val)：返回包含(this / val)后跟(this % val)的两个BigInteger的数组。 BigInteger pow(int exponent)：返回其值为this的exponent次幂的BigInteger。 BigInteger和基本数据类型转换： 转换为byte：byteValue() 转换为short：shortValue() 转换为int：intValue() 转换为long：longValue() 转换为float：floatValue() 转换为double：doubleValue() 直接调用以上方法，如果超出范围，不会抛出异常，会导致结果不正确。 调用xxxValueExact()方法，转换超出范围时，会抛出ArithmeticException异常，以保证结果准确。 2、BigDecimaljava.math.BigDecimal表示一个任意大小且精度完全准确的浮点数，同样是不可变的。 BigDecimal用scale()表示小数位数，小数末尾是0的时候也计算在内。如果调用scale()方法，返回值为负数，比如-2，表示这个数是整数，并且末尾有两个0。 构造器： public BigDecimal(double val) public BigDecimal(String val) 常用方法： public BigDecimal setScale(int newScale)：设置当前BigDecimal的精度，如果比原始值低，根据指定的处理方式进行四舍五入或者直接截断。 public BigDecimal stripTrailingZeros()：将一个BigDecimal格式化为一个相等的，但去掉了末尾0的BigDecimal public BigDecimal add(BigDecimal augend) public BigDecimal subtract(BigDecimal subtrahend) public BigDecimal multiply(BigDecimal multiplicand) public BigDecimal divide(BigDecimal divisor,int scale,int roundingMode)：如果除不尽，会报ArithmeticException异常，此时必须指定精度以及如何截断。 说明： 通过源码可知，一个BigDecimal是通过一个BigInteger和一个scale来表示的，即BigInteger表示一个完整的整数，而scale表示小数位数。 比较两个BigDecimal数的大小，应该使用compareTo()方法，根据两个值的大小分别返回-1、1和0，分别表示小于、大于和等于。 compareTo()比较的是两个数值的大小，而equals()方法不但要求两个BigDecimal的值相等，还要求它们的scale()相等： 1234567BigDecimal d1 = new BigDecimal(\"123.456\");BigDecimal d2 = new BigDecimal(\"123.45600\");System.out.println(d1.equals(d2)); // false, 因为scale不同// true,因为d2去除尾部0后scale变为2System.out.println(d1.equals(d2.stripTrailingZeros()));System.out.println(d1.compareTo(d2)); // 0，表示相等","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记09(2)-常用类之日期类","slug":"java-note-0902","date":"2021-04-04T11:34:14.000Z","updated":"2022-05-22T13:30:54.793Z","comments":true,"path":"2021/04/04/java-note-0902/","link":"","permalink":"http://kangshitao.github.io/2021/04/04/java-note-0902/","excerpt":"Date类、Calendar类、SimpleDateFormat类、LocalDate、Instant、DateTimeFormatter","text":"一、JDK8之前的日期时间APIJDK8.0之前，日期和时间的API主要有： java.lang.System类中的public static long currentTimeMillis()方法，用来返回当前时间与1970年1月1日0时0分0秒之间以毫秒为单位的时间差(毫秒数)，这个毫秒数称为时间戳。 java.util.Date 和java.sql.Date类。java.sql.Date类是java.util.Date类的子类。 java.text.SimpleDateFormat Calendar 1、Date类Date类有两个，一般使用的是java.util.Date类，java.sql.Date类是数据库中使用的日期类。 java.util.Date类有两个构造器： Date()：创建一个对应当前时间的Date对象。 Date(long date)：创建指定毫秒数的Date对象。 两个方法(大部分方法都过时了)： toString()：显示当前的年、月、日、时、分、秒。默认格式为 EEE MMM dd HH:mm:ss zzz yyyy，比如Sat Feb 16 16:35:31 GMT+08:00 2019 getTime()：获取当前Date对象对应的毫秒数（时间戳）。 java.sql.Date类没有空参的构造器： Date(long date)：创建指定毫秒数的Date对象。 Date(int year, int month, int day)，已过时。 将java.util.Date对象转换为java.sql.Date对象，具体见代码： 实现代码： 123456789101112131415161718192021222324public class DateTimeTest { @Test public void test2(){ //构造器一：Date()：创建一个对应当前时间的Date对象 Date date1 = new Date(); System.out.println(date1.toString());//Sat Feb 16 16:35:31 GMT+08:00 2019 System.out.println(date1.getTime());//1550306204104 //构造器二：创建指定毫秒数的Date对象 Date date2 = new Date(155030620410L); //创建java.sql.Date对象 java.sql.Date date3 = new java.sql.Date(35235325345L); System.out.println(date3);//1971-02-13 //如何将java.util.Date对象转换为java.sql.Date对象 //情况一： //Date date4 = new java.sql.Date(2343243242323L); //java.sql.Date date5 = (java.sql.Date) date4; //情况二： Date date6 = new Date(); java.sql.Date date7 = new java.sql.Date(date6.getTime()); }} 2、SimpleDateFormatjava.text.SimpleDateFormat是用来格式化和解析日期的具体类。 格式化：日期—&gt;文本 解析：文本—&gt;日期 格式化： public SimpleDateFormat()：根据默认的模式和语言环境创建对象。 public SimpleDateFormat(String pattern)：用参数pattern指定的格式创建一个对象。 public String format(Date date)：SimpleDateFormat类对象调用此方法来格式化Date类对象。 解析： public Date parse(String source)：从给定字符串的开始解析文本，生成一个Date类对象。 代码举例： 123456789101112131415161718192021222324252627public class DateTimeTest { @Test public void testSimpleDateFormat() throws ParseException { //实例化SimpleDateFormat:使用默认的构造器 SimpleDateFormat sdf = new SimpleDateFormat(); //格式化：日期 ---&gt;字符串 Date date = new Date(); System.out.println(date); //格式化前：Sun Apr 04 20:51:54 CST 2021 String format = sdf.format(date); System.out.println(format); // 格式化后：4/4/21 下午8:51 //解析：格式化的逆过程，字符串 ---&gt; 日期 String str = \"4/4/21 下午9:00\"; //解析前 Date date1 = sdf.parse(str); System.out.println(date1); //解析后：Sun Apr 04 21:00:00 CST 2021 //System.out.println(date1.toString()); //自动调用toString()方法 //*************按照指定的方式格式化和解析：调用带参的构造器***************** SimpleDateFormat sdf2 = new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss\"); //格式化：2021-04-04 09:00:32 System.out.println(sdf2.format(date)); //解析：Sun Apr 04 09:00:32 CST 2021 System.out.println(sdf2.parse(sdf2.format(date))); } 解析的时候要求字符串必须和格式化时的格式相同(通过构造器参数体现)，否则抛异常。 3、CalendarDate类不能转换时区，除了toGMTString()可以按GMT+0:00输出外，Date总是以当前计算机系统的默认时区为基础进行输出。此外，我们也很难对日期和时间进行加减，计算两个日期相差多少天，计算某个月第一个星期一的日期等。 java.util.Calendar类是一个抽象类，JDK 1.1版本引入，可以用于获取并设置年、月、日、时、分、秒，它和Date比，主要多了一个可以做简单的日期和时间运算的功能。 Calendar类实例化有两种方式： a.创建其子类GregorianCalendar的对象获取实例。 b.调用其静态方法getInstance()获取实例。(通过getClass可知，类型还是GregorianCalendar) Calendar类常用方法： 一个Calendar的实例是系统时间的抽象表示，通过public int get(int field)方法来取得想要的时间信息。参数field是Calendar中的静态变量，比如YEAR、MONTH、DAY_OF_WEEK、HOUR_OF_DAY、MINUTE、SECOND等。 public void set(int field,int value)：将给定的字段设置为给定值。 public void add(int field,int amount)：在给定的字段中添加或减去指定的时间。 public final Date getTime()：日历类—&gt;Date类 public final void setTime(Date date)：Date类—&gt;日历类 获取月份时：一月是0，二月是1，以此类推，12月是11获取星期时：周日是1，周二是2，……周六是7 代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class calendarTest { @Test public void testCalendar(){ System.out.println(new Date()); //当前时间：Sun Apr 04 21:40:07 CST 2021 //1.实例化 //方式一：创建其子类（GregorianCalendar）的对象 //方式二：调用其静态方法getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //class java.util.GregorianCalendar //2.常用方法 //get() int days = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(\"今天是本月的第\"+days+\"天\"); // 今天是本月的第4天 //set() //calendar可变性 calendar.set(Calendar.DAY_OF_MONTH,22); //设置calendar为本月的第22天 days = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(days); // 22，此时的calendar是本月的第22天，即4月22日 //add() calendar.add(Calendar.DAY_OF_MONTH,-3); //calendar减去3天 days = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(days); // 19，此时的calendar是本月的第19天，即4月19日 //getTime():日历类---&gt; Date Date date = calendar.getTime(); System.out.println(date); // Mon Apr 19 21:40:07 CST 2021 //setTime():Date ---&gt; 日历类 Date date1 = new Date(); //当前日期 calendar.setTime(date1); days = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(days); //4, 今天是本月的第4天 }}/*以上程序输出结果：Sun Apr 04 21:40:07 CST 2021class java.util.GregorianCalendar今天是本月的第4天2219Mon Apr 19 21:40:07 CST 20214*/ 二、JDK8的新日期时间API1、新日期APICalendar类和Date类存在的问题： 可变性：像日期和时间这样的类应该是不可变的。 偏移性：Date中的年份是从1900开始的，而月份都从0开始。 格式化：格式化只对Date有用，Calendar则不行。 此外，它们也不是线程安全的；不能处理闰秒等。 JDK 8.0提供了java.time这个API，其包含了所有关于本地日期（LocalDate）、本地时间（LocalTime）、本地日期时间（LocalDateTime）、时区（ZonedDateTime）和持续时间（Duration）的类。 JDK 8.0新增了toInstant()方法，用于把Date转换成新的表示形式。这些新增的本地化时间日期API大大简化了日期时间和本地化的管理。 和旧的API相比，新API严格区分了时刻、本地日期、本地时间和带时区的日期时间，并且，对日期和时间进行运算更加方便。 此外，新API修正了旧API不合理的常量设计： Month的范围用1~12表示1月到12月； Week的范围用1~7表示周一到周日。 最后，新API的类型几乎全部是不变类型（和String类似），可以放心使用不必担心被修改。 新日期API包含： java.time：包含值对象的基础包。常用 java.time.chrono：提供对不同的日历系统的访问。 java.time.format：格式化和解析时间和日期。常用 java.time.temporal：包括底层框架和扩展特性。 java.time.zone：包含时区支持的类。 新日期API和旧日期API的对应关系： java.util.Date和java.sql.Date 对应(类似) Instant SimpleDateFormat 对应(类似)DateTimeFormatter Calendar 对应(类似) LocalDate、LocalTime、LocalDateTime 2、常用的三个类其中三个比较重要的类，这三个类的实例是不可变对象： LocalDate代表IOS格式（yyyy-MM-dd）的日期,可以存储生日、纪念日等日期。 LocalTime表示一个时间，而不是日期。 LocalDateTime是用来表示日期和时间的，这是一个最常用的类之一。 这几个类常用的方法如下： 实现代码参考： 123456789101112131415161718192021222324252627282930313233343536373839public class JDK8Time { @Test public void test1(){ //now():获取当前的日期、时间、日期+时间 LocalDate localDate = LocalDate.now(); LocalTime localTime = LocalTime.now(); LocalDateTime localDateTime = LocalDateTime.now(); System.out.println(localDate); //2021-04-04 System.out.println(localTime); //22:10:12.279529500 System.out.println(localDateTime); //2021-04-04T22:10:12.279529500 //of():设置指定的年、月、日、时、分、秒。没有偏移量 LocalDateTime localDateTime1 = LocalDateTime.of(2020, 10, 6, 13, 23, 43); System.out.println(localDateTime1); //2020-10-06T13:23:43 //getXxx()：获取相关的属性 System.out.println(localDateTime.getDayOfMonth()); //4 System.out.println(localDateTime.getDayOfWeek()); //SUNDAY System.out.println(localDateTime.getMonth()); //APRIL System.out.println(localDateTime.getMonthValue()); //4 System.out.println(localDateTime.getMinute()); //10 //体现不可变性 //withXxx():设置相关的属性 LocalDate localDate1 = localDate.withDayOfMonth(22); //返回新的对象 System.out.println(localDate); //2021-04-04，原来的对象不会被修改 System.out.println(localDate1); //2021-04-22 //不可变性，不会改变原有对象 LocalDateTime localDateTime3 = localDateTime.plusMonths(3); //加3个月 System.out.println(localDateTime); //2021-04-04T22:10:12.279529500 System.out.println(localDateTime3); //2021-07-04T22:10:12.279529500 LocalDateTime localDateTime4 = localDateTime.minusDays(6); //减6天 System.out.println(localDateTime); //2021-04-04T22:10:12.279529500 System.out.println(localDateTime4); //2021-03-29T22:10:12.279529500 }} 3、Instantjava.time.Instant用来表示时间戳，它只是简单的表示自1970年1月1日0时0分0秒（UTC）开始的秒数。java.time包是基于纳秒计算的，Instant的精度可以达到纳秒级。 常用方法： 方法 描述 public static Instant now() 静态方法，返回默认UTC时区的Instant类的对象 public static Instant ofEpochMilli(long epochMilli) 静态方法，返回在1970-01-01 00:00:00基础上加上指定毫秒数之后的Instant类的对象 public long toEpochMilli() 返回1970-01-01 00:00:00到当前时间的毫秒数，即为时间戳 public OffsetDateTime atOffset(ZoneOffset offet) 结合即时的偏移来创建一个OffsetDateTime 实现代码： 1234567891011121314151617181920212223242526public class JDK8Time { /* Instant的使用 类似于 java.util.Date类 */ @Test public void test2(){ //now():获取本初子午线对应的标准时间 Instant instant = Instant.now(); System.out.println(instant);//2021-04-05T03:02:58.898817900Z //添加时间的偏移量 OffsetDateTime offsetDateTime = instant.atOffset(ZoneOffset.ofHours(8)); System.out.println(offsetDateTime);//2021-04-05T11:02:58.898817900+08:00 //toEpochMilli():获取自1970年1月1日0时0分0秒（UTC）开始的毫秒数 //相当于 Date类的getTime() long milli = instant.toEpochMilli(); System.out.println(milli); //1617591778898 //ofEpochMilli():通过给定的毫秒数，获取Instant实例 //相当于Date(long millis) Instant instant1 = Instant.ofEpochMilli(1550475314878L); System.out.println(instant1); //2019-02-18T07:35:14.878Z }} 4、DateTimeFormatter使用Date对象时，用SimpleDateFormat进行格式化显示。使用新的LocalDateTime或ZonedLocalDateTime时，使用java.time.format.DateTimeFormatter进行格式化显示。 和SimpleDateFormat不同的是，DateTimeFormatter是不变对象，并且是线程安全的。因为SimpleDateFormat不是线程安全的，使用的时候，只能在方法内部创建新的局部变量。而DateTimeFormatter可以只创建一个实例，到处引用。 DateTimeFormatter类有三种格式化方法： 预定义的标准格式。如：ISO_LOCAL_DATE_TIME、ISO_LOCAL_DATE、ISO_LOCAL_TIME 本地化相关的格式。如：ofLocalizedDateTime(FormatStyle.LONG) 自定义的格式。如：ofPattern(“yyyy-MM-ddhh:mm:ss”)，常用 同样地，DateTimeFormatter类也提供了相应的格式化和解析的函数： 方法 描述 public static DateTimeFormatter ofPattern(String pattern) 静态方法，返回一个指定字符串格式的DateTimeFormatter public String format(Temporal Accessort) 格式化一个日期、时间，返回字符串 public TemporalAccessor parse(CharSequence text) 将指定格式的字符序列解析为一个日期、时间 代码使用： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class JDK8Time { @Test public void test3(){ //方式一：预定义的标准格式。如：ISO_LOCAL_DATE_TIME; //ISO_LOCAL_DATE;ISO_LOCAL_TIME DateTimeFormatter formatter = DateTimeFormatter.ISO_LOCAL_DATE_TIME; //格式化:日期--&gt;字符串 LocalDateTime localDateTime = LocalDateTime.now(); String str1 = formatter.format(localDateTime); System.out.println(localDateTime); System.out.println(str1);//2019-02-18T15:42:18.797 //解析：字符串 --&gt;日期 TemporalAccessor parse = formatter.parse(\"2019-02-18T15:42:18.797\"); System.out.println(parse); //方式二： //本地化相关的格式。如：ofLocalizedDateTime()，适用于LocalDateTime //FormatStyle.LONG / FormatStyle.MEDIUM / FormatStyle.SHORT : DateTimeFormatter formatter1 = DateTimeFormatter. ofLocalizedDateTime(FormatStyle.LONG); //格式化 String str2 = formatter1.format(localDateTime); System.out.println(str2);//2019年2月18日 下午03时47分16秒 //本地化相关的格式。如：ofLocalizedDate()，适用于LocalDate //FormatStyle.FULL / FormatStyle.LONG / FormatStyle.MEDIUM / //FormatStyle.SHORT DateTimeFormatter formatter2 = DateTimeFormatter. ofLocalizedDate(FormatStyle.MEDIUM); //格式化 String str3 = formatter2.format(LocalDate.now()); System.out.println(str3);//2019-2-18 //方式三：自定义的格式。如：ofPattern(“yyyy-MM-dd hh:mm:ss”) DateTimeFormatter formatter3 = DateTimeFormatter.ofPattern(\"yyyy-MM-dd hh:mm:ss\"); //格式化 String str4 = formatter3.format(LocalDateTime.now()); System.out.println(str4);//2019-02-18 03:52:09 //解析 TemporalAccessor accessor = formatter3.parse(\"2019-02-18 03:52:09\"); System.out.println(accessor); //{HourOfAmPm=3, MinuteOfHour=52, MicroOfSecond=0, SecondOfMinute=9, //NanoOfSecond=0, MilliOfSecond=0},ISO resolved to 2019-02-18 }} 5、其他API ZoneId：该类中包含了所有的时区信息，一个时区的ID，如Europe/Paris ZonedDateTime`：一个在ISO-8601日历系统时区的日期时间，如2007-12-03T10:15:30+01:00Europe/Paris。其中每个时区都对应着ID，地区ID都为“{区域}/{城市}”的格式，例如：Asia/Shanghai等 Clock：使用时区提供对当前即时、日期和时间的访问的时钟。 持续时间：Duration，用于计算两个“时间”间隔 日期间隔：Period，用于计算两个“日期”间隔 TemporalAdjuster :时间校正器。有时我们可能需要获取例如：将日期调整到“下一个工作日”等操作。 TemporalAdjusters :该类通过静态方法(firstDayOfXxx()/lastDayOfXxx()/nextXxx())提供了大量的常用TemporalAdjuster的实现。 6、新旧日期转换","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记09(1)-常用类之String","slug":"java-note-0901","date":"2021-04-03T13:08:54.000Z","updated":"2022-05-22T13:30:54.793Z","comments":true,"path":"2021/04/03/java-note-0901/","link":"","permalink":"http://kangshitao.github.io/2021/04/03/java-note-0901/","excerpt":"String类，StringBuffer，StringBuilder","text":"一、String类1、字符串的使用String类的特征： String类声明为final的，不可以被继承。 String类实现了Serializable接口，表示字符串是支持序列化的。 String 类实现了Comparable接口，表示字符串可以比较大小 String类内部定义了final char[] value，用于存储字符串数据。数组不能被重新赋值，数组元素不能被修改。（JDK 9.0改为了byte数组） String代表不可变的字符序列，不可变性，以下操作需要重写指定内存区域进行赋值，不能使用原有的value进行赋值： 当对字符串重新赋值时 当对现有的字符串进行连接操作时 当调用String的replace方法修改指定的字符/字符串时 2、字符串创建和存储字符串有两种创建方式： 字面量定义：比如 String s1 = \"hello\"; 创建String类对象：比如：String s2 = new String(\"hello\"); 字面量定义的字符串存储在字符串常量池（位于方法区）中，目的是共享；通过创建对象构建的字符串存储在堆中，堆中的地址值又指向字符串常量池中的值。 字符串常量池中不会保存内容相同的字符串，每个字符串只保存一份。 通过创建String类对象构造的字符串，内存中一共创建了两个对象，一个String类对象，一个底层的数组对象。 两种方式定义的字符串，在内存中的区别： 具体案例： 123456789101112131415161718192021222324public class Test(){ public static void main(String[] args){ String s1 = \"hello\"; //字面量方式定义 String s2 = \"hello\"; String s3 = new String(\"hello\"); //创建对象的方式定义 String s4 = new String(\"hello\"); //字面量定义的字符串，直接指向常量池，所以地址相等 System.out.println(s1 == s2); //true //new出来的每个对象有单独的空间和地址，因此地址不同 System.out.println(s3 == s4); //false System.out.println(s1 == s3); //false System.out.println(s1 == s4); //false //只要其中一个是变量，地址就不相等 System.out.println(\"hello\"+\"java\" == \"hello\"+\"java\"); //true System.out.println(\"hello\"+\"java\" == \"hellojava\"); //true System.out.println((s1+\"java\") == (s1+\"java\")); //false System.out.println((s1+\"java\") == (s2+\"java\")); //false //此时的s5是新创建的字符串，s4本身并没有改变 String s5 = s4.replace('h','a'); System.out.println(s4); //hello System.out.println(s5); //aello }} 总结： 常量(字面量定义的，或者final修饰的，都是常量)与常量的拼接结果在常量池。且常量池中不会存在相同内容的常量。 只要其中有一个是变量，结果就在堆中，地址也不同。比如s1 + s2、s1+\"abc\"、s1+=\"abc\"等，用==比较是地址，结果是false，比如s1+\"abc\" == s1+\"abc\"为false 如果拼接的结果调用intern()方法，返回值就在常量池中。 二、String类常用方法String类的常用方法： int length()：返回字符串的长度：return value.lengthchar charAt(int index)：返回某索引处的字符：return value[index]boolean isEmpty()：判断是否是空字符串：return value.length==0String toLowerCase()：使用默认语言环境，将String中的所有字符转换为小写String toUpperCase()：使用默认语言环境，将String中的所有字符转换为大写String trim()：返回字符串的副本，忽略前导空白和尾部空白boolean equals(Object obj)：比较字符串的内容是否相同boolean equalsIgnoreCase(String anotherString)：与equals方法类似，忽略大小写String concat(String str)：将指定字符串连接到此字符串的结尾。等价于用“+”int compareTo(String anotherString)：比较两个字符串的大小String substring(int beginIndex)：返回一个新的字符串，它是此字符串的从beginIndex开始截取到最后的一个子字符串。String substring(int beginIndex,int endIndex)：返回一个新字符串，它是此字符串从beginIndex开始截取到endIndex(不包含)的一个子字符串。boolean endsWith(String suffix)：测试此字符串是否以指定的后缀结束boolean startsWith(String prefix)：测试此字符串是否以指定的前缀开始boolean startsWith(String prefix,int toffset)：测试此字符串从指定索引开始的子字符串是否以指定前缀开始boolean contains(CharSequence s)：当且仅当此字符串包含指定的char值序列时，返回trueint indexOf(String str)：返回指定子字符串在此字符串中第一次出现处的索引int indexOf(String str, int fromIndex)：返回指定子字符串在此字符串中第一次出现处的索引，从指定的索引开始int lastIndexOf(String str)：返回指定子字符串在此字符串中最右边出现处的索引int lastIndexOf(String str, int fromIndex)：返回指定子字符串在此字符串中最后一次出现处的索引，从指定的索引开始反向搜索 注：indexOf和lastIndexOf方法如果未找到都是返回-1 String replace(char oldChar,char newChar)：返回一个新的字符串，它是通过用newChar替换此字符串中出现的所有oldChar得到的。String replace(CharSequence target,CharSequence replacement)：使用指定的字面值替换序列替换此字符串所有匹配字面值目标序列的子字符串。String replaceAll(String regex,String replacement)：使用给定的replacement替换此字符串所有匹配给定的正则表达式的子字符串。String replaceFirst(String regex,String replacement)：使用给定的replacement替换此字符串匹配给定的正则表达式的第一个子字符串。boolean matches(String regex)：告知此字符串是否匹配给定的正则表达式。String[] split(String regex)：根据给定正则表达式的匹配拆分此字符串。String[] split(String regex,int limit)：根据匹配给定的正则表达式来拆分此字符串，最多不超过limit个，如果超过了，剩下的全部都放到最后一个元素中。 三、String类与基本数据类型之间的转换1、字符串与基本数据类型、包装类 字符串—&gt;基本数据类型、包装类: Integer包装类的public static int parseInt(String s)可将由“数字”字符组成的字符串转换为整型。类似地,使用java.lang包中的Byte、Short、Long、Float、Double类调相应的类方法可以将由“数字”字符组成的字符串，转化为相应的基本数据类型。 基本数据类型、包装类—&gt;字符串： 调用String类的public String valueOf(int n)可将int型转换为字符串。相应的valueOf(byte b)、valueOf(long l)、valueOf(float f)、valueOf(double d)、valueOf(boolean b)可由参数的相应类型到字符串的转换。 2、字符串与字符数组 字符数组—&gt;字符串： String类的构造器：String(char[])和String(char[]，int offset，int length)分别用字符数组中的全部字符和部分字符创建字符串对象。 字符串—&gt;字符数组： public char[] toCharArray()：将字符串中的全部字符存放在一个字符数组中。 public void getChars(int srcBegin, int srcEnd, char[]dst, int dstBegin)：提供了将指定索引范围内的字符串存放到数组中的方法。 3、字符串与字节数组 字节数组—&gt;字符串： String(byte[])：通过使用平台的默认字符集解码指定的byte数组，构造一个新的String。 String(byte[]，int offset，int length)：用指定的字节数组的一部分，即从数组起始位置offset开始取length个字节构造一个字符串对象。 字符串—&gt;字节数组： public byte[] getBytes()：使用平台的默认字符集(编码方式)将此String编码为byte序列，并将结果存储到一个新的byte数组中。 public byte[] getBytes(String charsetName)：使用指定的字符集将此String编码到byte序列，并将结果存储到新的byte数组。 字节数组转换为字符串的过程，就是解码的过程，反之，字符串变为字节数组是编码的过程。 编码和解码默认使用平台默认字符集。 编码和解码使用的字符集(比如都是UTF-8)应该相同，否则出现乱码。 四、StringBuffer和StringBuilderStringBuffer和StringBuilder都是可变的字符序列，对字符串修改，不会产生新的对象，直接在原来的字符串对象上进行修改。 String、StringBuffer、StringBuilder的异同： String： 1.0 ，不可变的字符序列；底层使用char[]来保存 StringBuffer：1.0 ，可变的字符序列；线程安全的，效率低；底层使用char[]来保存 StringBuilder：JDK 5.0新增 ，可变的字符序列；线程不安全，效率高；底层使用char[]来保存 JDK9.0之后，三者的底层存储结构都改为了byte[]数组 效率从高到低排列：StringBuilder &gt; StringBuffer&gt; String StringBuffer和StringBuilder在使用方法上类似，提供的方法也相同。这里以StringBuffer为例，讲解其扩容机制以及常用的方法。 1、构造StringBuffer/StringBuilder对象StringBuffer类不同于String，其对象必须使用构造器生成。有三个构造器： StringBuffer()：初始容量为16的字符串缓冲区。 StringBuffer(intsize)：构造指定容量的字符串缓冲区。 StringBuffer(String str)：将内容初始化为指定字符串内容。 举例： 12345678910111213141516public class test(){ public static main(String args[]){ StringBuffer sb1 = new StringBuffer(\"abc\"); //abc sb1.setCharAt(0,'m'); //直接修改sb1，不会创建新的对象 System.out.println(sb1); //mbc StringBuffer sb2 = new StringBuffer(); System.out.println(sb2.length()); //0 StringBuffer sb3 = new StringBuffer(); String s = null; sb3.append(s); //append方法可以将null当作字符串添加进去 System.out.println(sb3); //此时的sb3为字符串\"null\" System.out.println(sb3.length()); // 4 //StringBuffer sb4 = new StringBuffer(null); //构造的时候不行 }} String、StringBuffer、StringBuilder三者之间的相互转换： String—&gt;StringBuffer、StringBuilder，直接调用两者的构造器：StringBuffer sb = new StringBuffer(str); StringBuffer、StringBuilder—&gt;String： 调用两者的toString()方法 调用String的构造器。String str = new String(sb); 2、扩容机制对于StringBuffer和StringBuilder来说，如果添加的数据，底层数组装不下，就需要扩容底层的数组。 默认情况下，扩容为原来容量的2倍+2（JDK 7.0 ，不同JDK版本可能不同），同时将原有数组中的元素复制到新的数组中。 关于为什么+2，各种解释： 1、考虑到在创建Sf，Sb设置的初始长度不大时（例如1），+2 可以很大地提升扩容的效率，减少扩容的次数 2、在旧版本的JDK扩容语句是 (value.length + 1) * 2 先加一再乘2，推测原意思是扩容的话至少增添一个空间再乘2，兼顾到扩容的次数和要减少扩容过大浪费的空间 3、newCapacity(int)的传入参数有可能是0，那么在参数是0的情况下，0&lt;&lt;1运算结果也是0，如果没+2，那么在创建数组的时候会创建出MAX_ARRAY_SIZE大小，所以作为设计的安全性考虑，选择了+2。 4、在使用StringBuffer的时候，append()之后，我们一般会在后面在加上一个分隔符，例如逗号，也就是再加上一个char，而char在java中占2个字节，避免了因为添加分隔符而再次引起扩容 举例： 1234567891011String str = new String(); //底层操作：new char[0]String str1 = new String(\"abc\");//底层操作：new char[]{'a','b','c'}StringBuffer sb = new StringBuffer(); //sb.length()是0//默认创建长度为16的内容为空的数组，即char[] value = new char[16]//这里sb.length()的结果是0，返回长度不是底层value数组的长度sb.append('a'); //底层操作：value[0] = 'a';StringBuffer sb2 = new StringBuffer(\"abc\"); //构建一个长度为\"abc\".length()+16的数组，即：//char[] value = new char[\"abc\".length()+16] 为了提高效率，建议使用StringBuffer(int capacity) 或 StringBuilder(int capacity)指定初始容量，尽量避免自动扩容。 3、常用方法 String Buffer append(xxx)：提供了很多的append()方法，用于进行字符串拼接。如果参数是null，会被当成字符串添加进去 String Buffer delete(int start,int end)：删除指定位置的内容 String Buffer replace(int start,int end,String str)：把[start,end)位置替换为str String Buffer insert(int offset,xxx)：在指定位置插入xxx String Buffer reverse()：把当前字符序列逆转 public int indexOf(String str) public String substring(int start,int end) public int length() public char charAt(int n ) public void setCharAt(int n ,char ch)","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记08-多线程","slug":"java-note-0801","date":"2021-04-03T02:07:20.000Z","updated":"2022-05-22T13:30:54.792Z","comments":true,"path":"2021/04/03/java-note-0801/","link":"","permalink":"http://kangshitao.github.io/2021/04/03/java-note-0801/","excerpt":"进程、线程、线程同步和通信、Thread、synchronized、wait()、notify()、notifyAll()","text":"一、程序、进程、线程 程序(program)：是为完成特定任务、用某种语言编写的一组指令的集合，即指一段静态的代码，静态对象。 进程(process)：是程序的一次执行过程，是正在运行的一个程序。 是一个动态的过程，有自身的产生、存在和消亡的过程——即生命周期。 程序是静态的，进程是动态的。 进程是资源分配的单位，系统在运行时会为每个进程分配不同的内存区域。 线程(thread)：进程可进一步细化为线程，是一个程序内部的一条执行路径。 若一个进程同一时间并行执行多个线程，就是支持多线程的。 线程是调度和执行的单位，每个线程拥有独立的运行栈和程序计数器(pc)，线程切换开销小。 一个进程的多个线程共享进程的堆和方法区，每个线程有自己的程序计数器、虚拟机栈和本地方法栈，这些线程从同一堆中分配对象，可以访问相同的变量和对象。 多个线程操作共享的系统资源可能会带来安全的隐患。 一个Java程序java.exe，至少有三个线程：main()主线程、gc()垃圾回收线程、异常处理线程。 JVM结构： 方法区(Method Area)：存储类结构信息，包括常量池、静态变量、构造函数等。JVM规范把方法区描述为堆的一个逻辑部分，但它有个别名non-heap(非堆)。方法区还包含运行时常量池 堆(Heap)：存储Java实例或者对象，是GC的主要区域。 虚拟机栈(VM Stack，Stack，Java Stack)：即Java栈，每当创建一个线程时，JVM就会为这个线程创建一个其私有的Java栈。在这个栈中包含多个栈帧，每运行一个方法就创建一个栈帧，用于存储局部变量表、操作栈、方法返回值等。每一个方法从调用直至执行完成的过程，就对应一个栈帧在Java栈中入栈到出栈的过程。 程序计数器(PC Register)：保存当前线程执行的内存地址。由于JVM程序是多线程执行的（线程轮流切换），所以为了保证线程切换回来后，还能恢复到原先状态，就需要一个独立的计数器，记录之前中断的地方。 本地方法栈(Native Method Stack)：和Java栈的作用类似，只不过是为JVM使用到的native方法服务的。 参考：java中进程与线程的概念 并行和并发： 并行：多个CPU同时执行多个任务。 并发：一个CPU(采用时间片)同时执行多个任务。 二、线程的创建和使用线程的创建方式共有四种：继承Thread类、实现Runnable接口、实现Callable接口(5.0新增)、使用线程池(5.0新增)。 1、Thread类创建线程的第一种方式是继承Thread类： 创建继承Thread类的子类。 重写run()方法，将此线程执行的操作声明的此方法中。 创建子类的对象，然后使用此对象调用start()方法。 ①start()方法的作用：启动当前线程；调用当前线程的run()方法。 ②启动多线程，必须调用start()方法，不能通过直接调用run()的方式启动线程。 ③不能让已经start()的线程再start()，即一个线程不能启动多次，否则报IllegalThreadStateException异常。 ④如果想创建多个线程，需要创建多个对象。 实现代码： 123456789101112131415161718192021222324252627public class ThreadTest { public static void main(String[] args) { //3.创建Thread类的子类的对象 MyThread1 mt = new MyThread1(); //4.通过此对象调用start()方法 mt.start(); //主线程使用mt对象调用了start方法，启动新线程。 // start方法能够使线程执行，JVM调用这个线程的run方法 //这里是主线程运行 //同时运行两个线程，输出顺序就不确定，每个线程的输出也可能交叉 for( int i = 0; i&lt;100;i++){ if(i % 2 != 0) System.out.println(Thread.currentThread().getName()+\":\"+i); } }}// 1.创建一个继承于Thread类的子类class MyThread1 extends Thread{ //2.重写Thread的run() @Override public void run() { for(int i = 0; i&lt;100;i++){ if(i % 2 == 0) System.out.println(Thread.currentThread().getName()+\":\"+i); } }} Thread类的相关方法： start()：启动线程，并执行对象的run()方法 run()：线程被调度时执行的操作 currentThread()：返回当前线程，在Thread子类中就是this，通常用于主线程和Runnable实现类 getName()：返回线程名称 setName()：设置线程名称 yield()：线程让步，释放当前cpu的执行权。暂停当前正在执行的线程，把执行机会让给优先级相同或更高的线程。 join()：在线程A中调用线程B的join()方法，此时A进入阻塞状态，直到线程B完全执行完以后，线程A才结束阻塞状态 sleep(long millitime)：让当前线程指定时间内放弃对CPU的控制。指定的毫秒时间内，当前线程是阻塞状态。 isAlive()：判断线程是否活着 stop()：已过时。强制结束当前线程 suspend()：已过时 resume()：已过时 线程的优先级： MAX_PRIORITY：10 MIN_PRIORITY：1 NORM_PRIORITY：5 方法： getPriority()：返回线程优先级 setPriority(int newPriority)：改变线程优先级 线程创建时继承父线程的优先级 低优先级的线程只是获得调度的概率低，并不是说低优先级线程一定在高优先级线程执行完之后执行。 守护线程和用户线程 二者几乎每个方面都是相同的，唯一的区别是判断JVM何时离开。 守护线程是用来服务用户线程的，可以通过在start()方法前调用thread.setDaemon(true)把用户线程变成守护线程。 守护线程比如Java垃圾回收。当JVM中都是守护线程时，当前JVM将退出 2、Runnable接口创建线程的第二种方式是实现Runnable接口： 创建类，实现实现Runnable接口。 重写run()方法。 创建实现类对象，作为参数传入Thread类的构造器。 Thread类的对象调用start()方法启动线程。 ①实现接口的方法，避免了单继承的局限性。 ②多个线程共享一个接口实现类的对象，非常适合多个相同线程处理同一份资源。 ③和方法一相比，实现Runnable接口的方法优先使用。 实现代码： 1234567891011121314151617public class ThreadTest2 { public static void main(String[] args) { MyThread2 mt = new MyThread2(); Thread t1 = new Thread(mt,\"Thread-1\"); Thread t2 = new Thread(mt,\"Thread-2\"); //启动多个线程，只需要新建Thread对象，两个线程共享Runnable实现类对象 t1.start(); t2.start(); }}class MyThread2 implements Runnable{ @Override public void run() { for(int i = 0; i&lt; 100; i++) System.out.println(Thread.currentThread().getName()); }} 3、Callable接口创建线程的第三种方法是实现Callable接口(JDK 5.0新增)： 声明实现Callable接口的实现类。 重写call()方法。 声明实现类对象，比如mt3。 声明FutureTask类对象ft，构造器参数为实现类对象mt3。 声明Thread类对象t，构造器参数为FutureTask类对象ft。 通过对象t调用start()方法，启动并运行线程。 ①Future接口可以对具体Runnable、Callable任务的执行结果进行取消、查询是否完成、获取结果等。 ②FutureTask是Future接口唯一的实现类。 ③FutrueTask同时实现了Runnable、Future接口，它既可以作为Runnable被线程执行，也可以作为Future得到Callable的返回值。 实现Callable接口和实现Runnable接口相比，前者更强大，因为： call()方法可以有返回值。 call()可以抛出异常，被外面的操作捕获，获取异常信息 Callable支持泛型。 实现代码： 12345678910111213141516171819202122232425262728293031323334public class ThreadThree { public static void main(String[] args) { //创建实现类的对象 NumThread numThread = new NumThread(); //创建FutureTask类对象，将实现类对象作为参数 FutureTask futureTask = new FutureTask(numThread); //创建Thread类对象，将futureTask作为Runnable被线程执行 new Thread(futureTask).start(); //FutureTask作为Future得到Callable的返回值 try {//get的返回值即numThread重写的call的返回值 Object num = futureTask.get(); System.out.println(num); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } }}class NumThread implements Callable{ //实现Callable接口，并重写call方法 //call()函数有返回值，且能够抛出异常 @Override public Object call() throws Exception { int sum = 0; for (int i = 0; i &lt;= 100; i++) { if(i % 2 == 0){ System.out.println(i); sum += i; } } return sum; }} 4、线程池创建线程的第四种方式是使用线程池(JDK 5.0新增)。 经常创建和销毁、使用量特别大的资源，比如并发情况下的线程，对性能影响很大。线程池的思想是提前创建好多个线程，放入线程池中，使用时直接获取，使用完放回池中。可以避免频繁创建销毁、实现重复利用。 线程池的优势： 提高响应速度（减少了创建新线程的时间）。 降低资源消耗（重复利用线程池中线程，不需要每次都创建）。 便于线程管理。 JDK 5.0 提供了线程池相关的API：ExecutorService接口和Executors工具类。 ThreadPoolExecutor是ExecutorService的常见实现类，其中的常用方法： corePoolSize：核心池大小 maximumPoolSize：最大线程数 keepAliveTime：线程没有任务时，最多保持多长时间后会终止 ExecutorService：真正的线程池接口，常见的实现类为ThreadPoolExecutor void execute(Runnable command):执行任务/命令，一般用来执行Runnable &lt;T&gt;Future&lt;T&gt; submit(Callable&lt;T&gt; task):执行任务，有返回值，一般用来执行Callable void shutdown()：关闭连接池。 Executors：工具类、线程池的工厂类，用于创建并返回不同类型的线程池。 Executors.newCachedThreadPool()：创建一个可根据需要创建新线程的线程池 Executors.newFixedThreadPool(n)：创建一个可重用的固定线程数的线程池 Executors.newSingleThreadExecutor()：创建一个只有一个线程的线程池 Executors.newScheduledThreadPool(n)：创建一个线程池，可安排在给定延迟后运行命令或者定期地执行 使用步骤： 1.提供指定线程数量的线程池：调用工具类的方法创建线程池，返回ThreadPoolExecutor对象。 2.执行指定的线程的操作，需要提供实现Runnable接口或Callable接口实现类的对象。 3.关闭线程池。 具体代码： 1234567891011121314151617181920public class ThreadPool { public static void main(String[] args) { //1.提供指定线程数量的线程池 ExecutorService service = Executors.newFixedThreadPool(10); //ThreadPoolExecutor类实现了ExecutorService接口 ThreadPoolExecutor service1 = (ThreadPoolExecutor) service; //通过service1，可以设置线程池的属性... service1.setMaximumPoolSize(15); //2.执行指定的线程的操作，需要提供实现Runnable接口或Callable接口实现类的对象 service.execute(new NumThreadFour()); //适合于Runnable,分配线程1 service.execute(new NumThreadFour2()); //适合于Runnable，分配线程2 service.submit(new FutureTask(new NumThreadFour3())); //适合于Callable，分配线程3 //3.关闭线程池 service.shutdown(); }}class NumThreadFour implements Runnable {...}class NumThreadFour2 implements Runnable {...}class NumThreadFour3 implements Callable {...} 三、线程的生命周期一个线程的完整生命周期有六种状态，在Thread类中的State枚举类定义了线程的五种状态： 新建(NEW)：执行new指令，新创建的线程的状态 运行(RUNNABLE)：运行状态包括就绪(READY)和正在运行(RUNNING)两个状态。 就绪(READY)：执行start方法以后进入就绪状态，已经具备了运行的条件，只有分配到CPU资源以后才进入RUNNING状态。 正在运行(RUNNING)：就绪的线程分配到CPU资源(时间片)时，便进入RUNNING状态，run()方法定义了线程的操作和功能。 阻塞(BLOCKED)：线程进入synchronized方法/代码块中时，要判断同步锁是否被释放，等待同步锁被释放的状态就是阻塞状态。获取到同步锁以后进入就绪状态。 等待(WAITING)：等待状态下的线程不会被分配CPU时间片，必须被显式唤醒，即notify()/notifyAll()，否则会处于无限期等待的状态 超时等待(TIMED_WAITING)：超时等待状态下的线程不会被分配CPU时间片，无须被显式唤醒，在达到一定时间后会自动唤醒。 终止(TERMINATED)：线程的run()方法完成时，或者被强制终止，或出现异常导致结束，线程进入终止状态。 1、执行Object中的wait()方法后，线程释放同步锁并进入等待状态，只有被显示唤醒，比如notify()/notifyAll()，才能进入阻塞状态，等待同步锁被释放然后进入就绪状态。 2、执行sleep()、join()、IO操作以后，线程进入超时等待状态，等时间到或者操作结束，自动进入就绪状态。 线程的状态转换图(图中的阻塞状态包括了阻塞、等待、超时等待三个状态)： 四、线程的同步1、介绍多条语句在操作共享数据时，如果某个线程操作尚未完成时，其他线程参与进来，会导致共享数据出现错误，这就导致了线程安全问题。 比如有三个窗口共同卖100张票，如下的代码就会有线程安全问题： 1234567891011121314151617181920212223242526272829303132333435363738public class WindowTest2 { public static void main(String[] args) { Window2 w2 = new Window2(); //创建三个线程，即三个窗口 Thread t1 = new Thread(w2,\"窗口1\"); Thread t2 = new Thread(w2,\"窗口2\"); Thread t3 = new Thread(w2,\"窗口3\"); t1.start(); t2.start(); t3.start(); }}class Window2 implements Runnable{ private int ticket = 100; @Override public void run() { while(true){ if(ticket &gt; 0){ System.out.println(Thread.currentThread().getName()+\"票号为:\"+ticket); ticket--; }else break; } }}/*三个线程共享100张票，在其中一个窗口操作的同时，其他线程参与进来，导致票数出现异常以下是部分执行结果：窗口2票号为:23窗口2票号为:7窗口2票号为:6窗口1票号为:8窗口3票号为:19窗口1票号为:4窗口1票号为:2窗口2票号为:5窗口1票号为:1窗口3票号为:3*/ 为了解决类似于以上的线程安全问题，需要保证当前线程操作时，其他线程不能参与进来，直到当前线程操作完，其他线程才可以操作。即使当前线程出现了阻塞，也不能被改变。 Java中使用同步机制解决线程安全问题，包括同步代码块、同步方法、Lock锁(JDK 5.0新增)三种方法实现同步机制。其中同步代码块和同步方法都是使用synchronized关键字。 2、方法一：同步代码块格式和代码： 123456789101112131415161718192021222324252627282930313233343536//格式：synchronized(同步监视器){ //需要被同步的代码}//具体使用：public class TicketSell { public static void main(String[] args) { Window w = new Window(); //创建三个线程，即三个窗口 Thread t1 = new Thread(w, \"窗口1\"); Thread t2 = new Thread(w, \"窗口2\"); Thread t3 = new Thread(w, \"窗口3\"); t1.start(); t2.start(); t3.start(); }}class Window implements Runnable { private int ticket = 100; Object obj = new Object(); //同步监视器(同步锁) @Override public void run() { while (true) { //synchronized (this){ //也可以使用当前对象 //synchronized (Window.class){ //当前类也可以作为同步锁 synchronized (obj) { //以下为同步代码 if (ticket &gt; 0) { System.out.println(Thread.currentThread().getName() + \"票号为:\" + ticket); ticket--; } else break; } } }} 说明： 操作共享数据的代码，即为需要被同步的代码，同步代码不能多也不能少，否则容易导致错误。 共享数据：多个线程共同操作的数据，比如本例的ticket。 同步监视器，即“同步锁”：任何一个类的对象都可以充当同步锁。同步锁被某个线程持有的时候，只有当其执行完同步代码，然后释放同步锁以后，其他线程才可以继续执行。 要求多个线程必须共用同一把同步锁，即多个线程的同步锁必须是同一个对象，才能保证同步。 实现Runnable接口创建多线程的方式中，因为只创建一个实现类对象，可以考虑使用this充当同步锁。而在继承Thread类创建多线程的方式中，要慎用this作为锁，根据实际情况判断this是不是唯一的。 也可以考虑当前类作为同步锁(类也是对象，即当前类.class。 3、方法二：同步方法如果操作共享数据的代码完整的声明在一个方法中，可以使用synchrozied将此方法声明为同步的。可以将多个方法都使用synchronized监视起来，解决这几个方法的线程安全问题。 格式和使用： 1234567891011121314151617181920212223//格式：权限修饰符 synchronized 返回值类型 方法名(参数){ //操作共享数据的代码}//具体使用：class Window3 implements Runnable { private int ticket = 100; @Override public void run() { while (true) { show(); } } //同步方法。非静态方法默认的同步监视器是this private synchronized void show() { if (ticket &gt; 0) { System.out.println(Thread.currentThread().getName() + \"票号为:\" + ticket); ticket--; } }} 说明： 同步方法仍然涉及到同步监视器，不需要显式声明。 对于非静态的同步方法，同步监视器是this 对于静态的同步方法，同步监视器是当前类本身(类名.class，类也是对象)。 4、方法三：Lock锁Lock锁是JDK 5.0新增的解决线程安全问题的一种方式，通过显式定义同步锁对象来实现同步。同步锁使用Lock对象充当。 java.util.concurrent.locks.Lock接口是控制多个线程对共享资源进行访问的工具。锁提供了对共享资源的独占访问，每次只能有一个线程对Lock对象加锁，线程开始访问共享资源之前应先获得Lock对象。ReentrantLock类实现了Lock接口，它拥有与synchronized相同的并发性和内存语义，在实现线程安全的控制中，比较常用的是ReentrantLock，可以显式加锁、释放锁。 使用方法： 12345678910111213141516171819202122//首先需要声明ReentrantLock对象//然后调用lock方法加锁//最后调用unlock方法释放锁class Window implements Runnable { private int ticket = 100; private ReentrantLock lock = new ReentrantLock(); //步骤一 @Override public void run() { while (true) { lock.lock(); //步骤二，加锁 try { if (ticket &gt; 0) { System.out.println(Thread.currentThread().getName() + \":\" + ticket); ticket--; } else break; } finally { lock.unlock(); //步骤三，解锁 } } }} 使用Lock接口进行同步的时候，同样需要保证多个线程使用同一个ReentrantLock对象。 比较synchronized和Lock的异同： synchronized是隐式锁，在执行完相应的同步代码后，自动释放同步锁(同步监视器)。 Lock是显式锁，需要手动启动同步（执行Lock()），结束时也需要手动关闭（执行unLock()），try-catch结构中，解锁代码需要写在finally中，保证unlock()一定会被执行。 Lock只有代码块锁，synchronized有代码块锁和方法锁。 三种实现同步的方式，使用的优先顺序为：Lock—&gt;同步代码块(已经进入了方法体，分配了相应资源)—&gt;同步方法 5、死锁同的线程分别占用对方需要的同步资源(同步锁)不放弃，都在等待对方放弃自己需要的同步资源，就形成了线程的死锁。A线程持有锁a，等待操作b，而B线程持有锁b，等待操作a(此时a被A当作同步锁持有，没有被释放)，这就形成了死锁。 举例： 1234567891011121314151617181920212223242526public class DeadLock { public static void main(String[] args) { StringBuffer s1 = new StringBuffer(); StringBuffer s2 = new StringBuffer(); new Thread() {//Thread的匿名实现类 @Override public void run() { synchronized (s1) { s2.append(\"a\"); //持有同步锁 s1，等待s2被释放 System.out.println(getName() + \":\" + s1); System.out.println(getName() + \":\" + s2); } } }.start(); new Thread() { //Thread的匿名实现类 @Override public void run() { synchronized (s2) { s1.append(\"b\");//持有同步锁 s2，等待s1被释放，造成死锁 System.out.println(getName() + \":\" + s1); System.out.println(getName() + \":\" + s2); } } }.start(); }} 解决方法：1.专门的算法、原则2.尽量减少同步资源的定义3.尽量避免嵌套同步 五、线程的通信线程的通信涉及到三个方法： wait()：使当前线程进入等待状态(排队等待同步资源)，并释放同步锁(同步监视器)。 notify()：唤醒排队等待同步资源的一个进程，如果有多个线程排队等待同步资源，唤醒优先级高的线程。 notifyAll()：唤醒所有排队等待同步资源的线程。 调用以上三个方法的必要条件是当前线程具有对当前对象的监控权，即持有同步锁。这三个方法只能在同步代码块或同步方法中使用。 任意对象都能作为同步锁，因此以上三个方法在Object类中声明。 sleep()和wait()两个方法的异同： 都可以使当前线程进入阻塞状态，sleep使线程进入的是超时等待(TIMED_WAITING)状态，wait使线程进入等待(WAITING)状态。 声明位置不同，sleep声明在Thread类中，wait方法声明在Object类中。 调用的要求不同。sleep可以在任何需要的场景下使用。wait只能在同步代码块/同步方法中。 是否释放同步锁：两个方法都使用在同步代码块/同步方法中时，sleep不会释放同步锁，wait会释放同步锁。 总结： 能够释放锁的操作有以下几种： 线程的同步方法、同步代码块执行结束。 执行过程中遇到break、return终止了执行操作。 有未处理的Error和Exception，导致异常结束。 执行线程的wait()方法，使线程释放锁，并进入等待状态。 sleep、yield方法以及suspend方法不会释放同步锁。 尽量避免使用suspend和resume方法控制线程。 线程通信举例：创建两个线程，交替输出从1-100的数据 12345678910111213141516171819202122232425262728293031public class CommunicationTest { public static void main(String[] args) { CommunicationThread ct = new CommunicationThread(); Thread t1 = new Thread(ct, \"Thread-1\"); Thread t2 = new Thread(ct, \"Thread-2\"); t1.start(); t2.start(); }}//这里使用实现Runnable接口的方式class CommunicationThread implements Runnable { private int number = 0; public void run() { while (true) { synchronized (this) { notify(); //唤醒另一个线程，只有两个线程，也可以使用notifyAll if (number &lt; 100) { number++; System.out.println(Thread.currentThread().getName() + \":\" + number); try { wait(); //当前线程进入阻塞状态 } catch (InterruptedException e) { e.printStackTrace(); } } else break; } } }}","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记07-异常处理","slug":"java-note-0701","date":"2021-03-26T14:37:04.000Z","updated":"2022-05-22T13:30:54.792Z","comments":true,"path":"2021/03/26/java-note-0701/","link":"","permalink":"http://kangshitao.github.io/2021/03/26/java-note-0701/","excerpt":"异常处理，try-catch-finally，throws，throw，自定义异常类","text":"一、异常概述与异常体系结构1、异常概述Java中的异常可以分为两类： Error：Java虚拟机无法解决的严重问题，如：JVM系统内部错误、资源耗尽等严重情况。比如StackOverflowError和OOM。对于这类异常一般不编写针对性代码进行处理。 Exception：其他因编程错误或偶然的外在因素导致的一般性问题。可以使用针对性代码进行处理，如 空指针异常：NullPointerException 读取不存在的文件：FileNotFoundException 类型转换异常：ClassCastException 数组索引越界：ArrayIndexOutOfBoundException 2、异常体系结构Java中的异常体系结构如下： java.lang.Throwable有以下继承关系: java.lang.Error： StackOverflowError OutOfMemoryError ... java.lang.Exception： ClassNotFoundException CloneNotSupportedException IOException： EOFException FileNotFoundException MalformedURLException UnknowHostException ... RuntimeException: ArithmeticException：除数是0时报此异常 ClassCastException IllegalArgumentException IllegalStateException IndexOutOfBoundsException NoSuchElementException NullPointerException ... ... 可以看到，Throwable是异常体系的根父类，其有Error和Exception两个子类，Exception分为运行时异常(RuntimeException)和编译时异常(IOException等)，其中运行时异常又可以称为非受检(unchecked)异常，编译时异常称为受检(checked)异常。 3、异常处理Java中对于异常处理使用的抓抛模型： 第一步，“抛”出异常：执行过程中，一旦出现异常，会在代码处生成一个对应异常类的对象，并将此对象抛出，一旦抛出异常对象以后，其后的代码不再执行。 抛出异常有两种方式：①系统自动生成异常对象并自动抛出。②手动生成异常对象并抛出(throw) 第二步，“抓”住异常(捕获(catch)异常)，即异常的处理。 对于异常处理有两种方法：①try-catch-finally。②使用throws将异常交给方法调用者处理。 二、异常处理机制之一：try-catch-finally1、try-catch的使用try-catch-finally的使用： 1234567891011121314151617181920 try{ //可能出现异常的代码 }catch(异常类型1 变量名1){ //处理异常的方式1 }catch(异常类型2 变量名2){ //处理异常的方式2 }catch(异常类型3 变量名3){ //处理异常的方式3 } ...... finally{ //一定会执行的代码 }//例如： try{ ...//读取文件的语句 }catch(IOException e){ System.out.println(e.getMessage()); } finally是可选的，try-catch-finally结构可以嵌套。 使用try将可能出现异常的代码包装起来，一旦出现异常，会生成一个对应异常类的对象，根据此对象的类型，去catch中匹配。 try中的异常对象匹配到某个catch时，就进入catch中处理，处理完成后，跳出try-catch结构(没有finally时)，继续执行其后的代码 catch中的异常类型如果没有子父类关系，则多个catch无关顺序。如果多个catch的异常类型有子父类关系，需要将子类写在父类的前面，否则出错。比如NullPointerException必须写在RuntimeException前面。 常用的异常对象处理的方式： Sting getMessage()：获取异常信息，返回字符串。 printStackTrace()：获取异常类名和异常信息，以及异常出现在程序中的位置，返回值void。 try结构中声明的变量，在try结构外面不能调用。可以将变量声明在外面，在try结构中赋值。 2、finallyfinally的用法： finally中声明的是一定会被执行的代码。即使catch中又出现异常、try中有return语句、catch中有return语句，finally中的语句也会执行。 数据库连接、输入输出流、网络编程Socket等资源，JVM不能自动回收，需要手动进行资源的释放。此时的资源释放，需要声明在finally中。 3、不捕获异常的情况 使用try-catch-finally处理编译时异常，使程序在编译时不报错，但运行时仍可能报错。相当于使用try-catch-finally将编译时可能出现的异常延迟到运行时出现。 由于运行时异常比较常见，Java能够自动捕获，因此，对于运行时异常，通常不使用try-catch结构捕获。而对于编译时异常，必须进行异常处理(捕获异常)。 三、异常处理机制之二：throws1、throws的使用使用throws声明抛出异常是处理异常的第二种方式。如果一个方法中可能生成某种异常，但不能确定如何处理这种异常，就可以使用throws显式地声明抛出异常，表示该方法不对这些异常处理，而是由调用者负责处理。 当方法体执行时出现异常，会在异常代码处生成一个异常类对象，如果此对象满足throws后的异常类型，就会被抛出(抛给方法的调用者)，异常代码后面的语句不再执行。 throws的使用格式为：throws 异常类型，写在方法声明处的方法名后面。 例如： 12345public void method() throws FileNotFoundException, IOException{ //读取文件的语句 File file = new File(\"xxx.txt\"); ...} 可以同时声明多个类型的抛出异常。 对于重写的方法，子类重写的方法抛出的异常不大于父类被重写的方法抛出的异常类型。 2、throws和try-catchthrows和try-catch都是异常处理的两种方式，其区别是： try-catch-finally真正地将异常处理掉了。 throws的方式只是将异常抛给了方法的调用者，没有真正地处理掉异常。 如何选择两种处理方式？ 如果父类中被重写的方法没有throws方式处理异常，则子类重写的方法不能使用throws，如果有异常只能使用try-catch-finally的方式。 如果执行的方法a中先后调用了另外的几个递进关系的方法，建议这几个方法使用throws处理异常，而方法a使用try-catch-finally。 四、手动抛出异常：throwJava异常类对象除了系统自动生成以外，还可以手动创建异常类对象并抛出。需要先声明异常类对象，然后通过throw语句抛出： 12IOException e = new IOException(); //创建异常类对象throw e; //将异常类对象抛出 手动抛出异常的方式，可以用在try-catch结构里和使用了throws的方法中。 throw的应用： 12345678910111213141516//场景一：try { System.out.println(\"try\"); throw new RuntimeException(\"制造异常\");} catch{ System.out.println(\"catch\");}//场景二：public void method(int id) throws Exception { if(xxx){ //执行语句 }else{ //手动抛出异常对象 throw new RuntimeException(\"您输入的数据非法！\"); //throw new MyException(\"不能输入负数\"); //抛出自定义异常类对象 } 五、自定义异常类一般来说，自定义异常类都是RuntimeException、Exception的子类，过程如下： 编写重载的构造器。 提供serialVersionUID 通过throw抛出异常类对象 以下是自定义类的举例： 12345678public class MyException extends RuntimeException{ static final long serialVersionUID = -1234567890L; public MyException(){} public MyException(String msg){ super(msg); }}","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记06-面向对象编程(下)","slug":"java-note-0601","date":"2021-03-26T03:49:40.000Z","updated":"2022-05-22T13:30:54.792Z","comments":true,"path":"2021/03/26/java-note-0601/","link":"","permalink":"http://kangshitao.github.io/2021/03/26/java-note-0601/","excerpt":"static，fianl，单例模式，抽象类，接口，代码块，内部类","text":"一、关键字：static1、介绍static：静态的，可以用来修饰属性、方法、代码块、内部类。 被static修饰的成员，有以下特点： 随着类的加载而加载。 优先于对象存在。 修饰的成员，被所有对象共享。 访问权限允许时，可不创建对象，直接被类调用。 有关static修饰的成员特点，都可以从生命周期的角度来解释。 2、修饰属性static修饰的属性称为静态变量(类变量，类属性)，静态变量随着类的加载而加载，可以通过类名.静态变量的方法调用。静态变量的加载早于对象的创建，且在内存中只会存在一份，保存在方法区的静态域中。常见的静态变量：System.out、Math.PI等。 静态变量(类变量) vs 非静态变量(实例变量)： 静态变量：可以通过类.静态变量和对象.静态变量两种方法调用。多个对象共享一个静态变量，通过一个对象修改此属性，其他对象调用时是被修改后的值。 实例变量：只能通过对象.实例变量的方式调用。每个对象都独立地拥有一套类中的实例变量，实例对象归具体的某个对象所有，修改某个对象的实例变量，不会影响其他对象同样的变量。 3、修饰方法静态方法vs非静态方法： 静态方法：可以通过类.方法和对象.方法两种方法调用。静态方法只能调用静态方法和属性，可以通过创建对象的方法调用非静态方法和属性。静态方法不能使用this、super关键字。 非静态方法：既可以调用静态方法，也可以调用非静态方法。 静态方法不可以被重写。 4、使用场景 判断属性是否要声明为静态的： 属性可以被多个对象共享，不会随着对象的不同而不同，比如银行利率。 类中的常量一般声明为static final的。 判断方法是否要声明为静态的： 操作静态属性的方法一般声明为静态的。 工具类中的方法习惯上声明为静态的，比如Math、Arrays、Collections 5、单例模式单例模式，就是采取一定的方法保证在整个的软件系统中，对某个类只能存在一个对象实例，并且该类只提供一个取得其对象实例的方法。 设计单例模式根据以下思路： 想让类只能存在一个对象实例，就要将构造器权限设置为private，在类内部创建此对象。这样外部不能用new操作符创建新的对象。 外部想要得到这个类的对象，就需要调用public的static方法得到此对象。 获取对象的方法是static的，则指向类内部产生的该类对象的变量也必须是static的。 根据以上思路，有两种单例模式写法，饿汉式和懒汉式： 1234567891011121314151617181920212223242526272829303132//饿汉式单例模式class Bank{ //1.私有化类的构造器 private Bank{} //2.创建类的私有对象属性 //4.方法是静态的，则此对象属性必须是静态的 private static Bank instance = new Bank(); //3.提供公共的静态方法，返回类的对象 public static Bank getInstance(){ return instance; }}//懒汉式单例模式class Bank{ //1.私有化类的构造器 private Bank{} //2.创建类的私有对象属性,先不初始化 //4.方法是静态的，则此对象属性必须是静态的 private static Bank instance; //3.提供公共的静态方法，返回类的对象 public static Bank getInstance(){ if (instance == null){ instance = new Bank(); } return instance; }} 饿汉式单例模式vs懒汉式单例模式： 饿汉式：无论有没有使用，都创建对象实例，对象加载时间较长；但饿汉式单例模式线程安全的。 懒汉式：延迟对象的创建；以上写法是线程不安全的，可以修改为线程安全的。 单例模式的应用： 网站的计数器 应用程序的日志应用 数据库连接池 读取配置文件的类 Application Windows任务管理器 Windows回收站 二、理解main方法main()方法是程序的入口，其形式为：public static void main(String[] args){}，从形式上可知： main()方法也是普通的静态方法，可以通过类名.main()的方式调用。main()方法调用其他非静态方法需要创建对象，然后使用对象.非静态方法的方式调用。 main()有参数，可以作为与控制台交互的方式。 三、类的成员之四：代码块 代码块没有名字，自动执行。 作用：代码块用于对Java类或对象进行初始化。 一个类中可以定义多个代码块，按照先后顺序执行。 代码块如果有修饰符，只能使用static修饰。 静态代码块： 内部可以有输出语句。 随着类的加载而执行，只会执行一次。 作用：用来初始化类的信息，比如对类变量赋值。 非静态代码块： 内部可以有输出语句。 随着对象的创建而执行，每创建一次对象就执行一次。 非静态代码块先于构造器执行。 作用：可以在创建对象时，对对象的属性进行初始化。 静态代码块和静态方法类似，只能直接调用静态方法和属性。 代码块应用举例： 1234567891011121314151617181920212223242526272829303132333435363738public class BlockTest { public static void main(String[] args) { Student student = new Student(); } static { //先加载BlockTest类，再加载Person类 System.out.println(\"BlockTest block\"); }}class Person{ private String name; public Person(){} //非静态代码块 {System.out.println(\"Person block\");} //静态代码块 static{System.out.println(\"Person static block\");}}class Student extends Person{ private int number; public Student(){ System.out.println(\"Student constructor\"); } {System.out.println(\"Student block\");} static {System.out.println(\"Student static block\");}}/* 以上程序运行结果：BlockTest block //先加载主类Person static block //声明子类对象变量时，先加载父类，执行父类的静态代码块Student static block //然后加载子类，执行子类的静态代码块Person block //执行new语句通过构造器创建对象时，先执行父类非静态代码块Student block //然后执行子类代码块Student constructor //最后执行构造器/* 以上结论可以总结为：由父及子，静态先行。 属性赋值的方式以及顺序： 默认初始化 显式初始化；多个代码块赋值(这两种方式根据代码顺序执行) 构造器初始化 创建对象以后，通过对象调用属性或方法进行赋值 四、关键字：finalfinal：最后的，可以用来修饰类、方法、变量。 final修饰类：表示此类不能被其他类继承，比如String类、System类、StringBuffer类等 final修饰方法：表明此方法不能被重写，比如Object类的getClass()方法 final修饰变量：包括属性和局部变量，表示变量的值不允许被修改，此时的变量称为常量。 final修饰属性，可以直接赋值，也可以先声明，然后在代码块中、构造器中再初始化赋值。 构造器中初始化常量，可以通过形参为每个对象设置不同的常量值，比如身份证号。 final修饰局部变量时，对于方法内部的局部变量，使用final修饰变为常量；对于final修饰的形参，调用方法的时候赋值，然后不允许再修改。 static final用来修饰的属性，称为全局常量。 五、抽象类与抽象方法abstract：抽象的，可以用来修饰类、方法。 1、抽象类abstract修饰的类称为抽象类。 抽象类不能实例化对象，可以使用多态。 抽象类中一定有构造器，便于子类实例化时调用。 实际开发中会提供抽象类的子类，让子类对象实例化，完成相关操作。 2、抽象方法abstract修饰的方法称为抽象方法。 抽象方法只有方法的声明，没有方法体（没有{}），例：public void showInfo(); 包含抽象方法的类一定是抽象类，反之，抽象类可以没有抽象方法。 只有子类实现（类似于重写）了父类中的所有抽象方法(包括直接父类和间接父类的所有抽象方法)，此子类才可以实例化，否则该子类也是抽象类。 1.abstract不能修饰变量、构造器、代码块。 2.因为抽象方法必须要被实现(重写)，所以abstract不能用来修饰private方法、static方法、final的方法。同样，abstract也不能修饰final的类。 3、匿名子类定义抽象类Person的匿名子类： 12345678910Person p = new Person(){ @Override public abstract void eat(){ System.out.println(\"eat\"); }}; //匿名子类需要重写父类的抽象方法abstract class Person{ public abstract void eat();} 六、接口(interface)interface：接口。接口定义的是一组规则，是和类并列的结构。继承是一种“是不是”的关系，而接口是“能不能“的关系。定义接口：interface Flyable{} JDK 7及以前，接口中只能定义全局常量和抽象方法。 全局常量：默认权限是public static final，关键字可以省略不写。全局常量可以通过接口.常量调用。 抽象方法：默认权限是public abstract，关键字同样可以不写 JDK 8及以后，接口中除了能够定义全局常量和抽象方法以外，还能够定义静态方法，默认(default)方法。 接口中定义的静态方法，只能使用接口调用，即接口.静态方法。 实现类如果调用接口的默认方法，使用接口.super.默认方法的方式调用。 通过实现类的对象，可以调用接口的默认方法。默认方法可以被重写，但不是必须的，不强制，接口中的抽象方法必须被重写。 如果子类继承的父类和实现的接口中声明了同名同参的方法，如果子类没有重写，默认调用的是父类中的方法。(类优先原则) 如果实现类同时实现了多个接口，这多个接口中定义了同名同参的默认方法，实现类必须重写此方法，否则报错。(接口冲突) 接口中不能定义构造器，即接口不能够实例化。 接口通过被类实现(implements)来使用。实现类必须实现接口的所有抽象方法，此类才能被实例化，否则此类必须定义为抽象类。 Java类可以同时实现多个接口，弥补了Java无法多继承的缺陷。implements关键字在extends后面，比如父类B的子类A，实现了C、D两个接口：class A extends B implements C,D{} 接口和接口之间可以继承，而且可以多继承。接口的具体使用体现了多态性。 接口的匿名实现类，格式和抽象类的匿名子类相同。 七、类的成员之五：内部类Java中允许将一个类A声明在另一个类B中，则类A是内部类，类B是外部类。内部类和外部类的类名不能相同。 根据声明的位置不同，内部类又分为成员内部类和局部内部类(方法内、代码块内、构造器内) 1、成员内部类成员内部类直接声明在类的内部，有两种身份：作为类的成员，作为一个类。 作为类的成员，具有类的成员的特征： 可以调用外部类的结构 可以被static修饰 可以被四种不同的权限修饰符修饰 作为一个类，具有类的功能： 成员内部类内可以定义属性、方法、构造器等，和一般的类定义相同 可以被final修饰，表示不可以被继承。不加final则表示可以被继承 可以被abstract修饰 1.非static的成员内部类中的成员不能声明为static的，只有外部类，或者static的成员内部类中才可以声明static成员。 2.外部类访问成员内部类的成员，通过内部类.成员或内部类对象.成员的方式。 3.成员内部类可以直接使用外部类的所有成员，包括私有的数据。 2、局部内部类局部内部类是声明在方法内、代码块内、构造器内的类。 局部内部类只能在声明它的方法或代码块中使用，但是局部内部类的对象可以通过外部方法的返回值返回使用，返回值类型只能是局部内部类的父类或父接口类型。 局部内部类可以使用外部类的成员，包括私有的。 局部内部类可以使用外部方法的局部变量，但必须是final的。JDK 8之后可以省略final关键字。 和局部变量类似，局部内部类不能使用四种权限修饰符。 局部内部类不能使用static修饰，也不能包含静态成员。 3、内部类的使用实例化成员内部类的对象： 静态成员内部类：外部类.内部类 对象名 = new 外部类.内部类(); 非静态成员内部类：①创建外部类对象：外部类 p = new 外部类();②外部类.内部类 对象名 = p.new 内部类(); 在成员内部类中区分调用外部类的结构： this.属性表示内部类的属性 外部类.this.属性表示调用外部类的属性 局部内部类中的使用案例：如下面代码中的public Comparable getComparable(){} 内部类的使用代码： 123456789101112131415161718192021222324252627282930313233343536373839404142class Person{ //静态成员内部类 static class Brain{ } //非静态成员内部类 class Heart{ } public void method(){ int num = 10; class AA{ int aa = num; } //方法中的局部内部类 //num = 20; //编译错误。局部内部类调用了num，则num是final的，不可以被修改。 } { class BB{} //代码块中的局部内部类 } public Person(){ class CC{} //构造器中的局部内部类 } public Comparable getComparable(){ //返回一个实现了Comparable接口的类的对象 //方式一，定义局部内部类 /* class MyComparable implements Comparable{ public int compareTo(Object o){ return 0; } } return new MyComparable(); */ //方式二：使用匿名实现类，返回匿名实现类的匿名对象 return new Comparable() { @Override public int compareTo(Object o) {return 0;} }; }} 内部类在编译后，也会生成字节码文件： ①成员内部类：外部类$内部类名.class ​ 例如：Person$Brain.class ②局部内部类：外部类$数字 内部类名.class ​ 例如：Person$1AA.class 4、匿名内部类匿名内部类不能定义任何静态成员、方法和类，只能创建匿名内部类的一个实例。一个匿名内部类一定是在new的后面，用其隐含实现一个接口或实现一个类。 格式： new 父类构造器(实参列表)|实现接口(){ ​ //匿名内部类的类体部分 ​ } 匿名内部类特点： 匿名内部类必须继承父类或实现接口。 只能有一个对象。 对象只能使用多态形式引用。 匿名内部类举例： 12345678910111213141516171819202122interface Product{ public double getPrice(); public String getName();}public class AnonymousTest{ public void test(Product p){ System.out.println(\"购买了一个\" + p.getName() + \"，花掉了\" + p.getPrice()); } public static void main(String[] args) { AnonymousTest ta = new AnonymousTest(); //调用test方法时，需要传入一个Product参数， //此处传入其匿名实现类的实例，匿名内部类。 ta.test(new Product(){ public double getPrice(){ return 567.8; } public String getName(){ return \"AGP显卡\"; } }); }}","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记05-面向对象编程(中)","slug":"java-note-0501","date":"2021-03-21T09:00:21.000Z","updated":"2022-05-22T13:30:54.792Z","comments":true,"path":"2021/03/21/java-note-0501/","link":"","permalink":"http://kangshitao.github.io/2021/03/21/java-note-0501/","excerpt":"继承性，多态性，重写，super关键字，Object类，包装类","text":"一、面向对象特征之二：继承性多个类中存在相同属性和行为时，将这些内容抽取到单独一个类中，那么多个类无需再定义这些属性和行为，只要继承(extends)那个类即可。 此处的多个类称为子类(派生类)，单独的这个类称为父类(基类或超类)。可以理解为:“子类is a父类”，比如Student类继承Person类，可以说Student is Person。 1、优势继承有以下作用： 减少了代码冗余，提高代码复用性。 便于功能的扩展。 为多态性的使用提供了前提。 2、使用格式：class A extends B{} A：子类、派生类、subclass B：父类、超类、基类、superclass 子类A继承父类B，则子类A中获取了父类B中声明的结构、属性、方法。 子类能继承到父类的私有方法和属性，只是由于封装性的影响，子类无法显式调用。 子类继承父类以后，还可以声明自己特有的属性和方法，实现功能的扩展。 子类和父类的关系，是对父类的“扩展”，不等同于子集和集合的关系。 3、规定 一个类可以被多个子类继承，但一个类只能有一个父类。 子父类是一个相对的概念，可以多层继承。A→B→C，其中A是C的间接父类，B是C的直接父类。 子类继承父类以后，就获取了直接父类以及所有间接父类声明的属性和方法。 如果没有显式地声明父类，则此类继承与java.lang.Object类。 所有的java类(除java.lang.Object类以外），都直接或间接地继承于java.lang.Object类，也就是说所有的java类都有java.lang.Object类声明的功能。 继承(extends)的使用： 12345678910111213141516171819202122232425262728293031323334353637public class ExtendTest { public static void main(String[] args) { Person p = new Person(); p.age = 1; Student s = new Student(); s.age = 2; //父类的default权限的属性，子类可以直接调用 }class Person { String name; int age; public Person() {} public Person(String name, int age) { this.name = name; this.age = age; } public void eat() { System.out.println(\"eat\"); } public void sleep() { System.out.println(\"sleep\"); }}class Student extends Person { String major; //Student类特有的属性 public Student() {} public Student(String name, int age, String major) { this.name = name; //Student继承了Person类，因此可以使用Person类的属性 this.age = age; this.major = major; } public void study() { //Student类特有的方法 System.out.println(\"study\"); } public void showInfo(){ System.out.println(\"name:\"+name+\"age:\"+age); }} 二、方法的重写(override/overwrite)1、定义重写(override/overwrite)：在子类根据需要对从父类中继承来的方法进行改造，也称为方法的重置、覆盖。在程序执行时，子类的方法将覆盖父类的方法。 重写以后，子类对象调用此同名同参方法时，实际执行的是子类重写的方法。 2、要求 子类重写的方法与父类被重写的方法，方法名和形参列表相同。 重写方法的权限不小于父类被重写的方法，不能重写父类的private方法。 子类重写的方法抛出的异常类型不大于父类被重写方法的抛出的异常类型。 返回值类型： 如果父类方法返回值类型是void，则子类重写方法的返回值必须是void。 如果父类方法返回值类型是A类，则子类重写方法的返回值可以是A类或A类的子类。 如果父类方法返回值类型是基本数据类型，则子类重写方法的返回值类型必须是相同的基本数据类型。 重写只是对非static方法来说的，对于static方法不是重写。 3、重载和重写的区别 重载：类名、方法名相同，参数列表不同。不表现为多态性。 重载方法的调用地址在编译期就绑定了，称为“早绑定”或“静态绑定”。 重写：类名、方法名相同，参数列表相同。表现为多态性。运行时才确定要调用的方法，称为“晚绑定”或“动态绑定”。 三、super关键字super理解为“父类的”，可以用来调用父类的：属性、方法、构造器。 1、super调用属性和方法 可以在子类的方法或构造器中，通过super.属性或super.方法的方式，显式地调用父类中声明的属性或方法。但通常情况下省略super.。 当子类和父类中定义了同名的属性，如果想在子类中调用父类中的属性，必须使用super.属性的方式，表明调用的是父类中声明的属性。 2、super调用构造器 可以在子类中使用super(形参列表)的方式，调用父类中指定的构造器。 super调用构造器必须声明在子类构造器的首行。 子类所有构造器默认访问父类中的空参构造器，除非显式使用super(形参列表)调用父类构造器，或者使用this(形参列表)调用本类的构造器，且二者只能存在一种。 在类的构造器中，至少有一个构造器使用了super(形参列表)，调用父类中的构造器。 3、super和this的对比 this super 访问属性 访问本类中的属性，如果本类没有此属性则从父类中继续查找 直接访问父类中的属性 调用方法 访问本类中的方法，如果本类没有此方法则从父类中继续查找 直接访问父类中的方法 调用构造器 调用本类构造器，必须放在构造器的首行 调用父类构造器，必须放在子类构造器的首行 四、子类对象实例化过程 从结果上看：子类继承父类以后，就获取了父类中声明的属性或方法。创建子类对象，在堆空间中，就会加载所有父类中声明的属性。 从过程上看：当通过子类的构造器创建子类对象时，一定会直接或间接地调用其父类的构造器，进而向上调用父类的父类的构造器……，直到调用了java.lang.Object类中空参的构造器为止。因为加载过所有的父类的结构，所以才可以看到内存中有父类中的结构，子类对象才可以考虑进行调用。 虽然创建子类对象时，调用了父类的构造器，但只是创建过一个对象，即new出来的对象。 五、面向对象特征之三：多态性1、多态的使用Java中的多态性(Polymorphism)，是面向对象中最重要的概念。 对象的多态性：父类的引用指向子类的对象，比如Person p = new Student(); 多态的使用(虚拟方法调用)：对于多态，编译时只能调用父类中声明的方法，但在运行时，实际执行的是子类重写的方法，即编译看左边，运行看右边。 编译时类型和运行时类型不一致，就出现了对象的多态性。 对象的多态性，只适用于方法，不适用于属性（编译和运行都看左边）。 多态性是运行时的行为（动态绑定），即只有在运行时才知道具体执行哪个方法，在编译时是不知道的。 子类可以看作是特殊的父类，所以父类类型的引用可以指向子类的对象，即向上转型(upcasting)。 当一个对象声明为父类的类型，实际引用的是子类对象，那么该变量不能访问子类中的属性和方法(实际在内存中是加载的，只是不能调用）。 多态性的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class PersonTest { public static void main(String[] args){ //对象的多态性：父类的引用指向子类的对象。 Person pm = new Man(); Person pw = new Woman(); //多态的引用：当调用子父类同名同参数的方法时，实际执行的是子类重写的父类的方法——虚拟方法调用 pm.eat(); //Man:eat pw.eat(); //Woman：eat //多态的另一种使用方法，传入不同子类对象时，调用其重写的方法，提高了代码复用性 PersonTest test = new PersonTest(); test.walkPrint(new Man()); //Man：walk test.walkPrint(new Woman()); //Woman：walk } public void walkPrint(Person person){ person.walk(); }}class Person { private String name; private int age; public Person() {} public void eat(){System.out.println(\"Person:eat\"); } public void walk(){System.out.println(\"Person:walk\");} public String getName() {return name;} public void setName(String name) {this.name = name;} public int getAge() {return age;} public void setAge(int age) {this.age = age;}}class Man extends Person{ private boolean isSmoking; public void earnMoney(){System.out.println(\"Man:earnMoney\");} public void eat(){ System.out.println(\"Man:eat\");} public void walk(){ System.out.println(\"Man:walk\");}}class Woman extends Person{ private boolean isBeauty; public void goShopping(){System.out.println(\"Woman:goShopping\");} public void eat(){System.out.println(\"Woman:eat\");} public void walk(){System.out.println(\"Woman:walk\");}} 2、instanceof操作符x instanceof A用于检验x是否是类A的对象，返回boolean值。 要求x所属的类与A类必须是子类和父类的关系，否则编译错误。 如果x属于类B，B extends A，则x instanceof B和x instanceof A都为True。 12345678910111213//对于Person类、Man类，Woman类如下关系：//Man extends Person，Woman extends PersonMan man = new Man();Person person = new Person();Person pm = new Man();man instanceof Man; //trueman instanceof Person; //trueman instanceof Woman; //编译错误，Man类和Woman类没有关系，不是子类和父类的关系person instanceof Person; //trueperson instanceof Man; //falsepm instanceof Person; //truepm instanceof Man; //truepm instanceof Woman; //false 3、对象类型转换(Casting)类似于基本数据类型的类型转换，对象也有类型转换。 基本数据类型： 自动类型转换(提升)：小的数据类型自动转换为大的数据类型，比如int型自动转换为double型：double d = 12;。 强制类型转换：大的数据类型强制转换(casting)为小的数据类型，比如double强转为int型：int a = (int)12.0;。 对象类型： 向上转型：子类对象赋给父类对象的引用，即多态性，比如Person person = new Man(); 向下转型：父类对象强制转换为子类对象，比如：Person person = new Man();Man man=(Man)person;，将父类对象person强制转换为子类类型对象man，向下转型后，man对象就可以使用Man类定义的属性和方法。 自动类型提升和向上转型都可以自动进行。 基本数据类型的强制类型转换可能会带来精度损失。 无继承关系的引用类型间的转换是非法的，编译错误。 对象类型向下转型时，可以使用instanceof关键字进行判断，结果是true时才可以进行转换。 六、Object类 Object类是所有Java类的根父类。 如果类的声明中没有使用extends关键字指明父类，则默认父类为java.lang.Object。 Object类中的功能(属性、方法)具有通用性，Object类没有属性，但有常用的方法，比如equals()、toString()、getClass()、hashCode()、clone()、finalize()、wait()、notify()、notifyAll()。 Object类只声明了一个空参的构造器。 七、包装类对于Java中的8种基本数据类型，Java提供了各自对应的包装类，使基本数据类型的变量具有了类的特征。 基本数据类型 包装类 byte Byte short Short int Integer long Long float Float double Double boolean Boolean char Character 基本数据类型、包装类、String三者之间的相互转换。 基本数据类型和包装类之间的相互转换 基本数据类型→包装类，调用包装类的构造器或valueOf()方法： Integer i = new Integer(12); Integer i = Integer.valueOf(12); 包装类→基本数据类型，调用包装类的xxxValue()方法： int a = i.intValue(); JDK 5.0 以后，有了自动装箱(基本数据类型转换为包装类)和自动拆箱功能，包装类和基本数据类型可以直接相互转换，比如Integer i = 12;，因此，包装类和基本数据类型可以看出一个整体。 基本数据类型、包装类和String类型之间的相互转换 基本数据类型、包装类→String类型，可以使用+连接符，或者String类的valueOf()方法。 方法1：String s = 12 + \"\"; 方法2：String s = String.valueOf(12); String类型→基本数据类型、包装类，使用包装类的构造器或者parseXxx()方法： 例1：int i = new Integer(\"12\"); 例2：int i = Integer.parseInt(\"12\"); 特殊说明，Integer内部定义了IntegerCache结构，IntegerCache定义了Integer[]，保存了-128~127范围的整数，使用自动装箱的时候可以直接使用数组的元素，如果不在此范围内，则会new一个对象。比如下面的例子： 1234567Integer m = 1;Integer n = 1;System.out.println(m == n); //trueInteger x = 128;Integer y = 128;//数字128超出了IntegerCache数组的范围，此时x和y是两个不同的对象System.out.println(x == y); //false 八、== 和equals()的区别 ==是运算符，可以使用在基本数据类型和引用数据类型中： 对于基本数据类型，==操作符比较两个变量保存的数据是否相等。 对于引用数据类型，==比较的是两个对象的地址值是否相同，即两个引用是否指向同一个对象实体。 ==操作符两边变量的类型不一定相同，但必须要兼容，能够比较，比如10 == 10.0结果为true，int和char类型也能够比较，97 == 'a'结果为true。 equals()是方法，只能用于引用数据类型。 Object类中的equals()方法使用的是==运算符，因此比较的是对象的地址。 像String、Date、File、包装类等类，重写了Object类中的equals()方法。重写以后，比较的是两个对象的“实体内容(各种属性)”是否相同。 通常，自定义的类如果使用equals()方法，也是比较对象的内容是否相同，需要对equals()重写。重写equals()方法也可以使用自动生成的方法。 判断某个类中的equals()方法的功能，需要看其是否对equals()进行了重写，以及怎样重写的。","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记04-面向对象编程(上)","slug":"java-note-0401","date":"2021-03-20T13:50:55.000Z","updated":"2022-05-22T13:30:54.791Z","comments":true,"path":"2021/03/20/java-note-0401/","link":"","permalink":"http://kangshitao.github.io/2021/03/20/java-note-0401/","excerpt":"面向对象思想，对象，属性，方法，封装，构造器，this，package和import","text":"一、面向过程和面向对象 面向过程(Procedure Oriented Programming)：强调功能行为，以函数为最小单位，考虑怎么做。 面向对象(Object Oriented Programming，OOP)：将功能封装进对象，强调具备了功能的对象，以类/对象为最小单位，考虑谁来做。 面向对象三大特征：封装(Encapsulation)、继承(Inheritance)、多态(Polymorphism) 二、Java基本元素：类和对象 类是对一类事物的描述，是抽象的、概念上的定义 对象是实际存在的该类事物的每个个体，也称为实例(instance) 设计类，就是设计类的成员： 属性 = 成员变量 = filed = 域、字段 方法 = 成员方法 = 函数 = method 创建类的对象 = 类的实例化 = 实例化类 创建类： 123456789101112修饰符 class 类名{ 属性声明; 方法声明;}//创建Person类public class Person{ int age; //成员变量 String name; //成员变量 public void eat(){ //方法 System.out.pringln(\"eat\"); }} 三、对象的创建和使用通过 类名 对象名= new 类名();创建对象，通过对象名.对象成员访问对象的属性和方法。 123Person person = new Person();int age = person.age; //访问类的属性person.eat(); //访问类的方法 类的访问机制： 同一个类中，类中的方法可以直接访问类中的成员变量（非static）。 不同类中，需要先创建类的对象，通过对象访问类中的成员。 四、类的成员之一：属性声明格式：修饰符 数据类型 属性名 = 初始化值; 成员变量：方法体外，类内声明的变量。有默认初始值。 局部变量：方法体内部声明的变量。没有默认初始值，需要显式初始化(形参除外)。 成员变量 局部变量 声明位置 直接声明在类中 方法形参、方法内部、代码块内、构造器内 修饰符 private、public、static、final等 不能用权限修饰符，可以用final修饰 初始化值 有默认初始化值(同数组元素初始化) 无默认初始化值，必须显式赋值才能使用 内存加载位置 堆空间或静态域内 栈空间 例如： 1234567class Person(){ public int age; //成员变量 public String name; public void eat(){ int hour = 3; //局部变量 }} 五、类的成员之二：方法1、方法定义方法(method)用来完成某个功能，实现代码复用，简化代码。 Java里的方法不能独立存在，必须定义在类内。 声明格式： 123456789101112修饰符 返回值类型 方法名(参数类型 参数1,参数类型 参数2,...){ 方法体; return 返回值; //返回值类型为void时，可以没有return语句，或使用return;}public void showInfo(){ System.out.println(\"showInfo\"); //return;}public int getAge(){ return age;} 方法中只能调用方法或属性，不能在方法内定义方法。 2、方法重载重载(overload)：同一个类中，功能类似，方法名相同的多个方法。参数列表不同（类型，个数，顺序）。返回值类型可以相同也可以不同，但一般返回值类型是相同的。 两同一不同：类、方法名相同，参数列表不同。 是否重载和权限修饰符、返回值类型、形参变量名、方法体都没有关系。 举例： 1234567891011121314151617181920public class OverLoad { public static void main(String[] args) { OverLoad test = new OverLoad(); } public void getSum(int a, int b){} public void getSum(double a, double b){} //是重载 public void getSum(String s, int i){} //是重载 public void getSum(int i, String s){} //是重载，和上一个也构成重载，顺序不同。 public int getSum(int a, int b, int c){ //是重载，参数个数不同 return 0; } public int getSum(int a, int b){//不是重载，参数列表相同 return 0; }} 3、可变个数形参JavaSE 5.0提供了Varargs(variable number of arguments)机制，允许直接定义能和多个实参匹配的形参。 JDK5.0之前，使用数组形参定义方法，传入多个同一类型变量: public static void test(int a, String[] books); JDK5.0之后，使用可变形参，传入多个同一类型变量： public static void test(int a, String...books); 可变个数形参的方法，和同名的方法构成重载。 可变个数形参方法的使用，和使用数组时一样，使用索引获取某个参数。 可变形参需要放到参数列表的最后。 一个方法的参数中只能有一个可变个数形参。 如果有参数列表恰好符合的方法，优先调用。 12345678910111213141516171819202122232425public class MethodTest { public static void main(String[] args) { MethodTest m = new MethodTest(); m.show(1,2); //method 3，优先调用两个参数的方法。 m.show(new int[]{1,2,3,4}); //调用可变形参的方法 m.show(\"sss\",1,3,4,5); //method 4，两种参数方法都可以。 } public void show(int i){ System.out.println(\"method 1\"); } public void show(int ... i){ //可以接收任意个数的参数。也可以接受数组类型的参数。 System.out.println(\"可变形参\"); } public void show(int a, int b){ System.out.println(\"method 3\"); } public void show(String s, int ... i){ //可变形参必须放在最后。 for(int n = 0; n&lt;i.length; n++){ //将i当成数组处理即可。 } System.out.println(\"method 4\"); }} 4、值传递形参：方法声明时的参数。 实参：方法调用时实际传给形参的参数值。 Java里的方法参数传递方式只有一种：值传递。即将实际参数值的副本(复制品)传入方法内，而参数本身不受影响。 形参是基本数据类型：将实参基本数据类型变量的“数据值”传递给形参。 形参是引用数据类型：将实参引用数据类型变量的“地址值”传递给形参。 值传递练习： 123456789101112131415161718192021222324252627282930public class valueTransfer { public static void main(String args[]) { valueTransfer t = new valueTransfer(); t.first(); } public void first() { int i = 5; Value v = new Value(); v.i = 25; second(v, i); //经过second函数，v中的i被修改为20 System.out.println(v.i); } public void second(Value v, int i) { //参数的v和i是在栈空间中新建的，这里的v指向传入对象v的地址 i = 0; v.i = 20; // 将指向的地址中的i赋值为20 Value val = new Value(); v = val; //v指向对象val的地址。 System.out.println(v.i + \" \" + i); //15 0 }}class Value { int i = 15;}//以上程序输出结果：15 020 六、类的成员之三：构造器(构造方法)类的构造器(构造方法，constructor)用于给对象进行初始化。 构造器特征： 具有与类相同的名称 不声明返回值类型 不能被static、final、synchronized、abstract、native修饰，不能有return语句返回值 声明格式： 1234567891011121314权限修饰符 类名(参数列表){ 初始化语句;} public class Animal{ private int legs; private String name; public Animal(int l){ //构造器1 legs = l; } public Animal(int l, String n){ //构造器2 legs = l; name = n; }} 注意： Java中，每个类至少有一个构造器。 如果没有显式地定义类的构造器，系统默认提供一个空参的构造器。 一旦显式地定义了构造器，系统不再提供默认的构造器。 一个类中可以定义多个构造器，构成重载。 在IDEA中，可以右键→generate→Constructor，自动生成构造器 属性根据以下顺序赋值 ① 默认初始化。 ② 显式初始化，如int age = 1; ③ 构造器中初始化。 ④ 通过对象.方法 或 对象.属性的方式赋值。 七、面向对象特征之一：封装与隐藏1、封装性类的封装性是指将对象内部的复杂性隐藏起来，只对外提供必要的接口，便于调用。 如果直接将属性暴露出来，使用者对属性的直接操作可能导致数据错误、混乱或安全性问题。 Java中通过将数据声明为私有的(private)，再提供公共的(public)方法getXxx()和setXxx()实现对该属性的操作，以实现下述目的： 隐藏一个类中不需要对外提供的实现细节； 使用者只能通过事先定制好的方法来访问数据，可以方便地加入控制逻辑，限制对属性的不合理操作； 便于修改，增强代码的可维护性； 例如： 1234567891011121314151617181920212223242526public class PersonTest { public static void main(String[] args) { Person p = new Person(20); // new 后面的Person()就是构造器。 p.setAge(25); //将年龄设置为25 int age = p.getAge(); // age = 25 //int age = p.age; 无法直接通过对象调用age属性，因为类中的age是私有的 }}class Person{ private int age; public Person(){ //构造器（构造函数） System.out.println(\"constructor\"); } public Person(int a){ //重载的构造器 age = a; System.out.println(\"constructor\"); } public int getAge() { return age; } public void setAge(int a) { age = a; } public void eat(){}} 同样地，getXxx()和setXxx()方法可以使用自动生成的方法。 2、四种权限修饰符权限修饰符可以用来修饰类和方法，其中class只能用public和缺省(default)两种权限修饰符，四种权限修饰符的权限如下： 权限修饰符 类内部 同一个包 不同包的子类 同一个工程 private √ 缺省(default) √ √ protected √ √ √ public √ √ √ √ 3、JavaBeanJavaBean是一种Java语言写成的可重用组件。 所谓JavaBean，是指符合如下标准的Java类： 类是public的。 有一个无参的public构造器。 有属性，且有对应的get、set方法。 八、this关键字this可以用来修饰属性、方法、构造器。 1、修饰属性和方法this修饰属性和方法时，表示当前对象或当前正在构建的对象。使用this.属性和this.方法的方式，调用当前对象的属性和方法。 通常情况下，省略this，特殊情况下，当参数和属性同名时，必须使用this进行区分。 2、修饰构造器this修饰构造器： 在类的构造器中，可以用this(形参列表)方式，调用本类中其他构造器。 构造器不能用this(形参列表)方式调用自己。 如果一个类中有n个构造器，则最多有n-1个构造器中使用了this(形参列表)方式。 this(形参列表)必须声明在当前构造器的首行。 每个构造器内部，最多只能有一个this(形参列表)的方式。且多个构造器之间调用不能形成环，否则会导致死循环。 this关键字的用法： 123456789101112131415161718192021222324252627282930public class Person{ //JavaBean的形式构造Person类 private String name; private int age; public String getName() { return name; } public void setName(String name) { this.name = name; //使用this区分类的属性name和形参name } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public Person(){} //构造器（构造函数） public Person(String name){ this.name = name; System.out.println(\"second constructor\"); } public Person(String name, int age){ this(name); //使用this调用第二个构造器 this.age = age; System.out.println(\"third constructor\"); } public void eat(){}} 九、package和import1、packagepackage语句是Java源文件的第一条语句，指明该文件中定义的类所在的包。 比如pack1\\pack2\\PackageTest.java路径下的类PackageTest: 123456package pack1.pack2;public class PackageTest{ public static void main(String[] args){ System.out.println(\"PackageTest\"); }} JDK中常用的包： java.lang：包含一些Java语言的核心类，如String、Math、Integer、System和Thread，提供常用功能. java.net：包含执行与网络相关的操作的类和接口。 java.io：包含能提供多种输入/输出功能的类。 java.util：包含一些实用工具类，如定义系统特性、接口的集合框架类、使用与日期日历相关的函数。 java.text：包含了一些java格式化相关的类 java.sql：包含了java进行JDBC数据库编程的相关类/接口 java.awt：包含了构成抽象窗口工具集（abstract window toolkits）的多个类，这些类被用来构建和管理应用程序的图形用户界面(GUI)。B/S，C/S 2、importimport语句用于引入指定包层次下所需要的类。 格式：import 包名.类名; import语句声明在package声明和类的声明之间； *表示导入包下的所有类，比如import java.util.*;表示导入util包下的所有类或接口。 如果是java.lang包下，或是当前包下的，可以不使用import语句。 如果使用不同包下的同名的类。那么就需要使用类的全类名（包名.类名）的方式指明调用的是哪个类。 如果已经导入java.a包下的类。那么如果需要使用a包的子包下的类的话，仍然需要导入。 3、MVC设计模式MVC是常用的设计模式之一，将整个程序分为三个层次：数据模型层(Model)、视图层(View)和控制器层(Controller)。各个层的主要内容如下： 模型层(Model)，主要处理数据： 数据对象封装 ：model.bean/domain 数据库操作类：model.dao 数据库：model.db 视图层(View)，显示数据： 相关工具类：view.utils 自定义view：view.ui 控制层(Controller)： 应用界面相关：controller.activity 存放fragment：controller.fragment 显示列表的适配器：controller.adapte 服务相关的：controller.service 抽取的基类：controller.base MVC模式在项目中的应用：客户信息管理软件","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记03-数组","slug":"java-note-0301","date":"2021-03-20T13:13:12.000Z","updated":"2022-05-22T13:30:54.791Z","comments":true,"path":"2021/03/20/java-note-0301/","link":"","permalink":"http://kangshitao.github.io/2021/03/20/java-note-0301/","excerpt":"一维数组，二维数组，排序算法，Arrays工具类","text":"一、数组概述 数组中的元素必须是同一类型。 数组本身是引用数据类型，数组的元素可以是任何数据类型。 数组长度一旦确定就不能修改。 数组在内存中，数组首地址值存放在栈中，数组中的内容存放在堆中。 二、一维数组初始化方式： 动态初始化：int[] arr = new int[5]; 静态初始化：int[] arr = new int[]{1,2,3,4,5};或int[] arr = {1,2,3,4,5}; 中括号可以写在类型后面，也可以写在数组名后面，比如int arr[]也是正确的 数组的默认初始化值： 整型：0 浮点型：0.0 char型：0 boolean型：false 引用类型：null 三、二维数组初始化方式： 动态初始化：int[][] arr = new int[5][4];，int[][] arr = new int[5][];， 静态初始化：int[][] arr = new int[][]{{1,2,3},{2,3},{3}};或int[] arr = {1,2,3,4,5}; 中括号可以写在类型后面，也可以写在数组名后面，int arr[][]和int []arr[]都是正确的写法。 动态初始化时，第一个维度必须指定，第二个维度可以先不指定。int arr[][] arr = new int[][3]非法。 四、数组涉及的常见算法 查找算法 排序算法，可以参考排序算法总结 五、Arrays工具类java.util.Arrays类是操作数组的工具类，以下几个是常用的几个方法： boolean equals(int[] a, int[] b)：判断两个数组是否相等 String toString(int[] a)：输出数组信息 void fill(int[] a, int val)：将指定值填充到数组之中 void sort(int[] a)：对数组进行排序 int binarySearch(int[] a, int key)：对排序后的数组进行二分法检索指定的值 六、数组的常见异常 数组索引越界异常：ArrayIndexOutOfBoundsException 空指针异常：NullPointerException","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记02-Java基本语法","slug":"java-note-0201","date":"2021-03-19T12:42:47.000Z","updated":"2022-05-22T13:30:54.791Z","comments":true,"path":"2021/03/19/java-note-0201/","link":"","permalink":"http://kangshitao.github.io/2021/03/19/java-note-0201/","excerpt":"Java基本语法，变量、运算符、程序流程控制","text":"一、关键字和保留字1、关键字Java关键字被Java语言赋予了特殊含义，用做专门用途。一共有如下关键字 用于定义数据类型：class、interface、enum、byte、short、int、long、float、double、char、boolean、void 用于定义流程控制：if、else、switch、case、default、while、do、for、break、continue、return 用于定义访问权限修饰符：private、protected、public 用于定义类，函数，变量修饰符：abstract、final、static、synchronized 用于定义类与类之间关系：extends、implements 用于定义建立实例及引用实例，判断实例：new、this、super、instanceof 用于异常处理：try、catch、finally、throw、throws 用于包：package、import 其他修饰符：native、strictfp、transient、volatile、assert 2、保留字Java保留字指的是现有Java版本尚未使用，但以后版本可能会作为关键字使用。 有两个保留字：goto、const 二、标识符标识符（Identifier）是对各种变量、方法和类等要素命名时使用的字符序列。 标识符命名规则： 由26个英文字母大小写，0-9，_或$组成。 不能以数字开头。 不可以使用关键字和保留字，但能包含关键字和保留字。 Java中严格区分大小写，长度无限制。 不能包含空格。 Java中命名规范 包名：aaabbbccc 类名、接口名：AaaBbbCcc 变量名、方法名：aaaBbbCcc 常量名：AAA_BBB_CCC 起名时要遵循“见名知意”的原则。 三、变量1、变量的分类变量是程序中最基本的存储单元，包含变量类型、变量名和存储的值。 根据数据类型分： ​ 根据声明的位置： 成员变量是方法体外，类体内声明的变量。 局部变量是方法体内部声明的变量。 局部变量除形参外，需要显式初始化。而成员变量有默认的初始化值。 需要注意的点： long型常量需要在后面加‘l’或‘L’ float型常量需要在后面加‘f’或‘F’ Java中整型变量默认为int型，浮点型默认是doule型 2、自动类型转换自动类型转换以下几种类型从左到右自动类型提升(转换)： (byte，char，short) → int → long → float → double byte，short，char之间不会相互转换，他们三者在计算时首先转换为int型 boolean类型不能与其他数据类型运算 任何基本数据类型和String类型进行连接运算(+)时，基本数据类型会自动转化为String类型 强制类型转换强制类型转换是自动类型转换的逆过程。需要使用强制类型转换符：()，例int a = (int) 3.14; 四、运算符1、算数运算符算数运算符包括：+、-、*、/、%、++、--、+(字符串连接) 2、赋值运算符赋值运算符包括：=、+=、-=、*=、/=、%= 这里的+=、-=、*=、/=、%=以及++、--运算符，都不会改变变量本身的类型。比如： 12345short s = 10;s = s + 1; //编译错误，因为s+1已经被自动提升为int类型。s = (short)(s + 1); //使用强制类型转换，正确s++; //自增运算符不会改变数据类型，正确s += 1; //正确。 3、比较运算符比较运算符包括：==、!=、&gt;、&lt;、&gt;=、&lt;=、instanceof 4、逻辑运算符逻辑运算符包括：&amp;、&amp;&amp;(短路与)、|、||(短路或)、!、^(异或) 5、位运算符位运算符包括：&lt;&lt;、&gt;&gt;、&gt;&gt;&gt;(无符号右移)、&amp;(按位与)、|(按位或)、^(按位异或)、~(按位取反) 6、三元运算符(条件表达式) ? 表达式1 : 表达式2;表示如果条件表达式为true，则返回表达式1，否则返回表达式2。 这里的表达式1和表达式2必须是同种类型，或者能够自动类型提升。比如表达式1是int类型，表达式2是double类型，则表达式1会被自动转换为double类型。 五、程序流程控制1、顺序结构Java程序从上到下逐行地执行 2、分支结构 if语句 用法： 123456789101112131415161718192021//用法1：if(条件表达式){ 执行代码块;}//用法2：if(条件表达式){ 执行代码块1;}else{ 执行代码块2;}//用法3：if(条件表达式){ 执行代码块1;}else if{ 执行代码块2;}......else{ 执行代码块3;} switch语句 用法： 123456789101112131415switch(表达式){case 常量1: 语句1; //break;case 常量2: 语句2; //break;......case 常量N: 语句N; //break;default: 语句; //break;} switch(表达式)中的表达式必须是byte、short、char、int、枚举、String这几种类型之一。 case子句中的值必须是常量，不能是变量名或不确定的表达式值。 同一个switch语句，所有case子句中的常量值互不相同。 如果没有break，程序在运行第一个执行语句以后，会继续向下执行(即使case值不同，也会将下面的所有case中语句运行完)。 default语句是可选的，位置也是灵活的。没有匹配case时，会执行default的语句。 switch语句效率稍高，情况少的时候尽量不用if，选择switch语句。 3、循环结构 for语句 用法： 123for(1.初始化部分; 2.循环条件; 4.迭代部分){ 3.循环体部分;} while语句 用法： 123456789101112//用法11.初始化部分while(2.循环条件){ 3.循环体部分; 4.迭代部分;}//用法21.初始化部分do{ 3.循环体部分; 4.迭代部分;}while(2.循环条件) 4、break和continuebreak用于终止某个语句块的执行，只能用于switch语句和循环语句，表示跳过循环体，终止循环。 continue只能用在循环体中，表示跳过当前循环，继续下一次循环。 break和continue用于循环体内时，都可以使用label指明具体要跳过的循环体是哪个。如果没有明确指明，则都默认对当前循环体起作用，就近原则。","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Java学习笔记01-Java语言概述","slug":"java-note-0101","date":"2021-03-19T11:08:20.000Z","updated":"2022-05-22T13:30:54.790Z","comments":true,"path":"2021/03/19/java-note-0101/","link":"","permalink":"http://kangshitao.github.io/2021/03/19/java-note-0101/","excerpt":"Java运行过程，JDK、JRE、JVM","text":"一、软件开发介绍1、常用的DOS命令 dir：列出当前目录下的文件以及文件夹 md：创建目录 rd：删除目录 cd：进入指定目录 cd..：退回到上一级目录 cd\\：退回到根目录 del：删除文件 exit：退出dos命令行 echo：输出内容 2、常用快捷键 ← →：移动光标 ↑ ↓：调阅历史操作命令 Delete和Backspace：删除字符 二、计算机编程语言介绍 机器语言 汇编语言 高级语言： C、Pascal、Fortran面向过程的语言 C++面向过程/面向对象 Java跨平台的纯面向对象的语言 .NET跨语言的平台 Python、Scala 三、Java语言概述1、Java语言简史 1991年Green项目，开发语言最初命名为Oak (橡树) 1994年，开发组意识到Oak非常适合于互联网 1996年，发布JDK 1.0，约8.3万个网页应用Java技术来制作 1997年，发布JDK1.1，JavaOne会议召开，创当时全球同类会议规模之最 1998年，发布JDK 1.2，同年发布企业平台J2EE 1999年，Java分成J2SE、J2EE和J2ME，JSP/Servlet技术诞生 2004年，发布里程碑式版本：JDK1.5，为突出此版本的重要性，更名为JDK 5.0 2005年，J2SE-&gt; JavaSE，J2EE-&gt; JavaEE，J2ME-&gt; JavaME 2009年，Oracle公司收购SUN，交易价格74亿美元 2011年，发布JDK 7.0 2014年，发布JDK8.0，是继JDK 5.0以来变化最大的版本 2017年，发布JDK9.0，最大限度实现模块化 2018年3月，发布JDK10.0，版本号也称为18.3 2018年9月，发布JDK 11.0，版本号也称为18.9 2、Java技术平台 Java SE(Java Standard Edition)标准版：支持面向桌面级应用（如Windows下的应用程序）的Java平台，提供了完整的Java核心API，此版本以前称为J2SE。 Java EE(Java Enterprise Edition)企业版：是为开发企业环境下的应用程序提供的一套解决方案。该技术体系中包含的技术如:Servlet、Jsp等，主要针对于Web应用程序开发。版本以前称为J2EE。 Java ME(Java Micro Edition) 小型版 Java Card 四、运行机制及运行过程1、Java语言的特点 面向对象： 两个基本概念：类、对象 三大特征：封装、继承、多态 健壮性：吸收C/C++的优点，去掉了其指针、内存的申请和释放等，提供了相对安全的内存管理和访问机制。 跨平台性：“Write once，Run AnyWhere”，只需要在运行Java应用程序的操作系统上，先安装Java虚拟机(JVM,Java Virtual Machine)即可。由JVM负责Java程序在系统中的运行。、 2、Java两种核心机制 Java虚拟机（Java Virtual Machine） 垃圾收集机制（Garbage Collection） 3、Java运行过程`.java 文件经过编译生成\\ .class`文件（字节码文件），然后执行 五、Java的环境搭建1、环境搭建 下载JDK并安装JDK 配置环境变量（为了在任何目录下都能执行java命令） 使用javac java命令验证是否安装成功 使用编辑器或IDE开发 2、JDK、JRE、JVM JDK（Java Development Kit Java开发工具包）。JDK是提供给Java开发人员使用的，包含了Java的开发工具（比如编译工具（javac.exe）、打包工具（jar.exe）等），也包含了JRE，安装了JDK就不用再安装JRE。 JRE（Java Runtime Environment Java运行环境）。包括JVM和Java程序所需的核心类库等。只安装JRE就能够运行Java程序。 JVM（Java Virtual Machine）是一个虚拟的计算机，具有指令集并使用不同的存储区域。负责执行指令，管理数据、内存、寄存器。 JDK = JRE+开发工具集（例如Javac编译工具等） JRE = JVM+Java SE标准类库 Java SE 8概要图Java Platform Standard Edition 8 Documentation： 六、运行HelloWorld搭建好java环境后，可以在dos窗口编译运行Java程序。 将Java代码编写到扩展名为.java的文件中。 通过javac命令对该java文件进行编译。 通过java命令对生成的class文件进行运行。 注意： 1、Java应用程序的执行入口是main()方法。它有固定的书写格式： ​ public static void main ( String[]args ) {……} 2、一个源文件中只能有一个public类。其他类的个数不限，如果源文件中包含一个public类，则文件名必须按照该类名命名。 七、注释(Comment) 单行注释：//注释内容 多行注释：/*注释内容*/ 文档注释（Java特有）： 1234/** @author 指定程序作者 @version 指定源文件版本*/ 八、Java API文档API(Application Programming Interface,应用程序编程接口)是Java提供的基本编程接口。 JDK下载链接：https://www.oracle.com/java/technologies/javase-downloads.html","categories":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"}]},{"title":"Python爬虫-m3u8视频爬取","slug":"crawler-wuchizhitu","date":"2021-01-02T02:48:05.000Z","updated":"2022-05-22T13:30:54.782Z","comments":true,"path":"2021/01/02/crawler-wuchizhitu/","link":"","permalink":"http://kangshitao.github.io/2021/01/02/crawler-wuchizhitu/","excerpt":"使用python爬取流媒体网站的m3u8视频","text":"m3u8文件+ts文件是很多流媒体网站常用的一种方法，本文作为爬虫练习项目，记录了如何使用python爬虫爬取某视频网站的视频资源。 一、分析第一步是确定想要爬取的资源地址，通过网页源代码找到资源的url。 F12进入开发者模式，找到m3u8后缀的文件，可以看到有两个，把第一个m3u8文件下载下来以后发现，其内容是第二个m3u8的地址，第二个m3u8的url才是真实的地址 第一个m3u8文件内容 可见，第一个m3u8文件的内容，是真正的m3u8的地址。 第二个m3u8文件内容 第二个m3u8文件中的内容才是真正的ts文件的地址。 每一集视频是由多个ts文件构成的，将这些ts文件拼接起来就是完整的一集内容。这些ts文件的url都保存到第二个m3u8文件中。因此可以确定大体流程： 获取当前集的m3u8地址，并下载m3u8文件。 从m3u8文件中获取ts视频的url。 根据ts文件的url下载视频。 将多个ts文件合并，得到完整的一集内容，保存到相应路径。 二、获取m3u8文件分析网页源代码，可以看到m3u8的url保存在一个playurls的列表中，并且一季的所有集的地址都在，因此只需要在其中一集的网页源代码中获取出当前季的所有集的url即可： 12345678910111213141516# 获取每季中每集的m3u8地址,每季只获取一次即可def get_m3u8_list(url,S): req = requests.get(url) req.encoding = 'utf-8' html = req.text # 使用正则表达式从网页代码中找到m3u8的地址 res_url = re.findall(r'https:\\\\/\\\\/youku.com-youku.net.*?index.m3u8', html, re.S) m3u8list = [] for i in range(len(res_url)): url = res_url[i].split('\\\\') # m3u8文件下载下来以后，文件内容才是真正的m3u8地址，这里偷个懒，手动构建url # 真正的url多了'1000k/hls',手动添加上即可 m3u8list.append(''.join(url[:-1])+'/1000k/hls/index.m3u8') print(m3u8list[i]) print('第{}季m3u8地址获取完毕'.format(S)) return m3u8list 常规思路是获取到第一层m3u8文件，然后从中获取到真正的m3u8的地址，通过分析，真正的url是在第一层的url后面两个文件路径(仅对于当前视频网站，具体需要根据实际情况分析)，这里手动添加上了，没有读取文件。 三、获取ts文件url并下载获取到m3u8文件的地址后，就可以下载文件，通过读取文件内容，获取到当前集的所有ts文件url，然后下载。 1234567891011121314151617181920212223242526272829303132333435363738# 下载文件def download(m3u8_list,base_path,S): # base_path: \"F://Shameless//\",S表示当前季数 print('下载m3u8文件...') url = base_path+'Shameless_'+'S'+str(S) # F://Shameless//Shameless_S1 path = Path(url) # 如果文件夹不存在，则创建 if not path.is_dir(): os.mkdir(url) for i in range(len(m3u8_list)): print('正在下载第{}集...'.format(i+1)) start = datetime.datetime.now().replace(microsecond=0) time.sleep(1) # sleep一秒 ts_urls = [] # 保存每一集的ts文件的真实url m3u8 = requests.get(url=m3u8_list[i]) content = m3u8.text.split('\\n') # 获取ts文件地址 for s in content: if s.endswith('.ts'): ts_url = m3u8_list[i][:-10] + s.strip('\\n') # 生成ts文件的真实url ts_urls.append(ts_url) download_ts(ts_urls,down_path=url+'//'+\"E\"+str(i+1)+'.ts') # 根据ts的url下载每集的ts文件 end = datetime.datetime.now().replace(microsecond=0) print('耗时：%s' % (end - start)) print('第{}集下载完成...'.format(i+1))# 根据ts下载链接下载文件，并合并为完整的视频文件def download_ts(ts_urls,down_path): file = open(down_path, 'wb') # 这里将每个ts文件添加到file里面，即合并 for i in tqdm(range(len(ts_urls))): ts_url = ts_urls[i] # 例:https://youku.com-youku.net/20180626/14084_f3588039/1000k/hls/80ed70a101f861.ts time.sleep(1) try: response = requests.get(url=ts_url, stream=True, verify=False) file.write(response.content) except Exception as e: print('异常请求：%s' % e.args) file.close() 四、总结完整代码完整代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import requestsimport reimport osfrom pathlib import Pathimport timeimport datetimefrom tqdm import tqdmimport urllib3urllib3.disable_warnings() # 禁用证书认证和警告# 获取每季中每集的m3u8地址,每季只获取一次即可def get_m3u8_list(url,S): req = requests.get(url) req.encoding = 'utf-8' html = req.text res_url = re.findall(r'https:\\\\/\\\\/youku.com-youku.net.*?index.m3u8', html, re.S) m3u8list = [] for i in range(len(res_url)): url = res_url[i].split('\\\\') # m3u8文件下载下来以后，文件内容才是真正的m3u8地址，这里为了方便起见，手动构建url # 真正的url多了'1000k/hls',这里手动添加上 m3u8list.append(''.join(url[:-1])+'/1000k/hls/index.m3u8') print(m3u8list[i]) print('第{}季m3u8地址获取完毕'.format(S)) return m3u8list# 下载ts文件def download(m3u8_list,base_path,S): # base_path: \"F://Shameless//\",S表示当前季数 print('下载m3u8文件...') url = base_path+'Shameless_'+'S'+str(S) # F://Shameless//Shameless_S1 path = Path(url) # 如果文件夹不存在，则创建 if not path.is_dir(): os.mkdir(url) for i in range(len(m3u8_list)): print('正在下载第{}集...'.format(i+1)) start = datetime.datetime.now().replace(microsecond=0) time.sleep(1) # sleep一秒 ts_urls = [] # 保存每一集的ts文件的真实url m3u8 = requests.get(url=m3u8_list[i]) content = m3u8.text.split('\\n') for s in content: if s.endswith('.ts'): ts_url = m3u8_list[i][:-10] + s.strip('\\n') # 生成ts文件的真实url ts_urls.append(ts_url) download_ts(ts_urls,down_path=url+'//'+\"E\"+str(i+1)+'.ts') # 根据ts的url下载每集的ts文件 end = datetime.datetime.now().replace(microsecond=0) print('耗时：%s' % (end - start)) print('第{}集下载完成...'.format(i+1))# 根据ts下载链接下载文件def download_ts(ts_urls,down_path): file = open(down_path, 'wb') for i in tqdm(range(len(ts_urls))): ts_url = ts_urls[i] # 例:https://youku.com-youku.net/20180626/14084_f3588039/1000k/hls/80ed70a101f861.ts time.sleep(1) try: response = requests.get(url=ts_url, stream=True, verify=False) file.write(response.content) except Exception as e: print('异常请求：%s' % e.args) file.close()if __name__ == '__main__': savefile_path = 'F://Shameless//' section_url = ['http://www.tv3w.com/dushiqinggan/wuchizhitudiyiji/5-1.html', 'http://www.tv3w.com/dushiqinggan/wuchizhitudierji/3-1.html', 'http://www.tv3w.com/dushiqinggan/wuchizhitudisanji/4-1.html', 'http://www.tv3w.com/dushiqinggan/wuchizhitudisiji/4-1.html', 'http://www.tv3w.com/dushiqinggan/wuchizhitudiwuji/7-1.html', 'http://www.tv3w.com/dushiqinggan/wuchizhitudiliuji/7-1.html', 'http://www.tv3w.com/dushiqinggan/wuchizhitudiqiji/6-1.html'] for i in range(len(section_url)): print('开始下载第{}季...'.format(i+1)) episode_url = get_m3u8_list(url=section_url[i],S=i+1) # 获取每季中每一集的m3u8地址 download(episode_url,savefile_path,i+1) # 下载每一季的ts文件并拼接 print('done') 目标网站的资源前七季的源是同一个，这里只获取前七季。 改进第一次写完整的爬虫代码，可以改进的地方有很多： 可以改为自动获取m3u8真实地址。 使用多线程下载，提高下载速度。 添加文件验证机制，确保下载正确。 参考链接 Python爬虫——从流媒体网站获取的m3u8爬取视频 爬取m3u8视频","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://kangshitao.github.io/categories/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://kangshitao.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://kangshitao.github.io/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"10种常用排序算法总结","slug":"rank-algorithm","date":"2020-12-27T08:08:34.000Z","updated":"2022-05-22T13:30:54.801Z","comments":true,"path":"2020/12/27/rank-algorithm/","link":"","permalink":"http://kangshitao.github.io/2020/12/27/rank-algorithm/","excerpt":"整理总结常用的十种排序算法","text":"概述本文整理了常见的十种排序算法，介绍了其原理。开头先介绍几个相关的概念，然后是几种算法的复杂度以及稳定性的比较。 相关概念 稳定排序：如果排序前a在b前面,且a和b相等，排序后a也在b的前面，称为稳定排序。 不稳定排序：和稳定排序相反，如果排序后a在b的后面，则为不稳定排序。 原地排序：排序过程中不申请多余的存储空间，只利用原来存储待排数据的存储空间进行比较和交换的数据排序。 非原地排序：需要利用额外的数组来辅助排序。 比较类排序：通过比较来决定元素间的相对次序，时间复杂度不能突破 O(n\\log n) ，因此也被称为非线性时间比较类排序。 非比较排序：不通过比较来决定元素间的相对次序，可以突破基于比较排序的时间下界，以线性时间运行，因此也称为线性时间非比较排序。 本文中的计数排序、桶排序、基数排序属于非比较排序，其余的七种排序方法都是比较类排序。 算法概述 排序算法 平均时间复杂度 最好情况 最坏情况 空间复杂度 排序方式 稳定性 冒泡排序 O(n^2) O(n) O(n^2) O(1) In-place 稳定 选择排序 O(n^2) O(n^2) O(n^2) O(1) In-place 不稳定 插入排序 O(n^2) O(n) O(n^2) O(1) In-place 稳定 希尔排序* O(n^{1.3}) O(n) O(n^2) O(1) In-place 不稳定 归并排序 O(n\\log n) O(n\\log n) O(n\\log n) O(n) Out-place 稳定 快速排序 O(n\\log n) O(n\\log n) O(n^2) O(\\log n) In-place 不稳定 堆排序 O(n\\log n) O(n\\log n) O(n\\log n) O(1) In-place 不稳定 计数排序 O(n+k) O(n+k) O(n+k) O(k) Out-place 稳定 桶排序 O(n+k) O(n) O(n^2) O(n+k) Out-place 稳定 基数排序 O(n\\times k) O(n\\times k) O(n\\times k) O(n+k) Out-place 稳定 希尔排序算法的时间复杂度需要根据所选的增量决定。 下面从小到大排序为例，介绍各种排序算法的原理及其代码实现，如无特殊说明，算法演示图片来自文末的参考文章。 选择排序(Select Sort)算法原理： 从整个序列中找到最小的元素，和第一个元素交换位置。 从剩下的未排序的元素中找到最小元素，未排序的第一个元素交换位置。 重复第二步，不断地将未排序的最小值放到前面，直到所有元素均排列完毕。 动画演示： 选择排序算法图解 代码实现： 123456789101112131415public class SelectSort{ public static int[] selectSort(int[] nums){ int len = nums.length; for (int i=0;i&lt;len;i++){ int min = i; //记录最小值的位置 for(int j=i+1;j&lt;len;j++){ //从i之后的范围遍历查找 if (nums[j]&lt;nums[min]) min=j; //如果找到更小的值，记录索引 } int temp = nums[i]; //交换两元素的位置 nums[i] = nums[min]; nums[min] = temp; } return nums; }} 分析： 时间复杂度： O(n^2) 空间复杂度： O(1) 不稳定排序 原地排序 插入排序(Insert Sort)算法原理： 将待排序列第一个元素看作有序序列，从第2个元素开始依次抽取元素。 将抽取的元素与其左边第一个元素比较，如果左边第一个元素比它大，则继续与左边第二个元素比较，直到找到比它小的元素(或者已经到达序列头部)，插入这个元素的右边。 继续选取第3,4，…n个元素，重复步骤二，并将其插入适当的位置。 动画演示： 插入排序算法图解 代码实现： 123456789101112131415161718public class InsertSort{ public static int[] insertSort(int[] nums){ if(nums==null||nums.length&lt;2) return nums;//如果数组为空或只有一个元素，直接返回 int len = nums.length; for(int i=1;i&lt;len;i++){ //从下标为1的元素开始遍历，第0个元素默认是有序的 int cur = nums[i]; //记录当前值 int index = i-1; while(index&gt;=0 &amp;&amp; cur&lt;nums[index]){//往左遍历，直到找到一个比cur小的元素 index -= 1; }//要插入的位置是index+1 for(int j=i;j&gt;index+1;j--){ //将index+1和i之间的元素后移一位 nums[j] = nums[j-1]; } nums[index+1] = cur; //将cur插入到index+1的位置 } return nums; }} 分析： 时间复杂度： O(n^2) 空间复杂度： O(1) 稳定排序 原地排序 冒泡排序(Bubble Sort)算法原理： 比较相邻的两个元素，如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始的一对到最后一对，执行完一遍后，末尾的元素是最大的值。 对于最后一个元素外的其他元素，同样执行步骤二的操作。 重复以上步骤，直到排序完成。 动画演示： 冒泡排序算法图解 代码实现： 12345678910111213141516public class BubbleSort{ public static int[] bubbleSort(int[] nums){ int len = nums.length; //每次外层循环一次之后，最后的元素是最大的 for(int i=0;i&lt;len;i++){//i控制已经排序的个数，长度为len的序列需要循环len次 for (int j=0;j&lt;len-i-1;j++){ //对未排序的序列进行比较 if(nums[j]&gt;nums[j+1]){ int temp = nums[j]; nums[j] = nums[j+1]; nums[j+1] = temp; } } } return nums; }} 上面代码的缺陷是无论序列有没有序，循环次数总是固定的，如果一个序列本来就是从小到大排好序的，按照上述代码两层循环的次数不变。因此可以做进一步的优化，在内层循环中，如果从第一对元素到最后一对元素，都没有发生交换操作，说明序列是有序的，无需对剩余的元素重复比较下去了。 代码如下： 1234567891011121314151617181920public class BubbleSort{ public static int[] bubbleSort(int[] nums){ int len = nums.length; //每次外层循环一次之后，最后的元素是最大的 for(int i=0;i&lt;len;i++){//i控制已经排序的个数，长度为len的序列需要循环len次 boolean flag = true; //使用flag记录是否发生交换 for (int j=0;j&lt;len-i-1;j++){ //对未排序的序列进行比较 if(nums[j]&gt;nums[j+1]){ flag = false; //如果发生交换，则flag变为false int temp = nums[j]; nums[j] = nums[j+1]; nums[j+1] = temp; } } //如果一轮循环下来，没有发生元素交换，说明元素有序，之间跳出循环 if(flag) break; } return nums; }} 分析： 时间复杂度： O(n^2) 空间复杂度： O(1) 稳定排序 原地排序 希尔排序(Shell Sort)希尔排序(Shell Sort)是简单插入排序的改进版，先比较距离较远的元素，进行宏观调控。希尔排序又叫缩小增量排序 算法原理： 首先将序列分为间隔为gap的几组元素，每组使用插入排序的方法排序。 缩小h的值，比如第一次可以是gap=n/2，第二次gap=n/4，…，直到gap=1，重复步骤一的操作。 gap=1的时候，排序完以后说明序列中任意间隔为1的元素有序，此时的序列就是有序的了。 动画演示：（图源水印） 希尔排序算法图解 代码实现： 123456789101112131415161718public class ShellSort{ public static int[] shellSort(int[] nums){ int len = nums.length; for (int gap=len/2; gap&gt;0; gap=gap/2){//这里的间隔值每次取上一次的二分之一 for(int i=gap; i&lt;len; i++){ //这里交替对每个分组执行插入排序 int cur = nums[i]; //记录当前值 int j = i; //对于当前分组的当前值cur，找到其在当前分组中合适的位置，进行插入排序 while(j&gt;=gap &amp;&amp; nums[j-gap]&gt;cur){ nums[j] = nums[j-gap]; //将大于cur的值后移 j=j-gap; } nums[j] = cur; //最后将cur插入到合适的位置 } } return nums; }} 代码中，是轮流对每个分组进行排序，而不是单独对一个分组插入排序完再排序另一个。 分析： 时间复杂度：一般为 O(n\\log n) ，具体根据gap设置的大小决定。 空间复杂度： O(1) 不稳定排序 原地排序 归并排序(Merge Sort)算法原理： 利用分治的思想。如果数组只有一个元素，直接返回。 将数组均分为两部分(分)。 对于两部分分别进行归并排序(治)。 将两部分排好序的数组合并在一起，类似于两个有序链表合并。 动画演示： 归并算法图解 代码实现： 递归版本： 1234567891011121314151617181920212223242526public class MergeSort{ public static int[] mergeSort(int[] nums,int left,int right){ if(left==right) return nums; //如果数组只有一个值，直接返回 int mid = left+(right-left)/2;//这里取中值的方法没有直接求和然后除以2，防止数据溢出 mergeSort(nums,left,mid); //递归调用，对左半部分进行排序 mergeSort(nums,mid+1,right); //递归调用，对右半部分进行排序 merge(nums,left,mid,right);//对两部分进行合并 return nums; } //merge函数，将两个有序数组合并，类似于合并两个有序链表 public static void merge(int[] nums,int left,int mid,int right){ //合并两个有序数组，即nums[left,mid]和nums[mid+1,right] int[] temp = new int[right-left+1];//临时存放合并后的数组 int m = left; //第一个数组的指针 int n = mid+1; //第二个数组的指针 int index = 0; //指向临时数组temp while(m&lt;=mid &amp;&amp; n&lt;=right){ if(nums[m]&lt;nums[n]) temp[index++] = nums[m++]; //将较小的值加到temp数组中 else temp[index++] = nums[n++]; } //将没遍历完的数组直接添加到temp数组中 while(m&lt;=mid) temp[index++] = nums[m++]; while (n&lt;=right) temp[index++] = nums[n++]; for(int i:temp) nums[left++] = i; //将临时数组的值复制到nums数组中，表示合并结束 }} 非递归版本： 123456789101112131415161718192021222324252627282930313233343536public class MergeSort{ public static int[] mergeSort(int[] nums){ int len = nums.length; for(int i=1;i&lt;len;i=i+i){//子数组的大小分别为1,2,4,8,... int left = 0;//对数组进行划分 int mid = left+i-1; int right = mid+i; while (right&lt;len){//对大小为i的数组两两合并 merge(nums,left,mid,right); //合并函数和之前一样 left = right+1; mid = left+i-1; right = mid+i; } if(left&lt;len &amp;&amp; mid&lt;len){//有一些大小不足i的范围，也要合并起来 merge(nums,left,mid,len-1); } } return nums; } //merge函数，将两个有序数组合并，类似于合并两个有序链表 public static void merge(int[] nums,int left,int mid,int right){ //合并两个有序数组，即nums[left,mid]和nums[mid+1,right] int[] temp = new int[right-left+1];//临时存放合并后的数组 int m = left; //第一个数组的指针 int n = mid+1; //第二个数组的指针 int index = 0; //指向临时数组temp while(m&lt;=mid &amp;&amp; n&lt;=right){ if(nums[m]&lt;nums[n]) temp[index++] = nums[m++]; //将较小的值加到temp数组中 else temp[index++] = nums[n++]; } //将没遍历完的数组直接添加到temp数组中 while(m&lt;=mid) temp[index++] = nums[m++]; while (n&lt;=right) temp[index++] = nums[n++]; for(int i:temp) nums[left++] = i; //将临时数组的值复制到nums数组中，表示合并结束 }} 分析： 时间复杂度： O(n\\log n) 空间复杂度： O(n) 稳定排序 非原地排序 快速排序(Quick Sort)快排也是一个分治的算法，每次选择一个元素作为基准(pivot)，然后将序列根据pivot分为两部分，pivot此时是有序的，不需要再次移动。然后递归对两部分序列操作。 与归并排序不同的是，快排不需要额外的辅助空间和将排序好的临时序列的值复制到原序列的时间，因此一般比归并排序要快。 算法原理： 从序列中挑出一个元素，作为基准(pivot)。选择基准值的方法有多种，可以一直挑选第一个或最后一个元素，也可以随机选择或者取中间值等。 重新排列序列，将所有大于pivot的元素放到其后面，所有小于pivot的元素放到其前面。然后pivot就位于中间位置，其已经是有序的，不需要再移动。这个称为分区(partition)操作。 通过递归，将pivot左右两边的序列同样根据步骤二排列。直到序列的大小为1，递归终止。 实际操作的时候可以使用两个指针从两边开始遍历，只有两个指针指向的值同时需要移动的时候，交换两个值，这样可以减少交换次数，节省时间。 动画演示： 快速排序算法图解 代码实现： 12345678910111213141516171819202122232425262728293031public class QuickSort{ public static int[] quickSort(int[] nums,int left,int right){ if (left&gt;=right) return nums; //当前范围非法或者只有一个元素的时候直接返回 int mid = partition(nums,left,right); //获取pivot的所在位置 quickSort(nums,left,mid-1); //以pivot为中心，对左右两边递归 quickSort(nums,mid+1,right); return nums; } //根据pivot元素将序列分为左右两部分 public static int partition(int[] nums, int left, int right){ int pivot = nums[right]; //这里一直选用最右边的元素作为基准元素 int i = left; //定义i，j两个指针，分别从左右两边往中间遍历 int j = right-1; //因为最右边的元素已经是基准元素了，所以需要往左一位 while(true){ //这里判断条件包括等号，不然会出现两个相同的值重复交换陷入死循环的情况。 while(i&lt;=j &amp;&amp; nums[i]&lt;=pivot) i += 1;//左指针向右遍历，直到找到一个大于pivot的值 while(i&lt;=j &amp;&amp; nums[j]&gt;=pivot) j -= 1;//右指针向左遍历，直到找到一个小于pivot的值 if(i&gt;=j) break; swap(nums,i,j);//交换两个指针指向的元素的位置 } //将序列根据pivot划分为两部分后，将pivot的值放到分界点的位置 nums[right] = nums[i];//如果一直选用最右边元素，则和i交换，如果是选最左边，则和j交换 nums[i] = pivot; return i; } private static void swap(int[] nums, int i, int j) { //用于交换两个值 int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; }} 上述的快排函数是从两端开始遍历，也可以使用两个指针从一端开始遍历： 1234567891011121314//使用两个指针，从一端开始遍历public static int partition(int[] nums, int left, int right) { int pivot = nums[right]; //选用最右边的元素作为基准值 int i = left - 1; //每交换一次，i都+1，表示小于基准值的元素+1 for (int j = left; j &lt;= right - 1; ++j) { if (nums[j] &lt;= pivot) { //从最左边开始遍历，不断地把小于基准值的元素放到左边 i = i + 1; swap(nums, i, j); } } //最后，下标为i和小于i的元素都是小于基准值的元素，将基准值和i+1交换位置 swap(nums, i + 1, right); return i + 1;//交换位置后，i+1表示排序后基准值的位置 } 如果序列近乎有序，每次选取第一个数或者最后一个数作为基准的方法时间复杂度会接近 O(n^2) ，因此需要随机选取基准点。 如果是随机选取基准点，需要在int pivot = nums[right];语句前，将随机选取的值放到最右边或最左边，其余代码不变： 123int random_index = new Random().nextInt(right-left+1)+left; //随机选取下标swap(nums,right,random_index); //然后将选取的基准值放到最右边int pivot = nums[right]; //将此时最右边的元素作为基准值，也就是随机选取的基准值 分析： 时间复杂度： O(n\\log n) 空间复杂度： O(\\log n) 非稳定排序 原地排序 堆排序(Heap Sort)堆排序(Heapsort)是利用二叉堆的一种排序方法。二叉堆除了具有完全二叉树的特征外，所有父节点的值都大于或小于它的孩子节点。其中所有父节点的值都大于其孩子节点的堆叫做最大堆(大顶堆)，反之称为最小堆(小顶堆)。所以说，最大堆的堆顶元素即整个堆的最大值，最小堆的堆顶元素是堆的最小值，堆排序正是利用了二叉堆的这一特征。 二叉堆实现是采用数组的形式来存储的，假设一个节点的下标为n，则其左孩子和右孩子节点的下标分别为2n+1、2n+2。 二叉堆每次添加元素都是添加到最后一个位置，即数组最后，然后使用上浮 的方法再调整。 二叉堆删除元素是删除堆顶元素，然后把最后一个位置的元素放到堆顶，采用下沉 的方法调整。 关于二叉堆的上浮和下沉操作，可以参考二叉堆 算法原理： 创建一个最大堆，包含n个节点。 把堆顶(最大值)和堆最后一个位置元素互换(相当于删除堆顶元素)，这样最大值位于最后面。 将堆的大小减1，调整堆，使剩下的n-1个节点保持最大堆的性质。 重复步骤2、3，直到堆的大小为1，此时数组中的元素从小到大排列。 动画演示： 图片来自 here 堆排序算法图解 代码实现： 12345678910111213141516171819202122232425262728293031public class HeapSort{ public static int[] headSort(int[] nums){ int len = nums.length; //构建最大堆 for(int i = (len-2)/2;i&gt;=0;i--){//i初始化为最后一个元素的父节点 heapify(nums,i,len);//从最后一个元素的父节点开始调整堆结构，构建最大堆 } //进行堆排序，每次交换堆顶和堆尾两个节点，交换完一次就调整一次结构。 for(int i = len-1;i&gt;=1;i--){ swap(nums,0,i); heapify(nums,0,i);//这里每次传入i，用来表示堆的个数减一 } return nums; } public static void heapify(int[] nums,int parent,int len){//调整堆结构 int largest = parent; int left = 2*parent+1;//左孩子下标 int right = 2*parent+2;//右孩子下标 if(left&lt;len &amp;&amp; nums[left]&gt;nums[largest]) largest=left;//找到较大的那个值 if(right&lt;len &amp;&amp; nums[right]&gt;nums[largest]) largest=right; if(largest != parent){//然后交换最大值和父节点，实现父节点的下沉 swap(nums,parent,largest); heapify(nums,largest,len); //一直往下调整，直到父节点是最大值 } } public static void swap(int[] nums, int i, int j){//swap函数用于交换数组的两个值 int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; }} 上述用于调整堆结构的heapify函数使用了递归的方法，如果不使用递归，可以写成以下形式： 123456789101112131415//非递归形式实现调整堆结构public static void heapify(int[] nums,int parent,int len){ int temp = nums[parent];//临时保存父节点元素 int child = 2*parent+1;//用于指向孩子下标 while(child&lt;len){ if(child+1&lt;len &amp;&amp; nums[child+1]&gt;nums[child]){//寻找左右孩子中较大的值 child += 1; } if(nums[child]&gt;temp){//如果孩子节点比父节点要大，则父节点下沉 swap(nums,parent,child);//父节点下沉，即交换两个节点的值 parent = child; //然后把孩子节点作为父节点，继续向下调整 child = 2*parent+1; }else break; //如果父节点已经是最大的了，不必下沉，跳出循环。 } } 分析： 时间复杂度： O(n\\log n) 空间复杂度： O(1) 非稳定排序 原地排序 计数排序(Counting Sort)计数排序(counting sort)是一种适合最大值和最小值的差值k不是很大的排序，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。计数排序要求输入的数据必须是有确定范围的整数。 算法原理： 扫描待排序列，找出最大值max和最小值min。 开辟新的数组Res，长度为max-min+1。 以序列中的值为下标，对应数组B中的值为其在整个序列中出现的次数。 遍历数组B，得到每个值的出现次数，并输出。 动画演示： 计数排序算法图解 代码实现： 1234567891011121314151617181920212223242526public class CountSort{ public static int[] countSort(int[] nums){ if(nums==null || nums.length&lt;2) return nums; int len = nums.length; int max = nums[0]; int min = nums[0]; for (int i:nums){//遍历数组，得到最大值和最小值 if(i&lt;min) min=i; if(i&gt;max) max=i; } int n = max-min+1; //辅助数组的长度 int[] temp = new int[n];//建立辅助数组 for(int i:nums){//遍历原数组，获取每个值的出现次数,在辅助数组中记录 //下标=真实值-最小值 temp[i-min] = temp[i-min]+1; //当前值对应于辅助数组中的值+1，表示出现次数+1 } //将辅助数组中的值，根据出现次数恢复到原数组中，完成排序 int index = 0;//用于指向原数组 for(int i=0;i&lt;n;i++){ //遍历辅助数组 for(int j=0;j&lt;temp[i];j++){//辅助数组中的值作为出现次数，将对应的值恢复到原数组 nums[index++] = i+min;//下标+最小值=真实值 } } return nums; }} 分析： 时间复杂度： O(n+k) 空间复杂度：如果是在原数组的基础上修改，只需要 O(k) 的额外空间 稳定排序 非原地排序 桶排序(Bucket Sort)桶排序是计数排序的升级版，它利用一定的函数映射关系，划分出多个桶，将序列中的值放入对应的桶中，然后各个桶内元素再排序(递归或其他排序方法)。桶排序要求数据分布均匀。 需要根据待排序列的数据特征，选择合适的分桶方法。 算法原理： 根据一定方法，划分出n个桶。 将数据放入对应的桶中。 对每个桶中的数据进行排序，可以递归使用桶排序，或者其他排序方法。 将各个桶中的数据拼接，得出结果。 动画演示： 图片来自here 桶排序算法图解 代码实现： 这里的分桶方法根据序列中数值的范围确定，划分为(max-min)/5 + 1个桶，第i个桶中的元素存放的数值范围是5*i~5*i+5-1，即每个桶中存放5个数。 1234567891011121314151617181920212223242526272829public class BucketSort{ public static int[] bucketSort(int[] nums){ if(nums==null || nums.length&lt;2) return nums; int len = nums.length; int max = nums[0]; int min = nums[0]; for (int i:nums){//遍历数组，得到最大值和最小值 if(i&lt;min) min=i; if(i&gt;max) max=i; } int d = max-min; //创建d/5+1个桶，第 i 桶存放5*i ~ 5*i+5-1范围的数 int bucketNum = d/5 + 1; //桶的数量 //建立一个链表集合，每个桶都是一个LinkedList类型的链表 ArrayList&lt;LinkedList&lt;Integer&gt;&gt; bucketList = new ArrayList&lt;&gt;(bucketNum); //初始化bucketNum个桶 for(int i=0;i&lt;bucketNum;i++) bucketList.add(new LinkedList&lt;Integer&gt;()); //遍历数组，将每个值放入对应的桶中 for(int i:nums) bucketList.get((i-min)/d).add(i); //对每个桶内的元素排序，这里使用系统排序函数，对链表进行排序 for(int i=0;i&lt;bucketNum;i++) Collections.sort(bucketList.get(i)); //将各个桶的数据合并，放回原数组 int index = 0; //用于指向原数组 for(int i=0;i&lt;bucketNum;i++){//将每个桶中的值依次放回原数组 for(Integer t: bucketList.get(i)) nums[index++] = t; } return nums; }} 分析： 时间复杂度： O(n+k) 空间复杂度： O(n+k) 稳定排序 非原地排序 k表示桶的个数。桶排序的时间复杂度取决于各个桶内数据排序的时间复杂度，其他部分时间复杂度都是 O(n) 。桶划分的个数越多，桶内的个数越少，单个桶排序用的时间也越少，但空间复杂度也随之增加。 基数排序(Radix Sort)基数排序(Radix Sort)是按照低位先排序，然后收集；再按照高位排序，然后再收集；以此类推，直到最高位。如果有的属性有优先级顺序，则先按低优先级排序，再按高优先级排序。最后的结果是高优先级高的在前，如果高优先级相同，则低优先级高的在前。 下面以数字为例： 算法原理： 取序列中最大的数，并取得位数，将序列中所有数填充至和最大值位数相等，前面填充0。 从最低位开始，使用计数排序依次进行一次排序。 从最低位排序，一直到最高位排序完成后，序列变为有序序列。 动画演示： 基数排序算法图解 代码实现： 12345678910111213141516171819202122232425public class RaxixSort{ public static int[] radixSort(int[] nums){ if(nums==null || nums.length&lt;2) return nums; int max = nums[0]; for (int i:nums) if(i&gt;max) max=i; //求出序列最大值 for(int exp=1; max/exp&gt;0; exp = exp*10){//从最低位到最高位依次进行计数排序 countSort(nums,exp); } return nums; } public static void countSort(int[] nums,int exp){ int len = nums.length; int[] output = new int[len]; //临时存放根据当前位排序的序列 int[] temp = new int[10]; //定义辅助数组，用来存放每个基数下的值 for(int i:nums) temp[(i/exp)%10] += 1;//将每个值在对应数组中的出现次数+1 //和计数排序不同的是，这里的键是数值的某位的值，所以需要根据下标还原到原来的值 //将temp中的数值改为累和，表示小于等于当前下标的数值的总数 for(int i=1;i&lt;10;i++) temp[i] += temp[i-1]; for(int i=len-1;i&gt;=0;i--){ //一定要从后往前添加，保证temp数组计数正确 output[temp[(nums[i]/exp)%10]-1] = nums[i]; temp[(nums[i]/exp)%10]--; //每添加完一个数值，temp对应的下标的次数-1 } for(int i=0;i&lt;len;i++) nums[i] = output[i]; //将每次排序好的序列返回原数组 }} 分析： 时间复杂度： O(n\\times k) 空间复杂度： O(n+k) 稳定排序 非原地排序 这里的k指的是基的个数，比如0-9一共10个基，k就等于10。 总结实际应用中，需要根据序列的特点选择合适的排序算法，假设一个待排序列总元素个数为n。 当n较大时，应采用时间复杂度为 O(n\\log n) 的排序方法：快速排序、堆排序、归并排序。 快速排序时目前基于比较的内部排序中被认为最好的方法，当待排序的关键字时随机分布时，快排的平均时间最短。 堆排序适用于内存空间允许且要求稳定性。 归并排序有一定数量的数据移动。 当n较大，内存空间允许，且要求稳定性，使用归并排序。 当n较小，可采用直接插入排序或直接选择排序。 当元素分布有序，直接插入排序将大大减少比较次数和移动纪录的次数。 当元素分布有序，如果不要求稳定性，使用直接选择排序。 一般不使用或者不直接使用冒泡排序。 基数排序是一种稳定的排序算法，但有一定的局限性： a.要求关键字必须可分解。 b.记录的关键字位数较少，如果密集更好。 c.如果是数字时，最好是无符号数字，否则将增加相应的映射复杂度，可将正负数分开排序。 Reference 必学十大经典排序算法 十大经典排序算法(动图演示) 五分钟学算法 排序算法的比较和选择依据","categories":[{"name":"算法笔记","slug":"算法笔记","permalink":"http://kangshitao.github.io/categories/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://kangshitao.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"单链表反转","slug":"reverse-linkedlist","date":"2020-12-05T08:01:11.000Z","updated":"2022-05-22T13:30:54.802Z","comments":true,"path":"2020/12/05/reverse-linkedlist/","link":"","permalink":"http://kangshitao.github.io/2020/12/05/reverse-linkedlist/","excerpt":"单链表反转的几种方法，知识点来自剑指offer06、24","text":"前几天做题遇到了链表反转的问题，即剑指offer06和24，涉及到了链表反转的知识。奈何本人太菜，早已忘了数据结构课本中链表反转的具体操作，这里记录并复习一下有关单向链表反转的几种方法。 参考链接：单链表反转详解 定义链表节点定义如下(python)： 1234class ListNode: # 定义链表节点 def __init__(self, x): self.val = x self.next = None 原链表：1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL 反转后：5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL 新建链表法新建链表法的主要思想是新建一个链表，保证其与原链表顺序相反，然后返回新链表，实现原链表的反转。新建反转链表有两种方法，一种是使用头插法新建链表，另一种是使用辅助栈(或者数组等)。这类方法的主要特点是需要使用额外的存储空间。 头插法使用头插法新建一个链表(虽说是新链表，只是换了个头指针，但没有使用新的存储空间)，每次将新节点插入到新链表头节点之后，然后返回新链表实现反转。 123456789101112def reverseList(self, head: ListNode) -&gt; ListNode: if not head or not head.next: return head new_head = None # 新链表的头指针 tmp = None # 临时指针tmp，用于保存原链表的当前头节点 while head: tmp = head # 指向当前头节点 head = head.next # 当前头指针后移。这条语句一定要在tmp.next=new_head的前面 # 将tmp节点加入到新链表的头节点后面(头插法) tmp.next = new_head new_head = tmp return new_head 时间复杂度 O(N) ：遍历链表使用线性大小空间。 空间复杂度 O(1) ：只需要两个额外的指针，没有额外使用存储空间 辅助栈新建链表第二种方式是使用辅助栈的方法，将原链表依次入栈，然后新建链表，将栈中的元素依次出栈作为新链表的下一个节点，则新链表即为原链表的反转链表。 123456789101112def reverseList(self, head: ListNode) -&gt; ListNode: if not head or not head.next: return head stack = [] # 用列表表示栈 while head: # 将原链表的值依次入栈 stack.append(head.val) head = head.next new_head = ListNode(stack.pop()) # 注意这里的头节点是有值的 cur = new_head # cur用于尾插法构建新链表，理解为向后移动的指针 for i in range(len(stack)): # 将栈中数据出栈，并构建新链表 cur.next = ListNode(stack.pop()) cur = cur.next return new_head # 返回新链表。将new_head和cur都理解为指针 时间复杂度 O(N) ：遍历链表使用线性大小空间。 空间复杂度 O(N) ：额外辅助空间和新建链表的存储空间，均为线性大小。 迭代遍历法(双指针)迭代反转法(原地反转法)，从当前链表的头结点开始，一直遍历到链表的最后一个节点，期间逐个改变节点指针的方向，使其指向前一个节点，返回最后一个位置的指针(或者说将头指针指向最后一个位置)。参考链接 123456789def reverseList(self, head: ListNode) -&gt; ListNode: if not head or not head.next: return head pre,cur = None, head # pre初始化为空节点，可以理解为头节点的前一个节点 while cur: tmp = cur.next # 暂时存放当前节点的后继节点 cur.next = pre # 修改当前节点的指针方向 pre = cur # pre暂存cur(pre右移) cur = tmp # cur指针右移，访问下一节点 return pre # 最后返回pre指针，作为头指针，或者说是将头指针指向pre，实现反转。 时间复杂度 O(N) ：遍历链表使用线性大小空间。 空间复杂度 O(1) ：变量pre和cur使用常数大小额外空间。 就地逆置法就地逆置法(也叫头插法)，与头插法新建链表类似，不同的是不需要新链表，只需要用两个指针对原链表本身进行操作，将每个节点依次插入到头节点后面，最后返回头节点。 123456789def reverseList(self, head: ListNode) -&gt; ListNode: if not head or not head.next: return head pre, cur = head, head.next while cur: pre.next = cur.next # 将cur指向的节点\"摘除\" cur.nxet = head # 将上一步“摘除”的节点放到head的前面，此时头节点为cur指向的节点 head = cur # head更新，重新指向头节点 cur = pre.next # cur重新指向pre的next节点 return head 此方法和上面提到的头插法大同小异，一个是返回原来的头指针,一个是返回新指针。此方法中的原链表头指针不动，上面的头插法的原链表头指针是移动的。 这两种方法都可以叫做头插法。 时间复杂度 O(N) ：遍历链表使用线性大小空间。 空间复杂度 O(1) ：变量pre和cur使用常数大小额外空间。 递归法递归法的思想是递归到停止条件，即链尾，然后逐层返回递归结果(从后向前将链表的指向反向)。 123456789101112131415def reverseList(self, head: ListNode) -&gt; ListNode: if not head or not head.next: return head new_head = self.reverseList(head.next) # 一直递归，找到链表中最后一个节点 # 当逐层退出时，new_head 的指向都不变，一直指向原链表中最后一个节点； # 递归每退出一层，函数中 head 指针的指向都会发生改变，都指向上一个节点。 # 每退出一层，都需要改变 head-&gt;next 节点指针域的指向，同时令 head 所指节点的指针域为None。 head.next.next = head head.next = None # 每一层递归结束，都要将新的头指针返回给上一层。 # 由此，即可保证整个递归过程中，能够一直找得到新链表的表头。 return new_head 时间复杂度 O(N) ：一遍递归深入并返回 空间复杂度 O(1) ：不需要额外空间，只需要两个指针(但迭代过程需要一直创建/释放) 这递归太难理解了 :-( ，建议看大佬题解剑指offer24题解或者单链表反转详解。","categories":[{"name":"算法笔记","slug":"算法笔记","permalink":"http://kangshitao.github.io/categories/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://kangshitao.github.io/tags/%E9%93%BE%E8%A1%A8/"},{"name":"数据结构","slug":"数据结构","permalink":"http://kangshitao.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"PyTorch各种维度变换函数总结","slug":"pytorch-function","date":"2020-11-21T14:33:39.000Z","updated":"2022-05-22T13:30:54.801Z","comments":true,"path":"2020/11/21/pytorch-function/","link":"","permalink":"http://kangshitao.github.io/2020/11/21/pytorch-function/","excerpt":"记录reshape/view、resize_、transpose/permute、squeeze/unsqueeze、expand/repeat函数使用方法和区别","text":"介绍本文对于PyTorch中的各种维度变换的函数进行总结，包括reshape()、view()、resize_()、transpose()、permute()、squeeze()、unsqeeze()、expand()、repeat()函数的介绍和对比。 contiguous区分各个维度转换函数的前提是需要了解contiguous。在PyTorch中，contiguous指的是Tensor底层一维数组的存储顺序和其元素顺序一致。 Tensor是以一维数组的形式存储的，C/C++使用行优先(按行展开)的方式，Python中的Tensor底层实现使用的是C，因此PyThon中的Tensor也是按行展开存储的，如果其存储顺序和按行优先展开的一维数组元素顺序一致，就说这个Tensor是连续(contiguous)的。 形式化定义： 对于任意的 d 维张量 t ，如果满足对于所有的 i ，第 i 维相邻元素间隔=第 i+1 维相邻元素间隔 \\times 第 i+1 维长度的乘积，则 t 是连续的： stride[i]=stride[i+1]\\times size[i+1],\\forall i=0,\\ldots,d-1(i\\neq d-1) stride[i] 表示第 i 维相邻元素之间间隔的位数，称为步长，可通过stride()方法获得。 size[i] 表示固定其他维度时，第 i 维的元素数量，即第 i 维的长度，通过size()方法获得。 Python中的多维张量按照行优先展开的方式存储，访问矩阵中下一个元素是通过偏移来实现的，这个偏移量称为步长(stride)，比如python中，访问 2\\times3 矩阵的同一行中的相邻元素，物理结构需要偏移1个位置，即步长为1，同一列中的两个相邻元素则步长为3。 举例说明： 1234567891011&gt;&gt;&gt;t = torch.arange(12).reshape(3,4)&gt;&gt;&gt;ttensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])&gt;&gt;&gt;t.stride(),t.stride(0),t.stride(1) # 返回t两个维度的步长，第0维的步长，第1维的步长((4,1),4,1)# 第0维的步长，表示沿着列的两个相邻元素，比如‘0’和‘4’两个元素的步长为4&gt;&gt;&gt;t.size(1)4# 对于i=0，满足stride[0]=stride[1] * size[1]=1*4=4，那么t是连续的。 PyTorch中的有一些操作没有真正地改变tensor的内容，只是改变了索引和元素的对应关系，操作之前和操作之后的数据是共享的。这些操作包括narrow(),view(),expand(),transpose()等[2]。当执行这些函数时，原来语义上相邻、内存里也相邻的元素，可能会出现语义上相邻，但内存上不相邻的情况，就不连续(not contiguous)了。 PyTorch提供了两个关于contiguous的方法： is_contiguous() : 判断Tensor是否是连续的contiguous() : 返回新的Tensor，重新开辟一块内存，并且是连续的 举例说明(参考[1])： 123456789101112131415&gt;&gt;&gt;t = torch.arange(12).reshape(3,4)&gt;&gt;&gt;ttensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])&gt;&gt;&gt;t2 = t.transpose(0,1)&gt;&gt;&gt;t2tensor([[ 0, 4, 8], [ 1, 5, 9], [ 2, 6, 10], [ 3, 7, 11]])&gt;&gt;&gt;t.data_ptr() == t2.data_ptr() # 返回两个张量的首元素的内存地址True #说明底层数据是同一个一维数组&gt;&gt;&gt;t.is_contiguous(),t2.is_contiguous() # t连续，t2不连续(True, False) 可以看到，t和t2共享内存中的数据。如果对t2使用contiguous()方法，会开辟新的内存空间： 12345678910&gt;&gt;&gt;t3 = t2.contiguous()&gt;&gt;&gt;t3tensor([[ 0, 4, 8], [ 1, 5, 9], [ 2, 6, 10], [ 3, 7, 11]])&gt;&gt;&gt;t3.data_ptr() == t2.data_ptr() # 底层数据不是同一个一维数组False&gt;&gt;&gt;t3.is_contiguous()True 关于contiguous的更深入的解释可以参考[1]. view()/reshape()view()tensor.view()函数返回一个和tensor共享底层数据，但不同形状的tensor。使用view()函数的要求是tensor必须是contiguous的。 用法如下： 12345678910&gt;&gt;&gt;ttensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])&gt;&gt;&gt;t2 = t.view(2,6)&gt;&gt;&gt;t2tensor([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11]])&gt;&gt;&gt;t.data_ptr() == t2.data_ptr() # 二者的底层数据是同一个一维数组True reshape()tensor.reshape()类似于tensor.contigous().view()操作，如果tensor是连续的，则reshape()操作和view()相同，返回指定形状、共享底层数据的tensor；如果tensor是不连续的，则会开辟新的内存空间，返回指定形状的tensor，底层数据和原来的tensor是独立的，相当于先执行contigous()，再执行view()。 如果不在意底层数据是否使用新的内存，建议使用reshape()代替view(). resize_()tensor.resize_()函数，返回指定形状的tensor，与reshape()和view()不同的是，resize_()可以只截取tensor一部分数据，或者是元素个数大于原tensor也可以，会自动扩展新的位置。 resize_()函数对于tensor的连续性无要求，且返回的值是共享的底层数据（同view()），也就是说只返回了指定形状的索引，底层数据不变的。 transpose()/permute() permute()和transpose()还有t()是PyTorch中的转置函数，其中t()函数只适用于2维矩阵的转置，是这三个函数里面最”弱”的。 transpose()tensor.transpose()，返回tensor的指定维度的转置，底层数据共享，与view()/reshape()不同的是，transpose()只能实现维度上的转置，不能任意改变维度大小。 对于维度交换来说，view()/reshape()和transpose()有很大的区别，一定不要混用！混用了以后虽然不会报错，但是数据是乱的，血坑。 reshape()/view()和transpose()的区别在于对于维度改变的方式不同，前者是在存储顺序的基础上对维度进行划分，也就是说将存储的一维数组根据shape大小重新划分，而transpose()则是真正意义上的转置，比如二维矩阵的转置。 举个例子： 1234567891011121314&gt;&gt;&gt;ttensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])&gt;&gt;&gt; t.transpose(0,1) # 交换t的前两个维度，即对t进行转置。tensor([[ 0, 4, 8], [ 1, 5, 9], [ 2, 6, 10], [ 3, 7, 11]])&gt;&gt;&gt; a.reshape(4,3) # 使用reshape()/view()的方法，虽然形状一样，但是数据排列完全不同tensor([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]]) permute()tensor.permute()函数，以view的形式返回矩阵指定维度的转置，和transpose()功能相同。 与transpose()不同的是，permute()同时对多个维度进行转置，且参数是期望的维度的顺序，而transpose()只能同时对两个维度转置，即参数只能是两个，这两个参数没有顺序，只代表了哪两个维度进行转置。 举个例子： 1234567891011121314151617181920212223242526&gt;&gt;&gt; t # t的形状为(2,3,2)tensor([[[ 0, 1], [ 2, 3], [ 4, 5]], [[ 6, 7], [ 8, 9], [10, 11]]])&gt;&gt;&gt; t.transpose(0,1) # 使用transpose()将前两个维度进行转置，返回(3,2,2)tensor([[[ 0, 1], [ 6, 7]], [[ 2, 3], [ 8, 9]], [[ 4, 5], [10, 11]]])&gt;&gt;&gt; t.permute(1,0,2) # 使用permute()按照指定的维度序列对t转置，返回(3,2,2)tensor([[[ 0, 1], [ 6, 7]], [[ 2, 3], [ 8, 9]], [[ 4, 5], [10, 11]]]) squeeze()/unsqueeze()squeeze()tensor.squeeze()返回去除size为1的维度的tensor，默认去除所有size=1的维度，也可以指定去除某一个size=1的维度，并返回去除后的结果。 举个例子： 12345678&gt;&gt;&gt; t.shape torch.Size([3, 1, 4, 1])&gt;&gt;&gt; t.squeeze().shape # 去除所有size=1的维度torch.Size([3, 4])&gt;&gt;&gt; t.squeeze(1).shape # 去除第1维torch.Size([3, 4, 1])&gt;&gt;&gt; t.squeeze(0).shape # 如果指定的维度size不等于1，则不执行任何操作。torch.Size([3, 1, 4, 1]) unsqueeze()tensor.unsqueeze()与squeeze()相反，是在tensor插入新的维度，插入的维度size=1，用于维度扩展。 举个例子： 12345678&gt;&gt;&gt; t.shapetorch.Size([3, 1, 4, 1])&gt;&gt;&gt; t.unsqueeze(1).shape # 在指定的位置上插入新的维度，size=1torch.Size([3, 1, 1, 4, 1]) &gt;&gt;&gt; t.unsqueeze(-1).shape # 参数为-1时表示在最后一维添加新的维度，size=1torch.Size([3, 1, 4, 1, 1])&gt;&gt;&gt; t.unsqueeze(4).shape # 和dim=-1等价torch.Size([3, 1, 4, 1, 1]) expand()/repeat()expand()tensor.expand()的功能是扩展tensor中的size为1的维度，且只能扩展size=1的维度。以view的形式返回tensor，即不改变原来的tensor，只是以视图的形式返回数据。 举个例子： 12345678910111213141516171819202122232425262728293031&gt;&gt;&gt; ttensor([[[0, 1, 2], [3, 4, 5]]])&gt;&gt;&gt; t.shapetorch.Size([1, 2, 3])&gt;&gt;&gt; t.expand(3,2,3) # 将第0维扩展为3，可见其将第0维复制了3次tensor([[[0, 1, 2], [3, 4, 5]], [[0, 1, 2], [3, 4, 5]], [[0, 1, 2], [3, 4, 5]]])&gt;&gt;&gt; t.expand(3,-1,-1) # dim=-1表示固定这个维度，效果是一样的，这样写更方便tensor([[[0, 1, 2], [3, 4, 5]], [[0, 1, 2], [3, 4, 5]], [[0, 1, 2], [3, 4, 5]]])&gt;&gt;&gt; t.expand(3,2,3).storage() # expand不扩展新的内存空间 0 1 2 3 4 5[torch.LongStorage of size 6] repeat()tensor.repeat()用于维度复制，可以将size为任意大小的维度复制为n倍，和expand()不同的是，repeat()会分配新的存储空间，是真正的复制数据。 举个例子： 12345678910111213141516171819202122232425262728&gt;&gt;&gt; ttensor([[0, 1, 2], [3, 4, 5]])&gt;&gt;&gt; t.shapetorch.Size([2, 3])&gt;&gt;&gt; t.repeat(2,3) # 将两个维度分别复制2、3倍tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2], [3, 4, 5, 3, 4, 5, 3, 4, 5], [0, 1, 2, 0, 1, 2, 0, 1, 2], [3, 4, 5, 3, 4, 5, 3, 4, 5]])&gt;&gt;&gt; t.repeat(2,3).storage() # repeat()是真正的复制，会分配新的空间 0 1 2 0 1 2 0 1 2 3 4 5 ...... 3 4 5[torch.LongStorage of size 36] 如果维度size=1的时候，repeat()和expand()的作用是一样的，但是expand()不会分配新的内存，所以优先使用expand()函数。 总结 view()/reshape()两个函数用于将tensor变换为任意形状，本质是将所有的元素重新分配。 t()/transpose()/permute()用于维度的转置，转置和reshape()操作是有区别的，注意区分。 squeeze()/unsqueeze()用于压缩/扩展维度，仅在维度的个数上去除/添加，且去除/添加的维度size=1。 expand()/repeat()用于数据的复制，对一个或多个维度上的数据进行复制。 以上提到的函数仅有两种会分配新的内存空间：reshape()操作处理非连续的tensor时，返回tensor的copy数据会分配新的内存；repeat()操作会分配新的内存空间。其余的操作都是返回的视图，底层数据是共享的，仅在索引上重新分配。 Reference1. PyTorch中的contiguous 2. stackoverflow-pytorch-contiguous 3. PyTorch官方文档","categories":[{"name":"PyTorch","slug":"PyTorch","permalink":"http://kangshitao.github.io/categories/PyTorch/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://kangshitao.github.io/tags/Python/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://kangshitao.github.io/tags/PyTorch/"}]},{"title":"自注意力和Transformer","slug":"transformer","date":"2020-11-15T03:31:47.000Z","updated":"2022-05-22T13:30:54.806Z","comments":true,"path":"2020/11/15/transformer/","link":"","permalink":"http://kangshitao.github.io/2020/11/15/transformer/","excerpt":"自注意力机制和Transformer详解","text":"参考链接： [1] 邱锡鹏：神经网络与深度学习 [2] Jay Alammar：Illustrated Transformer [3] 深度学习-图解Transformer(变形金刚) [4] 详解Transformer 自注意力在讲述Transformer之前，首先介绍Self-Attention模型。 传统的RNN虽然理论上可以建立输入信息的长距离依赖关系，但是由于信息传递的容量和梯度消失的问题，实际上只能建立短距离（局部）依赖关系。为了建立输入序列之间的长距离依赖关系，并利用注意力机制来“动态”地生成不同连接的权重，诞生了自注意力模型(Self-Attention Model) 自注意力模型采用查询-键-值(Query-Key-Value,QKV)模式，计算过程如下图，红色字母表示维度：","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://kangshitao.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Attention","slug":"Attention","permalink":"http://kangshitao.github.io/tags/Attention/"},{"name":"深度学习","slug":"深度学习","permalink":"http://kangshitao.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"transformer","slug":"transformer","permalink":"http://kangshitao.github.io/tags/transformer/"}]},{"title":"Attention总结","slug":"attention","date":"2020-11-12T14:36:01.000Z","updated":"2022-05-22T13:30:54.781Z","comments":true,"path":"2020/11/12/attention/","link":"","permalink":"http://kangshitao.github.io/2020/11/12/attention/","excerpt":"注意力机制总结","text":"友情参考：邱锡鹏老师的神经网络与深度学习 注意力机制在计算能力有限的情况下，注意力机制(Attention Machanism)作为一种资源分配方案，将有限的计算资源用来处理更重要的信息，是解决信息过载问题的主要手段。通俗来说，注意力机制就是只关注和当前需求相关的信息，以阅读理解为例，对于给定的问题，只需要关注和问题相关的一个或几个句子，其余无关的部分不需要关注。 数学思想表达： \\boldsymbol{X} = [x_1,x_2,\\ldots,x_N] 表示N个输入信息，为了节省计算资源，只需要 \\boldsymbol{X} 中选择一些和任务相关的信息进行计算。 注意力的计算 一般情况下，我们使用的是Soft Attention，即各种信息的加权平均。还有一种Hard Attention，下文会讲。 为了从N个输入向量 \\boldsymbol{X}=[x_1,x_2,\\ldots,x_N] 中选择出与任务相关的信息，需要引入和任务相关的表示，称为查询向量 \\boldsymbol{q} (Query Vector)，并通过一个打分函数计算每个输入向量和查询向量之间的相关性。 查询向量q可以是动态生成的，也可以是可学习的参数。 Soft Attention机制示例如下： 给定查询向量 \\boldsymbol{q} 和输入信息 \\boldsymbol{X} ，根据“软性”的信息选择机制对输入信息进行汇总： att(\\boldsymbol{X},q)=\\sum^N_{n=1} {\\alpha_n \\boldsymbol{x}_n},\\\\ =\\mathbb{E}_{z \\sim p(z|\\boldsymbol{X},q)}[\\boldsymbol{x}_z] \\tag{1}上式中的 \\alpha_n 称为注意力分布，表示在给定 \\boldsymbol{q} 和 \\boldsymbol{X} 情况下，选择第 n 个输入向量的概率，也可以解释为在给定任务相关的查询 \\boldsymbol{q} 时，第 n 个输入向量受关注的程度： \\alpha_n = p(z=n|\\boldsymbol{X},q)\\\\ =softmax(s(\\boldsymbol{x}_n,\\boldsymbol{q}))\\\\ =\\frac{\\exp{(s(\\boldsymbol{x}_n,\\boldsymbol{q}))}}{\\sum^N_{j=1} \\exp{(s(\\boldsymbol{x}_j,\\boldsymbol{q}))}} \\tag{2})其中 s(\\boldsymbol{x},\\boldsymbol{q}) 为注意力打分函数，是注意力机制中最重要的一部分，它主要计算的是注意力分数的大小。可以通过以下几种方式计算： 加性（感知机）模型 s(\\boldsymbol{x},\\boldsymbol{q})=\\boldsymbol{v}^T \\tanh(\\boldsymbol{Wx+Uq}) \\tag{3} 点积模型 s(\\boldsymbol{x},\\boldsymbol{q})=\\boldsymbol{x}^T \\boldsymbol{q} \\tag{4} 缩放点击模型 s(\\boldsymbol{x},\\boldsymbol{q})=\\frac{\\boldsymbol{x}^T \\boldsymbol{q}}{\\sqrt{D}} \\tag{5} 双线性模型 s(\\boldsymbol{x},\\boldsymbol{q})=\\boldsymbol{x}^T \\boldsymbol{Wq} \\tag{6} 各自的优缺点: 加性模型对于大规模数据特别有效，但是训练成本较高。 理论上，点积模型和加性模型复杂度差不多，但是点积模型只利用矩阵相乘，计算效率更高。 输入向量维度较高时，最后得到的权重会增加，为了提升计算效率，防止数据上溢，对齐scaling，即缩放点积模型。 双线性模型通过权重矩阵直接建立x和q的关系映射，比较直接且速度较快。双线性模型的公式也可以写为 s(\\boldsymbol{x},\\boldsymbol{q})=\\boldsymbol{x}^T \\boldsymbol{U}^T \\boldsymbol{Vq}=(\\boldsymbol{Ux})^T(\\boldsymbol{Vq}) ，与点积模型相比，计算相似度时引入了非对称性。 注意力机制的变体硬性注意力上面介绍的是软性注意力，其选择的信息是所有输入向量在注意力分布下的期望。此外，还有一种注意力是只关注某一个输入向量，叫作硬性注意力(Hard Attention)。 硬性注意力有两种方式： 一种是选取最高概率的一个输入向量，即： att(\\boldsymbol{X,q})=\\boldsymbol{x}_{\\hat{n}} \\tag{7}其中 \\hat{n} 是概率最大的输入向量的下标，即 \\hat{n}=\\arg\\max^\\limits{N}_{n=1} \\alpha_n . 另一种通过在注意力分布上随机采样的方式实现。 硬性注意力的缺点是基于最大采样或随机采样的方式选择信息，使得最终的损失函数与注意力分布之间的函数关系不可导，无法使用反向传播算法进行训练，因此，硬性注意力通常需要使用强化学习来进行训练，为了使用反向传播算法，一般使用软性注意力代替硬性注意力。 键值对注意力键值对(key-value pair)注意力用 (\\boldsymbol{K,V})=[(\\boldsymbol{k_1,v_1}),\\ldots,(\\boldsymbol{k_N,v_N})] 表示 N 组输入信息，给定任务相关的查询向量 \\boldsymbol{q} 时，注意力函数为： att((\\boldsymbol{K,V}),\\boldsymbol{q})=\\sum^N_{n=1}{\\alpha_n\\boldsymbol{v}_n},\\\\ =\\sum^N_{n=1}{\\frac{\\exp(s(\\boldsymbol{k}_n,\\boldsymbol{q}))}{\\sum _j \\exp(s(\\boldsymbol{k}_n,\\boldsymbol{q}))}} \\boldsymbol{v}_n \\tag{8}其中 s(\\boldsymbol{x},\\boldsymbol{q}) 为打分函数，当 \\boldsymbol{K=V} 时，键值对模式就等价于普通的注意力机制。 键值对注意力机制的示例如下图： 多头注意力多头注意力(Multi-Head Attention)是利用多个查询 \\boldsymbol{Q}=[\\boldsymbol{q}_1,\\ldots,\\boldsymbol{q}_M] ，来并行地从输入信息中选取多个多组信息，每个注意力关注输入信息的不同表示空间： att((\\boldsymbol{K,V}),\\boldsymbol{Q}) = att((\\boldsymbol{K,V}),\\boldsymbol{q}_1)) \\oplus \\ldots \\oplus att((\\boldsymbol{K,V}),\\boldsymbol{q}_M)) \\tag{9}其中 \\oplus 表示向量拼接。 多头注意力通常用在自注意力之后，详情参见自注意力和Transformer. 指针网络注意力机制主要是用来做信息筛选，从输入信息中选取相关的信息。注意力机制可以分为两步：一是计算注意力分布 \\alpha ，二是根据 \\alpha 来计算输入信息的加权平均。我们可以只利用注意力机制中的第一步，将 \\alpha 作为一个软性的指针(poiner)来指出相关信息的位置。 指针网络是一种序列到序列模型，输入是长度为 N 的向量序列 \\boldsymbol{X}=\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_N ，输出是长度为 M 的下标序列 \\boldsymbol{c}_{1:M}=c_1,c_2,\\ldots,c_M ，其中 c_m \\in [1,N],\\forall m . 和一般的Seq2Seq任务不同，这里的输出序列是输入序列的下标（索引），比如输入一组乱序的数字，输出为按大小排序的输入数字序列的下标，比如输入为20,5,10，输出是1,3,2。 条件概率 p(c_{1:M}|\\boldsymbol{x}_{1:N}) 可以写为： p(c_{1:M}|\\boldsymbol{x}_{1:N}) = \\prod^M_{m=1} p(c_m|c_{1:(m-1)},\\boldsymbol{x}_{1:N}) \\\\ \\thickapprox {\\prod^M_{m=1} p(c_m|\\boldsymbol{x}_{c_1},\\ldots,\\boldsymbol{x}_{c_{m-1}},\\boldsymbol{x}_{1:N})} \\tag{10}其中条件概率 p(c_m|\\boldsymbol{x}_{c_1},\\ldots,\\boldsymbol{x}_{c_{m-1}},\\boldsymbol{x}_{1:N}) 可以通过注意力分布来计算。 关于指针网络的详情可以参考Pointer Networks简介及其应用.","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://kangshitao.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Attention","slug":"Attention","permalink":"http://kangshitao.github.io/tags/Attention/"},{"name":"深度学习","slug":"深度学习","permalink":"http://kangshitao.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"论文阅读-Star Graph Neural Networks for Session-based Recommendation","slug":"paper-SGNN-HN","date":"2020-11-05T12:19:11.000Z","updated":"2022-05-22T13:30:54.800Z","comments":true,"path":"2020/11/05/paper-SGNN-HN/","link":"","permalink":"http://kangshitao.github.io/2020/11/05/paper-SGNN-HN/","excerpt":"2020,CIKM,使用星型GNN的基于会话的推荐系统","text":"2020年10月份CIKM会议的一篇论文，主要内容是提出了带有Highway Network的Star-GNN模型，简称为SGNN-HN模型，原文链接 摘要现有基于GNN的模型，有两个缺陷： 一般的GNN模型只考虑了相邻item的转换信息，忽略了来自不相邻item的高阶转换信息。 一般的GNN模型，如果想要捕获高阶转换信息，必须要增加层数，这样就面临严重的过拟合问题 为了解决上述两个问题，作者提出了Star Graph Neural Networks with Highway Networks (SGNN-HN)模型： 对于问题1，使用Star GNN(SGNN)学习当前session中不相邻item的复杂转换信息。 对于问题2，使用Highway Networks(HN)自适应地从item表示中选择嵌入信息，缓解过拟合问题。 一、介绍基于session的推荐系统是根据当前正在进行的session生成推荐，SBRS没有用户的历史交互信息，只有当前session中的item信息，并且是很有限的。使用RNN考虑session的序列信息(如GRU4Rec)，或者使用注意力机制考虑主要目的(如NARM)，都不能完全考虑到item的复杂转换信息。后来的GNN模型(如SRGNN、TAGNN等)，虽然利用GNN的优势，考虑了item间的复杂转换信息，但是面临上述两个问题，即高阶转换信息和过拟合问题。 因此，作者提出了SGNN-HN模型，首先在图中加入star节点，构建SGNN，建立当前session复杂item转换信息的模型，解决长距离信息传播问题。然后使用HN，在SGNN前后动态选择item表示，解决过拟合问题。最后使用注意力机制将item表示融合，得到session表示，用于推荐。 二、相关工作 一般推荐模型：CF、MF、NCF、Item-KNN等 序列推荐模型：MC、FPMC、GRU4Rec、NARM、KNN、CSRM 注意力模型：STAMP、Co-Attention模型 GNN模型：SRGNN、FGNN 三、本文模型本文模型结构图如下： 3.1 问题定义 V=\\{v_1,v_2,\\dots,v_{|V|}\\} 表示所有session中的item集合，其中 |V| 表示item的个数。 S=\\{v_1,v_2,\\dots,v_t,\\dots,v_n\\} 是给定的当前session，包含n个item。 模型的目标是预测 v_{n+1} ，具体来说，对于每个session，输出 \\widehat{y}=\\{\\widehat{y}_1,\\widehat{y}_2,\\dots,\\widehat{y}_{|V|}\\} ，表示所有item的预测分数，最后取分数最高的K个作为推荐item。 3.2 构建星型图对于每个session S=\\{v_1,v_2,\\dots,v_t,\\dots,v_n\\} ,构建为一个星型图，表示为 G_s=\\{\\mathcal{V}_s,{\\Large{\\varepsilon}}_s\\} 。 其中 \\mathcal{V_s}=\\{\\{x_1,x_2,\\dots,x_m\\},x_s\\} 表示图中的所有节点。前半部分 \\{x_1,x_2,\\ldots,x_m\\} 表示satellite节点， x_s 表示star节点。注意这里的 m\\leqslant n ，因为session中可能会有重复出现的item。 {\\Large\\varepsilon}_s 是图中的边集合，包括satellite连接(图2中实线)和star连接(图2中虚线)两种有向边： Satellite connections：satellite连接用来传递session中的相邻item间的信息。论文中使用GGNN为例，实现相邻节点之间的信息传播，并且按照satellite边构建输入和输出矩阵，例如对于session S=\\{x_2,x_3,x_5,x_4,x_5,x_7\\} ，构建的输入输出矩阵如图3： Star connections：受Star-Transformer模型启发，在图中添加Star节点，构建星型图。star节点和satellite节点之间的边就是Star连接，如图2，Star连接是双向边，分别代表两种信息传递方向，更新两种节点。一方面，以star节点作为中间节点，非相邻的item之间能够以two-hop的方式进行信息传播，来更新satellite节点。另一方面，另一个方向的边能够用来考虑所有satellite节点的信息，生成准确的star节点表示。 本文模型使用门控网络控制分别从邻居节点和star节点获取信息量的多少。 3.3 学习item嵌入学习satellite节点和star节点表示 3.3.1 初始化 satellite节点：使用item的embedding h^0=\\{x_1,x_2,\\ldots,x_m\\} \\tag{1} star节点：对satellite节点进行平均池化，得到star节点初始状态 x_s^0 = \\frac 1{m}\\sum\\limits^{m}_{i=1} {x_i} \\tag{2}3.3.2 更新节点1、Satellite节点更新 对于每个satellite节点，邻居节点信息包括相邻节点信息和star节点信息，分别对应来自直接相连节点和没有直接相连节点的信息。 首先，考虑相邻节点信息，使用GGNN网络更新节点。对于图的第 l 层每个satellite节点 x_i ，使用出度和入度矩阵获得传播的信息： \\begin{align} a_i^l = Concat(\\mathbf{A}_i^I([\\mathbf{x}_1^{l-1},\\mathbf{x}_2^{l-1},\\ldots,\\mathbf{x}_m^{l-1}]^{\\mathbf{T}}\\mathbf{W}^I+\\mathbf{b}^I),\\\\ \\mathbf{A}_i^O([\\mathbf{x}_1^{l-1},\\mathbf{x}_2^{l-1},\\ldots,\\mathbf{x}_m^{l-1}]^{\\mathbf{T}}\\mathbf{W}^O+\\mathbf{b}^O)) \\tag{3} \\end{align}其中， \\mathbf{A}_i^I,\\mathbf{A}_i^O \\in \\mathbb{R}^{1\\times m} ，分别为入度和出度矩阵的第 i 行， \\mathbf{W}^I,\\mathbf{W}^O \\in \\mathbb{R}^{d \\times d} 是参数矩阵， \\mathbf{b}^I,\\mathbf{b}^O \\in \\mathbb{R}^d 是偏置向量。最终得到的 a_i^l \\in \\mathbb{R}^{1\\times 2d} 表示节点 x_i 的传播信息，然后继续使用GGNN网络计算： \\begin{align} \\mathbf{z}_i^l=\\sigma(\\mathbf{W}_z\\mathbf{a}_i^l+\\mathbf{U}_z\\mathbf{h}_i^{l-1}),\\\\ \\mathbf{r}_i^l=\\sigma(\\mathbf{W}_r\\mathbf{a}_i^l+\\mathbf{U}_r\\mathbf{h}_i^{l-1}),\\\\ \\mathbf{\\tilde{h}}_i^l=\\tanh(\\mathbf{W}_h\\mathbf{a}_i^l+\\mathbf{U}_h(\\mathbf{r}_i^l\\odot \\mathbf{h}_i^{l-1}),\\\\ \\mathbf{\\hat{h}}_i^l=(1-\\mathbf{z}_i^l)\\odot \\mathbf{h}_i^{l-1} + \\mathbf{z}_i^l \\odot \\mathbf{\\tilde{h}}_l \\tag{4} \\end{align}其中， \\mathbf{W}_z,\\mathbf{W}_r,\\mathbf{W}_h \\in \\mathbb{R}^{d\\times 2d} ， \\mathbf{U}_z,\\mathbf{U}_r,\\mathbf{U}_h \\in \\mathbb{R}^{d\\times d} 是参数矩阵， \\sigma 表示sigmoid激活函数， \\odot 表示向量的对应元素点乘。使用这种方式，相邻节点的信息能够在星型图中传播。 然后，考虑来自star节点的信息，对于每个satellite节点 x_i ，使用门控机制考虑应该从相邻节点和star节点分别获取多少信息。具体来说，使用自注意力计算 x_i 和star节点 x_s 的相似度 \\alpha_i^l : \\alpha_i^l=\\frac{(\\mathbf{W}_{q1} \\mathbf{\\hat{h}}_i^l)^\\mathbf{T} \\mathbf{W}_{k1} \\mathbf{x}_s^{l-1}} {\\sqrt{d}} \\tag{5}其中， \\mathbf{W}_{q1},\\mathbf{W}_{k1} \\in \\mathbb{R}^{d\\times d} 是参数矩阵， \\mathbf{\\hat{h}}_i^l 是 x_i 的表示向量。然后计算 x_i 最终的节点表示： \\mathbf{h}_i^l = (1-\\alpha_i^l) \\mathbf{\\hat{h}}_i^l + \\alpha_i^l \\mathbf{x}_s^{l-1} \\tag{6} 注意，这里的star节点是上一层的，因为这一层的star节点还没有更新，star节点需要在satellite节点更新完之后再更新。 2、Star节点更新 star节点是根据最新的satellite节点表示来更新的，同样使用self-attention，将star节点作为Query向量： \\beta = softmax(\\frac{\\mathbf{K}^ \\mathbf{T} \\mathbf{q}}{\\sqrt{d}}) = softmax(\\frac{(\\mathbf{W}_{k2} \\mathbf{h}^l)^ \\mathbf{T} \\mathbf{W}_{q2} \\mathbf{x}_s^{l-1}}{\\sqrt{d}}) \\tag{7}\\\\ \\mathbf{W}_{k2},\\mathbf{W}_{q2} \\in \\mathbb{R}^{d\\times d} 是对应的参数矩阵。最后计算得到star节点的向量表示 \\mathbf{x}_s^l = \\beta \\mathbf{h}^l \\tag{8}其中 \\beta \\in \\mathbb{R}^m ， \\mathbf{h}^l \\in \\mathbb{R}^{d\\times m} 3.3.3 Highway Networks上述节点更新的过程可以多次迭代，即堆叠多层SGNN，第 l 层SGNN可以表示为： \\mathbf{h}^l,\\mathbf{x}_x^l = SGNN(\\mathbf{h}^{l-1},\\mathbf{x}_s^{l-1},\\mathbf{A}^I,\\mathbf{A}^O) \\tag{9}多层图结构可以传播大量节点间的信息，同样也会带来偏差，导致过拟合，为了处理这个问题，使用highway networks从多层SGNN之前和之后选择性地获取信息。 用 \\mathbf{h}^0,\\mathbf{h}^L 分别表示多层SGNN之前和多层SGNN之后的satellite节点表示，HN网络用以下公式表示： \\mathbf{h}^f = \\mathbf{g} \\odot \\mathbf{h}^0 +(1-\\mathbf{g})\\odot \\mathbf{h}^L \\tag{10}其中 \\mathbf{g} \\in \\mathbb{R}^{d\\times m} ，是由SGNN的输入输出决定的： \\mathbf{g} = \\sigma(\\mathbf{W}_g[\\mathbf{h}^0;\\mathbf{h}^L]) \\tag{11} \\mathbf{W}_g \\in \\mathbb{R}^{d\\times2d} 。 HN网络处理之后，得到satellite节点和star节点的最终表示 \\mathbf{h}^f 和 \\mathbf{x}_s^L (简写为 \\mathbf{x}_s )​。将以上步骤用算法流程表示： ## 3.4 Session表示和预测 将 \\mathbf{h}^f \\in \\mathbb{R}^{d\\times m} 用 \\mathbf{u}\\in \\mathbb{R}^{d\\times n} 表示，然后加入可学习的位置编码 \\mathbf{p}\\in \\mathbb{R}^{d\\times n} ，则satellite节点表示变为 \\mathbf{u}^p = \\mathbf{u}+\\mathbf{p} 。 考虑使用用户的全局偏好和最近兴趣来生成session表示，使用最后一个点击item作为最近兴趣，即 \\mathbf{z}_r=\\mathbf{u}_n^p ，然后计算全局偏好： $$ \\mathbf{z}_g = \\sum _{i=1}^n \\gamma_i \\mathbf{u}_i^p \\tag{12} $$ $$ \\gamma_i = \\mathbf{W}_0^ \\mathbf{T} \\sigma(\\mathbf{W}_1 \\mathbf{u}_i^p+ \\mathbf{W}_2 \\mathbf{x}_s + \\mathbf{W}_3 \\mathbf{z}_r + \\mathbf{b}) \\tag{13} $$ \\mathbf{W}_0,\\mathbf{b} \\in \\mathbb{R}^d ， \\mathbf{W}_1,\\mathbf{W}_2,\\mathbf{W}_3 \\in \\mathbb{R}^{d\\times d} 。 然后计算最终的session表示： $$ \\mathbf{z}_h = \\mathbf{W}_4[\\mathbf{z}_g;\\mathbf{z}_r] \\tag{14} $$ 考虑到长尾效应，参考[NISER](https://arxiv.org/abs/1909.04276)，对session表示 \\mathbf{z}_h 和候选item \\mathbf{v}_i 的嵌入向量进行层标准化处理，即: $$ \\tilde{\\mathbf{z}}_h = LayerNorm(\\mathbf{z}_h) = \\frac{\\mathbf{z}_h}{\\Vert \\mathbf{z}_h \\Vert _2} \\\\ \\tilde{\\mathbf{v}}_i = LayerNorm(\\mathbf{v}_i)= \\frac{\\mathbf{v}_i}{\\Vert \\mathbf{v}_i \\Vert _2} $$ 然后计算推荐分数： $$ \\tilde{\\mathbf{y}_i} = \\tilde{\\mathbf{z}}_h^{\\mathbf{T}}\\tilde{\\mathbf{v}_i} \\tag{15} $$ 最后使用softmax函数进行归一化，根据[论文](https://dl.acm.org/doi/10.1145/3123266.3123359)，由于余弦相似度的值在 [-1,1] 之间，可能导致softmax损失很大，以致模型无法收敛，因此使用缩放因子用来帮助模型更好地收敛： $$ \\hat{\\mathbf{y}} = \\frac{\\exp(\\tau \\tilde{\\mathbf{y}_i})} {\\sum \\nolimits_i \\tau \\hat{\\mathbf{y}_i}}, \\forall i=1,2,\\ldots,|V| \\tag{16} $$ 其中 \\hat{\\mathbf{y}}=(\\hat{\\mathbf{y}}_1,\\hat{\\mathbf{y}}_2,\\ldots,\\hat{\\mathbf{y}}_{|V|}) 。损失函数使用交叉熵： $$ L(\\hat{\\mathbf{y}})=-\\sum\\limits_{i=1}^{|V|} \\mathbf{y}_i \\log(\\hat{\\mathbf{y}}_i)+ (1-\\mathbf{y}_i)\\log(1-\\hat{\\mathbf{y}}_i) \\tag{17} $$ \\mathbf{y}_i \\in \\mathbf{y} ， \\mathbf{y} 是one-hot向量， \\mathbf{y}_i=1 表示第 i 个item是给定session的目标item。 # 四、实验 实验数据和处理方式同SRGNN、NARM等模型，并且同样使用了数据增强的方法，具体细节见原文。 实验数据： 评估指标使用Precision和MRR。 五、实验结果5.1 与SOTA模型对比 5.2 SGNN网络的作用分别用自注意力网络(SAT)和门控图神经网络(GGNN)代替SGNN： 5.3 HN网络层的作用HN网络对于不同数量GNN层的作用： 5.4 Session长度的影响 六、结论本文提出了SGNN-HN模型，一方面解决了一般GNN模型不能考虑高阶信息转换的问题，另一方面解决了GNN模型容易过拟合的问题。","categories":[{"name":"论文笔记","slug":"论文笔记","permalink":"http://kangshitao.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Attention","slug":"Attention","permalink":"http://kangshitao.github.io/tags/Attention/"},{"name":"深度学习","slug":"深度学习","permalink":"http://kangshitao.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"SBRS","slug":"SBRS","permalink":"http://kangshitao.github.io/tags/SBRS/"},{"name":"paper","slug":"paper","permalink":"http://kangshitao.github.io/tags/paper/"},{"name":"GNN","slug":"GNN","permalink":"http://kangshitao.github.io/tags/GNN/"}]},{"title":"Python正则表达式","slug":"RegularExpression","date":"2020-11-01T03:43:54.000Z","updated":"2022-05-22T13:30:54.779Z","comments":true,"path":"2020/11/01/RegularExpression/","link":"","permalink":"http://kangshitao.github.io/2020/11/01/RegularExpression/","excerpt":"正则表达式的基础语法以及Python中re库的使用方法介绍","text":"Re简介正则表达式(Regular Expression，RE，以下简称Re)通常用来检索、替换那些符合某个模式(规则)的文本，也就是说，RE是用来记录文本规则的代码。 总的来说，正则表达式是： 通用的字符串表达框架 简洁表达一组字符串的表达式 针对字符串表达“简洁”和“特征”思想的工具 判断字符串的特征归属 Re的使用编程语言使用正则表达式时需要编译，将符合正则表达式语法的字符串转换成正则表达式特征，也就是说，编译是将一个符合正则表达式语法的字符串编译为正则表达式。 我们用字符串的形式表示正则表达式，如字符串[a-z]是表示匹配a到z中的任意一个字母的Re的表示方法 Re的语法Re的语法是核心部分，RE语法是由字符和操作符组成。 常用操作符： 操作符 描述 具体用例 . 表示除换行符\\n以外的任何单个字符，如果要匹配’.’，则使用\\.，其余字符同理 无 [] 字符集，对单个字符给出取值范围 例：[abc]表示a或b或c，[a-z]表示从a到z的任意单个字符 [^] 非字符集，对单个字符给出排除范围 例：[^abc]表示非a或b或c的单个字符 * 前一个字符0次或无限次扩展 例：abc*表示ab、abc、abcc、abccc等 + 前一个字符1次或无限次扩展 例：abc+表示abc、abcc、abccc等 ? 前一个字符0次或1次扩展 例：abc?表示ab、abc | 左右表达式任意一个 例：abc|def表示abc或def \\ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。 例： n 匹配字符 n。\\n 匹配换行符,而 \\\\ 匹配 \\， \\(匹配 “(“。 {m} 扩展前一个字符m次 例：ab{2}c表示abbc {m,n} 扩展前一个字符m到n(包括n)次 例：ab{1,2}c表示abc、abbc ^ 匹配字符串开头 例：^abc表示abc且在一个字符串的开头 $ 匹配字符串结尾 例：abc$表示abc且在一个字符串的结尾 () 分组标记，内部只能用|操作符 例：(abc)表示abc，(abc|def)表示abc或def \\d 表示数字，等价于[0-9] 无 \\w 表示单词字符，等价于[A-Za-z0-9_](包括下划线) 无 Re语法实例 正则表达式 匹配的字符串 P(Y|YT|YTH)?N ‘PN’、’PYN’、’PYTN’、’PYTHN’ PYTHON+ ‘PYTHON’、’PYTHONN’、’PYTHONNN’… PY[TH]ON ‘PYTON’,’PYHON’ PY[^TH]?ON ‘PYON’、’PYaON’、’PYbON’…（不含T和H即可） PY{0,3}N ‘PN’、’PYN’、’PYYN’、’PYYYN’ ^[A-Za-z]+$ 由26个字母组成的字符串 ^[A-Za-z0-9]+$ 由26个字母和数字组成的字符串 ^-?\\d+$ 整数形式的字符串 ^[0-9]*[1-9][0-9]*$ 正整数形式的字符串 [1-9]\\d{5} 中国境内邮政编码，6位 [\\u4e00-\\u9fa5] 匹配中文字符(UTF-8编码) \\d{3}-\\d{8}|\\d{4}-\\d{7} 国内电话号码，如000-12345678 如果想要匹配ip地址，需要考虑如何表示取值范围在0-255，将其分为四部分，即0-99,100-199,200-249,250-255： (([1-9]?\\d|1\\d{2}|2[0-4]\\d|25[0-5]).){3}([1-9]?\\d|1\\d{2}|2[0-4]\\d|25[0-5]) 上述正则表达式，每两个|之间的正则表达式表示一个范围内的数，比如[1-9]?\\d表示0-99 Python的re库python中的re库使用raw string(原生字符串类型)表示正则表达式，如原生字符串text写作r'text' 例如，r'[1-9]\\d{5}'是用来匹配邮政编码的Re字符串形式 raw string 是指不包含转义符的字符串，即\\不被认为是转义符也可以使用string类型，但是更繁琐，不建议使用 主要功能函数 re.search() # 在一个字符串中搜索匹配Re的第一个位置，返回match对象 re.match() # 从一个字符串的开始位置起匹配Re，返回match对象 re.findall() # 搜索字符串，以列表类型返回全部能匹配的字符串 re.split() # 将一个字符串按照Re匹配结果进行分割，返回列表类型 re.finditer() # 搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象 re.sub() # 在一个字符串中替换所有匹配Re的子串，返回替换后的子串 函数的具体参数使用，详见官方文档，以re.search()函数举例： 123re.search(pattern, string, flags=0)# 其中pattern是Re的字符串，string是待匹配的字符串# flags是Re使用时的控制标记，用于控制Re的匹配方式，如是否区分大小写等 使用方法 函数式用法，一次性操作： 1rst = re.search(r'[1-9]\\d{5}', 'BIT 100081') 面向对象用法，编译后的多次操作 12pat = re.compile(r'[1-9]\\d{5}')rst = pat.search('BIT 100081') pat = re.compile(pattern, flags=0)是编译函数，将Re的字符串形式编译为Re对象 生成的结果pat才是正则表达式，参数pattern只是正则表达式的字符串表示方法 Match对象match对象是re函数的一种返回值对象，其有很多属性。 属性： 代码 含义 match.string 待匹配的文本 match.re 匹配时使用的正则表达式 match.pos 正则表达式搜索文本的开始位置 match.endpos 正则表达式搜索文本的结束位置 方法： 代码 含义 match.group(0) 返回匹配后的字符串 match.start() 返回匹配字符串在原始字符串的开始位置 match.end() 返回匹配字符串在原始字符串的结束位置 match.span() 返回(start(),end())，即开始和结束位置 贪婪匹配和最小匹配re库默认采用贪婪匹配，即输出匹配最长的子串 若想得到最小匹配，则需要对以下操作符扩展，即在引起贪婪匹配的操作符后加?: 扩展 含义 *? 前一个字符0次或无限次扩展，最小匹配 +? 前一个字符1次或无限次扩展，最小匹配 ?? 前一个字符0次或1次扩展，最小匹配 {m,n}? 扩展前一个字符m至n次(含n)，最小匹配","categories":[{"name":"教程","slug":"教程","permalink":"http://kangshitao.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"http://kangshitao.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"Python","slug":"Python","permalink":"http://kangshitao.github.io/tags/Python/"}]},{"title":"Git命令","slug":"git","date":"2020-10-31T04:00:43.000Z","updated":"2022-05-22T13:30:54.790Z","comments":true,"path":"2020/10/31/git/","link":"","permalink":"http://kangshitao.github.io/2020/10/31/git/","excerpt":"Git基础教程和常用指令","text":"Git是一个开源的分布式版本控制系统，用于在软件开发过程中跟踪源代码的变化。 本文参考： Git教程-廖雪峰的官方网站 Git官方文档 Git-cheatsheet 基础指令在相关文件目录下，右键打开Git，其中Git Bash Here为命令行窗口，Git GUI Here为GUI界面，这里主要是针对命令行窗口。 1234$ mkdir learngit # 创建learngit文件夹 $ torch xx.txt 表示创建xx.txt文件$ cd learngit # 进入文件夹$ git init # 将当前文件夹初始化为Git仓库 12345678$ git add &lt;file&gt; # 添加特定文件$ git add . # 添加所有改动的文件$ git commit -m '提交说明' # 提交当前改动，提交说明要写$ git push origin master # 推送到远程库的origin master分支，默认为origin master$ git status # 查看当前状态，比如有哪些未提交文件等$ git diff # 查看具体修改了什么内容，即查看工作区和暂存区的区别$ git diff --cached # 查看暂存区和最后一次commit的差异$ git diff HEAD # 查看工作区和最后一次commit的差异 工作区和暂存区 工作区(working directory)是本地电脑看到的一个目录，比如learngit文件夹，或者说是项目文件夹。 工作区中有.git隐藏文件夹，为Git的版本库，其中包括最重要的暂存区(stage/index)。Git会自动创建一个分支master，以及指向master的指针HEAD add操作是将文件添加到暂存区，commit操作将暂存区的所有内容提交到当前分支(本地仓库)，push操作将本地仓库文件推送到远程仓库。 版本回退123456$ git log # 查看提交记录。如果超过一页，空格向下翻页，b向上翻页，q退出$ git log --pretty=oneline # 简化查看提交记录信息，只显示commit id和提交说明$ git reset --hard HEAD^ # 回退到上个commit版本，两个^^则表示回退到上上个版本，~n表示n个版本$ git reset --hard &lt;commit id&gt; # 回到指定id的版本，id只需要前几位字符，能区分出不同commit即可$ git reflog # 查看历史commit id变化情况，方便找到想要回到的版本$ git log --graph --pretty=oneline --abbrew-commit # 用图形显示提交记录 git log命令只能显示当前分支的commit记录，如果版本回退，只能显示回退到的版本及之前的commit记录，这时如果想要查看回退前的较新的版本信息，可以使用git reflog。 git reflog可以查看所有分支的所有操作记录，包括分支切换和版本切换的记录，也包括已经被删除的 commit 记录和 reset 的操作 管理修改 Git管理的是修改，而不是文件 使用add命令添加文件后，如果再次修改，此时提交是不包括第二次修改的。也就是说，每次修改之后都要add之后才能将修改提交到仓库。 撤销修改想要撤销修改的话，要根据不同的情况采取不同的操作： 没有git add 时，使用git checkout--&lt;file&gt;命令，file修改后没有放到暂存区，使用此命令回到版本库状态；如果是添加到暂存区后再修改，使用此命令可以回退没修改时的状态。总之，checkout操作让文件回到最近一次commit或者add时的状态。 已经git add到暂存区，使用git reset HEAD &lt;file&gt;，将暂存区的修改撤销，重新放回工作区 已经commit到版本库，使用git reset --hard HEAD^回退版本，或者使用回退到指定commit id 已经push到远程仓库，没救了:( 删除文件使用rm &lt;file&gt;指令或者其他方法删除文件后，工作区和仓库文件不一致，这时： 如果确定是删除文件，则继续下一步操作即可，git commit -m 'xxx'指令，提交删除，会删除仓库文件 如果是误删，此时仓库还有文件，使用git checkout--&lt;file&gt;恢复即可 比较文件差异 git diff [文件名] 将工作区的文件和暂存区进行比较 git diff [本地库中历史版本][文件名] 将工作区中的文件和本地库历史记录比较 不带文件名则比较工作区中所有文件 添加远程库在github上创建完仓库(repository)之后，在本地配置好之后，使用push指令可以将本地仓库到远程仓库。前提要求是本地仓库是git仓库，即有init初始化处理、commit等操作。此外，还需要Git配置好SSH环境，参考教程。 本地修改首先提交到本地仓库(无需Internet)，然后push到远程： 12345678# 第一次推送时，需要先关联远程库。origin表示将远程库地址起别名为origin$ git remote add origin git@github.com:&lt;path&gt;# 第一次push，需要添加-u参数,使用u参数后可以使之后的push操作不需要带参数# 不带参数的push，即simple方式$ git push -u origin master # 推送到指定远程库的指定分支$ git push 或者git push origin master # 如果不是第一次push，则无需-u参数，也可以推送到指定分支 将远程库地址命名为origin，以后推送时使用origin表示远程库地址. 从远程库克隆SSH方式： 1$ git clone git@github.com:&lt;path&gt; # 后面的地址可以在github上直接复制 http方式： 1$ git clone https://github.com/&lt;path&gt; # 同样，地址可以从github直接复制 http方式的速度比较慢，ssh方式速度比较快 clone命令的作用效果： 完整地把远程库下载到本地 创建origin远程地址别名(即默认将远程地址命名为origin，推送时也可以使用origin) 初始化本地库 分支管理创建与分支合并123456$ git branch # 查看分支$ git branch &lt;name&gt; # 创建分支$ git checkout &lt;name&gt; 或 git switch &lt;name&gt; # 切换分支$ git checkout -b &lt;name&gt; 或 git switch -c &lt;name&gt; # 创建并切换分支$ git merge &lt;name&gt; # 合并指定分支到当前分支$ git branch -d &lt;name&gt; # 删除指定分支 Git合并、删除、创建分支的速度非常快，鼓励用分支完成任务再合并，这样过程更安全 分支冲突如果两个分支都修改了同一个文件的相同位置，在分支合并时会产生冲突。 比如，现有文件内容如下： 12111222 在bug_fix分支上对第二行修改，并添加到暂存区，提交到本地库： 12111222 edit by but_fix 在master分支上也对第二行修改，并添加到暂存区，提交到本地库： 12111222 edit by master 这时，在bug_fix分支上使用git merge master命令将master分支内容合并过来，会产生冲突，提示自动合并失败。并进入merging状态。 此时需要手动合并文件，进入文件： 123456111&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD222 edit by hot_fix=======222 edit by master&gt;&gt;&gt;&gt;&gt;&gt;&gt; master 其中&lt;&lt;&lt;&lt;&lt;&lt;&lt;HEAD和=======之间的内容是当前分支的内容，下方是要合并过来的分支的内容。 根据实际需求，合并文件内容，将git生成的标记内容删除，保存退出。 这时使用git status查看状态，提示有未合并的路径，如果已解决完冲突并想要合并，使用add和commit（注意此时的commit命令不能添加文件名）命令提交，即可完成合并。 分支管理策略分支合并时，Git优先用Fastforward模式，这种模式下，删除分支后，会丢掉分支信息。 如果强制禁用Fastforward模式，Git会在merge时生成新的commit，并且在分支历史记录可以看到分支信息： 12$ git merge --no-ff -m 'commit information' &lt;brach name&gt;# 因为no-ff合并要创建新的commit，所以使用-m参数加上提交说明 团队开发中，master分支仅用于发布新版本，日常开发在各自的分支上。 2020.10.1起，github默认主分支改名为main，不再是master bug分支当在dev分支工作时，需要临时修复master上一个bug，需要创建临时bug分支，修复、合并，删除分支。 如果dev分支的工作未完成，可以使用$ git stash命令保留现场。 1234$ git stash apply stash@{xxx} # 有多个stash是，恢复指定的stash，stash不删除$ git stash pop # 恢复stash同时删掉stash内容$ git stash list # 查看stash列表$ git cherry-pick &lt;commit id&gt; # 用于将某个提交复制到当前分支 Feature分支项目中开发新功能/特征，最好用新的分支，每个功能一个feature分支，在上面开发，完成后，合并，最后删除feature分支。 如果feature分支还未合并，就需要删除掉，需要使用-D参数强行删除： 1$ git branch -D &lt;branch-name&gt; # 强行删除一个指定的未merge的分支 多人协作 情景一，团队内部：如果是同一个企业，不同账户，即多个人同时编写一个项目的场景，需要其他人都是协作者，即有push到远程库的权限。举例，创建者建立远程库，其他人使用clone复制远程库，修改后提交到本地库，然后需要有协作者权限，才能push到远程库。 情景二，跨团队协作：如果希望别的团队可以协助开发项目，但不能直接push，则他们需要先fork项目到自己的远程库，然后clone到本地进行开发，开发完以后，push到自己的远程库，再使用pull request通知项目管理者，管理者审核代码，确认以后进行merge操作。 fork操作完以后，项目相当于属于自己，可以随意进行push。如果想要推送给原有的远程库，需要使用pull request操作。 拉取操作 git fetch [远程库地址别名][远程分支名] git merge [远程库地址别名/远程分支名] git pull：是git fetch和git merge两个操作和合并。 多人协作的工作模式： 用$ git push origin &lt;branch-name&gt;推送自己的修改 如果推送失败，则因为远程分支比自己的分支更新，需要使用$ git pull命令合并，此命令会自动合并，如果pull请求之后提示no stracking information，说明本地分支和远程分支的链接关系没有创建，使用以下命令： 12$ git branch --set-upstream-to=origin/dev &lt;本地branch&gt;# 设置本地分支和远程origin/dev分支的链接 如果合并有冲突，则需要解决冲突，然后提交，push 如果没有冲突或者解决掉冲突后，则使用$ git push origin &lt;branch name&gt;推送到远程指定分支 命令总结： 1234$ git remote # 查看远程信息$ git remote -v # 查看远程库的详细信息$ git switch -c &lt;branch-name&gt; origin/&lt;remote-branch-name&gt; # 从本地创建和远程对应的分支$ git branch --set-upstream-to=origin/dev &lt;本地branch&gt; # 将本地分支与远程origin/dev分支链接 Rebase1$ git rebase # 把分叉的提交历史“整理”成一条直线，看上去更直观，缺点是本地的分叉提交会被修改 标签管理标签(tag)也是版本库的一个快照，是指向某个commit的指针，tag比直接使用commit更方便。因此，可以使用tag作为版本号。 创建标签123456$ git tag v1.0 # 给当前最新的commit添加标签v1.0$ git tag &lt;tag-name&gt; &lt;commit-id&gt; # 给特定的commit添加标签$ git tag # 查看所有标签$ git show v1.0 # 显示标签v1.0的详细信息$ git tag -a &lt;tag-name&gt; -m '说明' &lt;commit-id&gt; # 为特定commit添加标签并添加说明信息 # 这里的-a 用来指定标签名，-m指定说明文字 标签不会随着push推送到远程仓库，使用以下命令将tag信息push到远程： 12$ git push origin &lt;tagname&gt; # 推送单个标签$ git push origin --tags # 推送所有标签 操作标签12$ git tag -d &lt;tag-name&gt; # 删除一个指定的本地标签$ git push origin :refs/tags/&lt;tag-name&gt; # 删除远程仓库的指定标签","categories":[{"name":"教程","slug":"教程","permalink":"http://kangshitao.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://kangshitao.github.io/tags/Git/"}]},{"title":"Conda基础命令","slug":"conda","date":"2020-10-28T13:53:39.000Z","updated":"2022-05-22T13:30:54.782Z","comments":true,"path":"2020/10/28/conda/","link":"","permalink":"http://kangshitao.github.io/2020/10/28/conda/","excerpt":"Conda常用命令介绍","text":"Conda是一个开源的软件包管理系统和环境管理系统，用于安装多个版本的软件包及其依赖关系，并在它们之间轻松切换。 Anaconda是一个开源的Python发行版本，包含了conda、python等180多个科学包及其依赖项。 Miniconda是最小的conda安装环境，只包含最基本的内容——python和conda，以及相关的必须依赖项。 参考文档：官方Conda命令参考 Conda 指令查看指令1conda -V 或 conda --version # 查看conda版本 1conda env list 或 conda info --envs # 查看存在哪些虚拟环境 更新Conda1conda update conda # 检查并更新当前conda 创建虚拟环境1conda create -n [env_name] python=x.x # 创建python版本号为x.x的虚拟环境 激活/切换虚拟环境12Windows： activate [env_name]Linux: source activate [env_name] 关闭/退出虚拟环境12conda deactivate # 退出当前虚拟环境activate [env_name] # 切换到其他环境，也相当于关闭当前环境 删除虚拟环境1conda remove -n [env_name] --all 设置镜像1234conda config --add channels [mirroe_url] # 添加镜像地址conda config --set show_channel_urls yes # 设置搜索时显示通道地址conda config --get channels # 查看已经配置的channelsconda config --remove-key channels # 恢复为默认地址(删除所有其他镜像url) Conda的package管理命令查看已安装的包12conda list # 查看当前环境已安装的所有包conda list -n [env_name] # 查看指定环境已安装的所有包 安装包123conda install [package_name] # 当前环境下安装包conda install -n [env_name] [package_name] # 指定环境先安装包# 还可以使用-c参数，指定通过某个channel安装 更新包12conda update [package_name] # 更新当前环境下的包conda update -n [env_name] [package_name] # 更新指定环境下的包 删除包12conda remove [package_name] # 删除当前环境下的包conda remove -n [env_name] [package_name # 删除指定环境下的包 查找包的信息1conda search [package_name] # 查找指定包的信息","categories":[{"name":"教程","slug":"教程","permalink":"http://kangshitao.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Conda","slug":"Conda","permalink":"http://kangshitao.github.io/tags/Conda/"}]},{"title":"建立Hexo个人博客","slug":"BlogCreatProcess","date":"2020-10-25T11:15:21.000Z","updated":"2022-05-22T13:30:54.779Z","comments":true,"path":"2020/10/25/BlogCreatProcess/","link":"","permalink":"http://kangshitao.github.io/2020/10/25/BlogCreatProcess/","excerpt":"记录本博客的创建和功能完善的过程","text":"使用hexo和github.pages搭建博客，主题为zhaoo 文章部分功能是主题没更新之前写的，作为记录，已有的内容不再修改，具体配置情况根据主题而定。更多内容可以参考zhaoo主题作者博客主页：zhaoo 准备工作github创建名为username.github.io的repository 安装git 安装Node.js 安装Hexo新建文件夹blog，存放博客的所有内容 1234567# 安装hexonpm install hexo-cli -g# 确认是否安装成功hexo -v# inithexo initnpm install 生成的几个文件： node_modules：依赖包 public：存放生成的页面 scaffolds：生成文章的一些模版 source：用来存放文章 themes：主题 _config.yml: 配置文件 1hexo server 然后在浏览器输入localhost:4000即可看到生成的博客。 更换主题hexo默认主题是landscape，可以自由更换主题： 12#下载主题到themes/zhaoo路径git clone git@github.com:izhaoo/hexo-theme-zhaoo.git themes/zhaoo 根据需求创建tags、about、categories页面： 123hexo new page tagshexo new page abouthexo new page categories 以上代码会在source的对应文件夹下生成index.md文件，可根据需求配置页面: 12# 以tags的index为例，将layout设置为tags布局，不同与一般的布局。layout: tags layout(布局)有三种：post(文章)、draft(草稿)、page(页面)，默认是post 然后根据主题配置说明，配置主题的配置文件themes/zhaoo/_config.yml 关联git库12# 安装要用的插件npm install hexo-deployer-git --save 修改blog/_config.yml配置文件： 1234deploy： type: git repo: git@github.com:username/username.github.io.git branch: master 上述代码表示部署到指定的库中，并且默认部署到分支master。 部署的机制是将本地生成的.deploy_git文件夹里的文件，上传到远程库，并不包括配置文件和主题文件。 为了方便多终端工作，建议每次写完文章，除了deploy操作以外，将源代码也push到远程仓库保存。新建一个分支，将源文件push到这个分支里面，这样在另一台机器上只需要clone远程库，安装必要的文件就可以了。 新建文章12345678910# 创建新的文件，默认保存在source/_post路径下hexo new 'new blog'# run serverhexo server# 清除缓存hexo clean# 生成静态网页hexo generate/hexo g# 将网页部署到远程站点hexo deploy/hexo d 在scaffolds文件夹中，有三种默认布局新建时的模版，可以自定义新建文件时的格式。 tags和categories属性的值可以用列表，表示多个标签/类别。 数学公式渲染 主题更新添加了公式渲染配置的说明，方法简单快捷，可以参考。本节内容作为踩坑记录。 hexo默认的Markdown渲染器是hexo-renderer-marked，会先按照Markdown语法解析，然后才是LaTex，所以会有冲突。试了网上各种解决方法，终于遇到一个有效的方法：hexo无法显示公式的问题-DGZ’s Blog 重装插件首先，只保留一个公式渲染器，这里保留kramed渲染器。 123# 卸载默认的渲染器，其他的公式渲染器也卸载，只保留kramednpm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 修改js文件打开bolg/node_modules/hexo-renderer-kramed/lib/renderer.js，将： 12345//change inline math rulefunction formatText(text) { // Fit kramed's rule: $ + 1 + $ return text.replace(/` (.*?) `/g, ' $ $1 $ ');} 修改为： 1234// Change inline math rulefunction formatText(text) { return text;} 安装mathjax插件123# 如果有hexo-math，则卸载掉npm uninstall hexo-math --savenpm install hexo-renderer-mathjax --save 修改html文件打开blog/node_modules/hexo-renderer-mathjax/mathjax.html，将： 1&lt;script src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"&gt;&lt;/script&gt; 修改为： 1&lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML\"&gt;&lt;/script&gt; 激活插件在使用公式的md文件添加属性： 1mathjax: true 部署如果是第一次修改，修改完以后需要重新启动服务： 123hexo cleanhexo ghexo s 图床众所周知，github是万能的，使用PigGo和Github搭建个人图床，参考PigGo官方文档 新建github项目新建github项目用来存放图片，并生成token： 12github头像-&gt;Settings-&gt;Developer settings-&gt;Generate new token将repo选项打勾 配置PicGo1 然后点击确定，并设置为默认图床。 自定义域名可以按照图中的设置，也可以使用别的自定义域名。第二种域名方式就是使用CDN加速的方法，CDN(Content Delivery Network)是指内容分发网络，也称为内容传送网络。 jsDelivr是一种免费的CDN加速产品，可以加速Github和NPM的资源，其中使用jsDelivr的方法访问Github资源只需要将链接改为以下格式： 12https://cdn.jsdelivr.net/gh/username/repository@version/file # 其中的version指的是仓库版本，如果没有release版本，也可以使用分支名称 jsDelivr的更多用法可以参考官方文档 使用jsDelivr加速的自定义域名填写内容如下： 2 上传图片将图片拖入上传区，上传成功后会自动在剪切板生成图片链接。 其他设置其他参数设置可根据个人喜好进行设置： 3 图片上传失败问题由于某些原因，github当作图库不是很稳定，时好时坏也是正常现象。 参考PicGo踩坑记 首先检查设置的仓库名是否正确，仓库名不可包含空格，且不要出现奇怪的符号 上传的图片名字不要有奇怪符号 间歇性上传失败的话，可以将server的开关状态切换一下 另外，有条件的可以使用全局代理✈ 其他主题的其他设置可以参考zhaoo主题文档，这里只记录一部分 访问量统计主题默认使用的是leancloud，这里的统计是每篇文章的访问量，zhaoo主题支持leancloud，只需要按要求填写即可： 1234进入leancloud，创建应用(开发版)创建Class，ACL权限选择无限制打开设置-应用keys将AppID、AppKey、Rest API服务器地址复制到themes/_config.yml 如果想要设置本地访问不统计次数，则可以在\\themes\\zhaoo\\layout\\_partial\\common\\visitors.ejs中，修改以下内容： 123456789$(function () { const Counter = AV.Object.extend(\"Counter\"); showCount(Counter); const localhost = /http\\:\\/\\/localhost|http\\:\\/\\/127.0.0.1|http\\:\\/\\/0.0.0.0/; if (localhost.test(document.URL)) { return; } addCount(Counter); } 如果想对网站访问量统计，可以使用卜蒜子，在themes\\zhaoo\\layout\\_partial\\footer.ejs中合适的位置加入以下代码，其中的字体显示内容和风格可以自由设置： 1234567&lt;script async src=\"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"&lt;/script&gt;&lt;span id=\"busuanzi_container_site_pv\"&gt; 总浏览量：&lt;span id=\"busuanzi_value_site_pv\" style=\"font-size:12px;\"&gt;&lt;/span&gt; 次&lt;/span&gt;&lt;span id=\"busuanzi_container_site_uv\" &gt; 总访客数：&lt;span id=\"busuanzi_value_site_uv\" style=\"font-size:12px;\"&gt;&lt;/span&gt;人&lt;/span&gt; 评论功能开启Valine使用Valine，前提是主题支持： 1234leancloud,创建应用(开发版),可以和访问量统计使用一个应用创建Class，配置默认打开设置-应用keys将AppID、AppKey复制到themes/_config.yml 设置邮箱提醒如果想要在别人评论后，能够收到提醒，就需要设置邮箱提醒了。这里使用Valine-Admin插件，参考官方教程设置： 进入Leancloud对应的valine应用中， 点击云引擎—设置，添加环境变量，添加自定义环境变量，保存。 如果使用QQ邮箱，密码需要使用QQ邮箱的授权码。 设置好环境变量以后，选择Web—部署—Git部署，填写代码库https://github.com/zhaojun1998/Valine-Admin，分支使用master，部署。 此外，由于LeanCloud免费版有休眠策略，需要使用自定义计时器让容器一直保持运行状态。 具体使用方法： 创建两个定时任务，第一个定时器选self_wake函数,Cron表达式填0 */20 7-23 * * ?，表示每天的7-23点每20分钟访问一次。 第二个定时器选resend_mails函数，Cron表达式填0 0 8 * * ?，表示每天早8点检查过去24小时内漏发的通知邮件并补发。 更新设置以后，重新部署一下即可，至此，可以收到邮件的评论提醒，此外还可以设置邮件的回执格式等。 设置微信提醒如果想使用微信提醒，前提是配置好邮箱提醒。 使用Server酱设置微信提醒，首先需要根据Server酱的使用教程获取到SCKEY，在LeanCloud中添加自定义环境变量，name是SCKEY，value是SCKEY的值，保存，重新部署。这样配置完后，在Server酱官网进行测试，应该能够收到微信提醒。 设置别人评论收到微信提醒，需要在主题的JS文件中添加代码（参考链接），往 https://sctapi.ftqq.com/SENDKEY.send 发 HTTP 请求，就可以收到消息啦。具体设置，根据不同主题而定，对于zhaoo主题，在zhaoo\\layout\\_partial\\comments下的valine.ejs文件中，添加以下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 添加代码以后的文件&lt;% if (theme.valine.appId &amp;&amp; theme.valine.appKey) { %&gt;&lt;div id=\"valine\"&gt;&lt;/div&gt;&lt;script defer src=\"//unpkg.com/valine/dist/Valine.min.js\"&gt;&lt;/script&gt;&lt;script&gt; window.onload = function () { var loadValine = function () { new Valine({ el: '#valine', app_id: \"&lt;%= theme.valine.appId %&gt;\", app_key: \"&lt;%= theme.valine.appKey %&gt;\", placeholder: \"&lt;%= theme.valine.placeholder %&gt;\", avatar: \"&lt;%= theme.valine.avatar %&gt;\", pageSize: \"&lt;%= theme.valine.pageSize %&gt;\", lang: \"&lt;%= theme.valine.lang %&gt;\", }); } if ( &lt;%- theme.comments.button %&gt; ) { $(\"#comments-btn\").on(\"click\", function () { $(this).hide(); loadValine(); //从这里开始添加代码 var title1=\"text=Live and Learn有新评论啦~ --by Valine\" //自定义标题 var SCKEY_Server=\"\" //填写SCKEY的值 var ValineButton=document.getElementsByClassName(\"vsubmit vbtn\")[0]; function send_valine_Server(){ var text=\"desp=\"; var pageurl=document.URL; var ptime=new Date(); var vnick=document.getElementsByClassName(\"vnick vinput\")[0].value; var veditor=document.getElementsByClassName(\"veditor vinput\")[0].value; var data=text+\"|昵称\"+\"|评论内容\"+\"|跳转链接\"+\"|评论时间\"+\"\\n\"+\"|----|----|----|----|\"+\"\\n\"+\"|\"+vnick+\"|\"+veditor+\"|\"+pageurl+\"|\" +ptime.toLocaleString()+\"|\"; var httpRequest = new XMLHttpRequest();//第一步：创建需要的对象 httpRequest.open('POST', 'https://sctapi.ftqq.com/'+SCKEY_Server+'.send', true); //第二步：打开连接 httpRequest.setRequestHeader(\"Content-type\",\"application/x-www-form-urlencoded\");//设置请求头 注：post方式必须设置请求头（在建立连接后设置请求头） httpRequest.send(title1+\"&amp;\"+data);//发送请求 将请头体体写在send中 }; ValineButton.onclick=send_valine_Server; // 添加代码结束 }); } else { loadValine(); } }; &lt;/script&gt;&lt;% } %&gt; 至此，收到评论以后就能够收到微信提醒。 侧边目录zhaoo没有支持侧边目录，需要自己添加代码，使用hexo官方的toc函数。(2020.11.16主题更新，已经支持) 在themes\\zhaoo\\layout\\_partial\\post\\article.ejs中，最前面加以下代码： 12345678910&lt;aside class=\"post-widget\"&gt; &lt;nav id=\"toc\" class=\"toc-article fixed\"&gt; &lt;strong class=\"toc-title\"&gt;文章目录&lt;/strong&gt; &lt;%- toc(page.content, { class: 'post-toc', list_number: false, max_depth: '6', min_depth: '1'}) %&gt; &lt;/nav&gt;&lt;/aside&gt; 然后在themes\\zhaoo\\source\\css\\_partial\\post.styl中，最前面添加以下代码： 1234567891011121314.post-widget float right width 15% padding-left 10px min-hidden 1px.toc-article.fixed top 76px bottom 140px overflow-y auto.toc-article position fixed overflow-x hidden.toc-title padding-left 20px SEO优化 搜索引擎优化（Search Engine Optimization,SEO），是一种通过了解搜索引擎的运作规则来调整网站，以及提高目的网站在有关搜索引擎内排名的方式。 Github.pages屏蔽了百度的爬虫请求，配置较麻烦，这里仅以Google为例，使用Google Search Console，以下过程参考：hexo博客搭建(五) SEO优化 12345671、首先去google search console验证，有多种方式可选。2、添加站点地图 sitemapnpm install hexo-generator-sitemap --save # 安装站点地图自动生成的插件在_config.yml文件中添加以下代码：sitemap: path: sitemap.xml3、部署之后可以去google search console测试。 continue…… 参考教程 hexo官方文档 hexo史上最全搭建教程","categories":[{"name":"博客","slug":"博客","permalink":"http://kangshitao.github.io/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://kangshitao.github.io/tags/hexo/"},{"name":"blog","slug":"blog","permalink":"http://kangshitao.github.io/tags/blog/"}]},{"title":"Markdown简单教程","slug":"markdown","date":"2020-10-25T08:19:14.000Z","updated":"2022-05-22T13:30:54.797Z","comments":true,"path":"2020/10/25/markdown/","link":"","permalink":"http://kangshitao.github.io/2020/10/25/markdown/","excerpt":"Markdown基本语法介绍","text":"本文作为 Markdown基础语法教程，同时作为个人笔记 &amp;练习。使用 Typora工具，语法可能略有不同，以实际平台为准 标题Markdown标题有两种格式 使用 = 和 - 标记一级和二级标签语法如下： 12345一级标题=====二级标题----- 效果如下： 使用#号标记语法如下： 123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 注意：#号后面要加一个空格 段落换行：使用shift+enter键换行。 换段：Markdown的段落要求前后保留一个空行，Typora编辑器直接回车即可，或者先换行再加一个空行，表示更换段落。 两个或以上的空格+shift+enter，实现段内强制换行（行尾有↓箭头）。 字体格式字体格式： 123456*斜体文本*_斜体文本_**粗体文本**__粗体文本__***粗斜体文本***___粗斜体文本___ 显示效果如下：斜体文本斜体文本粗体文本粗体文本粗斜体文本粗斜体文本 列表Markdown支持无序列表和有序列表。 无序列表：无序列表有三种写法，+ 或-或*后加空格即可： 123+ 第一项* 第一项- 第一项 显示效果： 有序列表有序列表使用数字和.再加上空格即可： 1231. 第一项2. 第二项3. 第三项 显示效果： 列表嵌套列表嵌套需要在子列表选项前加四个空格： 1234561. 第一项： - 第一项的第一个元素 - 第一项的第二个元素2. 第二项： - 第二项的第一个元素 - 第二项的第二个元素 显示效果： Typora中，子列表选项前不加空格也可以。 插入区块和分隔线区块Markdown的区块引用是在段落开头使用&gt; 号和空格： 1&gt; 区块引用 显示效果： 另外，区块引用也可以像列表一样嵌套，一个&gt; 表示第一层，两个&gt; 表示第二层，以此类推： 123&gt; 第一层&gt;&gt; 第二层&gt;&gt;&gt; 第三层 区块中也可以使用列表，同样，列表中也可以使用区块。 分隔线在一个空行中，使用三个或以上的*、+、-、_来创建分隔线： 1234***++++-----______ 插入代码句中代码如果是句中的代码片段或函数，只需要一对反引号` 即可 (位于Tab键上面): 1`printf()`函数 显示效果： pringf()函数 代码块代码块需要两个以上反引号，可以指定语言，以下为python语言的代码块： 1234​```def main(): print('hello world')​``` 显示效果： 12def main(): print('hello world') 还可以使用缩进式方法，使用四个空格或者一个制表符(Tab键)，一段代码会持续到没有缩进的那一行 插入链接和图片插入链接插入链接有两种方法： 1[链接名称](链接地址) 或者： 1&lt;链接地址&gt; 例如：方法一：github方法二：https://github.com/ 插入图片插入图片的方法与插入链接的方法区别在于，插入图片的语法前加!号： 1![属性名称](图片地址) 还可以使用标签，用来指定图片大小： 1&lt;img src=\"图片地址\" width=\"80%\" Markdown需要以链接的形式插入图片，如果md文件发布到网站，则链接可能会失效，所以建议使用图床保存图片，这样无论md文件在哪里，只要链接不失效，就可以看到图片。 高级链接可以通过变量来设置一个链接，在文档末尾为变量赋值： 1234网址链接[链接名称][1]插入图片![][2][1]:https://github.com/[2]:https://www.google.com.hk/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png 插入表格Markdown制作表格使用| 来分隔不同的单元格，使用-分隔表头和其他行，代码如下： 1234| 表头 | 表头|| --- | ---||单元格|单元格||单元格|单元格| 效果如下： 表头 表头 单元格 单元格 单元格 单元格 对齐方式 ： -:设置内容和标题栏居右对齐 :-设置内容和标题栏居左对齐 :-:设置内容和标题栏居中对齐 代码如下： 1234|左对齐|右对齐|居中对齐||：---|---：|：----：||单元格|单元格|单元格||单元格|单元格|单元格| 效果如下： 左对齐 右对齐 居中对齐 单元格 单元格 单元格 单元格 单元格 单元格 HTML元素Markdown支持部分html标签，比如：&lt;kbd&gt;、&lt;b&gt;、&lt;i&gt;、&lt;em&gt;、&lt;sup&gt;、&lt;sub&gt;、&lt;br&gt;，以及&lt;fond&gt;等html标签： 12使用 &lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;c&lt;/kbd&gt; 复制&lt;font color=\"red\" size=5&gt;我是红色字体,大小为&lt;/font&gt; 效果如下： 使用 Ctrl+c 复制 我是红色字体,大小为5 其他页内跳转使用页内跳转可以用来进行引用等功能的快速跳转。 具体实现方法： 定义锚点(id)：在跳转到的目标处添加&lt;span&gt;标签或者&lt;div&gt;标签，比如&lt;span id=\"refer-1\"&gt;参考链接1&lt;/span&gt; 使用Markdown语法：在想要跳转的地点，使用[点击跳转](#refer-1)语句，如果想要“点击跳转”内容是上标的形式，可以将其放到&lt;sup&gt;标签中，即[&lt;sup&gt;点击跳转&lt;/sup&gt;](#refer-1) 转义使用\\符号转移特殊字符： 12**文本加粗**\\*\\*正常显示星号\\*\\* 效果如下： 文本加粗**正常显示星号** 插入公式使用两个美元符号$$$$将TeX或LaTeX格式的数字公式包裹，即可插入公式： 更多Markdown公式表示方法参考：Cmd Markdown公式指导手册 123$\\sqrt{ {x^2}+{y^2} }+v_1+v_2$ 效果如下： \\sqrt{ {x^2}+{y^2} }+v_1+v_2 插入流程图Typora插入横向流程图： 12345678​```mermaidgraph LRA[方形] --&gt;B(圆角) B --&gt; C{条件a} C --&gt;|a=1| D[结果1] C --&gt;|a=2| E[结果2] F[横向流程图]​``` 效果如下： 6 更多类型的流程图、顺序图等可以参考：typora画流程图、时序图(顺序图)、甘特图 参考链接 最完整的Markdown教程-简书 Markdown教程|菜鸟教程","categories":[{"name":"教程","slug":"教程","permalink":"http://kangshitao.github.io/categories/%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://kangshitao.github.io/tags/Markdown/"}]}],"categories":[{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"消息队列","slug":"消息队列","permalink":"http://kangshitao.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Nginx","slug":"Nginx","permalink":"http://kangshitao.github.io/categories/Nginx/"},{"name":"并发编程","slug":"并发编程","permalink":"http://kangshitao.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"SpringBoot2","slug":"SpringBoot2","permalink":"http://kangshitao.github.io/categories/SpringBoot2/"},{"name":"Tools","slug":"Tools","permalink":"http://kangshitao.github.io/categories/Tools/"},{"name":"SSM框架","slug":"SSM框架","permalink":"http://kangshitao.github.io/categories/SSM%E6%A1%86%E6%9E%B6/"},{"name":"CS基础","slug":"CS基础","permalink":"http://kangshitao.github.io/categories/CS%E5%9F%BA%E7%A1%80/"},{"name":"JVM","slug":"JVM","permalink":"http://kangshitao.github.io/categories/JVM/"},{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/categories/Java/"},{"name":"爬虫","slug":"爬虫","permalink":"http://kangshitao.github.io/categories/%E7%88%AC%E8%99%AB/"},{"name":"算法笔记","slug":"算法笔记","permalink":"http://kangshitao.github.io/categories/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://kangshitao.github.io/categories/PyTorch/"},{"name":"深度学习","slug":"深度学习","permalink":"http://kangshitao.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"论文笔记","slug":"论文笔记","permalink":"http://kangshitao.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"教程","slug":"教程","permalink":"http://kangshitao.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"博客","slug":"博客","permalink":"http://kangshitao.github.io/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://kangshitao.github.io/tags/MySQL/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://kangshitao.github.io/tags/Ubuntu/"},{"name":"消息队列","slug":"消息队列","permalink":"http://kangshitao.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://kangshitao.github.io/tags/RabbitMQ/"},{"name":"Nginx","slug":"Nginx","permalink":"http://kangshitao.github.io/tags/Nginx/"},{"name":"数据库","slug":"数据库","permalink":"http://kangshitao.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"SQL","slug":"SQL","permalink":"http://kangshitao.github.io/tags/SQL/"},{"name":"Redis","slug":"Redis","permalink":"http://kangshitao.github.io/tags/Redis/"},{"name":"Java","slug":"Java","permalink":"http://kangshitao.github.io/tags/Java/"},{"name":"JUC","slug":"JUC","permalink":"http://kangshitao.github.io/tags/JUC/"},{"name":"SpringBoot2","slug":"SpringBoot2","permalink":"http://kangshitao.github.io/tags/SpringBoot2/"},{"name":"Spring","slug":"Spring","permalink":"http://kangshitao.github.io/tags/Spring/"},{"name":"MyBatis","slug":"MyBatis","permalink":"http://kangshitao.github.io/tags/MyBatis/"},{"name":"Junit5","slug":"Junit5","permalink":"http://kangshitao.github.io/tags/Junit5/"},{"name":"SSM","slug":"SSM","permalink":"http://kangshitao.github.io/tags/SSM/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://kangshitao.github.io/tags/SpringMVC/"},{"name":"SprinMVC","slug":"SprinMVC","permalink":"http://kangshitao.github.io/tags/SprinMVC/"},{"name":"操作系统","slug":"操作系统","permalink":"http://kangshitao.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://kangshitao.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"JVM","slug":"JVM","permalink":"http://kangshitao.github.io/tags/JVM/"},{"name":"java","slug":"java","permalink":"http://kangshitao.github.io/tags/java/"},{"name":"Python","slug":"Python","permalink":"http://kangshitao.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://kangshitao.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"数据结构","slug":"数据结构","permalink":"http://kangshitao.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"链表","slug":"链表","permalink":"http://kangshitao.github.io/tags/%E9%93%BE%E8%A1%A8/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://kangshitao.github.io/tags/PyTorch/"},{"name":"Attention","slug":"Attention","permalink":"http://kangshitao.github.io/tags/Attention/"},{"name":"深度学习","slug":"深度学习","permalink":"http://kangshitao.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"transformer","slug":"transformer","permalink":"http://kangshitao.github.io/tags/transformer/"},{"name":"SBRS","slug":"SBRS","permalink":"http://kangshitao.github.io/tags/SBRS/"},{"name":"paper","slug":"paper","permalink":"http://kangshitao.github.io/tags/paper/"},{"name":"GNN","slug":"GNN","permalink":"http://kangshitao.github.io/tags/GNN/"},{"name":"正则表达式","slug":"正则表达式","permalink":"http://kangshitao.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"Git","slug":"Git","permalink":"http://kangshitao.github.io/tags/Git/"},{"name":"Conda","slug":"Conda","permalink":"http://kangshitao.github.io/tags/Conda/"},{"name":"hexo","slug":"hexo","permalink":"http://kangshitao.github.io/tags/hexo/"},{"name":"blog","slug":"blog","permalink":"http://kangshitao.github.io/tags/blog/"},{"name":"Markdown","slug":"Markdown","permalink":"http://kangshitao.github.io/tags/Markdown/"}]}